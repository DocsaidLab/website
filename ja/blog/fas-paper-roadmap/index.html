<!doctype html><html lang=ja dir=ltr class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.7.0"><title data-rh=true>Face Anti-Spoofing 技術地図 | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:url content=https://docsaid.org/ja/blog/fas-paper-roadmap><meta data-rh=true property=og:locale content=ja><meta data-rh=true property=og:locale:alternate content=zh_hant><meta data-rh=true property=og:locale:alternate content=en><meta data-rh=true name=docusaurus_locale content=ja><meta data-rh=true name=docusaurus_tag content=default><meta data-rh=true name=docsearch:language content=ja><meta data-rh=true name=docsearch:docusaurus_tag content=default><meta data-rh=true property=og:title content="Face Anti-Spoofing 技術地図 | DOCSAID"><meta data-rh=true name=description content="FAS の40本の論文ガイド。"><meta data-rh=true property=og:description content="FAS の40本の論文ガイド。"><meta data-rh=true property=og:image content=https://docsaid.org/ja/img/2025/0401.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/ja/img/2025/0401.jpg><meta data-rh=true property=og:type content=article><meta data-rh=true property=article:published_time content=2025-04-01T00:00:00.000Z><meta data-rh=true property=article:author content=https://github.com/zephyr-sh><meta data-rh=true property=article:tag content=face-anti-spoofing,liveness-detection><link data-rh=true rel=icon href=/ja/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/ja/blog/fas-paper-roadmap><link data-rh=true rel=alternate href=https://docsaid.org/blog/fas-paper-roadmap hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/blog/fas-paper-roadmap hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/blog/fas-paper-roadmap hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/blog/fas-paper-roadmap hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@id":"https://docsaid.org/ja/blog/fas-paper-roadmap","@type":"BlogPosting","author":{"@type":"Person","description":"Dosaid maintainer, Full-Stack AI Engineer","image":"https://github.com/zephyr-sh.png","name":"Z. Yuan","url":"https://github.com/zephyr-sh"},"datePublished":"2025-04-01T00:00:00.000Z","description":"FAS の40本の論文ガイド。","headline":"Face Anti-Spoofing 技術地図","image":{"@id":"https://docsaid.org/ja/img/2025/0401.jpg","@type":"ImageObject","caption":"title image for the blog post: Face Anti-Spoofing 技術地図","contentUrl":"https://docsaid.org/ja/img/2025/0401.jpg","url":"https://docsaid.org/ja/img/2025/0401.jpg"},"isPartOf":{"@id":"https://docsaid.org/ja/blog","@type":"Blog","name":"Blog"},"keywords":[],"mainEntityOfPage":"https://docsaid.org/ja/blog/fas-paper-roadmap","name":"Face Anti-Spoofing 技術地図","url":"https://docsaid.org/ja/blog/fas-paper-roadmap"}</script><link rel=alternate type=application/rss+xml href=/ja/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/ja/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/ja/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/ja/assets/css/styles.7e1f34fd.css><script src=/ja/assets/js/runtime~main.03dd7bc5.js defer></script><script src=/ja/assets/js/main.4c4ceb8f.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label=メインコンテンツまでスキップ><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>メインコンテンツまでスキップ</a></div><nav aria-label=ナビゲーション class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label=ナビゲーションバーを開く aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/ja/><div class=navbar__logo><img src=/ja/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/ja/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/ja/docs/>オープンソースプロジェクト</a><a class="navbar__item navbar__link" href=/ja/papers/intro>論文ノート</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/ja/blog>ブログ</a><a class="navbar__item navbar__link" href=/ja/playground/intro>遊び場</a><a class="navbar__item navbar__link" href=/ja/services>技術サービス</a><a class="navbar__item navbar__link" href=/ja/aboutus>私たちについて</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>日本語</a><ul class=dropdown__menu><li><a href=/blog/fas-paper-roadmap target=_self rel="noopener noreferrer" class=dropdown__link lang=zh-hant>繁體中文</a><li><a href=/en/blog/fas-paper-roadmap target=_self rel="noopener noreferrer" class=dropdown__link lang=en>English</a><li><a href=/ja/blog/fas-paper-roadmap target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="検索 (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>検索</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-1m2bkf9 ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=blog-hero-fullwidth><div class=postHero_mmE7 style=background-image:url(/ja/img/2025/0401.jpg)><div class=postHeroOverlay_UDxJ><h1 class=postTitle_weFP>Face Anti-Spoofing 技術地図</h1><div class=postMeta_oUa9><div class=postAuthors_wLk4><div class=postAuthor_NvIn><img class=postAuthorImg_omQD src=https://github.com/zephyr-sh.png alt="Z. Yuan"><div class=postAuthorText_C6S8><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=postAuthorLink_uKn3><span class=postAuthorName_SaVw>Z. Yuan</span></a><span class=postAuthorTitle_UTso>Dosaid maintainer, Full-Stack AI Engineer</span></div></div></div><div class=postMetaInfo__nS4><div class=postMetaRow_zK0w><span class=postDate_B0aP>2025年4月1日</span><span class=postReadingTime_roVj>29<!-- --> min read</span></div><div class=postTags_nipL><a class=postTag_inik href=/ja/blog/tags/face-anti-spoofing>face-anti-spoofing</a><a class=postTag_inik href=/ja/blog/tags/liveness-detection>liveness-detection</a></div></div></div></div></div></div><div class="container margin-vert--lg"><div class=row><main class="col col--9"><article class=markdown style="max-width:800px;margin:2rem auto"><article class=""><div><div id=__blog-post-container class=markdown><p>Face Anti-Spoofing とは何か？ なぜ重要なのか？ どう始めれば良いのか？</p>
<p>この記事は、私が膨大な文献を読んだ後、FAS システムを学び、研究し、開発しているあなたのために整理した完全なガイドマップです。</p>
<p>最も代表的な 40 本の論文を、時系列と技術の発展に基づいて 8 つのテーマに分け、各論文がなぜ読むべきか、重要な貢献と適切なポジショニングについて説明します。伝統的な LBP、rPPG、CNN から、Transformer、CLIP、Vision-Language Model に至るまで、すべて一度に把握できます。</p>
<p>今後、「論文ノート」で各論文の詳細を共有する予定ですが、まずは全体的な流れを把握しましょう。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第一章起源の低解像度光>第一章：起源の低解像度光<a href=#第一章起源の低解像度光 class=hash-link aria-label="第一章：起源の低解像度光 への直接リンク" title="第一章：起源の低解像度光 への直接リンク">​</a></h2>
<blockquote>
<p><strong>伝統的な特徴量エンジニアリングから深層学習の最初の光へ</strong></p>
</blockquote>
<p>Face Anti-Spoofing の初期の研究は主に伝統的な画像処理技術に基づいており、研究者はテクスチャ、コントラスト、周波数などの手作業で特徴量を用いて顔の真偽を判断し、古典的な分類器を使って二項分類を行っていました。</p>
<ol>
<li>
<p><a href=https://parnec.nuaa.edu.cn/_upload/article/files/4d/43/8a227f2c46bda4c20da97715f010/db1eef47-b25f-4af9-88d4-a8afeccda889.pdf target=_blank rel="noopener noreferrer"><strong>[10.09] Face Liveness Detection from a Single Image with Sparse Low Rank Bilinear Discriminative Model</strong></a>
ランバーティアンモデルと疎低ランク表示を用いて特徴空間を構築し、真顔と写真を効果的に分離。初期の単一画像での活体検出に理論的および実装の基盤を提供しました。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/slrbd/ target=_blank rel="noopener noreferrer"><strong>[10.09] SLRBD: 静かな反射光</strong></a></div></div>
</li>
<li>
<p><a href=https://ieeexplore.ieee.org/document/6313548 target=_blank rel="noopener noreferrer"><strong>[12.09] On the Effectiveness of Local Binary Patterns in Face Anti-Spoofing</strong></a>
LBP とその変種を用いて、平面写真とスクリーン再生攻撃を識別し、REPLAY-ATTACK データセットを構築。最も初期の公開データセットおよび古典的なベースラインの組み合わせの一つです。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/lbp/ target=_blank rel="noopener noreferrer"><strong>[12.09] LBP: 軽快な微細構造</strong></a></div></div>
</li>
<li>
<p><a href=https://ieeexplore.ieee.org/document/6810829 target=_blank rel="noopener noreferrer"><strong>[14.05] Spoofing Face Recognition with 3D Masks</strong></a>
3D マスクが異なる顔認識システム（2D/2.5D/3D）に対する攻撃効果を系統的に分析し、伝統的な平面顔に対する仮定が 3D 印刷技術では成り立たないことを指摘。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/three-d-mad/ target=_blank rel="noopener noreferrer"><strong>[14.05] 3DMAD: 現実の仮面</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/1909.08848 target=_blank rel="noopener noreferrer"><strong>[19.09] Biometric Face Presentation Attack Detection with Multi-Channel Convolutional Neural Network</strong></a>
RGB、深度、赤外線、熱感知信号を組み合わせた多チャネル CNN アーキテクチャを提案し、WMCA データセットを発表。高次の偽顔（シリコンマスクなど）の検出能力を向上。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/wmca/ target=_blank rel="noopener noreferrer"><strong>[19.09] WMCA: 見えない顔</strong></a></div></div>
</li>
<li>
<p><a href=https://ieeexplore.ieee.org/abstract/document/9925105 target=_blank rel="noopener noreferrer"><strong>[22.10] Deep Learning for Face Anti-Spoofing: A Survey</strong></a>
FAS 分野で初めての深層学習に基づいた系統的なレビュー論文。ピクセル単位の監視、多モーダルセンサー、ドメイン一般化など新しいトレンドを取り上げ、知識の全体像を構築。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/fas-survey/ target=_blank rel="noopener noreferrer"><strong>[22.10] FAS Survey: 攻撃と防御の年代記</strong></a></div></div>
</li>
</ol>
<hr>
<p>これらの手法は単純であるものの、平面顔（写真やスクリーン再生）の認識基盤を築くものであり、後の深層学習技術導入に向けた概念的枠組みを作り上げました。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第二章現実世界の舞台>第二章：現実世界の舞台<a href=#第二章現実世界の舞台 class=hash-link aria-label="第二章：現実世界の舞台 への直接リンク" title="第二章：現実世界の舞台 への直接リンク">​</a></h2>
<blockquote>
<p><strong>FAS 技術が実験室から現実のシーンに進出するマイルストーン</strong></p>
</blockquote>
<p>データセットとベンチマークは、ある分野が安定的に成長できるかどうかを決定します。</p>
<p>FAS 技術は、単一のシーンから複数のデバイス、複数の光源、複数の攻撃手法に対応するようになり、これらの代表的な公開データセットによって推進されてきました。</p>
<ol start=6>
<li>
<p><a href=https://ieeexplore.ieee.org/document/7961798 target=_blank rel="noopener noreferrer"><strong>[17.06] OULU-NPU: A Mobile Face Presentation Attack Database with Real-World Variations</strong></a>
モバイルシーン向けに設計された FAS データセットで、デバイス、環境光、攻撃手法などのさまざまな変数を含み、4 つのテストプロトコルを設計。これにより「一般化能力」の評価が可能になったマイルストーン。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/oulu-npu/ target=_blank rel="noopener noreferrer"><strong>[17.06] OULU-NPU: 四つの試練</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2003.05136 target=_blank rel="noopener noreferrer"><strong>[20.03] CASIA-SURF CeFA: A Benchmark for Multi-modal Cross-ethnicity Face Anti-Spoofing</strong></a>
世界初の「民族タグ付け」のある大型多モーダル FAS データセットで、RGB、深度、IR および複数の攻撃タイプを含み、特に民族偏向とモーダル融合戦略の研究に役立つ。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/cefa/ target=_blank rel="noopener noreferrer"><strong>[20.03] CeFA: モデルの偏見</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2007.12342 target=_blank rel="noopener noreferrer"><strong>[20.07] CelebASpoof: Large-scale Face Anti-Spoofing Dataset with Rich Annotations</strong></a>
現在最大規模の FAS データセットで、62 万枚以上の画像を含み、10 種類の spoof タグと元の CelebA の 40 の属性が含まれており、多タスクおよび spoof トレース学習に適しています。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/celeba-spoof/ target=_blank rel="noopener noreferrer"><strong>[20.07] CelebA-Spoof: 大規模な偽造防止の試練</strong></a></div></div>
</li>
<li>
<p><a href=https://openaccess.thecvf.com/content/WACV2022W/MAP-A/html/Belli_A_Personalized_Benchmark_for_Face_Anti-Spoofing_WACVW_2022_paper.html target=_blank rel="noopener noreferrer"><strong>[22.01] A Personalized Benchmark for Face Anti-Spoofing</strong></a>
ユーザー登録時の活体画像を識別プロセスに組み込む提案。CelebA-Spoof-Enroll および SiW-Enroll という 2 つの新しいテスト設定を提案し、個人化 FAS システムの可能性を探る。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/personalized-fas/ target=_blank rel="noopener noreferrer"><strong>[22.01] Personalized-FAS: 個人化の試み</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2402.04178 target=_blank rel="noopener noreferrer"><strong>[24.02] SHIELD: An Evaluation Benchmark for Face Spoofing and Forgery Detection with Multimodal Large Language Models</strong></a>
LLM と多モーダル入力を組み合わせ、QA タスク形式で MLLM の spoof/forgery 検出における推論能力を評価。攻撃を「言語モデリングで理解する」という新しい領域を開拓。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/shield/ target=_blank rel="noopener noreferrer"><strong>[24.02] SHIELD: 教えてください、なぜ？</strong></a></div></div>
</li>
</ol>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第三章跨領域の修羅場>第三章：跨領域の修羅場<a href=#第三章跨領域の修羅場 class=hash-link aria-label="第三章：跨領域の修羅場 への直接リンク" title="第三章：跨領域の修羅場 への直�接リンク">​</a></h2>
<blockquote>
<p><strong>単一データ学習から多シーン展開の核心技術</strong></p>
</blockquote>
<p>Face Anti-Spoofing（FAS）の最も難しい問題の一つは、一般化能力です: モデルが訓練データだけでなく、新しいデバイス、新しい環境、新しい攻撃にも対応できるようにする方法。</p>
<ol start=11>
<li>
<p><a href=https://arxiv.org/abs/2004.14043 target=_blank rel="noopener noreferrer"><strong>[20.04] Single-Side Domain Generalization for Face Anti-Spoofing</strong></a>
単一の対抗学習戦略を提案し、真顔のみでドメイン間調整を行い、偽顔の特徴を異なるドメインで自然に分散させることで、誤った情報の過度な圧縮を避ける。これは DG 設計における非常に示唆に富んだ方向性です。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/ssdg/ target=_blank rel="noopener noreferrer"><strong>[20.04] SSDG: 安定した真実</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2105.02453 target=_blank rel="noopener noreferrer"><strong>[21.05] Generalizable Representation Learning for Mixture Domain Face Anti-Spoofing</strong></a>
ドメインラベルを既知とせず、インスタンス正規化と MMD を使用して、無監督のクラスタリングと調整を実現。人工的なクラスタリングに依存しない一般化訓練フローを実現。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/d2am/ target=_blank rel="noopener noreferrer"><strong>[21.05] D²AM: 千界鍛魂術</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2303.13662 target=_blank rel="noopener noreferrer"><strong>[23.03] Rethinking Domain Generalization for Face Anti-Spoofing: Separability and Alignment</strong></a>
SA-FAS フレームワークを提案し、異なるドメインで特徴の分離性を保ちながら、live→spoof の変化軌跡が各ドメインで一貫するように強調。これは IRM 理論を FAS に深く適用したものです。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/sa-fas/ target=_blank rel="noopener noreferrer"><strong>[23.03] SA-FAS: 超平面の法則</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2402.19298 target=_blank rel="noopener noreferrer"><strong>[24.02] Suppress and Rebalance: Towards Generalized Multi-Modal Face Anti-Spoofing</strong></a>
多モーダル DG 問題を深く分析し、U-Adapter を使用して不安定なモーダルの干渉を抑制し、ReGrad で各モーダルの収束速度を動的に調整することで、モーダル不均衡と信頼性の問題に対する完全な解決策を提供。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/mmdg/ target=_blank rel="noopener noreferrer"><strong>[24.02] MMDG: 信頼管理学</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2403.14333 target=_blank rel="noopener noreferrer"><strong>[24.03] CFPL-FAS: Class Free Prompt Learning for Generalizable Face Anti-spoofing</strong></a>
　 プロンプトラーニングの手法に焦点を当てており、「手動でクラスを定義する必要がない」プロンプト設計を強調している。これは、言語プロンプトを活用して FAS モデルの汎化能力を高める新たなアプローチである。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/cfpl-fas/ target=_blank rel="noopener noreferrer"><strong>[24.03] CFPL-FAS: クラスなしのプロンプト学習</strong></a></div></div>
</li>
</ol>
<hr>
<p>これらの 5 本の論文は、現在の Domain Generalization（DG）テーマの技術的軸を構成しています。単一の対抗、ラベルなしクラスタリング、分離性分析から、言語を統合した監視方法に至るまで、クロスドメインの課題に対する完全な戦略を描き出しています。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第四章新世界の勃興>第四章：新世界の勃興<a href=#第四章新世界の勃興 class=hash-link aria-label="第四章：新世界の勃興 への直接リンク" title="第四章：新世界の勃興 への直接リンク">​</a></h2>
<blockquote>
<p><strong>CNN から ViT へ、FAS モデルのアーキテクチャ革新の道</strong></p>
</blockquote>
<p>Vision Transformer（ViT）の登場により、画像タスクは局所的な畳み込みから全体的なモデリング時代へと進化しました。Face Anti-Spoofing も例外ではありません。</p>
<ol start=16>
<li>
<p><a href=https://openaccess.thecvf.com/content/WACV2023/papers/Liao_Domain_Invariant_Vision_Transformer_Learning_for_Face_Anti-Spoofing_WACV_2023_paper.pdf target=_blank rel="noopener noreferrer"><strong>[23.01] Domain Invariant Vision Transformer Learning for Face Anti-Spoofing</strong></a>
DiVT アーキテクチャを提案し、2 つの主要な損失関数を通じてクロスドメイン汎化性能を強化。真の顔特徴を集約することで、より一貫性のあるドメイン不変表現を形成する。実験では、DiVT が複数の DG-FAS タスクにおいて SOTA の成果を達成しており、手法は簡潔でありながら、クロスドメイン認識における重要な情報を効果的に捉えることができることが示された。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/divt/ target=_blank rel="noopener noreferrer"><strong>[23.01] DiVT: オールスター選手権</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2302.05744 target=_blank rel="noopener noreferrer"><strong>[23.02] Rethinking Vision Transformer and Masked Autoencoder in Multimodal Face Anti-Spoofing</strong></a>
ViT が多モーダル FAS における主要な問題を全面的に再考。入力設計、事前学習戦略、パラメータ微調整フローを含む、AMA アダプターと M2A2E 事前学習アーキテクチャを提案し、クロスモーダルかつラベルなしの自己監督プロセスを構築。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/m2a2e/ target=_blank rel="noopener noreferrer"><strong>[23.02] M²A²E: 舉一反三</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2304.07549 target=_blank rel="noopener noreferrer"><strong>[23.04] MA-ViT: Modality-Agnostic Vision Transformers for Face Anti-Spoofing</strong></a>
単一分岐の早期融合アーキテクチャを採用し、Modal-Disentangle Attention と Cross-Modal Attention を通じて、モーダルに依存しない識別能力を実現。記憶効率と柔軟な展開を両立させた、ViT の実用性における重要な一歩。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/ma-vit/ target=_blank rel="noopener noreferrer"><strong>[23.04] MA-ViT: 凡所有相，皆是虚妄</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2309.04038 target=_blank rel="noopener noreferrer"><strong>[23.09] S-Adapter: Generalizing Vision Transformer for Face Anti-Spoofing with Statistical Tokens</strong></a>
Efficient Parameter Transfer Learning アーキテクチャを利用して、ViT に統計的アダプターを挿入し、主ネットワークのパラメータを固定。Token Style Regularization でスタイル差を抑制し、クロスドメイン FAS に特化した軽量ソリューション。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/s-adapter/ target=_blank rel="noopener noreferrer"><strong>[23.09] S-Adapter: 実際のノート</strong></a></div></div>
</li>
<li>
<p><a href=https://dl.acm.org/doi/pdf/10.1145/3664647.3680856 target=_blank rel="noopener noreferrer"><strong>[24.10] FM-CLIP: Flexible Modal CLIP for Face Anti-Spoofing</strong></a>
クロスモーダル詐欺強化器（CMS-Enhancer）とテキスト誘導（LGPA）による偽顔の動的アライメントにより、マルチモーダル訓練および単一または複数のモーダルテストで高い検出精度を維持し、複数のデータセットにおいて優れた汎化能力を示します。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/fm-clip/ target=_blank rel="noopener noreferrer"><strong>[24.10] FM-CLIP: 言語からの指針</strong></a></div></div>
</li>
</ol>
<hr>
<p>この段階の 5 本の論文は、Transformer アーキテクチャが多モーダル入力、モーダル欠損、クロスドメインスタイル、局所パッチ表現などの重要な課題をどのように処理しているかを示しています。これは FAS モデル設計ロジックの全面的な転換を表しています。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第五章スタイルの戦い>第五章：スタイルの戦い<a href=#第五章スタイルの戦い class=hash-link aria-label="第五章：スタイルの戦い への直接リンク" title="第五章：スタイルの戦い への直接リンク">​</a></h2>
<blockquote>
<p><strong>異なる世界からのスプーフィング、どのようにしてスタイルに敏感でないモデルを作るか？</strong></p>
</blockquote>
<p>FAS モデルの一般化は、ドメインシフトの挑戦だけでなく、異なるスタイル間の情報の非対称性による干渉も受けています。</p>
<p>この章では、スタイルの解消、対抗学習、テスト時適応、インスタンス認識設計に焦点を当てています。これらの手法は、未知のスタイルやサンプル分布のもとでも安定した認識性能を保つことを目指しています。</p>
<ol start=21>
<li>
<p><a href=https://arxiv.org/abs/2203.05340 target=_blank rel="noopener noreferrer"><strong>[22.03] Domain Generalization via Shuffled Style Assembly for Face Anti-Spoofing</strong></a>
コンテンツとスタイルの分離戦略を採用し、スタイル空間を再構成してスタイルシフトをシミュレートします。コントラスト学習を組み合わせ、生体性に関連するスタイルを強調することで、スタイル認識に基づいたドメイン一般化（DG）設計における重要なブレークスルーを実現します。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/ssan/ target=_blank rel="noopener noreferrer"><strong>[22.03] SSAN: スタイルの残像</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2212.03651 target=_blank rel="noopener noreferrer"><strong>[22.12] Cyclically Disentangled Feature Translation for Face Anti-spoofing</strong></a>
CDFTN を提案し、対抗学習によって生体性とスタイル成分を分離し、実際のラベルとターゲットドメインの外観を組み合わせた擬似ラベル付きサンプルを生成します。これにより、クロスドメインでの偽装認識の精度と堅牢性が大幅に向上します。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/cdftn/ target=_blank rel="noopener noreferrer"><strong>[22.12] CDFTN: スタイルの絡み合い</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2304.05640 target=_blank rel="noopener noreferrer"><strong>[23.04] Instance-Aware Domain Generalization for Face Anti-Spoofing</strong></a>
粗いドメインラベルを放棄し、インスタンスレベルのスタイルアライメント戦略を採用します。非対称ホワイトニング、スタイル強化、動的カーネル設計を通じて、スタイルに敏感でない認識特徴を洗練させます。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/iadg/ target=_blank rel="noopener noreferrer"><strong>[23.04] IADG: スタイルの独白</strong></a></div></div>
</li>
<li>
<p><a href=https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Towards_Unsupervised_Domain_Generalization_for_Face_Anti-Spoofing_ICCV_2023_paper.html target=_blank rel="noopener noreferrer"><strong>[23.10] Towards Unsupervised Domain Generalization for Face Anti-Spoofing</strong></a>
ラベルのないデータを学習プロセスに取り入れ、分割再構成とクロスドメイン類似度検索機構を使用して、複数のラベルなしシナリオに適応する一般化された表現を抽出します。これにより、真の無監督型ドメイン一般化（DG）FAS が達成されます。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/udg-fas/ target=_blank rel="noopener noreferrer"><strong>[23.10] UDG-FAS: スタイルの断片</strong></a></div></div>
</li>
<li>
<p><a href=https://papers.bmvc2023.org/0379.pdf target=_blank rel="noopener noreferrer"><strong>[23.11] Test-Time Adaptation for Robust Face Anti-Spoofing</strong></a>
推論段階で新しいシーンに対してモデルを動的に調整し、アクティベーションベースの擬似ラベリングとコントラスト学習を組み合わせて忘却を防止し、事前に学習した FAS モデルがテスト時に自己最適化できるようにし、未知の攻撃に対する感度を向上させます。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/three-a-tta/ target=_blank rel="noopener noreferrer"><strong>[23.11] 3A-TTA: 荒野でのサバイバル</strong></a></div></div>
</li>
</ol>
<hr>
<p>これらの 5 篇は、異なる観点から「スタイル一般化」というテーマに挑戦しています。特に、インスタンスベースとテスト時適応の試みでは、実際の応用シナリオの要求に徐々に近づいています。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第六章多モーダルの召喚術>第六章：多モーダルの召喚術<a href=#第六章多モーダルの召喚術 class=hash-link aria-label="第六章：多モーダルの召喚術 への直接リンク" title="第六章：多モーダルの召喚術 への直接リンク">​</a></h2>
<blockquote>
<p><strong>画像だけではなく、音声や生理信号も登場</strong></p>
</blockquote>
<p>従来の RGB モデルが高精度攻撃やクロスドメインの課題に直面した時、FAS コミュニティは視覚以外の信号、例えば<strong>rPPG、生理信号、音波エコー</strong>などの補助情報を探索し、「人間の信号」から出発して、より難易度の高い偽造に対抗するための識別基準を構築しました。</p>
<p>本章では、生理信号、3D 幾何学、音響知覚に跨る代表的な 5 篇の論文を紹介し、多モーダル FAS 技術の潜力と将来性を示します。</p>
<ol start=26>
<li>
<p><a href=https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICPR-2016/media/files/1223.pdf target=_blank rel="noopener noreferrer"><strong>[16.12] Generalized face anti-spoofing by detecting pulse from face videos</strong></a>
初期の FAS シナリオにおいて、深度センサーや赤外線センサーがなくても、顔の心拍信号だけで偽顔を識別できる方法が示され、rPPG の潜在能力を強調しています。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/rppg target=_blank rel="noopener noreferrer"><strong>[16.12] rPPG: 生命の光斑</strong></a></div></div>
</li>
<li>
<p><a href=https://dl.acm.org/doi/10.1007/978-3-030-01270-0_34 target=_blank rel="noopener noreferrer"><strong>[18.09] Remote Photoplethysmography Correspondence Feature for 3D Mask Face Presentation Attack Detection</strong></a>
初めて CFrPPG（対応型 rPPG）特徴を提案し、低光量やカメラの揺れなどの条件下でも心拍軌跡を正確に抽出。3D マスク攻撃に対して優れたパフォーマンスを発揮。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/cfrppg target=_blank rel="noopener noreferrer"><strong>[18.09] CFrPPG: 心拍の残響</strong></a></div></div>
</li>
<li>
<p><a href=https://ieeexplore.ieee.org/document/8761776 target=_blank rel="noopener noreferrer"><strong>[19.05] Multi-Modal Face Authentication Using Deep Visual and Acoustic Features</strong></a>
スマートフォン内蔵のスピーカーとマイクを使用して超音波を発射し、顔面エコーを解析。CNN で抽出した画像特徴と組み合わせ、追加のハードウェアなしで二重モーダルセキュリティ認証システムを構築。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/vafas target=_blank rel="noopener noreferrer"><strong>[19.05] VA-FAS: 音波の中の顔</strong></a></div></div>
</li>
<li>
<p><a href=https://ieeexplore.ieee.org/document/9868051 target=_blank rel="noopener noreferrer"><strong>[22.08] Beyond the Pixel World: A Novel Acoustic-Based Face Anti-Spoofing System for Smartphones</strong></a>
Echo-Spoof という音響 FAS データセットを構築し、Echo-FAS アーキテクチャを設計。音波を使用して 3D 幾何学と材料情報を再構築し、カメラに依存せず、モバイルデバイスにおける低コスト・高耐性のアプリケーション事例。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/echo-fas target=_blank rel="noopener noreferrer"><strong>[22.08] Echo-FAS: 偽造のエコー</strong></a></div></div>
</li>
<li>
<p><a href=https://dl.acm.org/doi/10.1145/3643510 target=_blank rel="noopener noreferrer"><strong>[24.03] AFace: Range-Flexible Anti-Spoofing Face Authentication via Smartphone Acoustic Sensing</strong></a>
Echo-FAS のアイデアを拡張し、iso-depth モデルと距離適応アルゴリズムを追加。3D プリントマスクに対抗し、ユーザーの距離に応じて自動調整。音波による活体認証の実用化への重要な設計。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p><strong>論文ノート</strong>：<a href=https://docsaid.org/ja/papers/face-antispoofing/aface target=_blank rel="noopener noreferrer"><strong>[24.03] AFace: 波動の邊界</strong></a></div></div>
</li>
</ol>
<hr>
<p>これらの 5 本の論文は、非視覚モーダルが FAS 分野における重要な始まりを築いたものであり、従来のカメラの制限を避けるために深く掘り下げるべき方向性です。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第七章偽りの軌跡を解体する>第七章：偽りの軌跡を解体する<a href=#第七章偽りの軌跡を解体する class=hash-link aria-label="第七章：偽りの軌跡を��解体する への直接リンク" title="第七章：偽りの軌跡を解体する への直接リンク">​</a></h2>
<blockquote>
<p><strong>偽装の構造と意味を深くモデル化し、モデルの識別力を高める</strong></p>
</blockquote>
<p>FAS（顔認証のなりすまし防止）モデルが、解釈可能性と汎化能力という二つの課題に直面する中で、研究者たちは「spoof trace（偽装痕跡）」という概念に注目し始めた。これは、偽顔が映像に残す微細なパターン、例えば色のずれや輪郭の異常、周波数の異変などを指す。</p>
<p>本章の 5 本の論文は、表現の分離（disentanglement）の観点からアプローチし、偽装特徴を顔の本来の情報から切り離すことで、偽装サンプルの再構築・解析・さらには合成までを可能にし、モデルが「偽装を見抜く」ことを学習することを目指している。</p>
<ol start=31>
<li>
<p><a href=https://arxiv.org/abs/2007.09273 target=_blank rel="noopener noreferrer"><strong>[20.07] On Disentangling Spoof Trace for Generic Face Anti-Spoofing</strong></a>
多尺度で偽装痕跡を分離するモデルを提案。偽装信号を多層のパターンの組み合わせと捉え、敵対的学習を通じて本物の顔と偽装マスクを再構築。新たな攻撃サンプルの合成にも応用できる、偽装認識表現学習の代表的研究。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2008.08250 target=_blank rel="noopener noreferrer"><strong>[20.08] Face Anti-Spoofing via Disentangled Representation Learning</strong></a>
顔の特徴を「生体（liveness）」と「個人識別（identity）」の 2 つのサブ空間に分解。CNN アーキテクチャで低次・高次信号を分離し、より転移可能な生体分類器を構築。異なる攻撃タイプに対する安定性を向上。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2110.09157 target=_blank rel="noopener noreferrer"><strong>[21.10] Disentangled representation with dual-stage feature learning for face anti-spoofing</strong></a>
二段階の分離学習機構を用い、顔画像を生体に関連する部分と無関係な部分の 2 つのサブ空間に分離。未知の攻撃タイプに対する認識能力を効果的に向上させ、汎化性能強化の重要な設計。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2112.00568 target=_blank rel="noopener noreferrer"><strong>[21.12] Dual spoof disentanglement generation for face anti-spoofing with depth uncertainty learning</strong></a>
DSDG 生成フレームワークを提案。VAE を用いて個人識別と攻撃テクスチャの因子化潜在表現を学習し、多様な偽装画像を大規模に合成可能。深度不確実性モジュールを導入し深度監督の安定化を図る、「生成対抗偽装」の代表例。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2212.03943 target=_blank rel="noopener noreferrer"><strong>[22.12] Learning Polysemantic Spoof Trace: A Multi-Modal Disentanglement Network for Face Anti-Spoofing</strong></a>
偽装痕跡の分離構造をマルチモーダルに拡張。RGB/Depth の二系統ネットワークで相補的な偽装手がかりを捉え、クロスモーダル融合で両者の意味情報を結合。汎用的な FAS モデルの先進的な提案。</p>
</li>
</ol>
<hr>
<p>本章は重要な転換点を示している。すなわち「生体検出」から「偽装解析」へ、そして「攻撃のシミュレーション」へと、FAS 研究は徐々に「生成可能・解釈可能・制御可能」という次の段階へと進化している。これらの手法はモデルの精度向上だけでなく、将来の攻防の進化の道筋を示唆する可能性を秘めている。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第八章未来の混沌>第八章：未来の混沌<a href=#第八章未来の混沌 class=hash-link aria-label="第八章：未来の混沌 への直接リンク" title="第八章：未来の混沌 への直接リンク">​</a></h2>
<blockquote>
<p><strong>CLIP から人間の知覚へ、FAS の次の境界</strong></p>
</blockquote>
<p>単一モーダル、単一攻撃タイプだけでは実際のニーズを満たすのが難しくなったとき、FAS はさらに高次の挑戦に直面しています：<strong>物理的+デジタルな二重攻撃、セマンティクス駆動の識別、さまざまな環境でのゼロショット一般化</strong>。</p>
<p>これらの 5 本の代表作は、FAS の未来に向けた 3 つの主要な発展軸：<strong>融合識別、言語モデル、そして人間の感知</strong>を示しています。</p>
<ol start=36>
<li>
<p><a href=https://arxiv.org/abs/2007.02157 target=_blank rel="noopener noreferrer"><strong>[20.07] Face Anti-Spoofing with Human Material Perception</strong></a>
材質知覚を FAS モデル設計に取り入れ、BCN アーキテクチャを用いて人間の知覚レベル（マクロ/ミクロ）で材質差を判定。皮膚、紙、シリコンなどの材質差を軸に、モデルのセマンティックな解釈性と材質間識別能力を向上。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2309.16649 target=_blank rel="noopener noreferrer"><strong>[23.09] FLIP: Cross-domain Face Anti-Spoofing with Language Guidance</strong></a>
CLIP モデルを FAS タスクに応用し、自然言語による記述で視覚的特徴空間を導く。クロスドメインでの一般化能力を向上させ、セマンティックアライメントと多モーダル対比学習戦略を提案。言語駆動でのゼロショット FAS を実現。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2404.08450 target=_blank rel="noopener noreferrer"><strong>[24.04] Joint Physical-Digital Facial Attack Detection via Simulating Spoofing Clues</strong></a>
SPSC と SDSC データ拡張戦略を提案し、物理的およびデジタル攻撃の手がかりをシミュレート。単一のモデルで両方の攻撃タイプを識別できるようにし、CVPR2024 コンペで優勝。融合型モデルの新たな基準を打ち立てました。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2404.06211 target=_blank rel="noopener noreferrer"><strong>[24.04] Unified Physical-Digital Attack Detection Challenge</strong></a>
初の統一攻撃識別挑戦コンペを立ち上げ、2.8 万件の複合型攻撃データセット UniAttackData を公開。各チームのモデルアーキテクチャを分析し、Unified Attack Detection への道を開くカタリストとなりました。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2408.12793 target=_blank rel="noopener noreferrer"><strong>[24.08] La-SoftMoE CLIP for Unified Physical-Digital Face Attack Detection</strong></a>
CLIP と Mixture of Experts アーキテクチャを組み合わせ、soft-adaptive メカニズムを導入してサブモデルを動的に割り当て、複雑な意思決定境界に対応。物理的およびデジタル攻撃の融合処理に効率的なパラメータ選択を提供。</p>
</li>
</ol>
<hr>
<p>この章は FAS 分野の未来のトレンドを象徴しています：<strong>偽顔の識別 → 攻撃タイプの推測 → セマンティクスの理解 → 多モーダル言語論理推論との統合</strong>。研究は「視覚理解」から「セマンティック認知」へと進化しており、攻撃も単一のモデルから複雑な混合型に進化しています。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=結語>結語<a href=#結語 class=hash-link aria-label="結語 への直接リンク" title="結語 への直接リンク">​</a></h2>
<p>現実世界で最も不足しているものは悪意であり、顔認識のニーズがある限り、防偽のニーズは止まることはありません。</p>
<p>最初のテクスチャ解析、光影モデリングから畳み込みネットワークの登場、さらに ViT、CLIP、音波、そして人間の知覚の導入に至るまで、FAS 技術はその境界を拡大し続けています。これらの論文は、単なる古典やトレンドの整理にとどまらず、数十年にわたる技術進化の地図であり、過去、現在、未来を繋げるものです。</p>
<p>この地図の中で私たちは以下のことを見ています：</p>
<ul>
<li><strong>単一モーダルから多モーダルへ</strong>：画面を見るだけでなく、深度、音、脈動、材質も感知する。</li>
<li><strong>分類から解耦へ</strong>：真偽を判定するだけでなく、各偽装の構成方法を理解しようとしている。</li>
<li><strong>識別から推論へ</strong>：活体を識別するだけでなく、セマンティクス、材料、そして言語記述の背後にある真実を理解しようとしている。</li>
<li><strong>防御から生成へ</strong>：単に受動的な防御にとどまらず、積極的に模擬、再構築、干渉するようになった。</li>
</ul>
<p>この分野に足を踏み入れようとしているあなたにとって、この技術ガイドは「万能の解決策」を提供するものではありませんが、出発点を見つける手助けになるでしょう。<section class=ctaSection_iCjC><div class="
        simpleCta_ji_Y
        simple-cta__coffee_YwC8
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>☕ 1杯のコーヒーが支えになります</h3><p class=simple-cta__subtitle_ol86>AIやフルスタックの情報発信を続けるため、ご支援お願いします。<div class=simple-cta__buttonWrapper_jk1Y><img src=/ja/img/bmc-logo.svg alt=cta-button class=simple-cta__buttonImg_Q9VV></div></div><div class="ant-row ant-row-stretch cardsSection_wRaP css-1m2bkf9" style=margin-left:-8px;margin-right:-8px;row-gap:16px><div style=padding-left:8px;padding-right:8px;display:flex class="ant-col ant-col-xs-24 css-1m2bkf9"><div class="ant-card ant-card-bordered card_gKx9 fadeInUp_n33J hoverTransform_Mozy css-1m2bkf9" style=flex:1;display:flex;flex-direction:column><div class=ant-card-body><div style=text-align:center;margin-top:1rem><img src=/ja/img/icons/all_in.svg alt="AI・開発・運用まで一括対応 icon" style=width:48px;height:48px></div><span class="ant-tag ant-tag-orange card__tag_PLj3 css-1m2bkf9">ALL</span><h4 class=card__title_SQBY>AI・開発・運用まで一括対応</h4><p class=card__concept_Ak8F>アイデアからリリースまで、技術面はまるごとお任せください。<div class=card__bulletHeader_b6cf><h5 class=card__bulletTitle_R_wg>対応内容</h5></div><ul class=card__bulletList_SrNN><li class=card__bulletItem_wCRd>技術相談 + 開発 + デプロイ<li class=card__bulletItem_wCRd>継続サポート & 拡張</ul></div></div></div></div><div class="
        simpleCta_ji_Y
        simple-cta__outro_AXbn
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>🚀 次のプロジェクト、始めましょう！</h3><p class=simple-cta__subtitle_ol86>カスタム開発や長期支援をご希望の方は、ぜひご相談ください。</div></section><div style=margin-top:3rem> </div></div></div><button aria-label=先頭へ戻る class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button></article></article><nav class="pagination-nav docusaurus-mt-lg" aria-label=ブログ記事のナビゲーション><a class="pagination-nav__link pagination-nav__link--prev" href=/ja/blog/colorful-cli-with-ansi-escape-codes><div class=pagination-nav__sublabel>新しい記事</div><div class=pagination-nav__label>ターミナルは黒と白だけではない</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/ja/blog/should-you-choose-docusaurus><div class=pagination-nav__sublabel>過去の記事</div><div class=pagination-nav__label>Docusaurusを選ぶべきか？</div></a></nav></main><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label=最近のブログ記事のナビゲーション><div class="sidebarItemTitle_pO2u margin-bottom--md">All our Posts</div><div role=group><h3 class=yearGroupHeading_rMGB>2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/read-papers-lightly>論文を読む、無理をしない</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/cgi-injection-log-analysis>CGI攻撃の技術的側面</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/closure-in-python>Closure とは？</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/react-hook-vs-python>Reactは結局、何をHookしているのか？</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/colorful-cli-with-ansi-escape-codes>ターミナルは黒と白だけではない</a><li class=sidebarItem__DBe><a aria-current=page class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href=/ja/blog/fas-paper-roadmap>Face Anti-Spoofing 技術地図</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/should-you-choose-docusaurus>Docusaurusを選ぶべきか？</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/looking-up-the-ten-steps-of-a-master>大師の十段階を仰ぎ見る</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/build-a-resume>JSを使って履歴書を書いてみよう！</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/pydantic-intro>Pydantic 入門：Python データ検証と管理</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/builds-dashboard-system>AIをやっている私が、なぜバックエンドシステムを作ったのか？</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/amazon-ses-setting-dns-on-namecheap>Amazon SES における Namecheap の DNS 設定</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/download-from-google-drive-using-python>PythonでGoogle Driveからファイルをダウンロードする</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/mount-disk-on-ubuntu>Ubuntu での外付けハードディスクのマウント</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/github-markdown-advanced-syntax>便利な GitHub Markdown の文法</a></ul></div><div role=group><h3 class=yearGroupHeading_rMGB>2024</h3><ul class="sidebarItemList_Yudw clean-list"><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/extract-font-info-by-python>フォントファイルの情報を取得</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/flexible-video-conversion-by-python>バッチ動画変換</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/system-status-checking-by-chatgpt>Ubuntu システムの基本状態チェック自動化</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/customized-docusaurus-author-to-plugin-content-docs>DocusaurusのDocsに著者情報を追加する</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/graph-convolutional-networks>グラフ畳み込みネットワークの概要</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/fourier-transform>フーリエ変換の概要</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/fixed-pyenv-install-error>pyenvビルドエラーを修復</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/update-docusaurus-to-3-6-0>Docusaurusを3.6.0にアップデート</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/file-crawler-python-implementation>ウェブページのファイルをダウンロードするPython実装</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/customized-docusaurus-sidebars-auto-count>Docusaurusのサイドバーに記事数を自動計算させる</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/customized-docusaurus-404-page>Docusaurus の 404 ページをカスタマイズする</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/torch-layernorm-mismatch>手計算したLayerNormの値が合わない？</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/get-taiwan-all-stocks-info>TWSEの全ての株式コード情報を取得する</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/windows-python-settings>Win11 システムでの Python 環境の簡単設定</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/latex-usage>LaTeX 構文クイックリファレンス表</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/impl-normalized-levenshtein-similarity>ANLS の実装</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/python-js-basic-command-equivalents>Python と JS の基本コマンドの対応</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/vscode-settings>よく使う VScode 設定</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/setting-up-nextcloud>Nextcloud の設定記録</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/pytorch-training-out-of-memory>PyTorchのListによる罠</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/convert-pdf-to-images>Pythonを使用してPDFを画像に変換する</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/opencv-imread>PythonでHEIC画像を読み込む方法と読み込みの高速化</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/error-record>日常的なエラー排除記録</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/gosu-usage>コンテナ内のユーザー切り替えツール：gosu</a></ul></div><div role=group><h3 class=yearGroupHeading_rMGB>2023</h3><ul class="sidebarItemList_Yudw clean-list"><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/buy-a-new-computer>パソコン購入記録</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/pyenv-installation>pyenvでPythonバージョンを管理する</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/python-env-info-collector>モデル訓練環境の問題を記録してトラブルシューティング</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/setting-up-pypiserver-on-ubuntu-with-docker>PyPiServerのセットアップ記録</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/ubuntu-install-ssh>UbuntuにSSHサーバーを設定する</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/ubuntu-github-runner-systemd>GitHub Runnerの自動実行</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/login-rtf8207w>RTF8207W ルーターにログインする</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/fail2ban-settings>Fail2ban：SSHサービスの保護</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/unicode-table>Unicode コードポイント表</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/ja/blog/mac-selective-vpn-routing>VPNに選択的なトラフィックルーティングを設定する</a></ul></div></nav></aside><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#第一章起源の低解像度光 class="table-of-contents__link toc-highlight">第一章：起源の低解像度光</a><li><a href=#第二章現実世界の舞台 class="table-of-contents__link toc-highlight">第二章：現実世界の舞台</a><li><a href=#第三章跨領域の修羅場 class="table-of-contents__link toc-highlight">第三章：跨領域の修羅場</a><li><a href=#第四章新世界の勃興 class="table-of-contents__link toc-highlight">第四章：新世界の勃興</a><li><a href=#第五章スタイルの戦い class="table-of-contents__link toc-highlight">第五章：スタイルの戦い</a><li><a href=#第六章多モーダルの召喚術 class="table-of-contents__link toc-highlight">第六章：多モーダルの召喚術</a><li><a href=#第七章偽りの軌跡を解体する class="table-of-contents__link toc-highlight">第七章：偽りの軌跡を解体する</a><li><a href=#第八章未来の混沌 class="table-of-contents__link toc-highlight">第八章：未来の混沌</a><li><a href=#結語 class="table-of-contents__link toc-highlight">結語</a></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/ja/docs>オープンソースプロジェクト</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/papers/intro>論文ノート</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/blog>ブログ</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/terms-of-service>利用規約</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/privacy-policy>プライバシーポリシー</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/become-an-author>著者になる</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/worklog>作業日誌</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>