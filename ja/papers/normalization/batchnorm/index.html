<!doctype html><html lang=ja dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-normalization/batchnorm/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.6.3"><title data-rh=true>[15.02] BatchNorm | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width,initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/ja/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/ja/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/ja/papers/normalization/batchnorm/><meta data-rh=true property=og:locale content=ja><meta data-rh=true property=og:locale:alternate content=zh_hant><meta data-rh=true property=og:locale:alternate content=en><meta data-rh=true name=docusaurus_locale content=ja><meta data-rh=true name=docsearch:language content=ja><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[15.02] BatchNorm | DOCSAID"><meta data-rh=true name=description content=バッチ正規化><meta data-rh=true property=og:description content=バッチ正規化><link data-rh=true rel=icon href=/ja/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/ja/papers/normalization/batchnorm/><link data-rh=true rel=alternate href=https://docsaid.org/papers/normalization/batchnorm/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/normalization/batchnorm/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/normalization/batchnorm/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/normalization/batchnorm/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin><link rel=alternate type=application/rss+xml href=/ja/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/ja/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/ja/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin><link rel=stylesheet href=/ja/assets/css/styles.d64ff131.css><script src=/ja/assets/js/main.0e6725d6.js defer></script><script src=/ja/assets/js/runtime~main.04902afd.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label=メインコンテンツまでスキップ><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>メインコンテンツまでスキップ</a></div><nav aria-label=ナビゲーション class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class=navbar__inner><div class=navbar__items><button aria-label=ナビゲーションバーを開く aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/ja/><div class=navbar__logo><img src=/ja/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/ja/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/ja/docs/>オープンソースプロジェクト</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/ja/papers/intro>論文ノート</a><a class="navbar__item navbar__link" href=/ja/blog>ブログ</a><a class="navbar__item navbar__link" href=/ja/playground/intro>遊び場</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>日本語</a><ul class=dropdown__menu><li><a href=/papers/normalization/batchnorm/ rel="noopener noreferrer" class=dropdown__link lang=zh-hant>繁體中文</a><li><a href=/en/papers/normalization/batchnorm/ rel="noopener noreferrer" class=dropdown__link lang=en>English</a><li><a href=/ja/papers/normalization/batchnorm/ rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=ja>日本語</a></ul></div><a href=https://github.com/DocsaidLab target=_blank rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a><a href=https://buymeacoffee.com/docsaid target=_blank rel="noopener noreferrer" class="navbar__item navbar__link">サポートする<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a><a class="navbar__item navbar__link" href=/ja/aboutus>私たちについて</a><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="検索 (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>検索</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label=先頭へ戻る class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/ja/><img src=/ja/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/ja/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label=ドキュメントのサイドバー class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/ja/papers/intro>論文ノート</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="'Classic CNNs (11)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/face-anti-spoofing-1>Face Anti-Spoofing (1)</a><button aria-label="'Face Anti-Spoofing (1)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="'Face Recognition (4)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/feature-fusion-7>Feature Fusion (7)</a><button aria-label="'Feature Fusion (7)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="'Lightweight (10)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/mamba-3>Mamba (3)</a><button aria-label="'Mamba (3)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/model-tuning-8>Model Tuning (8)</a><button aria-label="'Model Tuning (8)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/multimodality-24>Multimodality (24)</a><button aria-label="'Multimodality (24)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/ja/papers/category/normalization-1>Normalization (1)</a><button aria-label="'Normalization (1)'の目次を隠す" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/ja/papers/normalization/batchnorm/>[15.02] BatchNorm</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/object-detection-8>Object Detection (8)</a><button aria-label="'Object Detection (8)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/reparameterization-7>Reparameterization (7)</a><button aria-label="'Reparameterization (7)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="'Segmentation (1)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/text-detection-14>Text Detection (14)</a><button aria-label="'Text Detection (14)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="'Text Recognition (20)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="'Text Spotting (4)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/transformers-17>Transformers (17)</a><button aria-label="'Transformers (17)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/vision-transformers-12>Vision Transformers (12)</a><button aria-label="'Vision Transformers (12)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/ja/papers/intro>All Notes: 152 entries</a></ul></nav><button type=button title=サイドバーを隠す aria-label=サイドバーを隠す class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=パンくずリストのナビゲーション><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label=�ホームページ class=breadcrumbs__link href=/ja/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/ja/papers/category/normalization-1><span itemprop=name>Normalization (1)</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>[15.02] BatchNorm</span><meta itemprop=position content=2></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">このページの見出し</button></div><div class="theme-doc-markdown markdown"><header><h1>[15.02] BatchNorm</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt=Zephyr class=docAuthorImg_vlJe><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Zephyr</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=バッチ正規化>バッチ正規化<a href=#バッチ正規化 class=hash-link aria-label="バッチ正規化 への直接リンク" title="バッチ正規化 への直接リンク">​</a></h2>
<p><a href=https://arxiv.org/abs/1502.03167 target=_blank rel="noopener noreferrer"><strong>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</strong></a></p>
<hr>
<p>深層学習は、視覚や音声などの多くの分野で顕著な進展を遂げており、確率的勾配降下法（SGD）とその変種であるモーメンタム（Momentum）や Adagrad は、深層神経ネットワークのトレーニングに非常に効果的な方法であることが証明されています。これらの最適化アルゴリズムは、損失を最小化するためにネットワークのパラメータを調整し、トレーニング中に小さなバッチデータを順次処理することで行われます。</p>
<p>SGD の過程では、通常、毎回 1 つの訓練例を使ってパラメータを更新するのではなく、少量のデータ（ミニバッチ）を使用します。この方法の利点は、まず、ミニバッチの損失勾配が全体の訓練セットの勾配をよく推定しており、バッチサイズが増えるにつれて、この推定の質が向上することです。次に、現代の計算プラットフォームがサポートする並列計算能力により、単一のデータを何度も処理するよりも、バッチ全体のデータを処理する方が効率的であるという点です。</p>
<p>しかし、確率的勾配降下法は、学習率のようなハイパーパラメータを慎重に調整する必要があり、トレーニング中にネットワークが深くなると、小さな変化が増幅され、いわゆる**共変量シフト（Covariate Shift）**を引き起こす可能性があります。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>ヒント</div><div class=admonitionContent_BuS1><p>これは「現在の層」が「前の層」のパラメータ変化によって引き起こされる入力分布の変化に適応し続ける必要があるという意味です。<p>例えば次のように考えます：<p>シグモイド活性化関数を持つ層 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>g</mi><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo>⁡</mo><mo stretchy=false>(</mo><mo>−</mo><mi>x</mi><mo stretchy=false>)</mo></mrow></mfrac></mrow><annotation encoding=application/x-tex>g(x) = \frac{1}{1+\exp(-x)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.3651em;vertical-align:-0.52em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8451em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mop mtight"><span class=mtight>e</span><span class=mtight>x</span><span class=mtight>p</span></span><span class="mopen mtight">(</span><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.394em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.52em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> を考えます：<p><span class=katex><span class=katex-mathml><math><semantics><mrow><mi>z</mi><mo>=</mo><mi>g</mi><mo stretchy=false>(</mo><mi>W</mi><mi>u</mi><mo>+</mo><mi>b</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>z = g(Wu + b)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal" style=margin-right:0.04398em>z</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.13889em>W</span><span class="mord mathnormal">u</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">b</span><span class=mclose>)</span></span></span></span><p>ここで <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>u</mi></mrow><annotation encoding=application/x-tex>u</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">u</span></span></span></span> は層の入力、重み行列 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>W</mi></mrow><annotation encoding=application/x-tex>W</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>W</span></span></span></span> とバイアスベクトル <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>b</mi></mrow><annotation encoding=application/x-tex>b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span></span></span></span> は学習すべきパラメータです。<p><span class=katex><span class=katex-mathml><math><semantics><mrow><mi mathvariant=normal>∣</mi><mi>x</mi><mi mathvariant=normal>∣</mi></mrow><annotation encoding=application/x-tex>|x|</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>∣</span><span class="mord mathnormal">x</span><span class=mord>∣</span></span></span></span> が増加すると、<span class=katex><span class=katex-mathml><math><semantics><mrow><msup><mi>g</mi><mo mathvariant=normal lspace=0em rspace=0em>′</mo></msup><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>g'(x)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0019em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.7519em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span></span></span></span> はゼロに近づきます。これは、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>x</mi><mo>=</mo><mi>W</mi><mi>u</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding=application/x-tex>x = Wu + b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.7667em;vertical-align:-0.0833em></span><span class="mord mathnormal" style=margin-right:0.13889em>W</span><span class="mord mathnormal">u</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span></span></span></span> の絶対値が小さい次元を除き、勾配が <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>u</mi></mrow><annotation encoding=application/x-tex>u</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">u</span></span></span></span> に流れる際に消失し、モデルのトレーニングが遅くなることを意味します。しかし、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> は <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>W</mi></mrow><annotation encoding=application/x-tex>W</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>W</span></span></span></span>、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>b</mi></mrow><annotation encoding=application/x-tex>b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span></span></span></span> とそれ以下のすべての層のパラメータに影響されるため、トレーニング中にパラメータの変化が <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> の多くの次元を非線形飽和領域に導き、収束速度が遅くなる可能性があります。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=定義問題>定義問題<a href=#定義問題 class=hash-link aria-label="定義問題 への直接リンク" title="定義問題 への直接リンク">​</a></h2>
<p>著者は内部共変量転送を以下のように定義しています：</p>
<ul>
<li><strong>訓練過程中のネットワークパラメータの変化によって引き起こされるネットワークの出力分布の変化</strong>。</li>
</ul>
<p>訓練を改善するために、内部共変量転送を減少させることが望ましいです。層の入力 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> の分布を固定することで、訓練速度を加速できると予想されます。</p>
<p>過去の研究によると、ネットワークの訓練は、その入力がホワイトニングされている、すなわち線形変換を通じてゼロ平均および単位分散を持ち、かつ相関がなくなっている場合、収束が速くなることが示されています。各層の入力は前の層の出力に由来するため、各層の入力をホワイトニングすることは有利です。</p>
<p>しかし、これらの修正を最適化ステップと交互に実行すると、勾配降下ステップは正規化が必要な方法でパラメータを更新しようとする可能性があり、これが勾配ステップの効果を減少させます。</p>
<p>例えば、入力が <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>u</mi></mrow><annotation encoding=application/x-tex>u</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">u</span></span></span></span> の層を考え、学習されたバイアス <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>b</mi></mrow><annotation encoding=application/x-tex>b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span></span></span></span> を加え、出力の平均を引くことで正規化します：<span class=katex><span class=katex-mathml><math><semantics><mrow><mover accent=true><mi>x</mi><mo>^</mo></mover><mo>=</mo><mi>x</mi><mo>−</mo><mi>E</mi><mo stretchy=false>[</mo><mi>x</mi><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>\hat{x} = x - E[x]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6667em;vertical-align:-0.0833em></span><span class="mord mathnormal">x</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=mopen>[</span><span class="mord mathnormal">x</span><span class=mclose>]</span></span></span></span>、ここで <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>x</mi><mo>=</mo><mi>u</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding=application/x-tex>x = u + b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6667em;vertical-align:-0.0833em></span><span class="mord mathnormal">u</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span></span></span></span>、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy=false>{</mo><msub><mi>x</mi><mn>1</mn></msub><mi mathvariant=normal>.</mi><mi mathvariant=normal>.</mi><mi mathvariant=normal>.</mi><mi>N</mi><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>X = \{x_1...N\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>...</span><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=mclose>}</span></span></span></span> は <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> の訓練セットの値で、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>E</mi><mo stretchy=false>[</mo><mi>x</mi><mo stretchy=false>]</mo><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>E[x] = \frac{1}{N} \sum_{i=1}^N x_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=mopen>[</span><span class="mord mathnormal">x</span><span class=mclose>]</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.3262em;vertical-align:-0.345em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8451em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.10903em>N</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.394em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.345em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop><span class="mop op-symbol small-op" style=position:relative;top:0em>∑</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.9812em><span style=top:-2.4003em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.2029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.10903em>N</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2997em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> です。もし勾配降下ステップが <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>E</mi><mo stretchy=false>[</mo><mi>x</mi><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>E[x]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=mopen>[</span><span class="mord mathnormal">x</span><span class=mclose>]</span></span></span></span> の <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>b</mi></mrow><annotation encoding=application/x-tex>b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span></span></span></span> に対する依存を無視した場合、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>b</mi><mo>←</mo><mi>b</mi><mo>+</mo><mi mathvariant=normal>Δ</mi><mi>b</mi></mrow><annotation encoding=application/x-tex>b \leftarrow b + \Delta b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>←</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.7778em;vertical-align:-0.0833em></span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6944em></span><span class=mord>Δ</span><span class="mord mathnormal">b</span></span></span></span> で更新されます、ここで <span class=katex><span class=katex-mathml><math><semantics><mrow><mi mathvariant=normal>Δ</mi><mi>b</mi><mo>∝</mo><mo>−</mo><mfrac><mrow><mi mathvariant=normal>∂</mi><mi mathvariant=normal>ℓ</mi></mrow><mrow><mi mathvariant=normal>∂</mi><mover accent=true><mi>x</mi><mo>^</mo></mover></mrow></mfrac></mrow><annotation encoding=application/x-tex>\Delta b \propto -\frac{\partial \ell}{\partial \hat{x}}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class=mord>Δ</span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∝</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.2251em;vertical-align:-0.345em></span><span class=mord>−</span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8801em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style=margin-right:0.05556em>∂</span><span class="mord accent mtight"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-2.7em><span class=pstrut style=height:2.7em></span><span class="mord mathnormal mtight">x</span></span><span style=top:-2.7em><span class=pstrut style=height:2.7em></span><span class=accent-body style=left:-0.2222em><span class="mord mtight">^</span></span></span></span></span></span></span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.394em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style=margin-right:0.05556em>∂</span><span class="mord mtight">ℓ</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.345em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。</p>
<p>したがって、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>u</mi><mo>+</mo><mo stretchy=false>(</mo><mi>b</mi><mo>+</mo><mi mathvariant=normal>Δ</mi><mi>b</mi><mo stretchy=false>)</mo><mo>−</mo><mi>E</mi><mo stretchy=false>[</mo><mi>u</mi><mo>+</mo><mo stretchy=false>(</mo><mi>b</mi><mo>+</mo><mi mathvariant=normal>Δ</mi><mi>b</mi><mo stretchy=false>)</mo><mo stretchy=false>]</mo><mo>=</mo><mi>u</mi><mo>+</mo><mi>b</mi><mo>−</mo><mi>E</mi><mo stretchy=false>[</mo><mi>u</mi><mo>+</mo><mi>b</mi><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>u + (b + \Delta b) - E[u + (b + \Delta b)] = u + b - E[u + b]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6667em;vertical-align:-0.0833em></span><span class="mord mathnormal">u</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>(</span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>Δ</span><span class="mord mathnormal">b</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=mopen>[</span><span class="mord mathnormal">u</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>(</span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>Δ</span><span class="mord mathnormal">b</span><span class=mclose>)]</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6667em;vertical-align:-0.0833em></span><span class="mord mathnormal">u</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.7778em;vertical-align:-0.0833em></span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=mopen>[</span><span class="mord mathnormal">u</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">b</span><span class=mclose>]</span></span></span></span> となります。このように、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>b</mi></mrow><annotation encoding=application/x-tex>b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span></span></span></span> の更新とその後の正規化変化の組み合わせにより、層の出力と損失は変化しません。訓練が進むにつれて、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>b</mi></mrow><annotation encoding=application/x-tex>b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span></span></span></span> は無限に増加し、損失は一定のままになります。正規化が単に中心化だけでなく、スケーリングを行う場合、この問題はさらに悪化します。</p>
<hr>
<p>上記の方法の問題は、勾配降下法が正規化の存在を考慮していないことにあります。</p>
<p>この問題を解決するために、著者は、任意のパラメータ値についてネットワークが常に必要な分布を持つ出力を生成することを保証したいと考えています。これにより、損失がモデルパラメータに関する勾配が正規化およびそのモデルパラメータ <span class=katex><span class=katex-mathml><math><semantics><mrow><mi mathvariant=normal>Θ</mi></mrow><annotation encoding=application/x-tex>\Theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class=mord>Θ</span></span></span></span> に対する依存関係を考慮するようになります。</p>
<p><span class=katex><span class=katex-mathml><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> を層の入力ベクトルとし、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>X</mi></mrow><annotation encoding=application/x-tex>X</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07847em>X</span></span></span></span> を訓練データセット上のこれらの入力の集合とします。正規化は次のように書けます：</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math display=block><semantics><mrow><mover accent=true><mi>x</mi><mo>^</mo></mover><mo>=</mo><mtext>Norm</mtext><mo stretchy=false>(</mo><mi>x</mi><mo separator=true>,</mo><mi>χ</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\hat{x} = \text{Norm}(x, \chi)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>Norm</span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">χ</span><span class=mclose>)</span></span></span></span></span>
<p>これは、与えられた訓練サンプル <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> に依存するだけでなく、すべてのサンプル <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>χ</mi></mrow><annotation encoding=application/x-tex>\chi</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal">χ</span></span></span></span> に依存します。</p>
<p>逆伝播において、<span class=katex><span class=katex-mathml><math><semantics><mrow><mfrac><mrow><mi mathvariant=normal>∂</mi><mtext>Norm</mtext><mo stretchy=false>(</mo><mi>x</mi><mo separator=true>,</mo><mi>χ</mi><mo stretchy=false>)</mo></mrow><mrow><mi mathvariant=normal>∂</mi><mi>x</mi></mrow></mfrac></mrow><annotation encoding=application/x-tex>\frac{\partial \text{Norm}(x, \chi)}{\partial x}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.355em;vertical-align:-0.345em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.01em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style=margin-right:0.05556em>∂</span><span class="mord mathnormal mtight">x</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.485em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style=margin-right:0.05556em>∂</span><span class="mord text mtight"><span class="mord mtight">Norm</span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">χ</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.345em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> と <span class=katex><span class=katex-mathml><math><semantics><mrow><mfrac><mrow><mi mathvariant=normal>∂</mi><mtext>Norm</mtext><mo stretchy=false>(</mo><mi>x</mi><mo separator=true>,</mo><mi>χ</mi><mo stretchy=false>)</mo></mrow><mrow><mi mathvariant=normal>∂</mi><mi>χ</mi></mrow></mfrac></mrow><annotation encoding=application/x-tex>\frac{\partial \text{Norm}(x, \chi)}{\partial \chi}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.4911em;vertical-align:-0.4811em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.01em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style=margin-right:0.05556em>∂</span><span class="mord mathnormal mtight">χ</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.485em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style=margin-right:0.05556em>∂</span><span class="mord text mtight"><span class="mord mtight">Norm</span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">χ</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.4811em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> を計算する必要があります。後者を無視すると、上記の爆発が生じます。</p>
<p>この枠組みでは、共分散行列 <span class=katex><span class=katex-mathml><math><semantics><mrow><mtext>Cov</mtext><mo stretchy=false>[</mo><mi>x</mi><mo stretchy=false>]</mo><mo>=</mo><msub><mi>E</mi><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></msub><mo stretchy=false>[</mo><mi>x</mi><msup><mi>x</mi><mi>T</mi></msup><mo stretchy=false>]</mo><mo>−</mo><mi>E</mi><mo stretchy=false>[</mo><mi>x</mi><mo stretchy=false>]</mo><mi>E</mi><mo stretchy=false>[</mo><mi>x</mi><msup><mo stretchy=false>]</mo><mi>T</mi></msup></mrow><annotation encoding=application/x-tex>\text{Cov}[x] = E_{x \in X}[xx^T] - E[x]E[x]^T</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>Cov</span></span><span class=mopen>[</span><span class="mord mathnormal">x</span><span class=mclose>]</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.0913em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.0576em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style=margin-right:0.07847em>X</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1774em><span></span></span></span></span></span></span><span class=mopen>[</span><span class="mord mathnormal">x</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span></span></span></span></span><span class=mclose>]</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.0913em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=mopen>[</span><span class="mord mathnormal">x</span><span class=mclose>]</span><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=mopen>[</span><span class="mord mathnormal">x</span><span class=mclose><span class=mclose>]</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span></span></span></span></span></span></span></span> とその逆平方根を計算してホワイトニングされた出力 <span class=katex><span class=katex-mathml><math><semantics><mrow><mtext>Cov</mtext><mo stretchy=false>[</mo><mi>x</mi><msup><mo stretchy=false>]</mo><mrow><mo>−</mo><mn>1</mn><mi mathvariant=normal>/</mi><mn>2</mn></mrow></msup><mo stretchy=false>(</mo><mi>x</mi><mo>−</mo><mi>E</mi><mo stretchy=false>[</mo><mi>x</mi><mo stretchy=false>]</mo><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\text{Cov}[x]^{-1/2}(x - E[x])</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.138em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>Cov</span></span><span class=mopen>[</span><span class="mord mathnormal">x</span><span class=mclose><span class=mclose>]</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1/2</span></span></span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=mopen>[</span><span class="mord mathnormal">x</span><span class=mclose>])</span></span></span></span> を生成し、これらの変換の導関数を逆伝播のために計算する必要があります。</p>
<p>ホワイトニングされた層入力全体を計算するのは非常に高価であるため、著者は、パラメータ更新後に訓練セット全体を分析することなく、入力正規化を微分可能な方法で実行する代替方法を探し始めました。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>ヒント</div><div class=admonitionContent_BuS1><p><strong>ホワイトニング vs 標準化</strong><ul>
<li>
<p><strong>標準化 (Standardization)</strong></p>
<p>標準化はデータ処理において、データの平均を 0、標準偏差を 1 にする方法です。この方法は通常 Z スコア正規化と呼ばれ、計算式は次の通りです：</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math display=block><semantics><mrow><mi>z</mi><mo>=</mo><mfrac><mrow><mo stretchy=false>(</mo><mi>x</mi><mo>−</mo><mi>μ</mi><mo stretchy=false>)</mo></mrow><mi>σ</mi></mfrac></mrow><annotation encoding=application/x-tex>z = \frac{(x - \mu)}{\sigma}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal" style=margin-right:0.04398em>z</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.113em;vertical-align:-0.686em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.427em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>σ</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span><span class="mord mathnormal">μ</span><span class=mclose>)</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>ここで <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> は元のデータ、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding=application/x-tex>\mu</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal">μ</span></span></span></span> はデータの平均、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>σ</mi></mrow><annotation encoding=application/x-tex>\sigma</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal" style=margin-right:0.03588em>σ</span></span></span></span> はデータの標準偏差です。標準化後のデータ分布は標準正規分布の特性を持ち、これにより異なる特徴（または異なる次元）を比較しやすくし、特に勾配ベースの最適化方法を用いたモデルの訓練時に処理が容易になります。</p>
</li>
<li>
<p><strong>ホワイトニング (Whitening)</strong></p>
<p>ホワイトニングは、データの入力を同じ分散を持つ新しい特徴に変換し、新しい特徴間で相関がない（すなわち特徴間の共分散行列が対角行列である）ことを目的とした高度なデータ前処理技術です。これは単にデータの平均をゼロにし、分散を標準化するだけでなく、入力特徴間の相関を取り除くことも含みます。計算過程は通常、次の手順を含みます：</p>
<ol>
<li>データのセンタリング（平均を引く）。</li>
<li>データの共分散行列を計算する。</li>
<li>共分散行列を固有値分解する。</li>
<li>固有値を使ってデータをスケーリングし、固有ベクトルでデータを回転させて変換後の特徴を互いに独立にします。</li>
</ol>
<p>ホワイトニングの効果は、互いに線形無関係な（独立した）特徴を生成することで、主成分分析（PCA）やいくつかの神経ネットワークモデルなど、いくつかのアルゴリズムで非常に有用です。これにより、学習効率や結果の解釈性が改善されます。</p>
</li>
</ul><p>標準化は主にデータを共通の尺度に規範化するために使用され、機械学習モデルの訓練に広く適用され、特にデータのスケールに敏感なモデル（例えばサポートベクターマシン（SVM）や神経ネットワーク）において重要です。一方、ホワイトニングは特徴をさらに独立させ、多重共線性の問題を解消するのに役立ちますが、計算が標準化よりも複雑で、固有値分解や行列演算を含みます。<p>実際のアプリケーションでは、標準化が一般的であり、その計算が簡単であり、通常はほとんどのモデル訓練のニーズを満たすのに十分です。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=解決問題>解決問題<a href=#解決問題 class=hash-link aria-label="解決問題 への直接リンク" title="解決問題 への直接リンク">​</a></h2>
<p>各層入力に対する完全なホワイトニング操作の計算コストが高く、完全には微分不可能であるため、著者は 2 つの必要な簡略化を行いました。</p>
<p>まず、層の入力と出力の特徴に対して共通のホワイトニングを行うのではなく、各スカラー特徴を独立に正規化し、ゼロ平均および単位分散にします。入力が <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>d</mi></mrow><annotation encoding=application/x-tex>d</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">d</span></span></span></span> 次元のベクトル <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>x</mi><mo>=</mo><mo stretchy=false>(</mo><msup><mi>x</mi><mrow><mo stretchy=false>(</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msup><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msup><mi>x</mi><mrow><mo stretchy=false>(</mo><mi>d</mi><mo stretchy=false>)</mo></mrow></msup><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>x = (x^{(1)}, \ldots, x^{(d)})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.138em;vertical-align:-0.25em></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">d</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span> である層について、各次元を次のように正規化します：</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math display=block><semantics><mrow><msup><mover accent=true><mi>x</mi><mo>^</mo></mover><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup><mo>=</mo><mfrac><mrow><msup><mi>x</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup><mo>−</mo><mi mathvariant=double-struck>E</mi><mo stretchy=false>[</mo><msup><mi>x</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup><mo stretchy=false>]</mo></mrow><msqrt><mrow><mrow><mi mathvariant=normal>V</mi><mi mathvariant=normal>a</mi><mi mathvariant=normal>r</mi></mrow><mo stretchy=false>[</mo><msup><mi>x</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup><mo stretchy=false>]</mo></mrow></msqrt></mfrac></mrow><annotation encoding=application/x-tex>\hat{x}^{(k)} = \frac{x^{(k)} - \mathbb{E}[x^{(k)}]}{\sqrt{\mathrm{Var}[x^{(k)}]}}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.938em></span><span class=mord><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.938em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.695em;vertical-align:-1.13em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.565em><span style=top:-2.143em><span class=pstrut style=height:3em></span><span class=mord><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.967em><span class=svg-align style=top:-3.2em><span class=pstrut style=height:3.2em></span><span class=mord style=padding-left:1em><span class=mord><span class="mord mathrm">Var</span></span><span class=mopen>[</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.814em><span style=top:-2.989em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mclose>]</span></span></span><span style=top:-2.927em><span class=pstrut style=height:3.2em></span><span class=hide-tail style=min-width:1.02em;height:1.28em><svg width=400em height=1.28em viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119 c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120 c340,-704.7,510.7,-1060.3,512,-1067 l0 -0 c4.7,-7.3,11,-11,19,-11 H40000v40H1012.3 s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232 c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1 s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26 c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z M1001 80h400000v40h-400000z"/></svg></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.273em><span></span></span></span></span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span><span class="mord mathbb">E</span><span class=mopen>[</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mclose>]</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.13em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>ここで、期待値と分散は訓練データセットに基づいて計算されます。</p>
<p>注意すべきは、単純に各層の入力を正規化することが層の表現能力を変える可能性がある点です。例えば、シグモイド関数の入力を正規化すると、非線形領域内に制限されてしまいます。この問題を解決するために、著者はネットワークに挿入する変換が恒等変換を表現できるようにしました。そのために、各活性化値 <span class=katex><span class=katex-mathml><math><semantics><mrow><msup><mi>x</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup></mrow><annotation encoding=application/x-tex>x^{(k)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.888em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> に対してパラメータ <span class=katex><span class=katex-mathml><math><semantics><mrow><msup><mi>γ</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup></mrow><annotation encoding=application/x-tex>\gamma^{(k)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0824em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05556em>γ</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> と <span class=katex><span class=katex-mathml><math><semantics><mrow><msup><mi>β</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup></mrow><annotation encoding=application/x-tex>\beta^{(k)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0824em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05278em>β</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> を導入し、正規化された値をスケーリングおよび平行移動します：</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math display=block><semantics><mrow><msup><mi>y</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup><mo>=</mo><msup><mi>γ</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup><msup><mover accent=true><mi>x</mi><mo>^</mo></mover><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup><mo>+</mo><msup><mi>β</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup></mrow><annotation encoding=application/x-tex>y^{(k)} = \gamma^{(k)} \hat{x}^{(k)} + \beta^{(k)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.1324em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.938em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.1324em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05556em>γ</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.938em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mord><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.938em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.1324em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05278em>β</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.938em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span>
<p>これらのパラメータは元のモデルのパラメータと一緒に学習され、ネットワークの表現能力を回復させます。</p>
<p>実際、<span class=katex><span class=katex-mathml><math><semantics><mrow><msup><mi>γ</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup><mo>=</mo><msqrt><mrow><mrow><mi mathvariant=normal>V</mi><mi mathvariant=normal>a</mi><mi mathvariant=normal>r</mi></mrow><mo stretchy=false>[</mo><msup><mi>x</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup><mo stretchy=false>]</mo></mrow></msqrt></mrow><annotation encoding=application/x-tex>\gamma^{(k)} = \sqrt{\mathrm{Var}[x^{(k)}]}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0824em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05556em>γ</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.24em;vertical-align:-0.273em></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.967em><span class=svg-align style=top:-3.2em><span class=pstrut style=height:3.2em></span><span class=mord style=padding-left:1em><span class=mord><span class="mord mathrm">Var</span></span><span class=mopen>[</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.814em><span style=top:-2.989em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mclose>]</span></span></span><span style=top:-2.927em><span class=pstrut style=height:3.2em></span><span class=hide-tail style=min-width:1.02em;height:1.28em><svg width=400em height=1.28em viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119 c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120 c340,-704.7,510.7,-1060.3,512,-1067 l0 -0 c4.7,-7.3,11,-11,19,-11 H40000v40H1012.3 s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232 c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1 s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26 c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z M1001 80h400000v40h-400000z"/></svg></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.273em><span></span></span></span></span></span></span></span></span> と <span class=katex><span class=katex-mathml><math><semantics><mrow><msup><mi>β</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup><mo>=</mo><mi mathvariant=double-struck>E</mi><mo stretchy=false>[</mo><msup><mi>x</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>\beta^{(k)} = \mathbb{E}[x^{(k)}]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0824em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05278em>β</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.138em;vertical-align:-0.25em></span><span class="mord mathbb">E</span><span class=mopen>[</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mclose>]</span></span></span></span> を設定することで、最適な状況下で元の活性化値を回復できます。</p>
<p>訓練セット全体に基づくバッチ設定では、一般的に訓練セット全体を使用して活性化値を正規化します。しかし、ランダム最適化を使用する場合、これは非現実的です。</p>
<p>したがって、著者は 2 つ目の簡略化を行いました：ランダム勾配訓練では小さなバッチを使用し、各小バッチが各活性化値の平均と分散を推定します。このようにして、正規化に使用される統計量は勾配逆伝播に完全に参加できます。ここで注意すべきは、小バッチ方式では各次元の分散を計算するだけで、共分散行列を計算しない点です；共分散行列が必要となる場合、正規化を行う必要があり、バッチサイズがホワイトニングする活性化値の数より小さい場合、共分散行列が特異となる可能性があります。</p>
<p>サイズが <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>m</mi></mrow><annotation encoding=application/x-tex>m</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span></span></span></span> の小バッチ <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>B</mi></mrow><annotation encoding=application/x-tex>B</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span></span></span></span> を考えます。正規化は各活性化値に独立に適用されるため、特定の活性化値 <span class=katex><span class=katex-mathml><math><semantics><mrow><msup><mi>x</mi><mrow><mo stretchy=false>(</mo><mi>k</mi><mo stretchy=false>)</mo></mrow></msup></mrow><annotation encoding=application/x-tex>x^{(k)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.888em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> に集中し、簡単化のために <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>k</mi></mrow><annotation encoding=application/x-tex>k</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.03148em>k</span></span></span></span> を省略します。この活性化値の小バッチにおける <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>m</mi></mrow><annotation encoding=application/x-tex>m</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span></span></span></span> 個の値を <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>B</mi><mo>=</mo><mo stretchy=false>{</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mi>x</mi><mi>m</mi></msub><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>B = \{x_1, \ldots, x_m\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>}</span></span></span></span> とします。</p>
<p>正規化後の値を <span class=katex><span class=katex-mathml><math><semantics><mrow><msub><mover accent=true><mi>x</mi><mo>^</mo></mover><mn>1</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mover accent=true><mi>x</mi><mo>^</mo></mover><mi>m</mi></msub></mrow><annotation encoding=application/x-tex>\hat{x}_1, \ldots, \hat{x}_m</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> とし、それらの線形変換を <span class=katex><span class=katex-mathml><math><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mi>y</mi><mi>m</mi></msub></mrow><annotation encoding=application/x-tex>y_1, \ldots, y_m</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> とします。この変換を BatchNorm 変換 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>B</mi><msub><mi>N</mi><mrow><mi>γ</mi><mo separator=true>,</mo><mi>β</mi></mrow></msub></mrow><annotation encoding=application/x-tex>BN_{\gamma, \beta}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05556em>γ</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05278em>β</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span> と呼び、その過程は次の通りです。アルゴリズム内で、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding=application/x-tex>\epsilon</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">ϵ</span></span></span></span> は数値的安定性のために小バッチの分散に追加される定数です。</p>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt="bn algo" src=/ja/assets/images/img1-81d300c554ff6dd970e74a7f5c52e910.jpg width=1016 height=824 class=img_ev3q></figure></div>
<p><span class=katex><span class=katex-mathml><math><semantics><mrow><mi>y</mi><mo>=</mo><mi>B</mi><msub><mi>N</mi><mrow><mi>γ</mi><mo separator=true>,</mo><mi>β</mi></mrow></msub><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>y = BN_{\gamma, \beta}(x)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.0361em;vertical-align:-0.2861em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05556em>γ</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05278em>β</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span></span></span></span> の表現では、パラメータ <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>γ</mi></mrow><annotation encoding=application/x-tex>\gamma</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.05556em>γ</span></span></span></span> と <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>β</mi></mrow><annotation encoding=application/x-tex>\beta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.05278em>β</span></span></span></span> は学習が必要ですが、BN 変換は各訓練サンプルの活性化値を独立に処理するわけではないことに注意する必要があります。代わりに、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>B</mi><msub><mi>N</mi><mrow><mi>γ</mi><mo separator=true>,</mo><mi>β</mi></mrow></msub><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>BN_{\gamma, \beta}(x)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0361em;vertical-align:-0.2861em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05556em>γ</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05278em>β</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span></span></span></span> は訓練サンプルに依存するだけでなく、小バッチ内の他のサンプルにも依存します。スケーリングと平行移動された値 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=application/x-tex>y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span></span></span></span> は他のネットワーク層に伝達されます。</p>
<p>BN 変換は微分可能な変換であり、正規化された活性化値をネットワークに導入します。これにより、モデルの訓練過程で各層が内部共変量転送の少ない入力分布上で学習を続け、訓練を加速することができます。さらに、これらの正規化された活性化値に適用される学習可能なアフィン変換は、BN 変換が恒等変換を表現できることを可能にし、ネットワークの容量を保持します。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=学習率の向上>学習率の向上<a href=#学習率の向上 class=hash-link aria-label="学習率の向上 への直接リンク" title="学習率の向上 への直接リンク">​</a></h3>
<p>従来の深層神経ネットワークでは、高すぎる学習率が勾配爆発や消失を引き起こし、悪い局所的最小値に陥る原因となります。BatchNorm はこれらの問題の解決に役立ちます。ネットワーク全体で活性化値を正規化することで、パラメータの微小な変化が活性化値や勾配の大きな次優的な変化に増幅されることを防ぎ、訓練が非線形関数の飽和領域に陥るのを防ぎます。</p>
<p>BatchNorm はまた、パラメータのスケールに対して訓練をより堅牢にします。通常、大きな学習率は層のパラメータのスケールを増加させ、その結果、逆伝播過程で勾配を増幅させ、モデルが爆発的になる可能性があります。しかし、BatchNorm を使用することで、層の逆伝播はそのパラメータのスケールに影響されなくなります。</p>
<p>スカラー <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>a</mi></mrow><annotation encoding=application/x-tex>a</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">a</span></span></span></span> に対して、</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math display=block><semantics><mrow><mrow><mi mathvariant=normal>B</mi><mi mathvariant=normal>N</mi></mrow><mo stretchy=false>(</mo><mi>W</mi><mi mathvariant=bold>u</mi><mo stretchy=false>)</mo><mo>=</mo><mrow><mi mathvariant=normal>B</mi><mi mathvariant=normal>N</mi></mrow><mo stretchy=false>(</mo><mo stretchy=false>(</mo><mi>a</mi><mi>W</mi><mo stretchy=false>)</mo><mi mathvariant=bold>u</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\mathrm{BN}(W\mathbf{u}) = \mathrm{BN}((aW)\mathbf{u})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathrm">BN</span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.13889em>W</span><span class="mord mathbf">u</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathrm">BN</span></span><span class=mopen>((</span><span class="mord mathnormal" style=margin-right:0.13889em>aW</span><span class=mclose>)</span><span class="mord mathbf">u</span><span class=mclose>)</span></span></span></span></span>
<p>が成立し、</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math display=block><semantics><mrow><mfrac><mrow><mi mathvariant=normal>∂</mi><mrow><mi mathvariant=normal>B</mi><mi mathvariant=normal>N</mi></mrow><mo stretchy=false>(</mo><mo stretchy=false>(</mo><mi>a</mi><mi>W</mi><mo stretchy=false>)</mo><mi mathvariant=bold>u</mi><mo stretchy=false>)</mo></mrow><mrow><mi mathvariant=normal>∂</mi><mi mathvariant=bold>u</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant=normal>∂</mi><mrow><mi mathvariant=normal>B</mi><mi mathvariant=normal>N</mi></mrow><mo stretchy=false>(</mo><mi>W</mi><mi mathvariant=bold>u</mi><mo stretchy=false>)</mo></mrow><mrow><mi mathvariant=normal>∂</mi><mi mathvariant=bold>u</mi></mrow></mfrac></mrow><annotation encoding=application/x-tex>\frac{\partial \mathrm{BN}((aW)\mathbf{u})}{\partial \mathbf{u}} = \frac{\partial \mathrm{BN}(W\mathbf{u})}{\partial \mathbf{u}}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:2.113em;vertical-align:-0.686em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.427em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class=mord style=margin-right:0.05556em>∂</span><span class="mord mathbf">u</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord style=margin-right:0.05556em>∂</span><span class=mord><span class="mord mathrm">BN</span></span><span class=mopen>((</span><span class="mord mathnormal" style=margin-right:0.13889em>aW</span><span class=mclose>)</span><span class="mord mathbf">u</span><span class=mclose>)</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.113em;vertical-align:-0.686em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.427em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class=mord style=margin-right:0.05556em>∂</span><span class="mord mathbf">u</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord style=margin-right:0.05556em>∂</span><span class=mord><span class="mord mathrm">BN</span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.13889em>W</span><span class="mord mathbf">u</span><span class=mclose>)</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<span class=katex-display><span class=katex><span class=katex-mathml><math display=block><semantics><mrow><mfrac><mrow><mi mathvariant=normal>∂</mi><mrow><mi mathvariant=normal>B</mi><mi mathvariant=normal>N</mi></mrow><mo stretchy=false>(</mo><mo stretchy=false>(</mo><mi>a</mi><mi>W</mi><mo stretchy=false>)</mo><mi mathvariant=bold>u</mi><mo stretchy=false>)</mo></mrow><mrow><mi mathvariant=normal>∂</mi><mo stretchy=false>(</mo><mi>a</mi><mi>W</mi><mo stretchy=false>)</mo></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>a</mi></mfrac><mo>⋅</mo><mfrac><mrow><mi mathvariant=normal>∂</mi><mrow><mi mathvariant=normal>B</mi><mi mathvariant=normal>N</mi></mrow><mo stretchy=false>(</mo><mi>W</mi><mi mathvariant=bold>u</mi><mo stretchy=false>)</mo></mrow><mrow><mi mathvariant=normal>∂</mi><mi>W</mi></mrow></mfrac></mrow><annotation encoding=application/x-tex>\frac{\partial \mathrm{BN}((aW)\mathbf{u})}{\partial (aW)} = \frac{1}{a} \cdot \frac{\partial \mathrm{BN}(W\mathbf{u})}{\partial W}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:2.363em;vertical-align:-0.936em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.427em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class=mord style=margin-right:0.05556em>∂</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.13889em>aW</span><span class=mclose>)</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord style=margin-right:0.05556em>∂</span><span class=mord><span class="mord mathrm">BN</span></span><span class=mopen>((</span><span class="mord mathnormal" style=margin-right:0.13889em>aW</span><span class=mclose>)</span><span class="mord mathbf">u</span><span class=mclose>)</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.936em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.0074em;vertical-align:-0.686em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3214em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal">a</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:2.113em;vertical-align:-0.686em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.427em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class=mord style=margin-right:0.05556em>∂</span><span class="mord mathnormal" style=margin-right:0.13889em>W</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord style=margin-right:0.05556em>∂</span><span class=mord><span class="mord mathrm">BN</span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.13889em>W</span><span class="mord mathbf">u</span><span class=mclose>)</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>比例は層のヤコビ行列に影響を与えず、勾配伝播にも影響を与えません。</p>
<p>著者はさらに、BatchNorm が層のヤコビ行列の特異値を 1 に近づける可能性があり、これが訓練に有益であると推測しています。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>ヒント</div><div class=admonitionContent_BuS1><p>正規化された入力を持つ 2 つの連続層を考え、それらの正規化ベクトル間の変換：<span class=katex><span class=katex-mathml><math><semantics><mrow><mover accent=true><mi>z</mi><mo>^</mo></mover><mo>=</mo><mi>F</mi><mo stretchy=false>(</mo><mover accent=true><mi>x</mi><mo>^</mo></mover><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\hat{z} = F(\hat{x})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:0.04398em>z</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.1944em><span class=mord>^</span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>F</span><span class=mopen>(</span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>。<p>もし<span class=katex><span class=katex-mathml><math><semantics><mrow><mover accent=true><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding=application/x-tex>\hat{x}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span></span></span></span>と<span class=katex><span class=katex-mathml><math><semantics><mrow><mover accent=true><mi>z</mi><mo>^</mo></mover></mrow><annotation encoding=application/x-tex>\hat{z}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:0.04398em>z</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.1944em><span class=mord>^</span></span></span></span></span></span></span></span></span></span>がガウス分布で無相関であり、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>F</mi><mo stretchy=false>(</mo><mover accent=true><mi>x</mi><mo>^</mo></mover><mo stretchy=false>)</mo><mo>≈</mo><mi>J</mi><mover accent=true><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding=application/x-tex>F(\hat{x}) \approx J\hat{x}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>F</span><span class=mopen>(</span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>≈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.09618em>J</span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span></span></span></span> が与えられたモデルパラメータに対する線形変換であると仮定すると、<span class=katex><span class=katex-mathml><math><semantics><mrow><mover accent=true><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding=application/x-tex>\hat{x}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span></span></span></span>と<span class=katex><span class=katex-mathml><math><semantics><mrow><mover accent=true><mi>z</mi><mo>^</mo></mover></mrow><annotation encoding=application/x-tex>\hat{z}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:0.04398em>z</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.1944em><span class=mord>^</span></span></span></span></span></span></span></span></span></span>は単位共分散を持ち、</p><span class=katex-display><span class=katex><span class=katex-mathml><math display=block><semantics><mrow><mi>I</mi><mo>=</mo><mrow><mi mathvariant=normal>C</mi><mi mathvariant=normal>o</mi><mi mathvariant=normal>v</mi></mrow><mo stretchy=false>[</mo><mover accent=true><mi>z</mi><mo>^</mo></mover><mo stretchy=false>]</mo><mo>=</mo><mi>J</mi><mrow><mi mathvariant=normal>C</mi><mi mathvariant=normal>o</mi><mi mathvariant=normal>v</mi></mrow><mo stretchy=false>[</mo><mover accent=true><mi>x</mi><mo>^</mo></mover><mo stretchy=false>]</mo><msup><mi>J</mi><mi>T</mi></msup><mo>=</mo><mi>J</mi><msup><mi>J</mi><mi>T</mi></msup></mrow><annotation encoding=application/x-tex>I = \mathrm{Cov}[\hat{z}] = J\mathrm{Cov}[\hat{x}]J^T = JJ^T</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07847em>I</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathrm" style=margin-right:0.01389em>Cov</span></span><span class=mopen>[</span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:0.04398em>z</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.1944em><span class=mord>^</span></span></span></span></span></span></span><span class=mclose>]</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.1413em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.09618em>J</span><span class=mord><span class="mord mathrm" style=margin-right:0.01389em>Cov</span></span><span class=mopen>[</span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6944em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">x</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.2222em><span class=mord>^</span></span></span></span></span></span></span><span class=mclose>]</span><span class=mord><span class="mord mathnormal" style=margin-right:0.09618em>J</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8913em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8913em></span><span class="mord mathnormal" style=margin-right:0.09618em>J</span><span class=mord><span class="mord mathnormal" style=margin-right:0.09618em>J</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8913em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span></span></span></span></span></span></span></span></span><p>したがって、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>J</mi><msup><mi>J</mi><mi>T</mi></msup><mo>=</mo><mi>I</mi></mrow><annotation encoding=application/x-tex>JJ^T = I</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8413em></span><span class="mord mathnormal" style=margin-right:0.09618em>J</span><span class=mord><span class="mord mathnormal" style=margin-right:0.09618em>J</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07847em>I</span></span></span></span> となり、<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>J</mi></mrow><annotation encoding=application/x-tex>J</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.09618em>J</span></span></span></span> のすべての特異値は 1 に等しく、これが逆伝播過程で勾配の大きさを保ちます。<p>実際、変換は線形ではなく、正規化値がガウス分布や独立であることも保証されませんが、著者はそれでも BatchNorm が勾配伝播の改善に寄与することを期待しており、その具体的な影響については今後の研究が必要です。</div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=dropout-は不要>Dropout は不要<a href=#dropout-は不要 class=hash-link aria-label="Dropout は不要 への直接リンク" title="Dropout は不要 への直接リンク">​</a></h3>
<p>BatchNorm を使って訓練する場合、訓練サンプルは小バッチ内の他のサンプルとともに観察され、訓練ネットワークは与えられた訓練サンプルに対して確定的な値を生成しなくなります。著者の実験では、この効果がネットワークの汎化に有利であることが分かりました。Dropout は通常、過学習を減らすために使用されますが、BatchNorm を使用した後、Dropout は除去することができます。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=討論>討論<a href=#討論 class=hash-link aria-label="討論 への直接リンク" title="討論 への直接リンク">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=mnist-実験での結果>MNIST 実験での結果<a href=#mnist-実験での結果 class=hash-link aria-label="MNIST 実験での結果 への直接リンク" title="MNIST 実験での結果 への直接リンク">​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=mnist src=/ja/assets/images/img2-74ce6d2d256ab73385329b2617c54111.jpg width=1224 height=440 class=img_ev3q></figure></div>
<p>内部共変量シフトが訓練に与える影響と、BatchNorm がそれに対抗する能力を検証するために、著者は MNIST データセットで数字の分類問題を扱いました。</p>
<p>ここでは、非常にシンプルなネットワークを使用し、入力は 28x28 のバイナリ画像で、隠れ層は 3 層、各層に 100 個のユニットがあります。各隠れ層は <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>y</mi><mo>=</mo><mi>g</mi><mo stretchy=false>(</mo><mi>W</mi><mi>u</mi><mo>+</mo><mi>b</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>y = g(Wu + b)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.13889em>W</span><span class="mord mathnormal">u</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">b</span><span class=mclose>)</span></span></span></span> を計算し、ここで <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>g</mi></mrow><annotation encoding=application/x-tex>g</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>g</span></span></span></span> は Sigmoid 非線形関数、重み<span class=katex><span class=katex-mathml><math><semantics><mrow><mi>W</mi></mrow><annotation encoding=application/x-tex>W</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>W</span></span></span></span>は小さなランダムなガウス値で初期化されます。</p>
<p>最後の隠れ層の後には、10 個のユニット（各クラスに 1 つ）の全結合層があり、交差エントロピー損失を使用します。ネットワークは 50,000 ステップで訓練され、各ミニバッチには 60 個のサンプルが含まれています。最後に、ネットワークの各隠れ層に BatchNorm を追加しました。</p>
<p>上の図は、訓練が進むにつれて、2 つのネットワークがテストデータに対する正しい予測率を保持している様子を示しています。BatchNorm を使用したネットワークは、テスト精度が高くなっています。図(b,c)では、各ネットワークの最後の隠れ層での典型的なアクティベーション値の分布がどのように進化するかを示しています。元のネットワークでは、分布は時間とともに著しく変化し、平均値や分散が変動するため、後続の層の訓練が難しくなります。一方、BatchNorm ネットワークでは、分布は訓練中に安定しており、訓練が容易になります。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=imagenet-実験での結果>ImageNet 実験での結果<a href=#imagenet-実験での結果 class=hash-link aria-label="ImageNet 実験での結果 への直接リンク" title="ImageNet 実験での結果 への直接リンク">​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=imagenet src=/ja/assets/images/img3-7ed16ef5069522a4997d7207a7bdf9e2.jpg width=1116 height=624 class=img_ev3q></figure></div>
<p>著者は次に、BatchNorm を新しい Inception ネットワークの変種に適用し、ImageNet 分類タスクで訓練を行いました。</p>
<p>実験では、BatchNorm を使用したいくつかの Inception の修正バージョンが評価されました。すべての場合において、BatchNorm は各非線形関数の入力に適用され、残りのアーキテクチャは変更されませんでした。</p>
<p>BatchNorm をネットワークに追加するだけでは、この方法の効果を十分に活用することはできません。そこで、著者はネットワークとその訓練パラメータをさらに変更しました：</p>
<ul>
<li><strong>学習率の増加</strong>：BatchNorm モデルでは、学習率を高くすることで訓練速度が向上し、副作用はありません。</li>
<li><strong>Dropout の削除</strong>：前述の通り、BatchNorm は Dropout と同じ目的を達成します。BatchNorm を使用した Inception から Dropout を削除することで、訓練を加速でき、過学習も増加しません。</li>
<li><strong>L2 重み正則化の削減</strong>：Inception では、モデルパラメータに対する L2 損失が過学習を抑制していますが、BatchNorm Inception では、この損失の重みが 5 倍削減されました。</li>
<li><strong>学習率減衰の加速</strong>：Inception の訓練中、学習率は指数関数的に減衰します。BatchNorm ネットワークは Inception よりも訓練速度が速いため、学習率の減衰速度を 6 倍速くしました。</li>
<li><strong>局所応答正規化の削除</strong>：Inception や他のネットワークでは有益ですが、BatchNorm を使用すると必要なくなります。</li>
<li><strong>訓練サンプルのシャッフルの徹底</strong>：著者は訓練データをミニバッチ内でシャッフルし、同じサンプルが常に同じミニバッチに現れないようにしました。これにより、検証精度が約 1％向上し、BatchNorm が正則化器として機能するという見解に一致します。</li>
<li><strong>光度歪みの削減</strong>：BatchNorm ネットワークは訓練速度が速く、各訓練サンプルの観察回数が少ないため、訓練者は「真実に近い」画像に焦点を当てることができ、歪みが減少しました。</li>
</ul>
<p>著者は次のネットワークを評価しました。すべてのネットワークは LSVRC2012 訓練データで訓練され、検証データでテストされました：</p>
<ul>
<li><strong>Inception</strong>：最初に説明したアーキテクチャで、初期学習率は 0.0015 です。</li>
<li><strong>BN-Baseline</strong>：Inception と同じですが、各非線形関数の前に BatchNorm を適用します。</li>
<li><strong>BN-x5</strong>：BatchNorm を使用した Inception。初期学習率は 5 倍に増加し、0.0075 になりました。同じ学習率の増加により、元の Inception のモデルパラメータは機械の限界に達しました。</li>
<li><strong>BN-x30</strong>：BN-x5 と似ていますが、初期学習率は 0.045（Inception の 30 倍）です。</li>
<li><strong>BN-x5-Sigmoid</strong>：BN-x5 に似ていますが、非線形関数として Sigmoid <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>g</mi><mo stretchy=false>(</mo><mi>t</mi><mo stretchy=false>)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo>⁡</mo><mo stretchy=false>(</mo><mo>−</mo><mi>x</mi><mo stretchy=false>)</mo></mrow></mfrac></mrow><annotation encoding=application/x-tex>g(t) = \frac{1}{1+\exp(-x)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=mopen>(</span><span class="mord mathnormal">t</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.3651em;vertical-align:-0.52em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8451em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mop mtight"><span class=mtight>e</span><span class=mtight>x</span><span class=mtight>p</span></span><span class="mopen mtight">(</span><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.394em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.52em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> を使用します。著者はまた、Sigmoid を使って元の Inception を訓練したが、モデル精度は常にランダムに等しかったと報告しています。</li>
</ul>
<p>上の図は、訓練ステップ数に対するネットワークの検証精度の変化を示しています。Inception は 3100 万訓練ステップ後に 72.2％の精度に達しました。以下の表は、各ネットワークが同じ 72.2％の精度に達するのに必要な訓練ステップ数と、ネットワークが達成した最高の検証精度とその精度に達するのに必要なステップ数を示しています。</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt="imagenet table" src=/ja/assets/images/img4-580d43e934ee2251340b393683ae8865.jpg width=1064 height=408 class=img_ev3q></figure></div>
<p>BatchNorm のみ（BN-Baseline）では、Inception の精度を半分以下の訓練ステップで達成しました。BN-x5 は、Inception よりも 14 倍少ないステップで 72.2％の精度を達成しました。興味深いことに、学習率をさらに高める（BN-x30）と、初期の訓練速度は少し遅くなりますが、最終的に高い精度を達成することができます。600 万ステップ後に 74.8％に達し、Inception が 72.2％に達するのに必要なステップ数の 5 倍少ないです。</p>
<p>さらに、著者は、内部共変量シフトの減少が BatchNorm を使用した深層ネットワークが「Sigmoid を非線形関数として使用して訓練できる」ことを示したと検証しました。BN-x5-Sigmoid は 69.8％の精度に達しました。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>ヒント</div><div class=admonitionContent_BuS1><p>Sigmoid を使用してネットワークを訓練することは非常に困難であることは周知の事実であり、BatchNorm なしで Sigmoid を使用した Inception は、精度が 1/1000 を超えることはありませんでした。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=結論>結論<a href=#結論 class=hash-link aria-label="結論 への直接リンク" title="結論 への直接リンク">​</a></h2>
<p>BatchNorm は、各バッチのデータを標準化することによって内部共変量シフト問題を解決します。この方法は、学習過程を安定させるだけでなく、より高い学習率の使用を可能にし、モデル訓練速度を大幅に向上させ、訓練過程で正則化効果を発揮し、過学習を減少させます。</p>
<p>しかし、この技術の効果はバッチサイズに大きく依存します。小さなバッチでは、標準化の安定性が低下し、数値的な安定性の問題を引き起こすことがあります。特に、データの分布が極端な値に近い場合、以前の RepVGG の量子化問題のような問題が発生することがあります：</p>
<ul>
<li><a href=/ja/papers/reparameterization/qarepvgg/><strong>[22.12] QARepVGG: RepVGG を再び偉大にする</strong></a></li>
</ul>
<p>最後に、訓練と推論の段階で BatchNorm の挙動には違いがあり、これはエンジニアがよく遭遇する問題です。訓練時には現在のバッチの統計を使用しますが、推論時には通常、全訓練データセットのグローバルな統計を使用します。この違いは、モデルが訓練時と推論時で異なる性能を示す原因となります。</p>
<p>実際の応用では、BatchNorm を使用する際にこれらの要因を慎重に考慮し、モデルが異なるシナリオにうまく適応できるようにする必要があります。</header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated><b><time datetime=2024-12-10T14:04:39.000Z itemprop=dateModified>2024年12月10日</time></b>に<b>zephyr-sh</b>が<!-- -->最終更新</span></div></div><div style=margin-top:3rem> </div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label=ドキュメントページ><a class="pagination-nav__link pagination-nav__link--prev" href=/ja/papers/category/normalization-1><div class=pagination-nav__sublabel>前へ</div><div class=pagination-nav__label>Normalization (1)</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/ja/papers/category/object-detection-8><div class=pagination-nav__sublabel>次へ</div><div class=pagination-nav__label>Object Detection (8)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#バッチ正規化 class="table-of-contents__link toc-highlight">バッチ正規化</a><li><a href=#定義問題 class="table-of-contents__link toc-highlight">定義問題</a><li><a href=#解決問題 class="table-of-contents__link toc-highlight">解決問題</a><ul><li><a href=#学習率の向上 class="table-of-contents__link toc-highlight">学習率の向上</a><li><a href=#dropout-は不要 class="table-of-contents__link toc-highlight">Dropout は不要</a></ul><li><a href=#討論 class="table-of-contents__link toc-highlight">討論</a><ul><li><a href=#mnist-実験での結果 class="table-of-contents__link toc-highlight">MNIST 実験での結果</a><li><a href=#imagenet-実験での結果 class="table-of-contents__link toc-highlight">ImageNet 実験での結果</a></ul><li><a href=#結論 class="table-of-contents__link toc-highlight">結論</a></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/ja/docs>オープンソースプロジェクト</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/papers/intro>論文ノート</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/blog>ブログ</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/terms-of-service>利用規約</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/privacy-policy>プライバシーポリシー</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/become-an-author>著者になる</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/worklog>作業日誌</a><span class=footer__link-separator>·</span><a href=https://buymeacoffee.com/docsaid target=_blank rel="noopener noreferrer" class=footer__link-item>サポートする<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>