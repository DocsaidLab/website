<!doctype html><html lang=ja dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-retail-product/retail-product-recognition-review/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.8.1"><title data-rh=true>[20.11] RPR: Review | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/ja/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/ja/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/ja/papers/retail-product/retail-product-recognition-review/><meta data-rh=true property=og:locale content=ja><meta data-rh=true property=og:locale:alternate content=zh_hant><meta data-rh=true property=og:locale:alternate content=en><meta data-rh=true name=docusaurus_locale content=ja><meta data-rh=true name=docsearch:language content=ja><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[20.11] RPR: Review | DOCSAID"><meta data-rh=true name=description content=小売商品認識><meta data-rh=true property=og:description content=小売商品認識><link data-rh=true rel=icon href=/ja/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/ja/papers/retail-product/retail-product-recognition-review/><link data-rh=true rel=alternate href=https://docsaid.org/papers/retail-product/retail-product-recognition-review/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/retail-product/retail-product-recognition-review/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/retail-product/retail-product-recognition-review/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/retail-product/retail-product-recognition-review/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://docsaid.org/ja/papers/category/retail-product","name":"Retail Product (6)","position":1},{"@type":"ListItem","item":"https://docsaid.org/ja/papers/retail-product/retail-product-recognition-review/","name":"[20.11] RPR: Review","position":2}]}</script><link rel=alternate type=application/rss+xml href=/ja/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/ja/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/ja/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/ja/assets/css/styles.33bb565a.css><script src=/ja/assets/js/runtime~main.6237656d.js defer></script><script src=/ja/assets/js/main.90fbb82b.js defer></script><body class=navigation-with-keyboard><svg xmlns=http://www.w3.org/2000/svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light",e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label=メインコンテンツまでスキップ><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>メインコンテンツまでスキップ</a></div><nav aria-label=ナビゲーション class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label=ナビゲーションバーを開く aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/ja/><div class=navbar__logo><img src=/ja/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/ja/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/ja/docs/>オープンソースプロジェクト</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/ja/papers/intro>論文ノート</a><a class="navbar__item navbar__link" href=/ja/blog>ブログ</a><a class="navbar__item navbar__link" href=/ja/playground/intro>遊び場</a><a class="navbar__item navbar__link" href=/ja/services>技術サービス</a><a class="navbar__item navbar__link" href=/ja/aboutus>私たちについて</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>日本語</a><ul class=dropdown__menu><li><a href=/papers/retail-product/retail-product-recognition-review/ target=_self rel="noopener noreferrer" class=dropdown__link lang=zh-hant>繁體中文</a><li><a href=/en/papers/retail-product/retail-product-recognition-review/ target=_self rel="noopener noreferrer" class=dropdown__link lang=en>English</a><li><a href=/ja/papers/retail-product/retail-product-recognition-review/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="検索 (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>検索</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-mc1tut ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label=先頭へ戻る class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/ja/><img src=/ja/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/ja/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label=ドキュメントのサイドバー class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/ja/papers/intro>論文ノート</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/classic-cnns>Classic CNNs (11)</a><button aria-label="'Classic CNNs (11)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/contrastive-learning>Contrastive Learning (14)</a><button aria-label="'Contrastive Learning (14)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/deepseek>DeepSeek (5)</a><button aria-label="'DeepSeek (5)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/face-antispoofing>Face Anti-Spoofing (43)</a><button aria-label="'Face Anti-Spoofing (43)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/face-recognition>Face Recognition (4)</a><button aria-label="'Face Recognition (4)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/feature-fusion>Feature Fusion (10)</a><button aria-label="'Feature Fusion (10)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/image-generation>Image Generation (1)</a><button aria-label="'Image Generation (1)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/lightweight>Lightweight (10)</a><button aria-label="'Lightweight (10)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/mamba>Mamba (4)</a><button aria-label="'Mamba (4)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/model-tuning>Model Tuning (8)</a><button aria-label="'Model Tuning (8)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/multimodality>Multimodality (24)</a><button aria-label="'Multimodality (24)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/normalization>Normalization (1)</a><button aria-label="'Normalization (1)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/object-detection>Object Detection (21)</a><button aria-label="'Object Detection (21)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/reparameterization>Reparameterization (8)</a><button aria-label="'Reparameterization (8)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/ja/papers/category/retail-product>Retail Product (6)</a><button aria-label="'Retail Product (6)'の目次を隠す" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/retail-product/rpc/>[19.01] RPC Dataset</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/retail-product/sku-110k/>[19.04] SKU-110K</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/retail-product/dpsnet/>[20.11] DPSNet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/ja/papers/retail-product/retail-product-recognition-review/>[20.11] RPR: Review</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/retail-product/deepaco/>[22.06] DeepACO</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/retail-product/checksort/>[23.06] CheckSORT</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/segmentation>Segmentation (1)</a><button aria-label="'Segmentation (1)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/text-detection>Text Detection (14)</a><button aria-label="'Text Detection (14)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/text-recognition>Text Recognition (20)</a><button aria-label="'Text Recognition (20)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/text-spotting>Text Spotting (4)</a><button aria-label="'Text Spotting (4)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/transformers>Transformers (17)</a><button aria-label="'Transformers (17)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/vision-transformers>Vision Transformers (13)</a><button aria-label="'Vision Transformers (13)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/ja/papers/intro>All Notes: 240 entries</a></ul></nav><button type=button title=サイドバーを隠す aria-label=サイドバーを隠す class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=パンくずリストのナビゲーション><ul class=breadcrumbs><li class=breadcrumbs__item><a aria-label=ホームページ class=breadcrumbs__link href=/ja/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li class=breadcrumbs__item><a class=breadcrumbs__link href=/ja/papers/category/retail-product><span>Retail Product (6)</span></a><li class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>[20.11] RPR: Review</span></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">このページの見出し</button></div><div class="theme-doc-markdown markdown"><header><h1>[20.11] RPR: Review</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt="Z. Yuan" class=docAuthorImg_vlJe><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Z. Yuan</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a href=https://www.linkedin.com/in/ze-yuan-sh7/ target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 448 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=小売商品認識>小売商品認識<a href=#小売商品認識 class=hash-link aria-label="小売商品認識 への直接リンク" title="小売商品認識 への直接リンク">​</a></h2>
<p><a href=https://onlinelibrary.wiley.com/doi/pdf/10.1155/2020/8875910 target=_blank rel="noopener noreferrer"><strong>Deep Learning for Retail Product Recognition: Challenges and Techniques</strong></a></p>
<hr>
<p>最近、自動レジ（Automatic Check-Out, ACO）分野の参考文献を整理し直した。</p>
<p>まずは、いくつかのレビュー論文からこの分野の全体像を素早く理解する。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=問題の定義>問題の定義<a href=#問題の定義 class=hash-link aria-label="問題の定義 への直接リンク" title="問題の定義 への直接リンク">​</a></h2>
<p>小売商品認識技術（Retail Product Recognition）の主な目的は、小売業者が効果的に商品管理を行い、顧客の購買体験を向上させることにある。これまで最も広く使われてきた技術はバーコード認識であり、商品の包装に印刷されたバーコードをスキャンすることで商品情報の自動取得を実現している。</p>
<p>しかし、バーコードの印刷位置は固定されておらず、実際の運用ではスキャナーに合わせるために商品を手動で回転させる必要が多く、これが処理の遅延を招いている。</p>
<p>Digimarc の調査によると、約 45%の顧客がバーコードのスキャンが不便だと感じている。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>ヒント</div><div class=admonitionContent_BuS1><p>Digimarc Corporation はアメリカ・オレゴン州ビーバートンに本社を置く上場企業であり、デジタル不可視ウォーターマークやシリアライズされた QR コードなどの認識技術を開発し、製品の真偽認証、サプライチェーン追跡、リサイクル分別などの応用を強化している。</div></div>
<p>この状況において、RFID 技術は潜在的な代替手段とみなされる可能性がある。無線電波を用いてデータを送信するため、視線スキャンに依存せずに認識作業を行うことができ、理論的には効率の優位性を持つ。各商品に独立したタグを付け、遠距離から読み取りが可能であり、一つずつ位置合わせする必要がない。</p>
<p>欠点はコストが高いことである。</p>
<p>小売業というコスト競争の激しい業界では、商品一つにつき 1 枚の RFID タグを消費するため、積み重なるとかなりの出費となる。また、複数商品の同時認識時には、信号が遮蔽や干渉によって誤動作する可能性があり、大量販売される商品にとってはコスト管理上の課題となる。</p>
<p>小売産業の急速なデジタル化に伴い、企業は人工知能技術を活用して運営効率と顧客体験の向上を目指している。</p>
<p>Juniper Research の報告によると、世界の小売業者による AI 関連サービスへの支出は 2019 年の 36 億ドルから 2023 年には 120 億ドルに成長すると予測されており、この種の技術への高い投資意欲を示している。一方で、スーパーマーケットの陳列商品数は増加の一途をたどり、人手による管理コストも著しく上昇しており、より高い自動化レベルの認識ソリューションを模索する動機となっている。</p>
<p>デジタルカメラ機器の普及は大量の商品画像データの生成を促進し、コンピュータビジョン認識システムの発展における重要な基盤となっている。</p>
<p>商品認識タスクは画像分類と物体検出を統合した問題とみなすことができ、その核心目標は画像から自動的に商品カテゴリと位置を認識することである。この技術は以下のような多様なシーンに応用可能である：</p>
<ol>
<li><strong>棚管理</strong>：欠品商品を自動検出し、スタッフに補充を促す。研究によれば、棚計画の完全実施により売上が 7.8%、粗利益が 8.1%向上するとされる。</li>
<li><strong>セルフレジシステム</strong>：商品画像認識を通じて会計時間を短縮し、顧客満足度を高める。SCO システムは 2014 年から 2019 年にかけて継続的に成長し、人件費削減のため広く導入されている。</li>
<li><strong>視覚障害者支援</strong>：視覚障害者が商品情報（価格、ブランド、賞味期限など）を認識する手助けをし、買い物のハードルを下げ、自立性と社会参加を向上させる。</li>
</ol>
<p>技術的には、従来の手工特徴量手法と比較して、深層学習は画像から直接特徴を自動学習でき、高い認識性能と汎化能力を持つ。また、多層構造によりより細かな意味情報を抽出でき、複雑かつ多カテゴリの商品シーンに適している。</p>
<p>現在、複数の研究チームが小売分野に深層学習を適用し、多様なタスクで具体的な成果を挙げている。業界においても Amazon Go や Walmart Intelligent Retail Lab などの応用例が登場している。</p>
<p>近年、関連研究の成果は増加傾向にあるものの、「商品認識タスクにおける深層学習」についての体系的なレビューは依然として非常に限られている。過去には小売棚商品検出に関する 2 件のサーベイ論文が発表されたが、どちらもレジのシーンを含まず、深層学習手法に特化していなかった。</p>
<p>本論文の著者は、CVPR、ICCV、AAAI など主要会議やジャーナルの 100 本以上の文献をレビューし、現状の技術、課題、資源を統合しようとしている。本論文がこの分野の研究者やエンジニアの入門指針となり、核心課題や既存成果の迅速な把握に役立つことを期待している。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>ヒント</div><div class=admonitionContent_BuS1><p>私たちはこうした熱意ある著者を非常に好感している。感謝してもしきれない。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=伝統的手法>伝統的手法<a href=#伝統的手法 class=hash-link aria-label="伝統的手法 への直接リンク" title="伝統的手法 への直接リンク">​</a></h2>
<p>商品画像認識の核は、パッケージ画像から代表的な特徴を抽出し、分類・認識タスクを完遂することである。</p>
<p>初期のコンピュータビジョン研究では、モジュール化された処理フローを採用し、認識システムを以下の主要ステップに分割していた：</p>
<ol>
<li><strong>画像取得</strong>：カメラやスマートフォン等の装置で商品画像を収集する。</li>
<li><strong>前処理</strong>：入力画像に対しノイズ除去や情報簡略化を行う。画像分割、幾何変換、コントラスト強調などを含む。</li>
<li><strong>特徴抽出</strong>：位置やサイズの変化に影響されない安定した特徴を画像領域から解析する。</li>
<li><strong>特徴分類</strong>：抽出された特徴をベクトル空間にマッピングし、特定の分類アルゴリズムで予測を行う。</li>
<li><strong>認識出力</strong>：事前学習済み分類器により商品カテゴリ結果を出力する。</li>
</ol>
<p>この構造の中で重要なステップは「特徴抽出」であり、その精度が最終的な認識性能に直結する。深層学習普及以前は、研究者は手作りの特徴に依存して画像の視覚的特性を捉えていた。</p>
<p>代表的な 2 つの手法は：</p>
<ul>
<li><strong>SIFT（Scale-Invariant Feature Transform）</strong>：1999 年に David Lowe が提案。画像ピラミッド構造を用いて多尺度領域の局所特徴を抽出し、回転・平行移動・スケール変化に不変な特徴を持つ。物体マッチングや分類タスクで広く利用された。</li>
<li><strong>SURF（Speeded Up Robust Features）</strong>：2006 年に SIFT を基に開発され、計算効率を最適化。リアルタイム性が求められる応用に適用された。</li>
</ul>
<p>しかし、これらの特徴は手作りであり、開発者の経験や仮定に依存するため、画像中の全ての潜在的な重要情報を網羅できない。また、商品種別が多くパッケージデザインに大きな差異があり、撮影条件（角度、照明）が変動すると、手作り特徴は認識の安定性や拡張性を維持しにくい。これが、研究コミュニティがデータ駆動型の深層学習へ徐々に転換し、エンドツーエンドで画像から最も判別力のある特徴表現を学習する方向へ動いた背景である。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=深層学習手法>深層学習手法<a href=#深層学習手法 class=hash-link aria-label="深層学習手法 への直接リンク" title="深層学習手法 への直接リンク">​</a></h2>
<p>深層学習は機械学習のサブフィールドであり、データから自動的に多層の表現を学習し、高次の意味構造を捉えることを目標とする。この手法は手作り特徴の限界を回避し、画像・音声・テキストなど高次元データに特に適している。</p>
<p>画像認識タスクにおいては、GPU 計算能力の向上により深層学習の優位性が拡大し、伝統的手法に取って代わり主流となった。現在、零售商品認識での応用は主に以下の二大タスクに分かれる：</p>
<ol>
<li><strong>画像分類（Image Classification）</strong>：入力画像を所定のカテゴリに分類。十分な訓練データがある場合、モデルの分類精度は人間の水準を超える。</li>
<li><strong>物体検出（Object Detection）</strong>：分類に加え、画像中の物体位置（バウンディングボックス）を返す。モデル設計や計算効率に高い要求があり、商品認識に不可欠なモジュール。</li>
</ol>
<p>深層学習の画像分野における突破口は畳み込みニューラルネットワーク（CNN）である。この構造は猫の視覚皮質の生理学研究に着想を得ており、LeCun らが 1988 年に初めて CNN を用いた画像分類モデルを提案し、手書き数字や小切手認識で成功した。</p>
<p>2010 年以降、ImageNet チャレンジの推進で CNN 構造は急速に進化し、多くの主流アーキテクチャが誕生した：</p>
<ul>
<li><strong>AlexNet (2012)</strong>：ReLU や Dropout を導入し、従来の画像認識の限界を打破、深層学習ブームを牽引。</li>
<li><strong>GoogLeNet (2014)</strong>：Inception モジュール採用によりパラメータ数削減とモデルの深層化を実現。</li>
<li><strong>VGG (2014)</strong>：3x3 畳み込みカーネルに統一し、構造の組み合わせや再利用を容易に。</li>
<li><strong>ResNet (2015)</strong>：残差接続を提案し、深層化による性能劣化問題を解決、100 層以上のモデル訓練を可能に。</li>
</ul>
<p>近年は CNN の応用を 3D 構造認識へ拡張した多視点 CNN（Multiview CNN）も研究され、多角度画像を同時入力し高精度分類を実現、立体商品認識等の高度タスクに適用されている。</p>
<p>まとめると、深層学習の二大推進力は「大規模データ」と「より深いネットワーク構造」であり、これらが相乗効果を生み、視覚認識モデルの進化を促進し、商品認識システムの技術的基盤を築いている。</p>
<p>物体検出タスクに話を戻す。</p>
<p>深層学習技術における物体検出の核心目標は、</p>
<blockquote>
<p><strong>画像から対象物のカテゴリと位置（バウンディングボックス）を自動的に識別すること。</strong></p>
</blockquote>
<p>深層学習導入前は、スライディングウィンドウ手法が主流で、画像全体に一定サイズのウィンドウを滑らせ、区画ごとに分類判定していた。しかし、大サイズ画像や多数物体シーンでは計算量が膨大で非効率だった。</p>
<p>深層学習を用いた物体検出アルゴリズムは大きく二系統に分かれる：</p>
<ul>
<li>
<p><strong>Two-stage 法（領域提案優先）</strong>
R-CNN シリーズに代表され、第一段階で Selective Search などの領域提案アルゴリズムにより候補領域を生成し、第二段階で CNN により分類・位置回帰を行う。</p>
<ul>
<li>R-CNN：各候補領域を個別に CNN 処理し精度向上も速度遅延。</li>
<li>Fast R-CNN：画像全体を CNN 処理し、特徴マップ上で ROI プーリングを行い重複計算削減。</li>
<li>Faster R-CNN：RPN（Region Proposal Network）を導入し、特徴共有で領域提案を深層学習に統合、精度と速度を両立。</li>
</ul>
</li>
<li>
<p><strong>One-stage 法（エンドツーエンド回帰）</strong>
領域提案段階を省略し、直接画像から物体の位置とカテゴリを回帰する。高速だが初期は精度が若干劣る。</p>
<ul>
<li>YOLO（You Only Look Once）や SSD（Single Shot MultiBox Detector）が代表例であり、リアルタイム性が重要な即時会計や視覚ナビゲーションで優位。</li>
</ul>
</li>
</ul>
<p>両者は特性が異なり、Two-stage は複雑背景での安定性が高く、One-stage は遅延要件の低い環境に適する。実用では精度と速度のトレードオフを考慮し選択される。</p>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=画像ベースの商品認識パイプライン src=/ja/assets/images/img1-71e1d4e810038c545f9d4251984afc04.jpg width=1508 height=580 class=img_ev3q></figure></div>
<p>商品認識タスクは技術的に物体検出の特殊ケースとみなせる。典型的な流れは上図の通り：</p>
<ol>
<li><strong>商品検出</strong>：物体検出モデルで複数のバウンディングボックスを生成し、商品領域を示す。</li>
<li><strong>領域切り出し</strong>：予測領域ごとに単一商品画像を切り出す。</li>
<li><strong>画像分類</strong>：切り出した画像を分類モデルに入力し、商品カテゴリを推定する。</li>
</ol>
<p>近年、多数の企業が深層学習を小売分野に導入している：</p>
<ul>
<li><strong>Amazon Go（2018）</strong>：数十台のカメラで顧客動線を取得し、CNN モデルで購買行動と商品を認識。純粋な画像認識の不足を補うため、Bluetooth や重量センサーも活用し全体精度を向上。</li>
<li><strong>Walmart IRL（2019）</strong>：棚のリアルタイム監視に注力し、カメラと深層学習で欠品を自動検知し補充を促す。</li>
<li><strong>中国企業（DeepBlue Technology、Malong Technologies）</strong>：統合型自動販売機、スマート計量システム、商品認識モジュールを提供し、商品画像分析、即時会計、分類推薦を実現。Malong の AI Fresh は特に生鮮商品向けに設計され、非構造化視覚特徴（果物や野菜の外観変異）を扱う。</li>
</ul>
<p>現状を見ると、商用展開は始まっているものの、深層学習による商品認識技術には依然として多くの課題が残る：</p>
<ul>
<li>精度と推論速度のバランス調整；</li>
<li>視覚的に類似した異商品間の誤認識；</li>
<li>多カテゴリデータの不均衡、長尾分布の顕著さ；</li>
<li>導入コストと複数デバイスの安定運用；</li>
<li>遮蔽、反射、手の干渉など実環境での非理想条件への対応困難。</li>
</ul>
<p>これらを踏まえ、深層学習は商品認識で最も有望な手法であるものの、技術応用はさらなる実証研究と大規模現場展開により洗練・最適化される必要がある。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=商品認識の課題>商品認識の課題<a href=#商品認識の課題 class=hash-link aria-label="商品認識の課題 への直接リンク" title="商品認識の課題 への直接リンク">​</a></h2>
<p>商品認識は物体検出タスクの応用変形にあたるが、実際の環境は一般的な物体検出と大きく異なり、既存モデルの直接転用が困難である。</p>
<p>本章では、小売商品認識が直面する 4 大課題を整理した。以下に主要な 4 つの問題を示す。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=課題-1クラス数の大規模化>課題 1：クラス数の大規模化<a href=#課題-1クラス数の大規模化 class=hash-link aria-label="課題 1：クラス数の大規模化 への直接リンク" title="課題 1：クラス数の大規模化 への直接リンク">​</a></h3>
<p>一般的な物体検出と比較し、商品認識の最大の特徴は「<strong>クラス数が標準データセットを大きく上回ること</strong>」である。</p>
<p>中規模スーパーマーケットの在庫単位（SKU）は数千に及び、一般的なデータセットを大幅に超過する。さらに、実際の小売シーンでは 1 枚の画像に十数種の商品が含まれ、同一ブランドの異なる仕様など、クラス間の差異は非常に微細であり、検出難度は格段に高い。</p>
<p>また、Faster R-CNN、YOLO、SSD など主流モデルは固定クラス数を前提としており、クラス数が数千に拡大すると精度・再現率が大幅に低下する。</p>
<p>論文内の実験結果（下図参照）では、</p>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt="large classes" src=/ja/assets/images/img2-d22281f4b59a1045a398a579f7c303de.jpg width=1176 height=856 class=img_ev3q></figure></div>
<p>いずれのモデルにおいても、<strong>クラス数が 20 から 80 に増加すると全体精度が著しく低下する</strong>。</p>
<p>よって商品認識では、従来の物体検出アーキテクチャに頼るだけでは、高次元分類による学習困難と推論の不安定化が避けられない。これはモデル設計のみならず、データ分布、クラス間差異表現、分類戦略設計など多面的課題を含む。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=課題-2データ分布のギャップ>課題 2：データ分布のギャップ<a href=#課題-2データ分布のギャップ class=hash-link aria-label="課題 2：データ分布のギャップ への直接リンク" title="課題 2：データ分布のギャップ への直接リンク">​</a></h3>
<p>深層学習モデルは大量の注釈付きデータを必要とするが、商品認識分野におけるデータ収集は以下の 3 点で制約がある：</p>
<ol>
<li><strong>注釈コストの高さ</strong>：
バウンディングボックスやセグメンテーションの注釈は多くが手作業であり、数万枚の訓練データ生成は多大な労力と時間を要する。LabelImg や LabelMe などのツール支援があっても、スケール拡大は難しい。</li>
</ol>
<p><img decoding=async loading=lazy alt="domain gap" src=/ja/assets/images/img3-029aad43816b45a288c2e637a287d32b.jpg width=1584 height=374 class=img_ev3q></p>
<ol start=2>
<li><strong>訓練データと実環境のドメインギャップ</strong>：
既存商品データは固定角度かつ単純背景（例：回転台での撮影）など理想環境で収集される。一方、テスト・実運用環境は複雑背景、変動光源、頻繁な遮蔽があるため、モデルの性能に乖離が生じる。</li>
</ol>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt="domain gap" src=/ja/assets/images/img4-1de51520d838b446530489d3331c1b25.jpg width=1224 height=464 class=img_ev3q></figure></div>
<ol start=3>
<li><strong>データの不均衡とロングテール分布</strong>：
商品データセットは「少数サンプル・多数クラス」の特徴を持つ。VOC や COCO のように均衡を重視したデータセットとは対照的に、商品認識では画像数が少なくクラス数が多いため、モデル学習が困難である。</li>
</ol>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=unbalance src=/ja/assets/images/img5-e3d6023a6002f0e5286859cefe24c186.jpg width=1196 height=680 class=img_ev3q></figure></div>
<p>以上より、データ不足はモデル性能を制限するだけでなく、汎化能力の向上や新商品への迅速な転移学習も妨げる。データ不足と実務環境の分布差を系統的に解決しない限り、高度なモデル設計も実運用に耐えられない。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=課題-3クラス内変異>課題 3：クラス内変異<a href=#課題-3クラス内変異 class=hash-link aria-label="課題 3：クラス内変異 への直接リンク" title="課題 3：クラス内変異 への直接リンク">​</a></h3>
<p>商品認識の大きな難題は、「クラス内異質性が高い製品の正確な識別」、すなわち「サブクラス認識」や「細粒度分類（fine-grained classification）」である。</p>
<p>この課題には以下の特徴がある：</p>
<ol>
<li><strong>視覚差異が極めて微細</strong>：
同一ブランドの異なるフレーバーのクッキーや異サイズ包装は、色彩の飽和度や文字位置の微差程度で、肉眼でも識別困難な場合がある。</li>
<li><strong>多様な外観変異</strong>：
同一製品が異なる角度・拡大率で明確に外観が変わり、モデルはスケール・視点不変性を求められる。</li>
<li><strong>環境ノイズの大きさ</strong>：
照明、背景、遮蔽が識別に大きく影響し、モデルの判別境界を複雑化する。</li>
</ol>
<p>細粒度分類は鳥種識別や車種分類など他分野で専用技術が発展しているが、多くは追加注釈（キーポイントや部位アライメント）を利用し微細差を学習する。一方、商品認識への適用は以下の点で難易度が高い：</p>
<ul>
<li>商品間の視覚類似度は外形のみならず、包装構造、色彩、書体まで高度に重複する。</li>
<li>専用の細粒度商品データセットが不足し、既存データは全体カテゴリ注釈に留まり、サブクラス定義が不十分。</li>
<li>追加注釈や専門知識なしでは、モデルは効果的な区別戦略を学習しづらく、誤認率が増加する。</li>
</ul>
<p>例として、下図 (a) は類似する 2 種の異なるフレーバー製品を示す。</p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt="intraclass products" src=/ja/assets/images/img6-326ad5eddf6574487948d7db965ccf5b.jpg width=1212 height=360 class=img_ev3q></figure></div>
<p>文字色や位置の微調整が差異であり、(b) は同ブランドの異容量包装を示すが、単一画像からサイズ差を判別するのは困難である。これらは実環境で「極めて似るが同一でない」識別を要求される細かな表現力を示す。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=課題-4システムの柔軟性不足>課題 4：システムの柔軟性不足<a href=#課題-4システムの柔軟性不足 class=hash-link aria-label="課題 4：システムの柔軟性不足 への直接リンク" title="課題 4：システムの柔軟性不足 への直接リンク">​</a></h3>
<p>小売業は商品入れ替えが激しく、新製品の継続的な投入や包装変更が頻繁である。商品画像認識システムが新製品ごとにモデルを全面再訓練するのは時間・労力の面で非効率であり、実用性を損なう。</p>
<p>理想的システムは以下を備えるべきである：</p>
<ul>
<li><strong>迅速な拡張性</strong>：少数ショットやゼロショット学習により新クラスを追加可能。</li>
<li><strong>継続学習能力</strong>：旧クラス知識を忘れずに新製品を学習（continual / lifelong learning）。</li>
</ul>
<p>しかし、CNN 構造は「破滅的忘却（catastrophic forgetting）」問題を抱える。新クラスで微調整すると既存クラス識別能力が著しく低下する。</p>
<p>下図の例では、</p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt="new classes" src=/ja/assets/images/img7-80b439ddf15c1a3e526f133e23b72cae.jpg width=1224 height=712 class=img_ev3q></figure></div>
<p>元は orange を検出可能であったが、banana クラスのみの更新後、orange 識別能力が失われている。</p>
<p>現状の主流は全データで再訓練する手法であり、実務における展開コストや効率面のボトルネックとなる。将来は以下特性を持つ認識モデル開発が望まれる：</p>
<ul>
<li>長期記憶能力を備えること。</li>
<li>クラス追加のインクリメンタルトレーニング対応。</li>
<li>サンプル記憶や正則化に基づくリプレイ戦略で忘却を抑制。</li>
</ul>
<p>商品認識システムの「柔軟性」は急変市場での実用性と寿命を決定づける要素である。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=技術概観>技術概観<a href=#��技術概観 class=hash-link aria-label="技術概観 への直接リンク" title="技術概観 への直接リンク">​</a></h2>
<p>本章では前節で挙げた 4 つの主要課題に対し、既存文献で提案されている対応技術を整理する。深層学習を核とした認識アーキテクチャを中心に、これと組み合わせ可能な補助的手法も合わせて紹介する。</p>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt=techniques src=/ja/assets/images/img8-dc52ef5fa133476b5ebd7a7362376b68.jpg width=1164 height=832 class=img_ev3q></figure></div>
<p>この分類整理により、読者は商品認識タスクの解決手法の全体像と研究動向をより迅速に把握できる。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>備考</div><div class=admonitionContent_BuS1><p>本稿では以降、文献番号を【xx】の形式で示し、原著論文の参考文献に対応させている。詳細を調べたい場合は該当番号をもとに原論文を参照されたい。</div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=畳み込みネットワークに基づく手法>畳み込みネットワークに基づく手法<a href=#畳み込みネットワークに基づく手法 class=hash-link aria-label="畳み込みネットワークに基づく手法 への直接リンク" title="畳み込みネットワークに基づく手法 への直接リンク">​</a></h3>
<p>小売商品分類タスクの核心的課題の一つは、大規模なクラス数の処理である。この背景のもと、CNN モデルは画像特徴抽出段階で広く用いられ、特徴記述子として識別可能な埋め込みベクトルを生成し、分類や類似度検索に利用される。</p>
<p>初期の SIFT や SURF といった手作り特徴は回転・スケール不変性を持つものの、意味的な階層表現を欠き、大規模クラス認識には対応困難であったため、徐々に CNN に置き換えられた。</p>
<p>以下に代表的な研究を示す。詳細は文献番号を参照されたい。</p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=cnn-based src=/ja/assets/images/img9-343d8c002016ade55b458913b2b4b2fc.jpg width=1208 height=424 class=img_ev3q></figure></div>
<p>多くの手法は数百〜千クラスの商品分類を支援可能だが、中大型スーパーではクラス数がこれを大幅に上回るため、さらなる性能向上が求められる。最近では千クラス超の分類に挑戦する代表的な研究がある：</p>
<ol>
<li><strong>Tonioni et al.【20】</strong>：VGG をバックボーンに用い、MAC（Maximum Activations of Convolutions）特徴で全画像埋め込みを構築。3,288 クラスを扱い、Precision=57.07%、mAP=36.02%を達成。</li>
<li><strong>Karlinsky et al.【21】</strong>：微調整した VGG-F（層 2–15 を固定）を採用し、3,235 クラスの認識に対応、最終的に mAP=52.16%を実現。</li>
</ol>
<p>これらの研究から、CNN は千クラス規模まで拡張可能な潜力を持つ一方で、特に再現率や細粒度識別能力の面でまだ改善余地が大きいことが示唆される。</p>
<p>また、YOLO9000 は改良版 Darknet を用い 9,000 クラス同時認識可能な検出フレームワークを提案。複数データセットの合同訓練と WordTree のような意味埋め込みが鍵となっている。しかし、数百万の注釈画像を必要とし、商品データが取得困難・注釈コストが高い小売現場への適用は難しい。</p>
<p>まとめると、CNN は大規模クラスの商品分類に実用的な基盤を提供するものの、「クラス数爆発」へのスケーラビリティ、データ効率、認識精度向上が今後の重要課題である。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=データ拡張>データ拡張<a href=#データ拡張 class=hash-link aria-label="データ拡張 への直接リンク" title="データ拡張 への直接リンク">​</a></h3>
<p>深層学習は大量の訓練データに依存するが、小売商品認識では注釈付きデータの取得が時間的・経済的に困難なため、データ拡張が重要な対策となる。</p>
<p>代表的なデータ拡張技術は以下の 2 分類に分けられる。関連文献は表を参照。</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=cnn-based src=/ja/assets/images/img10-756f3e37d3ed8f7b07a1d04405667da7.jpg width=1212 height=272 class=img_ev3q></figure></div>
<ul>
<li><strong>従来型画像変換（common synthesis methods）</strong></li>
<li><strong>生成モデル（generative models）</strong></li>
</ul>
<p>従来のデータ合成は幾何学的・光学的変換により原画像を拡張する手法が中心である（以下図）。</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt="common synthesis methods" src=/ja/assets/images/img11-1656609ca0ec0bd52883afbbc48b5c84.jpg width=1224 height=808 class=img_ev3q></figure></div>
<p>例えば <a href=https://github.com/albumentations-team/albumentations target=_blank rel="noopener noreferrer"><strong>Albumentations</strong></a> は平行移動、回転、スケーリング、鏡映、ランダム遮蔽、ノイズ付加、色調補正、輝度・コントラスト調整など多彩な API を備え、商品検出タスクで広く用いられている。</p>
<p>しかし、これら合成手法は実際の複雑な照明変化や背景ノイズ、自然遮蔽などの条件を模擬するのが困難であるため、よりリアルなデータ生成を求めて生成モデルへ注目が移っている。</p>
<p>生成モデルはより高いリアリティを持つ画像合成を可能にし、主に以下 2 種の構造がある：</p>
<ul>
<li><strong>VAE（Variational Autoencoder）</strong>
エンコーダ・デコーダ構造で潜在空間分布を学習しサンプル生成、特徴学習や属性制御に適するが、画像変換には未だ課題が多い。</li>
<li><strong>GAN（Generative Adversarial Networks）</strong>
生成器と識別器の対抗学習により視覚的に逼真なサンプルを生成し、画像間のスタイル変換や合成に強みを持つ。</li>
</ul>
<p>関連研究は以下の通り。</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=gan-based src=/ja/assets/images/img12-de359f41f8084e0dea3e3fdebe1e41ec.jpg width=1204 height=640 class=img_ev3q></figure></div>
<p>VAE はエンコーダ・デコーダによる潜在空間学習を通じ原データに類似したサンプル生成を可能とする。商品認識分野への応用例はまだ少ないが、顔や鳥類画像生成では属性制御を実現し、Wild や CUB データセットで高い類似度を達成している【101】。また conditional VAE を用いた zero-shot 学習も標準データセットで好成績を収めている【112】。これらは多様性強化と属性制御の可能性を示し、将来的に商品認識へ展開される可能性がある。</p>
<p>一方、GAN は 2014 年提案以来、生成器・識別器の対抗訓練で多くの逼真画像を生み出し、多様なデータ拡張タスク（夜間車両検出【115】、半教師あり意味的ハッシュ【116】、車牌画像生成【122】など）でモデル性能を向上させている。PixelCNN と one-hot クラス符号化で特定クラス画像を生成【119】や CycleGAN によるスタイル変換・実環境シミュレーションも良好な一般化性能を示す。</p>
<p>商品認識領域での GAN 応用は少ないが、いくつかの研究で有効性が示されている。例えば Wei ら【7】は背景合成と CycleGAN スタイル変換でレジ環境に適合した商品画像を生成し、FPN 検出器で 96.57% mAP を達成（下図）。</p>
<p><img decoding=async loading=lazy alt=cyclegan src=/ja/assets/images/img13-5ebc0a09bcf2533ca4bbf6b29d8fa80b.jpg width=1818 height=494 class=img_ev3q></p>
<p>続く Li ら【78】は DPNet を提案し合成データから信頼性の高い画像を抽出、チェックアウト精度を 80.51%に向上。別研究【71】も GAN とエンコーダの対抗学習を組み合わせ、商品認識用の視覚サンプルを生成した。</p>
<p>ただし現状の多くの手法は平坦な背景を前提とし、実際のレジ台や棚場面における複雑な背景テクスチャや商品重なり、遮蔽関係は十分に再現できていない。今後はよりリアルな商品画像生成を追求する必要がある。</p>
<p>将来的には画像意味制御の強化、3D モデリングや物理レンダリングエンジンの統合、ドメイン適応やクロスドメイン拡張戦略の併用により、合成データと実環境のギャップ縮小が期待される。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=細粒度分類>細粒度分類<a href=#細粒度分類 class=hash-link aria-label="細粒度分類 への直接リンク" title="細粒度分類 への直接リンク">​</a></h3>
<p>細粒度分類はコンピュータビジョンにおける代表的な難題の一つで、同一上位クラス内のサブクラス（例：異なる花種、車種、動物種など）を識別することを目的とする。</p>
<p>商品認識分野では、商品間の高い視覚的類似性に加え、撮影のぼやけや照明変化、変形、姿勢角度、配置方法など多様なノイズ要因が存在し、より高い難易度を示す。</p>
<p>既存文献を踏まえると、商品細粒度認識の手法は大きく以下の 2 種類に分類される：</p>
<ol>
<li><strong>細粒度特徴表現（Fine Feature Representation）</strong></li>
<li><strong>コンテキスト認識（Context Awareness）</strong></li>
</ol>
<p>細粒度分類の核は、視覚的に類似した物体から識別的な微細特徴を抽出することである。監督信号の強度により「強監督」と「弱監督」に分けられる。</p>
<ul>
<li>
<p><strong>強監督手法（Strongly Supervised）</strong>
追加でバウンディングボックスや部位情報の注釈を提供し、局所領域を正確に整列させ、モデルが重要な差異に注目しやすくする。</p>
<div style=white-space:nowrap;overflow-x:auto;font-size:1rem;line-height:0.8;justify-content:center;display:flex><table><thead><tr><th>研究<th>手法<th>ポイント<th>応用例<tbody><tr><td>Part-based R-CNN【127】<td>R-CNN 構造で全体・局所特徴を抽出<td>鳥類認識データセットで SOTA 達成<td>商品認識の局所特徴融合の示唆<tr><td>Pose-normalized CNN【137】<td>DPM で位置検出・領域分割後特徴抽出し SVM 分類<td>精度 75.7%<td>商品姿勢変動が顕著な場面向け<tr><td>DiffNet【139】<td>似た商品画像の差異を自動検出し差分ラベル生成<td>一般的な商品に注釈不要<td>商品認識で mAP95.56%達成</table></div>
</li>
<li>
<p><strong>弱監督手法（Weakly Supervised）</strong>
追加注釈なしでモデルが局所領域を自動検出し学習。注釈コストの高い商品認識に適する。</p>
<div style=white-space:nowrap;overflow-x:auto;font-size:1rem;line-height:0.8;justify-content:center;display:flex><table><thead><tr><th>研究<th>手法<th>概念<th>効果<tbody><tr><td>Two-Level Attention【126】<td>全体・局所注意機構で特徴抽出<td>部位注釈不要で差異領域学習<td>細粒度分類に有効<tr><td>Bilinear CNN【141】<td>双分岐 CNN で領域検出と特徴分類を協調<td>A が領域検出、B が特徴分類<td>Caltech-UCSD 鳥類 84.1%精度<tr><td>Attention Map【74】<td>注意機構で細部に焦点<td>CAPG-GP データセットで実装<td>ベースラインを大きく上回る精度<tr><td>Discriminative Patch + SVM【143】<td>中間層重要領域抽出し分類<td>類似商品識別に適用<td>スーパーマーケット棚分類で良好<tr><td>Self-Attention Module【144】<td>activation map で重要位置判定<td>クロスドメイン分類に効果的<td>モデルの汎化能力を強化</table></div>
</li>
</ul>
<p>もう一つのアプローチはコンテキスト認識である。</p>
<p>商品外観だけで分類困難な場合、「文脈情報」が重要な補助情報となりうる。特に棚配置規則下では、商品の相対位置が意味的関連を含むことが多い。</p>
<div style=white-space:nowrap;overflow-x:auto;font-size:1rem;line-height:0.8;justify-content:center;display:flex><table><thead><tr><th>研究<th>手法<th>内容<th>成果<tbody><tr><td>CRF + CNN【53】<td>CNN 特徴と隣接商品の視覚類似性を組み合わせ分類<td>隣接文脈情報を加えて商品埋め込み学習<td>精度 91%、再現率 87%<tr><td>SIFT + Context【64】<td>従来特徴と配置関係のハイブリッド分類<td>文脈なし手法より 11.4%向上<td>実用的だが非深層学習手法<tr><td>Graph-based Consistency Check【148】<td>商品配置を部分グラフ同型問題としてモデル化<td>欠品や誤置商品検出<td>空間的一貫性推論が強み</table></div>
<p>全体的にコンテキスト認識は初期段階の探索的研究にとどまり、応用例は限られる。今後 Transformer 構造や空間モデリング、グラフニューラルネットとの統合により分類性能や現場適応性の向上が期待される。</p>
<hr>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=少数ショット学習>少数ショット学習<a href=#少数ショット学習 class=hash-link aria-label="少数ショット学習 への直接リンク" title="少数ショット学習 への直接リンク">​</a></h3>
<p>実務では商品種類が絶えず変化し、新商品追加やパッケージ改変が頻繁に起こる。毎回モデルを全面再訓練すると、時間と労力が膨大になる。</p>
<p><strong>One-Shot Learning（少数ショット学習）</strong> はこれを解決するために提案された技術で、目標は</p>
<blockquote>
<p><strong>極少数（時には単一）のサンプルのみで新クラスを認識し、分類器の全面再訓練を不要とすること。</strong></p>
</blockquote>
<p>この技術は距離学習（distance metric learning）に基づき【149】、深層モデルで画像を特徴空間に埋め込み、クエリ画像と各クラス中心点間の距離で最近傍分類を行う。</p>
<p>下図のように、</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt="metric learning" src=/ja/assets/images/img14-68e0e3837efb303e28d84ac8f4a7ec9d.jpg width=1112 height=676 class=img_ev3q></figure></div>
<p>入力画像 X は、特徴距離が最も近いクラス中心（例えば C1、C2、C3）に割り当てられる。</p>
<p>この方法の主な特徴と潜在力は、</p>
<ul>
<li><strong>動的なクラス拡張をサポート</strong>：新商品はサンプルを特徴ベースに加えるだけでよく、再訓練不要。</li>
<li><strong>訓練データ必要量の大幅削減</strong>：特にロングテールクラスやデータ不足環境に有効。</li>
<li><strong>CNN 特徴抽出モジュールと統合可能</strong>で、意味的埋め込みの質と分類安定性を維持。</li>
</ul>
<p>画像分類や物体検出における応用例は以下の通り：</p>
<div style=white-space:nowrap;overflow-x:auto;font-size:1rem;line-height:0.8;justify-content:center;display:flex><table><thead><tr><th>タスク<th>手法<th>ポイント<th>効果概要<tbody><tr><td>画像分類【152】<td>CNN 埋め込みと色彩情報の距離学習結合<td>照明や色差による埋め込み歪み解消<td>person re-ID 性能向上<tr><td>画像分類【150】<td>Matching Networks<td>ImageNet で新クラスを迅速認識<td>one-shot 精度が 87.6%→93.2%に向上<tr><td>物体検出【155】<td>R-CNN と組み合わせ動物検出<td>少数サンプル動物認識<td>極小訓練データ環境で成功<tr><td>動画分割【154】<td>単画像注釈で特定物体追跡<td>CNN 埋め込みを対象に微調整<td>シングルショット認識とフレーム間追跡強化</table></div>
<p>商品認識に応用する研究も多い：</p>
<ol>
<li>
<p><strong>Geng et al.【74】</strong></p>
<ul>
<li>coarse-to-fine 構造で特徴比較と one-shot 分類器を組み合わせ、再訓練不要で商品クラスを追加可能。</li>
<li>評価データセット：GroZi-3.2k（mAP73.93%）、GP-20（65.55%）、GP181（85.79%）。</li>
</ul>
</li>
<li>
<p><strong>Tonioni et al.【20】</strong></p>
<ul>
<li>類似度比較戦略でクエリ画像と商品サンプルの CNN 特徴を比較。</li>
<li>単一サンプルで分類可能、パッケージ変更や新規クラス導入に対応。</li>
</ul>
</li>
</ol>
<p>One-shot 学習は商品認識システムに柔軟性と拡張性をもたらす有力な設計思想である。現状は CNN 特徴と距離学習の組み合わせが主流で、今後は few-shot 分類、メタラーニング、クロスドメイン適応との融合により実環境の変動対応力向上が期待される。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=公開データセット>公開データセット<a href=#公開データセット class=hash-link aria-label="公開データセット への直接リンク" title="公開データセット への直接リンク">​</a></h2>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=dataset src=/ja/assets/images/img15-ce427782aa8efc15610e4001a3f2d247.jpg width=1778 height=646 class=img_ev3q></figure></div>
<p>深層モデルの性能はデータ品質と規模に依存するが、商品画像の手動アノテーションは高コストとなる。</p>
<p>比較検証や迅速なプロトタイプ開発のため、研究コミュニティは複数の公開データセットを提供しており、用途に応じて以下に分類される：</p>
<ul>
<li><strong>棚上画像（on-shelf）</strong>：商品が静的に棚に陳列され、補充・配置検査・案内などのシーンを模擬。</li>
<li><strong>会計画像（checkout）</strong>：会計視点で撮影され、商品重なり、混在、多数商品の数え上げなどの課題に対応。</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=棚上画像データセット>棚上画像データセット<a href=#棚上画像データセット class=hash-link aria-label="棚上画像データセット への直接リンク" title="棚上画像データセット への直接リンク">​</a></h3>
<ul>
<li>
<p><strong>GroZi‑120</strong>
広く引用される初期の小売商品認識データセット。120 クラス含む。訓練画像は白背景の単品 676 枚で one-shot モデル向き。テストは 4,973 枚の実棚画像と 30 分の動画断片で、照明・角度多様。ドメイン適応性能検証に適する。</p>
</li>
<li>
<p><strong>GroZi‑3.2k</strong>
クラス数とサンプル数を拡大し、80 大カテゴリを含む。訓練は 8,000 枚超のウェブ画像、テストは実店舗 5 店のスマホ撮影 680 枚と手動注釈付き。細粒度分類とドメインシフト評価に適合。</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=GroZi‑120 src=/ja/assets/images/img16-a03a1357e781167a24e701deac4208c3.jpg width=932 height=428 class=img_ev3q></figure></div>
</li>
<li>
<p><strong>Freiburg Grocery</strong>
ドイツの研究チームによる 25 種日用品セット。約 5,000 枚のスマホ撮影低解像度訓練画像（256×256）、74 枚の Kinect v2 高解像度テスト画像（遮蔽・ノイズ含む）。多スケール頑健性評価に最適。</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt="Freiburg Grocery" src=/ja/assets/images/img17-c1276f665f70b2e2e2713aee150854e4.jpg width=1128 height=424 class=img_ev3q></figure></div>
</li>
<li>
<p><strong>Cigarette Dataset</strong>
タバコ識別に特化。10 クラス。訓練 3,600 枚単品写真、テストは 40 店舗棚撮影 354 枚、約 13,000 物体注釈。外観類似かつ密集陳列のため、細粒度と遮蔽評価に適用。</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt="Cigarette Dataset" src=/ja/assets/images/img18-dfafbe22a87c9204ee84494861ef745f.jpg width=1200 height=480 class=img_ev3q></figure></div>
</li>
<li>
<p><strong>Grocery Store Dataset</strong>
81 クラス、5,125 枚画像、18 店舗由来。アイコニック画像（ウェブ商品ページ）と実景画像を同時収録。クロスドメイン学習や検索タスクに有効。</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt="Grocery Store Dataset" src=/ja/assets/images/img19-d5d2b0e1facc10b3bb6c253d508aa9eb.jpg width=1076 height=616 class=img_ev3q></figure></div>
</li>
<li>
<p><strong>GP181</strong>
GroZi‑3.2k のサブセット。訓練 183 枚、テスト 73 枚で厳密なバウンディングボックス注釈付き。小規模かつ高品質で、プロトタイプ、few-shot 学習、他データセットとの併用実験に適切。</p>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=GP181 src=/ja/assets/images/img20-a44b4c0efda9a522013070bf02a603c0.jpg width=1664 height=362 class=img_ev3q></figure></div>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=会計画像データセット>会計画像データセット<a href=#会計画像データセット class=hash-link aria-label="会計画像データセット への直接リンク" title="会計画像データセット への直接リンク">​</a></h3>
<p>会計シーンは画像条件が厳しく、商品重なり、視点固定、不均一な数量などの課題がある。</p>
<p>代表的なデータセットは以下：</p>
<ul>
<li>
<p><strong>D2S（Dataset to Shop）</strong>
初のインスタンスレベルマスクを含む会計データセット。21,000 枚の高解像度画像、60 クラス（瓶飲料、シリアル、果物等）。訓練は単品、テストは混在陳列、物体数 1 ～ 15、一部合成画像含む。光源、背景、角度の多様性重視で、汎化能力・精密セグメンテーション評価に適する。Mask R-CNN や RetinaNet でも IoU=0.75 で性能低下が見られ、シーンの複雑さを示す。</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=D2S src=/ja/assets/images/img21-e10d56942162b338e7a8046d4578686b.jpg width=1196 height=568 class=img_ev3q></figure></div>
</li>
<li>
<p><strong>RPC（Retail Product Checkout）</strong>
現実に最も近い大規模会計画像データセット。83,739 枚画像、200 クラス、17 中カテゴリ含む。訓練は 4 台カメラで多視点単品撮影、テストは上方からの混雑会計画像。バウンディングボックス・クラス注釈とともに <strong>Checkout Accuracy（cAcc）</strong> を定義し、「画像内全商品が正確に認識・計数」されて初めて成功とする。基準モデル（FPN）は cAcc56.7%だが、DPNet による信頼合成サンプル抽出で 80.5%まで向上。データ拡張の質が会計タスクで鍵となる。</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=RPC src=/ja/assets/images/img22-53b67b30d16f9b0afc42972e1ceb3c46.jpg width=1224 height=548 class=img_ev3q></figure></div>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=実務上の推奨>実務上の推奨<a href=#実務上の推奨 class=hash-link aria-label="実務上の推奨 への直接リンク" title="実務上の推奨 への直接リンク">​</a></h3>
<ul>
<li><strong>商品検索、細粒度分類、ドメイン適応</strong>には GroZi‑3.2k、Grocery Store、GP181 が適切。</li>
<li><strong>遮蔽環境での検出・分割</strong>には Cigarette や Freiburg Grocery が推奨。</li>
<li><strong>会計タスクと正確な計数評価</strong>には RPC が最良のベンチマーク。遮蔽やセグメンテーション検証は D2S が理想的。</li>
<li>多くのデータセットは理想背景と実景画像の両方を含み、データ拡張、スタイル変換、クロスドメイン学習のテストに活用可能。</li>
</ul>
<p>今後はより大規模で多様な背景や時期を跨ぐベンチマークの整備が望まれ、研究者はアノテーションツール共創や半自動アノテーション技術開発によりデータ取得・保守コストの軽減を目指すべきである。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=今後の研究方向>今後の研究方向<a href=#今後の研究方向 class=hash-link aria-label="今後の研究方向 への直接リンク" title="今後の研究方向 への直接リンク">​</a></h2>
<p>著者が本分野のさらなる発展に重要と考える以下 6 つの研究テーマ：</p>
<ol>
<li>
<p><strong>深層ニューラルネットワークによる商品画像生成</strong></p>
<p>現存最大の公開データセットは 200 クラスのみで、実際のスーパーにおける数千 SKU の需要を大きく下回る。加えて包装デザインの頻繁な更新により包括的な画像収集は困難である。DCGAN や CycleGAN などの生成モデルはリアルな合成画像生成能力を実証しており、貨架視点や遮蔽構造、光影変化を模擬可能な生成器の開発は訓練データの多様性と適応力を大幅に高める可能性がある。</p>
</li>
<li>
<p><strong>グラフニューラルネットワークを用いた棚配置検査</strong></p>
<p>商品配置は空間構造や文脈規則を持ち、従来の畳み込みネットワークでは物体間の非ユークリッド関係を捉えにくい。GNN はノード（商品）間の隣接関係や類似性をグラフ構造としてモデル化可能で、推薦システムや知識グラフ構築に応用されている。プラノグラム課題では、観測棚グラフと理想棚グラフの差異学習を通じ、欠品や誤配置検知を支援する。</p>
</li>
<li>
<p><strong>転移学習を活用したクロスチャネル認識</strong></p>
<p>多くの物体検出モデルは訓練・テストデータ分布の一致を仮定するが、実際の店舗間では照明・背景・陳列スタイルが大きく異なり再学習が必要となる。転移学習（例：ImageNet 事前学習モデル利用）により新環境への迅速適応が可能であり、無監督ドメイン適応や few-shot ファインチューニングの研究も進む。</p>
</li>
<li>
<p><strong>パッケージ文字情報と画像のマルチモーダル特徴学習</strong></p>
<p>細粒度商品は外観類似でも、味や容量を示すラベル文字が重要な識別情報となる。人間の購買判断も包装文字に依存することが多いため、画像特徴と OCR で抽出した文字情報の統合学習は視覚情報の不足を補完する。将来的には BLIP や CLIP のような Vision-Language モデルによるマルチモーダル事前学習の活用も期待される。</p>
</li>
<li>
<p><strong>増分学習を支援するモデル更新機構</strong></p>
<p>深層モデルは新クラス追加時に既存知識を忘れる「破滅的忘却」問題を抱える。増分学習により再訓練不要で新商品を導入可能となる。既存研究は旧モデルで履歴知識維持、新モデルで新クラス学習、双方を特徴整合や知識蒸留で融合する二重ネット構造を提案し、実用展開に有効な方向性を示す。</p>
</li>
<li>
<p><strong>回帰型検出モデルの高速性と精度向上</strong></p>
<p>YOLO や SSD など回帰型検出モデルはリアルタイム性に優れ、エッジデバイスやセルフチェックアウトに適する一方、Faster R-CNN など二段階モデルに比べて精度が劣る。今後は推論速度を損なわずに位置検出や分類性能を高める研究（例：anchor-free 構造、軽量注意機構など）が求められる。</p>
</li>
</ol>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=結論>結論<a href=#結論 class=hash-link aria-label="結論 への直接リンク" title="結論 への直接リンク">​</a></h2>
<p>本レビューは近年の深層学習を用いた小売商品認識の主要発展を、タスクの本質と応用課題に即して体系的に整理・分析した。4 つの技術的課題、</p>
<ol>
<li><strong>大規模クラス分類</strong></li>
<li><strong>訓練データ不足</strong></li>
<li><strong>類内高類似商品の細粒度識別</strong></li>
<li><strong>システムの柔軟性と迅速な更新</strong></li>
</ol>
<p>に対する先行研究を幅広く紹介し、代表的データセットや評価基準も交え、研究者が効率よく分野の技術座標を把握し、潜在的な突破口に注力できるよう支援する。</p>
<p>商品多様化と複雑化する小売現場に対応するため、今後はモデル設計とシステム実装戦略をさらに深化させ、より高次の実環境適用を目指すことが期待される。</header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated><b><time datetime=2025-06-30T14:30:24.000Z itemprop=dateModified>2025年6月30日</time></b>に<b>zephyr-sh</b>が<!-- -->最終更新</span></div></div><section class=ctaSection_iCjC><div class="
        simpleCta_ji_Y
        simple-cta__coffee_YwC8
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>☕ 1杯のコーヒーが支えになります</h3><p class=simple-cta__subtitle_ol86>AIやフルスタックの情報発信を続けるため、ご支援お願いします。<div class=simple-cta__buttonWrapper_jk1Y><img src=/ja/img/bmc-logo.svg alt=cta-button class=simple-cta__buttonImg_Q9VV></div></div><div class="ant-row ant-row-stretch cardsSection_wRaP css-mc1tut" style=margin-left:-8px;margin-right:-8px;row-gap:16px><div style=padding-left:8px;padding-right:8px;display:flex class="ant-col ant-col-xs-24 css-mc1tut"><div class="ant-card ant-card-bordered card_gKx9 fadeInUp_n33J hoverTransform_Mozy css-mc1tut" style=flex:1;display:flex;flex-direction:column><div class=ant-card-body><div style=text-align:center;margin-top:1rem><img src=/ja/img/icons/all_in.svg alt="AI・開発・運用まで一括対応 icon" style=width:48px;height:48px></div><span class="ant-tag ant-tag-orange card__tag_PLj3 css-mc1tut">ALL</span><h4 class=card__title_SQBY>AI・開発・運用まで一括対応</h4><p class=card__concept_Ak8F>アイデアからリリースまで、技術面はまるごとお任せください。<div class=card__bulletHeader_b6cf><h5 class=card__bulletTitle_R_wg>対応内容</h5></div><ul class=card__bulletList_SrNN><li class=card__bulletItem_wCRd>技術相談 + 開発 + デプロイ<li class=card__bulletItem_wCRd>継続サポート & 拡張</ul></div></div></div></div><div class="
        simpleCta_ji_Y
        simple-cta__outro_AXbn
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>🚀 次のプロジェクト、始めましょう！</h3><p class=simple-cta__subtitle_ol86>カスタム開発や長期支援をご希望の方は、ぜひご相談ください。</div></section><div style=margin-top:3rem> </div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label=ドキュメントページ><a class="pagination-nav__link pagination-nav__link--prev" href=/ja/papers/retail-product/dpsnet/><div class=pagination-nav__sublabel>前へ</div><div class=pagination-nav__label>[20.11] DPSNet</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/ja/papers/retail-product/deepaco/><div class=pagination-nav__sublabel>次へ</div><div class=pagination-nav__label>[22.06] DeepACO</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#小売商品認識 class="table-of-contents__link toc-highlight">小売商品認識</a><li><a href=#問題の定義 class="table-of-contents__link toc-highlight">問題の定義</a><li><a href=#伝統的手法 class="table-of-contents__link toc-highlight">伝統的手法</a><li><a href=#深層学習手法 class="table-of-contents__link toc-highlight">深層学習手法</a><li><a href=#商品認識の課題 class="table-of-contents__link toc-highlight">商品認識の課題</a><ul><li><a href=#課題-1クラス数の大規模化 class="table-of-contents__link toc-highlight">課題 1：クラス数の大規模化</a><li><a href=#課題-2データ分布のギャップ class="table-of-contents__link toc-highlight">課題 2：データ分布のギャップ</a><li><a href=#課題-3クラス内変異 class="table-of-contents__link toc-highlight">課題 3：クラス内変異</a><li><a href=#課題-4システムの柔軟性不足 class="table-of-contents__link toc-highlight">課題 4：システムの柔軟性不足</a></ul><li><a href=#技術概観 class="table-of-contents__link toc-highlight">技術概観</a><ul><li><a href=#畳み込みネットワークに基づく手法 class="table-of-contents__link toc-highlight">畳み込みネットワークに基づく手法</a><li><a href=#データ拡張 class="table-of-contents__link toc-highlight">データ拡張</a><li><a href=#細粒度分類 class="table-of-contents__link toc-highlight">細粒度分類</a><li><a href=#少数ショット学習 class="table-of-contents__link toc-highlight">少数ショット学習</a></ul><li><a href=#公開データセット class="table-of-contents__link toc-highlight">公開データセット</a><ul><li><a href=#棚上画像データセット class="table-of-contents__link toc-highlight">棚上画像データセット</a><li><a href=#会計画像データセット class="table-of-contents__link toc-highlight">会計画像データセット</a><li><a href=#実務上の推奨 class="table-of-contents__link toc-highlight">実務上の推奨</a></ul><li><a href=#今後の研究方向 class="table-of-contents__link toc-highlight">今後の研究方向</a><li><a href=#結論 class="table-of-contents__link toc-highlight">結論</a></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/ja/docs>オープンソースプロジェクト</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/papers/intro>論文ノート</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/blog>ブログ</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/terms-of-service>利用規約</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/privacy-policy>プライバシーポリシー</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/become-an-author>著者になる</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/worklog>作業日誌</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>