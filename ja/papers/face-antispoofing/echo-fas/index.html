<!doctype html><html lang=ja dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-face-antispoofing/echo-fas/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.8.1"><title data-rh=true>[22.08] Echo-FAS | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/ja/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/ja/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/ja/papers/face-antispoofing/echo-fas/><meta data-rh=true property=og:locale content=ja><meta data-rh=true property=og:locale:alternate content=zh_hant><meta data-rh=true property=og:locale:alternate content=en><meta data-rh=true name=docusaurus_locale content=ja><meta data-rh=true name=docsearch:language content=ja><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[22.08] Echo-FAS | DOCSAID"><meta data-rh=true name=description content=偽造のエコー><meta data-rh=true property=og:description content=偽造のエコー><link data-rh=true rel=icon href=/ja/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/ja/papers/face-antispoofing/echo-fas/><link data-rh=true rel=alternate href=https://docsaid.org/papers/face-antispoofing/echo-fas/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/face-antispoofing/echo-fas/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/face-antispoofing/echo-fas/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/face-antispoofing/echo-fas/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://docsaid.org/ja/papers/category/face-anti-spoofing-43","name":"Face Anti-Spoofing (43)","position":1},{"@type":"ListItem","item":"https://docsaid.org/ja/papers/face-antispoofing/echo-fas/","name":"[22.08] Echo-FAS","position":2}]}</script><link rel=alternate type=application/rss+xml href=/ja/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/ja/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/ja/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/ja/assets/css/styles.523de46a.css><script src=/ja/assets/js/runtime~main.b5890940.js defer></script><script src=/ja/assets/js/main.ef3c41aa.js defer></script><body class=navigation-with-keyboard><svg xmlns=http://www.w3.org/2000/svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light",e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label=メインコンテンツまでスキップ><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>メインコンテンツまでスキップ</a></div><nav aria-label=ナビゲーション class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label=ナビゲーションバーを開く aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/ja/><div class=navbar__logo><img src=/ja/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/ja/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/ja/docs/>オープンソースプロジェクト</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/ja/papers/intro>論文ノート</a><a class="navbar__item navbar__link" href=/ja/blog>ブログ</a><a class="navbar__item navbar__link" href=/ja/playground/intro>遊び場</a><a class="navbar__item navbar__link" href=/ja/services>技術サービス</a><a class="navbar__item navbar__link" href=/ja/aboutus>私たちについて</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>日本語</a><ul class=dropdown__menu><li><a href=/papers/face-antispoofing/echo-fas/ target=_self rel="noopener noreferrer" class=dropdown__link lang=zh-hant>繁體中文</a><li><a href=/en/papers/face-antispoofing/echo-fas/ target=_self rel="noopener noreferrer" class=dropdown__link lang=en>English</a><li><a href=/ja/papers/face-antispoofing/echo-fas/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="検索 (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>検索</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-mc1tut ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label=先頭へ戻る class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/ja/><img src=/ja/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/ja/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label=ドキュメントのサイドバー class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/ja/papers/intro>論文ノート</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="'Classic CNNs (11)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/contrastive-learning-14>Contrastive Learning (14)</a><button aria-label="'Contrastive Learning (14)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/deepseek-5>DeepSeek (5)</a><button aria-label="'DeepSeek (5)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/ja/papers/category/face-anti-spoofing-43>Face Anti-Spoofing (43)</a><button aria-label="'Face Anti-Spoofing (43)'の目次を隠す" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/slrbd/>[10.09] SLRBD</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/lbp/>[12.09] LBP</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/three-d-mad/>[14.05] 3DMAD</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/rppg/>[16.12] rPPG</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/oulu-npu/>[17.06] OULU-NPU</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/cfrppg/>[18.09] CFrPPG</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/vafas/>[19.05] VA-FAS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/wmca/>[19.09] WMCA</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/cdcn/>[20.03] CDCN</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/cefa/>[20.03] CeFA</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/ssdg/>[20.04] SSDG</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/celeba-spoof/>[20.07] CelebA-Spoof</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/stdn/>[20.07] STDN</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/disentangle-fas/>[20.08] Disentangle-FAS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/d2am/>[21.05] D²AM</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/dualstage/>[21.10] DualStage</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/dsdg/>[21.12] DSDG</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/personalized-fas/>[22.01] Personalized-FAS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/ssan/>[22.03] SSAN</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/ja/papers/face-antispoofing/echo-fas/>[22.08] Echo-FAS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/fas-survey/>[22.10] FAS Survey</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/cdftn/>[22.12] CDFTN</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/divt/>[23.01] DiVT</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/m2a2e/>[23.02] M²A²E</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/sa-fas/>[23.03] SA-FAS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/iadg/>[23.04] IADG</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/ma-vit/>[23.04] MA-ViT</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/flip/>[23.09] FLIP</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/s-adapter/>[23.09] S-Adapter</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/udg-fas/>[23.10] UDG-FAS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/three-a-tta/>[23.11] 3A-TTA</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/mmdg/>[24.02] MMDG</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/shield/>[24.02] SHIELD</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/aface/>[24.03] AFace</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/cfpl-fas/>[24.03] CFPL-FAS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/fas-challenge/>[24.04] FAS-Challenge</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/pd-fas/>[24.04] PD-FAS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/hpdr/>[24.06] HPDR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/la-softmoe/>[24.08] La-SoftMoE</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/fm-clip/>[24.10] FM-CLIP</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/i-fas/>[25.01] I-FAS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/faceshield/>[25.05] FaceShield</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/ja/papers/face-antispoofing/instructflip/>[25.07] InstructFLIP</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="'Face Recognition (4)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/feature-fusion-10>Feature Fusion (10)</a><button aria-label="'Feature Fusion (10)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/image-generation-1>Image Generation (1)</a><button aria-label="'Image Generation (1)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="'Lightweight (10)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/mamba-4>Mamba (4)</a><button aria-label="'Mamba (4)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/model-tuning-8>Model Tuning (8)</a><button aria-label="'Model Tuning (8)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/multimodality-24>Multimodality (24)</a><button aria-label="'Multimodality (24)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/normalization-1>Normalization (1)</a><button aria-label="'Normalization (1)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/object-detection-14>Object Detection (14)</a><button aria-label="'Object Detection (14)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/reparameterization-8>Reparameterization (8)</a><button aria-label="'Reparameterization (8)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/retail-product-3>Retail Product (3)</a><button aria-label="'Retail Product (3)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="'Segmentation (1)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/text-detection-14>Text Detection (14)</a><button aria-label="'Text Detection (14)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="'Text Recognition (20)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="'Text Spotting (4)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/transformers-17>Transformers (17)</a><button aria-label="'Transformers (17)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/ja/papers/category/vision-transformers-13>Vision Transformers (13)</a><button aria-label="'Vision Transformers (13)'の目次を開く" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/ja/papers/intro>All Notes: 229 entries</a></ul></nav><button type=button title=サイドバーを隠す aria-label=サイドバーを隠す class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=パンくずリストのナビゲーション><ul class=breadcrumbs><li class=breadcrumbs__item><a aria-label=ホームページ class=breadcrumbs__link href=/ja/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li class=breadcrumbs__item><a class=breadcrumbs__link href=/ja/papers/category/face-anti-spoofing-43><span>Face Anti-Spoofing (43)</span></a><li class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>[22.08] Echo-FAS</span></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">このページの見出し</button></div><div class="theme-doc-markdown markdown"><header><h1>[22.08] Echo-FAS</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt="Z. Yuan" class=docAuthorImg_vlJe><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Z. Yuan</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a href=https://www.linkedin.com/in/ze-yuan-sh7/ target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 448 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=偽造のエコー>偽造のエコー<a href=#偽造のエコー class=hash-link aria-label="偽造のエコー への直接リンク" title="偽造のエコー への直接リンク">​</a></h2>
<p><a href=https://drive.google.com/file/d/1ggyRAQgWdSSS-tVMJvxPE7QwNUXSBLqf/view target=_blank rel="noopener noreferrer"><strong>Beyond the Pixel World: A Novel Acoustic-Based Face Anti-Spoofing System for Smartphones</strong></a></p>
<p>音波技術が顔認証詐欺防止（FAS）の分野で利用されることは、あまり多くありません。</p>
<p>大体、年に一度か二度、引用回数が多い関連研究を見つけることができます。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=問題の定義>問題の定義<a href=#問題の定義 class=hash-link aria-label="問題の定義 への直接リンク" title="問題の定義 への直接リンク">​</a></h2>
<p>FAS 技術の進化の歴史は、深く掘り下げる識別技術のようなものです。</p>
<p>私たちは、LBP の重ね合わせ、HOG の勾配、CNN 特徴マップ上の高周波のフリッカーを学び、rPPG の心拍信号から生命のリズムを探しました。偽造手法が進化するたびに、「生体証拠」を再定義する必要に迫られます。</p>
<p>しかし、変わらないことがあります：</p>
<ul>
<li><strong>どんなに特徴を強化し、モダリティを補完し、損失関数を混合しても、これらの方法は「見る」ことに過度に依存しています。</strong></li>
</ul>
<p>よく見て、細かく見て、正確に見て。</p>
<p>しかし現実はどうでしょう？</p>
<p>カメラには指紋がついているかもしれませんし、光源が逆光で過曝しているかもしれません。使用者の顔も、アルゴリズムが求める角度に必ずしも一致しないことがあります。</p>
<p>さらに、ほぼすべての RGB ベースの識別システムは、いくつかの古典的な課題から逃れることができません：</p>
<ul>
<li>新しいスマートフォンと古いモデル間のドメイングラップ；</li>
<li>室内光源と屋外の太陽光の間のスペクトル差；</li>
<li>データ分布と推論条件の間のギャップ。</li>
</ul>
<p>これらの問題を解決するために、ハードウェア強化に転向する人もいます。例えば、赤外線、深度モジュール、さらにはミリ波レーダーです。</p>
<p>しかし、これらのソリューションは高価です！</p>
<p>高価であり、展開が複雑で、最終的には識別のしきい値をアルゴリズムからコストやスペックに転嫁することにしかなりません。本当に汎用性のニーズに応えているわけではありません。</p>
<p>そこで、著者は異なる視点を提案します：</p>
<blockquote>
<p><strong>もし正確に見ることができないなら、聞いてみるのはどうでしょうか？</strong></p>
</blockquote>
<p>スピーカーとマイクは、スマートフォンに無限に存在しており、追加のインストールも技術の普及も必要ありません。</p>
<p>そして、音は単なる情報の運び手ではなく、同時に探査機にもなり得ます。反射する音波の経路から顔の幾何学的情報を識別することができます：</p>
<ul>
<li>一枚の紙、そのエコーは乾いて薄い；</li>
<li>一度再生された画面、その反射は歪んで不安定である；</li>
</ul>
<p>本物の肉体だけが、密度に対応する音波のテクスチャを残します。</p>
<p>でも、これは本当に役立つのでしょうか？</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=問題の解決>問題の解決<a href=#問題の解決 class=hash-link aria-label="問題の解決 への直接リンク" title="問題の解決 への直接リンク">​</a></h2>
<p>システム設計に入る前に、著者は新しい音波データベースである<strong>Echo-Spoof</strong>を作成しました。</p>
<p>これは従来の FAS データベースとは全く異なります。従来のデータベースは画像を収集することが主な目的でしたが、Echo-Spoof は「音波」の反射信号を収集しています。</p>
<p>もし、スマートフォンの内蔵スピーカーとマイクだけで詐欺防止ができることを期待するなら、現実の世界でも有効であることを確認する必要があります。</p>
<p>そのため、著者は以下の三つの重要な要件を設定しました：</p>
<ol>
<li>
<p><strong>音波ベース（Acoustic-based）</strong>：
従来の FAS データベースは顔写真やビデオを収集していましたが、Echo-Spoof は音波反射信号のみを収集しています。顔の曲線、輪郭、材質から幾何学的情報を抽出し、RGB を使用せず、ユーザーのプライバシーも漏れません。</p>
</li>
<li>
<p><strong>大規模（Large-scale）</strong>：
このデータベースは 30 人のボランティア（男女半々）から収集され、25 万件以上の音波信号を集めました。十分な規模でないと、現実のシーンで予測不可能な変数をカバーできません。</p>
</li>
<li>
<p><strong>高い多様性（High-diversity）</strong>：
現実の世界では、変化はあらゆる方向からやってきます：異なるスマートフォン、異なる距離、異なる音のレベル、異なる角度など。</p>
<p>著者はこれらの条件を明確に規定し、ユーザーが実際にスマートフォンを使用する際によく遭遇するシーンを模倣しました。たとえば、「ユーザーとスマートフォンの距離は 25cm から 45cm」、「環境音量は 40dB、60dB、70dB の範囲で変動」または「顔の俯仰角度は-10°、0°、+10°」などです。</p>
<p>これらの細かい点はデータ収集マニュアルに記載されており、Echo-Spoof が理想的な小規模なデータセットにとどまらないことを保証しています。</p>
</li>
</ol>
<p>データ収集の過程は以下の図のようになっています：</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=data-collection src=/ja/assets/images/img0-2b2a6ff31d86022b1f85de645c70ea38.jpg width=848 height=666 class=img_ev3q></figure></div>
<p>著者はスマートフォンのイヤホン・スピーカーから設計した音波を発し、上部マイクで反射信号を録音します。もしそれが本物の顔であれば、波形の中には本物の顔の幾何学情報が含まれます。もしそれが紙やスクリーンの再生であれば、異なる歪んだ形態になります。</p>
<p>このようにして得られた大量の音波サンプルは、倫理審査（human ethics application）を経て正式に収集され、実験の安全性とプライバシーの規定に準拠しています。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=変数の考慮>変数の考慮<a href=#変数の考慮 class=hash-link aria-label="変数の考慮 への直接リンク" title="変数の考�慮 への直接リンク">​</a></h3>
<ul>
<li>
<p><strong>デバイス（Device）</strong>：
著者は、Samsung S9、Samsung S21、Samsung Edge Note、Xiaomi Redmi7 の 4 種類の Android スマートフォンを使用してデータを収集しました。異なるスマートフォンはスピーカーとマイクの製造に微妙な差異があり、追加の雑音分布を引き起こしやすいため、モデルのクロスデバイス安定性を検証するのに最適です。</p>
</li>
<li>
<p><strong>距離（Distance）</strong>：
ユーザーが日常的にスマートフォンを使用する際、顔は通常画面から 25〜45cm の距離にあります。著者は、25cm、35cm、45cm で音波を収集し、距離が信号対雑音比（SNR）に与える影響を観察しました。</p>
</li>
<li>
<p><strong>環境音（Ambient Noise）</strong>：
現実の生活では、静かなオフィスと賑やかなカフェは全く異なる世界です。著者は環境音を 40dB（静かな状態）、60dB（少し騒がしい）、70dB（かなり騒がしい）の 3 つのレベルで管理し、ノイズ検出アプリで基準に達しているかを監視しました。</p>
</li>
<li>
<p><strong>ピッチ（Pitch）</strong>：
手持ちの角度も顔とスマートフォンの相対位置に影響を与える可能性があります。-10°、0°、+10° の俯仰角度が考慮されました。顔認識は現実では常に垂直のままで維持できるわけではなく、少しの角度変化の方がユーザーの実際の習慣に近いです。</p>
</li>
</ul>
<p>このように精緻な設計を経て、Echo-Spoof は「規模」と「多様性」の面で高い基準を持っています。これにより、後のテスト段階では、異なるシナリオでの音波検出の安定性と耐干渉能力を効果的に評価することができます。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=信号設計>信号設計<a href=#信号設計 class=hash-link aria-label="信号設計 への直接リンク" title="信号設計 への直接リンク">​</a></h3>
<p>Echo-FAS が日常のシーンで正常に動作するように、著者は以下の重要な考慮事項を提案しました：</p>
<ol>
<li>
<p><strong>認識品質の向上</strong>：
線形変調周波数（FMCW、Frequency-Modulated Continuous Wave）を使用して顔の各領域から複数の反射音をキャプチャし、顔の幾何学的情報を抽出します。</p>
</li>
<li>
<p><strong>環境干渉の低減</strong>：
より高い周波数範囲（12〜21kHz）を活用し、一般的なノイズ周波数（8kHz 未満）との区別を行い、パイロットトーンを加えて同期し、デバイス間のタイミング差を排除します。</p>
</li>
<li>
<p><strong>ユーザー体験</strong>：
不快な音を避け、検出に十分なエネルギーを保持するようにします。著者は Hamming ウィンドウ関数を使用して不要な周波数成分を抑制し、音量を適切に調整することで「人間の耳で聞こえる確率」を最小限に抑えました。</p>
</li>
</ol>
<p>最終的な設計は以下の図の通りです：</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=signal-design src=/ja/assets/images/img2-e2352c78138ed2920ee3a470478c6978.jpg width=1222 height=772 class=img_ev3q></figure></div>
<p>信号全体の長さは約 0.8 秒、サンプリングレートは 44.1kHz（ほとんどの Android デバイスでサポートされている典型的な値）です。</p>
<p>説明を簡単にするために、著者は信号に<strong>11.025kHz のパイロットトーン</strong>を加え、これを 9 つのチープ（線形周波数変調）と組み合わせて最終出力を生成しました。信号の周波数範囲は 12〜21kHz で、3 つの異なる周波数範囲（12〜17kHz、14〜19kHz、16〜21kHz）に細分され、それぞれが 3 回繰り返されます。</p>
<p>各チープの実際のサンプル数は 60 で、2 つのチープ間の間隔は 3000 サンプルで、これにより時間領域での重複を避けています。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=信号分析>信号分析<a href=#信号分析 class=hash-link aria-label="信号分析 への直接リンク" title="信号分析 への直接リンク">​</a></h3>
<p>Echo-FAS は<strong>FMCW</strong>（Frequency-Modulated Continuous Wave）技術を採用しています。これはレーダーでよく使用される周波数変調技術で、元々は精密な距離計測に使用されていました。ここでは、顔の幾何学的情報を識別する音響スキャナーとして応用されています。</p>
<p>その原理は簡単に理解できます。顔の異なる部位（例えば鼻筋、唇、額）とスマートフォンのスピーカーとの距離は異なり、したがって音波はこれらの構造に遭遇した際、異なる時間遅延と位相変化を反射します。これらの微妙な差異を特定の周波数帯域内で正確に解析できれば、顔の輪郭特徴を識別できる情報として形成できます。</p>
<p>この能力の理論的な基礎を説明するために、著者は FMCW アーキテクチャにおける解像度計算の公式を引用しました：</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>R</mi><mi>d</mi></msub><mo>=</mo><mfrac><mrow><mi>v</mi><mo>⋅</mo><mi>δ</mi><mi>T</mi></mrow><mn>2</mn></mfrac><mo>=</mo><mfrac><mrow><mi>v</mi><mo>⋅</mo><mi>δ</mi><mi>f</mi></mrow><mrow><mn>2</mn><mi>k</mi></mrow></mfrac><mo>=</mo><mfrac><mi>v</mi><mrow><mn>2</mn><mo>⋅</mo><mi>B</mi><mi>W</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>343</mn><mtext>m/s</mtext></mrow><mrow><mn>2</mn><mo>×</mo><mn>5000</mn><mtext>Hz</mtext></mrow></mfrac><mo>=</mo><mn>3.43</mn><mtext>cm</mtext></mrow><annotation encoding=application/x-tex>R_d
= \frac{v \cdot \delta T}{2}
= \frac{v \cdot \delta f}{2k}
= \frac{v}{2 \cdot BW}
= \frac{343 \text{m/s}}{2 \times 5000 \text{Hz}}
= 3.43 \text{cm}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.00773em>R</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0077em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.0574em;vertical-align:-0.686em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3714em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>2</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>v</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span><span class="mord mathnormal" style=margin-right:0.03785em>δ</span><span class="mord mathnormal" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.0574em;vertical-align:-0.686em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3714em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>2</span><span class="mord mathnormal" style=margin-right:0.03148em>k</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>v</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span><span class="mord mathnormal" style=margin-right:0.03785em>δ</span><span class="mord mathnormal" style=margin-right:0.10764em>f</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.7936em;vertical-align:-0.686em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.1076em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>2</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span><span class="mord mathnormal" style=margin-right:0.13889em>W</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>v</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.1963em;vertical-align:-0.7693em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.427em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>2</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:0.2222em></span><span class=mord>5000</span><span class="mord text"><span class=mord>Hz</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>343</span><span class="mord text"><span class=mord>m/s</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.7693em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>3.43</span><span class="mord text"><span class=mord>cm</span></span></span></span></span></span>
<p>ここで、<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>v</mi></mrow><annotation encoding=application/x-tex>v</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal" style=margin-right:0.03588em>v</span></span></span></span>は音速（約 343 m/s）、<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>B</mi><mi>W</mi></mrow><annotation encoding=application/x-tex>BW</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span><span class="mord mathnormal" style=margin-right:0.13889em>W</span></span></span></span>は周波数変調信号の帯域幅、<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>k</mi></mrow><annotation encoding=application/x-tex>k</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.03148em>k</span></span></span></span>は周波数変化の傾斜を示します。</p>
<p>この公式から分かることは、顔の 2 点間の深さの差が 3.43cm を超えると、反射信号に識別可能な時間遅延が残るということです。この解像度は、鼻先と顎、額と頬などの主要な幾何学構造を区別するのに十分です。</p>
<p>この識別要求に基づいて、著者は 12〜21kHz の周波数範囲を選択しました。</p>
<p>この周波数帯には多くの利点があります：それはほとんどの環境ノイズの主要な周波数（通常は 8kHz 以下）よりも高く、また成人の可聴周波数の上限（約 15〜17kHz）に近いため、ユーザーの感知を効果的に低減できます。</p>
<p>しかし、周波数が高すぎるとスマートフォンのスピーカーの出力に制限が生じ、特に 21kHz を超えると信号が急激に減衰し、その後の特徴抽出に対する効果が低下します。そのため、この範囲は「聴覚性、抗ノイズ性、ハードウェア能力」の三者間でバランスを取ったものです。</p>
<p>信号が録音で正確に識別できるように、最初に 11.025kHz のパイロットトーンが追加されています。これは持続的で安定した純音波で、他の chirp 信号や環境ノイズと明確に区別されます。</p>
<p>録音内容との相関演算を通じて、モデルは信号の開始点を正確に位置決定し、異なるスマートフォンデバイス間のタイミング遅延を自動的に補正することができます。これは実際のデプロイメントで重要な安定性要因となります。</p>
<p>また、掃引信号の設計では、各 chirp の長さを 60 サンプル（約 1.4 ミリ秒）に設定し、その間に 3000 サンプルの間隔を設けています。</p>
<p>この設定は物理的および工学的な制約を考慮しています：</p>
<p>chirp が長すぎると、信号対雑音比を向上させることができますが、顔の反射と時間的に重複する可能性があります。たとえば、距離 30cm では音波の往復に約 1.7 ミリ秒かかり、サンプル数に換算すると 77 サンプルです。もし chirp の長さがこの値を超えると、反射と直達信号を区別するのが困難になります。</p>
<p>逆に、chirp 間隔が短すぎると、前の chirp から遠くの物体（例えば壁）から反射されたエコーが次の chirp の顔のエコー範囲に入ってしまい、混乱と干渉が発生する可能性があります。</p>
<p>実験結果は、3000 サンプル（約 68 ミリ秒）の間隔がこれらの問題を効果的に回避でき、全体的な検出時間が長すぎることなく、0.8 秒以内で信号が終了し、ユーザーが受け入れ可能な感知閾値内に収まることを示しました。</p>
<p>もちろん、周波数設計ができる限り人間の耳が感知できる範囲を避けるようにしているものの、特定の信号は 17kHz 以下に残り、特定のユーザーには聴覚的な干渉を引き起こす可能性があります。</p>
<p>そのため、著者は信号設計に Hamming ウィンドウを追加し、chirp の開始と終了が滑らかなエンベロープ形状を持つようにし、音の鋭さをさらに低減させました。また、各スマートフォンモデルに対して音量最適化テストも行い、「歪みなく十分な音量」を確保するようにしました。</p>
<p>調査によると、参加者の 90%以上が「ほとんど音を感じなかった」と回答しており、この設計の実際の適用可能性に対して良好な証拠を提供しています。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=信号処理>信号処理<a href=#信号処理 class=hash-link aria-label="信号処理 への直接リンク" title="信号処理 への直接リンク">​</a></h3>
<p>もし、音の設計が言語であるなら、信号処理はその意味を理解することに相当します。</p>
<p>Echo-FAS では、録音された音は単なるエコーではなく、複合物です。それはスピーカーからの<strong>直達信号</strong>、顔からの<strong>主エコー</strong>、および環境の他の物体からの<strong>背景反射</strong>を同時に含んでいます。</p>
<p>信号処理の目的は、この音波の中から本当に顔の幾何学的輪郭を表す部分を抽出し、後続の識別モデルの入力として使用することです。</p>
<p>全体の処理フローは三つの段階に分かれています：</p>
<ul>
<li><strong>信号のセグメンテーション（segmentation）</strong></li>
<li><strong>直達信号の除去（direct transmission removal）</strong></li>
<li><strong>目標エコーの抽出（target reflection extraction）</strong></li>
</ul>
<p>以下の図のようになります：</p>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=signal-processing src=/ja/assets/images/img3-937552e95a843e445ffc6f2e97b7ed4c.jpg width=1584 height=844 class=img_ev3q></figure></div>
<p>最初は<strong>信号のセグメンテーション</strong>です。</p>
<p>録音の開始点は安定していません。スピーカーとマイクはスマートフォン上で完全に同期していないため、著者は 11.025kHz のパイロットトーンを同期マーカーとして設計しました。録音内容との相互相関を通じて、システムは信号の正確な開始点を特定することができます。</p>
<p>開始点が決定された後、録音全体は九つのセグメントに分割され、それぞれが前述の九つの chirp に対応します。各セグメントには直達信号とさまざまなエコーが混在しており、これが粗い位置決めの第一歩です。</p>
<p>次に、<strong>直達信号の除去</strong>に進みます。</p>
<p>この信号はスピーカーから発信され、反射されずにマイクで直接受信された部分で、最短の伝達距離とほとんど減衰しないエネルギーを持ち、録音全体で最もピークが高いことがよくあります。これを除去するために、著者は元の chirp とのマッチングフィルタを使用して、この信号の開始位置を識別し、その前後のサンプルを削除して、顔や背景のエコーを含む可能性がある部分だけを残します。</p>
<p>最後に、重要な<strong>顔のエコーの抽出</strong>段階に入ります。</p>
<p>直達信号を除去した後、残る信号は壁やテーブルなどの遠くの物体からのエコーを含んでいる可能性がありますが、それらは遅れて現れ、比較的分散しています。一方、顔のエコーは最も近い距離にあり、各セグメントで「最も早く、最も集中して」現れます。以下の図のように：</p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=signal-segmentation src=/ja/assets/images/img4-5d652113b5576efacc5aa8ffebf033d3.jpg width=1204 height=510 class=img_ev3q></figure></div>
<p>そこで、著者は<strong>適応型位置決めアルゴリズム</strong>を提案しました。各録音セグメントでマッチドフィルター演算を行い、最もエネルギーが高いピークを見つけ、九つのセグメントのピーク位置を平均化して、時間的に「最も一貫しており、顔のエコーである可能性が高い」位置を特定します。このアルゴリズムは標準偏差が最小の平均点を繰り返し求め、安定した位置決めを保証します。その後、各セグメントでその位置以降の 60 サンプルを切り出し、最終的な顔の音響特徴として出力します。</p>
<p>これにより、各検出ごとに元の録音から九つの 60 サンプルの音波セグメントを抽出し、その後のモデルが真偽を判断する基準として使用します。この過程では追加のハードウェアや多チャンネル設計は必要なく、1 つのマイクとよく設計された音声で顔の音響構造をキャプチャすることができます。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=モデルアーキテクチャ>モデルアーキテクチャ<a href=#モデルアーキテクチャ class=hash-link aria-label="モデルアーキテクチャ への直接リンク" title="モデルアーキテクチャ への直接リンク">​</a></h3>
<p>音声の問題が解決された後、次は私たちが馴染みのあるモデルアーキテクチャの話です。</p>
<p>下の図は、この識別プロセス全体を示しており、3 つの段階に分かれています：</p>
<p><img decoding=async loading=lazy alt=model-architecture src=/ja/assets/images/img5-2e003cce65d75fc43c45203dc95baf80.jpg width=1808 height=452 class=img_ev3q></p>
<ul>
<li><strong>前処理（Preprocessing）</strong></li>
<li><strong>二分岐特徴抽出（Two-Branch Feature Extraction）</strong></li>
<li><strong>交差融合決定（Cross-Attention Fusion）</strong></li>
</ul>
<p>読者にとって、この部分は比較的簡単だと思われるので、順を追って見ていきましょう。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=前処理>前処理<a href=#前処理 class=hash-link aria-label="前処理 への直接リンク" title="前処理 への直接リンク">​</a></h3>
<p>入力は、マイクで録音された原始的な音声信号です。</p>
<p>先ほど紹介した信号処理ステップを通じて、システムは同期処理、直達信号の除去を行い、録音全体から 9 つのエコーセグメントを抽出します。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=二分岐アーキテクチャ>二分岐アーキテクチャ<a href=#二分岐ア��ーキテクチャ class=hash-link aria-label="二分岐アーキテクチャ への直接リンク" title="二分岐アーキテクチャ への直接リンク">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=two-branch src=/ja/assets/images/img7-d7be056bbf344958d5627daa25fc4345.jpg width=996 height=1080 class=img_ev3q></figure></div>
<p>これらの 9 つのエコーは、それぞれ 2 つの平行かつ補完的なニューラルネットワーク分岐に送られ、2 種類の周波数特徴を解読します：</p>
<ul>
<li>
<p><strong>Global Frequency Branch（右側、Transformer 分岐）</strong>：</p>
<p>各信号を Fast Fourier Transform（FFT）で変換し、周波数領域に表現を移して、9 つのトークンを Transformer 構造に入力します。</p>
<p>この分岐は、信号の全体的な周波数分布関係や長距離依存特徴をキャプチャすることに重点を置いています。Transformer はこれらの周波数スペクトルから顔の構造に関連する「周波数のパターン」を学習し、全体的な視点で特徴マップを構築します。</p>
</li>
<li>
<p><strong>Local Frequency Branch（左側、CNN 分岐）</strong>：</p>
<p>もう一方では、各信号を Short-Time Fourier Transform（STFT）で変換し、時間–周波数図（スペクトログラム）に変換します。</p>
<p>これらの画像は、音波の時間的な変調プロセスを保持しており、顔をスキャンする際に捕えることができる動的特徴を反映しています。これらの画像はその後、局所的なパターンや詳細な変化を捉えるのが得意な CNN ネットワークに送られ、「幾何学的な詳細なテクスチャ」を抽出する学習を行います。</p>
</li>
</ul>
<hr>
<p>この 2 つのルートは、それぞれ異なる建模上の利点を持っています：Transformer は全体的な周波数構造に焦点を当て、CNN は局所的な応答パターンに焦点を当てます。Echo-FAS では、これらは対立するものではなく、補完的に設計されています。</p>
<p>2 つの分岐はそれぞれ、全域特徴<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub></mrow><annotation encoding=application/x-tex>f_1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>、局所特徴<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mn>2</mn></msub></mrow><annotation encoding=application/x-tex>f_2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>を出力します。</p>
<p>これらの 2 つの視点を真正面から対齐させるために、Echo-FAS は**双方向交差注意モジュール（Dual Cross-Attention Module）**を設計しました。上の図(d)のように、Cross-Attention モジュールは<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub></mrow><annotation encoding=application/x-tex>f_1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>が<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mn>2</mn></msub></mrow><annotation encoding=application/x-tex>f_2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>に注目し、また<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mn>2</mn></msub></mrow><annotation encoding=application/x-tex>f_2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>が<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub></mrow><annotation encoding=application/x-tex>f_1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>に注目するようにします。これにより、両者は互いに注目し、融合し、最終的に 2 組の特徴を結合して分類層に渡し、最終的な判断が行われます。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=深さ選択>深さ選択<a href=#深さ選択 class=hash-link aria-label="深さ選択 への直接リンク" title="深さ選択 への直接リンク">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=depth-selection src=/ja/assets/images/img6-51caf68291851c287948d0074154fdaf.jpg width=1134 height=482 class=img_ev3q></figure></div>
<p>このアーキテクチャの設計が合理的かどうかを確認するために、著者は一連のアブレーション実験を行いました。</p>
<p>上の図に示されているように、Transformer ブロック数（右図）と CNN 層数（左図）が増加すると、システムの識別精度は徐々に向上しますが、ある深さで性能が安定します。最終的に、著者は 10 層の Transformer と 5 層の CNN を二分岐のバックボーンとして選択し、性能とリソース消費のバランスを取っています。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=討論>討論<a href=#討論 class=hash-link aria-label="討論 への直接リンク" title="討論 への直接リンク">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=跨身份識別能力>跨身份識別能力<a href=#跨身份識別能力 class=hash-link aria-label="跨身份識別能力 への直接リンク" title="跨身份識別能力 への直接リンク">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=cross-identity src=/ja/assets/images/img8-1c00291737e30b7601e6d0ad747b464a.jpg width=792 height=366 class=img_ev3q></figure></div>
<p>実際のシーンでは、FAS システムはすべてのユーザーを事前に認識することはできません。未知の顔に対しても正しく判断できる必要があります。したがって、最初の実験は最も重要な一般化の課題に焦点を当てています：<strong>クロスアイデンティティ活体検出</strong>。</p>
<p>上の表では、著者は Echo-FAS を 25 人のユーザーでトレーニングし、訓練データに一度も登場しなかった 5 人の被験者でテストしました。</p>
<p>結果として、Echo-FAS はこの設定でも<strong>98.79%の AUC と 95.18%の ACC</strong>を達成し、安定した優れたパフォーマンスを発揮しました。さらに、表には MLP、CNN、Transformer などの他の分類モデルの結果も示されていますが、これらは一定の認識性能を達成できるものの、全体的に Echo-FAS には大きく遅れを取っています。</p>
<p>これは、音波信号自体が非常に識別可能であることを再確認させるだけでなく、Echo-FAS アーキテクチャが「信号モデリング」と「情報整合」の面で優れていることを強調しています。</p>
<p>簡単に言えば、Echo-FAS はあなたの顔を見たことがなくても、<strong>あなたが本物であることを音で聞き分けることができる</strong>のです。</p>
<p>これは、音響を利用した活体識別能力の効率的なデモンストレーションであり、今後のデバイス間や攻撃種類のテストにおける一般化性能の自信の基盤を築いています。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=ユーザー習慣における安定性>ユーザー習慣における安定性<a href=#ユーザー習慣における安定性 class=hash-link aria-label="ユーザー習慣��における安定性 への直接リンク" title="ユーザー習慣における安定性 への直接リンク">​</a></h3>
<div align=center><figure style=width:85%><p><img decoding=async loading=lazy alt=user-habit src=/ja/assets/images/img9-e98ad37b86410875c1236b7a2ff4cee6.jpg width=1224 height=480 class=img_ev3q></figure></div>
<p>すべての人がスマートフォンをまっすぐに持つわけではありません。</p>
<p>ある人は下を向いてスマホを操作し、ある人は横向きにロックを解除し、またある人はスマホを少し仰角で操作する習慣があります。これらの日常的な習慣は、従来の FAS システムでは「非理想的な姿勢」として扱われてきましたが、実際の世界ではこれらが標準的な状態です。</p>
<p>Echo-FAS の操作差異における安定性を検証するために、著者は「ユーザー仰角耐性テスト」を設計しました：</p>
<ul>
<li><strong>顔とスマートフォン間の角度（ピッチ）を-10°、0°、+10° の 3 つの設定に分け、それぞれに仰角、正対、俯角の最も一般的な使用シナリオを対応させ、各角度でモデルのテストを行いました。</strong></li>
</ul>
<p>結果として、Echo-FAS はどの角度でも安定した高精度な認識性能を維持し、すべてのベースラインモデルにおいて最良のパフォーマンスを示しました。これは、Echo-FAS が固定された撮影姿勢に依存せず、その音波信号の幾何学的特徴のキャプチャ能力が、実際の使用過程での姿勢変化を十分にカバーできることを証明しています。</p>
<p>これはユーザーフレンドリーな保証です：<strong>モデルに合わせて角度を調整する必要はなく、モデルは自分で調整してあなたを理解します。</strong></p>
<p>Echo-FAS が強調する「音波幾何学」は、技術的なアーキテクチャの言語にとどまらず、実際のインタラクションシーンでの安定性を追求する実践的なアプローチです。これにより、Echo-FAS は単にベンチマークで高得点を取るだけでなく、ユーザーの日常に溶け込むことができます。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=多モーダル融合>多モーダル融合<a href=#多モーダル融合 class=hash-link aria-label="多モーダル融合 への直接リンク" title="多モーダル融合 への直接リンク">​</a></h3>
<p>多くの実際のアプリケーションシーンでは、ユーザーがどのスマートフォンを使用し、どのような光源の下で身分認証を行うかを予測することはできません。これにより、RGB を主とする FAS モデルはデバイスの異質性によりドメイングラップを生じ、性能が顕著に低下することがあります。</p>
<p>Echo-FAS の音響モダリティは、顔の構造を読み取るため、画像の外観に影響されることが少なく、より安定した信号源を提供します。</p>
<p>音声と画像の相補性を検証するために、著者は次のような多モーダル融合実験を設計しました：</p>
<div align=center><figure style=width:85%><p><img decoding=async loading=lazy alt=multi-modal src=/ja/assets/images/img11-42844db961f27807aecba366d2390721.jpg width=1224 height=416 class=img_ev3q></figure></div>
<p>各サンプルは 2 つの信号から構成されています：1 つは音波（Echo-FAS 提供の幾何学的特徴）、もう 1 つは顔の画像（RGB モダリティの外観特徴）です。</p>
<p>音声信号は Echo-FAS のバックボーンで特徴<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mi>A</mi></msub></mrow><annotation encoding=application/x-tex>f_A</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>を抽出し、画像は ImageNet で事前学習した ResNet18 で視覚特徴<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mi>V</mi></msub></mrow><annotation encoding=application/x-tex>f_V</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.22222em>V</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>を抽出し、両者は融合モジュールを通じて一緒に判断を行います。</p>
<p>実験では、4 台のスマートフォン（Samsung S9、S21、Edge Note、Redmi7）を使用してデータ収集を行い、毎回 3 台のデバイスを使ってトレーニングし、残りの 1 台をテスト領域として使用し、実際のデプロイメントでのデバイス間の一般化チャレンジをシミュレートしました。</p>
<p>実験結果は以下の表の通りです：</p>
<div align=center><figure style=width:85%><p><img decoding=async loading=lazy alt=multi-modal-result src=/ja/assets/images/img10-4fe920e501af1ffe005618684020a8d7.jpg width=1224 height=298 class=img_ev3q></figure></div>
<p>融合後のモデルは、すべてのテストシナリオにおいて RGB モデルを上回り、音声モダリティが RGB モデルの不足を成功裏に補完したことを証明しました。</p>
<p>撮影機器の変更や画像品質の不安定さに対して、Echo-FAS は構造的な信号を提供し、幾何学的特徴を意思決定ロジックに戻し、モデルが外観の細部に過度に依存することを減少させます。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=結論>結論<a href=#結論 class=hash-link aria-label="結論 への直接リンク" title="結論 への直接リンク">​</a></h2>
<p>Echo-FAS は非常に実用的な FAS ソリューションを提供します。</p>
<p>追加のハードウェアは必要なく、信号は軽量で、推論も迅速に行え、日常のデバイスで即座に使用可能で、強力な認識安定性を示します。その優位性は、ユーザーが何も変更する必要がないことです：新しい習慣を学ぶ必要はなく、特別な角度や光源に依存せず、長い遅延を我慢する必要もありません。</p>
<p>基本的に、スマートフォンにマイクがあれば、それは動作します。</p>
<p>しかし、このシステムにはいくつかの制限もあります。</p>
<p>まず、立体的な偽顔（3D マスク）の複雑な素材と深さの層には対応できません。これは平面音波では解析が難しい次元です。次に、ハードウェア間の周波数応答差異を完全に排除することは依然として難しく、デバイス間の音響指紋がモデルの一般化に微妙な痕跡を残す可能性があります。フィルタリングや適応設計を行ったとしても、音はその機器に依存するため制約を受けます。</p>
<p>したがって、Echo-FAS の位置づけは、既存の方法を革新して取って代わることではなく、低依存、高補償、軽量な識別モダリティを提供することです。環境が制御できない、または画像が信頼できない状況で、別の可能性を示しています：</p>
<p>偽造の手がかりは、画像からだけでなく、音のエコーからも得られるのです。</header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated><b><time datetime=2025-05-14T06:43:15.000Z itemprop=dateModified>2025年5月14日</time></b>に<b>zephyr-sh</b>が<!-- -->最終更新</span></div></div><section class=ctaSection_iCjC><div class="
        simpleCta_ji_Y
        simple-cta__coffee_YwC8
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>☕ 1杯のコーヒーが支えになります</h3><p class=simple-cta__subtitle_ol86>AIやフルスタックの情報発信を続けるため、ご支援お願いします。<div class=simple-cta__buttonWrapper_jk1Y><img src=/ja/img/bmc-logo.svg alt=cta-button class=simple-cta__buttonImg_Q9VV></div></div><div class="ant-row ant-row-stretch cardsSection_wRaP css-mc1tut" style=margin-left:-8px;margin-right:-8px;row-gap:16px><div style=padding-left:8px;padding-right:8px;display:flex class="ant-col ant-col-xs-24 css-mc1tut"><div class="ant-card ant-card-bordered card_gKx9 fadeInUp_n33J hoverTransform_Mozy css-mc1tut" style=flex:1;display:flex;flex-direction:column><div class=ant-card-body><div style=text-align:center;margin-top:1rem><img src=/ja/img/icons/all_in.svg alt="AI・開発・運用まで一括対応 icon" style=width:48px;height:48px></div><span class="ant-tag ant-tag-orange card__tag_PLj3 css-mc1tut">ALL</span><h4 class=card__title_SQBY>AI・開発・運用まで一括対応</h4><p class=card__concept_Ak8F>アイデアからリリースまで、技術面はまるごとお任せください。<div class=card__bulletHeader_b6cf><h5 class=card__bulletTitle_R_wg>対応内容</h5></div><ul class=card__bulletList_SrNN><li class=card__bulletItem_wCRd>技術相談 + 開発 + デプロイ<li class=card__bulletItem_wCRd>継続サポート & 拡張</ul></div></div></div></div><div class="
        simpleCta_ji_Y
        simple-cta__outro_AXbn
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>🚀 次のプロジェクト、始めましょう！</h3><p class=simple-cta__subtitle_ol86>カスタム開発や長期支援をご希望の方は、ぜひご相談ください。</div></section><div style=margin-top:3rem> </div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label=ドキュメントページ><a class="pagination-nav__link pagination-nav__link--prev" href=/ja/papers/face-antispoofing/ssan/><div class=pagination-nav__sublabel>前へ</div><div class=pagination-nav__label>[22.03] SSAN</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/ja/papers/face-antispoofing/fas-survey/><div class=pagination-nav__sublabel>次へ</div><div class=pagination-nav__label>[22.10] FAS Survey</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#偽造のエコー class="table-of-contents__link toc-highlight">偽造のエコー</a><li><a href=#問題��の定義 class="table-of-contents__link toc-highlight">問題の定義</a><li><a href=#問題の解決 class="table-of-contents__link toc-highlight">問題の解決</a><ul><li><a href=#変数の考慮 class="table-of-contents__link toc-highlight">変数の考慮</a><li><a href=#信号設計 class="table-of-contents__link toc-highlight">信号設計</a><li><a href=#信号分析 class="table-of-contents__link toc-highlight">信号分析</a><li><a href=#信号処理 class="table-of-contents__link toc-highlight">信号処理</a><li><a href=#モデルアーキテクチャ class="table-of-contents__link toc-highlight">モデルアーキテクチャ</a><li><a href=#前処理 class="table-of-contents__link toc-highlight">前処理</a><li><a href=#二分岐アーキテクチャ class="table-of-contents__link toc-highlight">二分岐アーキテクチャ</a><li><a href=#深さ選択 class="table-of-contents__link toc-highlight">深さ選択</a></ul><li><a href=#討論 class="table-of-contents__link toc-highlight">討論</a><ul><li><a href=#跨身份識別能力 class="table-of-contents__link toc-highlight">跨身份識別能力</a><li><a href=#ユーザー習慣における安定性 class="table-of-contents__link toc-highlight">ユーザー習慣における安定性</a><li><a href=#多モーダル融合 class="table-of-contents__link toc-highlight">多モーダル融合</a></ul><li><a href=#結論 class="table-of-contents__link toc-highlight">結論</a></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/ja/docs>オープンソースプロジェクト</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/papers/intro>論文ノート</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/blog>ブログ</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/terms-of-service>利用規約</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/privacy-policy>プライバシーポリシー</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/become-an-author>著者になる</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/ja/worklog>作業日誌</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>