"use strict";(self.webpackChunkdocsaid_website=self.webpackChunkdocsaid_website||[]).push([["56256"],{79241:function(e,n,t){t.r(n),t.d(n,{assets:function(){return o},contentTitle:function(){return a},default:function(){return c},frontMatter:function(){return l},metadata:function(){return r},toc:function(){return u}});var r=t(86315),i=t(85893),s=t(50065);let l={slug:"file-crawler-python-implementation",title:"\u30A6\u30A7\u30D6\u30DA\u30FC\u30B8\u306E\u30D5\u30A1\u30A4\u30EB\u3092\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u3059\u308BPython\u5B9F\u88C5",authors:"Z. Yuan",image:"/ja/img/2024/0923.webp",tags:["Python","File Crawler"],description:"\u30B7\u30F3\u30D7\u30EB\u306A\u30A6\u30A7\u30D6\u30D5\u30A1\u30A4\u30EB\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u30D7\u30ED\u30B0\u30E9\u30E0\u3002"},a=void 0,o={authorsImageUrls:[void 0]},u=[{value:"\u30D1\u30C3\u30B1\u30FC\u30B8\u306E\u30A4\u30F3\u30B9\u30C8\u30FC\u30EB",id:"\u30D1\u30C3\u30B1\u30FC\u30B8\u306E\u30A4\u30F3\u30B9\u30C8\u30FC\u30EB",level:2},{value:"\u30D7\u30ED\u30B0\u30E9\u30E0\u30B3\u30FC\u30C9",id:"\u30D7\u30ED\u30B0\u30E9\u30E0\u30B3\u30FC\u30C9",level:2},{value:"\u30D7\u30ED\u30B0\u30E9\u30E0\u306E\u5B9F\u884C",id:"\u30D7\u30ED\u30B0\u30E9\u30E0\u306E\u5B9F\u884C",level:2}];function p(e){let n={code:"code",h2:"h2",p:"p",pre:"pre",...(0,s.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"\u3042\u308B\u30A6\u30A7\u30D6\u30DA\u30FC\u30B8\u3092\u898B\u3064\u3051\u305F\u3068\u3053\u308D\u3001\u305D\u3053\u306B\u306F\u6570\u767E\u500B\u306E PDF \u30D5\u30A1\u30A4\u30EB\u30EA\u30F3\u30AF\u304C\u542B\u307E\u308C\u3066\u3044\u307E\u3057\u305F\u3002"}),"\n",(0,i.jsx)(n.p,{children:"\u30A8\u30F3\u30B8\u30CB\u30A2\u3068\u3057\u3066\u3001\u4E00\u3064\u305A\u3064\u624B\u52D5\u3067\u30AF\u30EA\u30C3\u30AF\u3057\u3066\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u3059\u308B\u306E\u306F\u3001\u3061\u3087\u3063\u3068\u9055\u3044\u307E\u3059\u3088\u306D\uFF1F"}),"\n",(0,i.jsx)(n.p,{children:"\u305D\u3053\u3067\u3001\u5C0F\u3055\u306A\u30D7\u30ED\u30B0\u30E9\u30E0\u3092\u66F8\u3044\u3066\u3001\u3059\u3079\u3066\u306E\u30D5\u30A1\u30A4\u30EB\u3092\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u3057\u3066\u307F\u307E\u3057\u3087\u3046\u3002"}),"\n",(0,i.jsx)(n.h2,{id:"\u30D1\u30C3\u30B1\u30FC\u30B8\u306E\u30A4\u30F3\u30B9\u30C8\u30FC\u30EB",children:"\u30D1\u30C3\u30B1\u30FC\u30B8\u306E\u30A4\u30F3\u30B9\u30C8\u30FC\u30EB"}),"\n",(0,i.jsx)(n.p,{children:"\u307E\u305A\u3001\u5FC5\u8981\u306A\u30D1\u30C3\u30B1\u30FC\u30B8\u3092\u30A4\u30F3\u30B9\u30C8\u30FC\u30EB\u3059\u308B\u5FC5\u8981\u304C\u3042\u308A\u307E\u3059\u3002\u307E\u3060\u30A4\u30F3\u30B9\u30C8\u30FC\u30EB\u3057\u3066\u3044\u306A\u3044\u5834\u5408\u306F\u3001\u4EE5\u4E0B\u306E\u30B3\u30DE\u30F3\u30C9\u3092\u5B9F\u884C\u3057\u3066\u304F\u3060\u3055\u3044\uFF1A"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install requests beautifulsoup4 urllib3\n"})}),"\n",(0,i.jsx)(n.h2,{id:"\u30D7\u30ED\u30B0\u30E9\u30E0\u30B3\u30FC\u30C9",children:"\u30D7\u30ED\u30B0\u30E9\u30E0\u30B3\u30FC\u30C9"}),"\n",(0,i.jsx)(n.p,{children:"\u3055\u3066\u3001\u30D7\u30ED\u30B0\u30E9\u30E0\u304C\u5B8C\u6210\u3057\u305F\u306E\u3067\u3001\u65E9\u901F\u30B3\u30FC\u30C9\u3092\u5171\u6709\u3057\u307E\u3059\uFF01"}),"\n",(0,i.jsx)(n.p,{children:"\u91CD\u8981\u306A\u7B87\u6240\u306F\u67A0\u3067\u56F2\u307E\u308C\u3066\u3044\u308B\u90E8\u5206\u3067\u3001\u3042\u306A\u305F\u306E\u30CB\u30FC\u30BA\u306B\u5FDC\u3058\u3066\u8ABF\u6574\u3059\u308B\u5FC5\u8981\u304C\u3042\u308A\u307E\u3059\u3002"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:'{13,16} title="file_crawler.py"',children:'import os\nfrom urllib.parse import urljoin\n\nimport requests\nfrom bs4 import BeautifulSoup\n\n# \u30D6\u30E9\u30A6\u30B6\u306E\u30D8\u30C3\u30C0\u30FC\u3092\u6A21\u5023\nheaders = {\n    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36"\n}\n\n# \u30A6\u30A7\u30D6\u30DA\u30FC\u30B8\u306EURL\nurl = "put_your_url_here"\n\n# \u5BFE\u8C61\u30D5\u30A1\u30A4\u30EB\u5F62\u5F0F\ntarget_format = ".pdf"\n\n# HTTP GET\u30EA\u30AF\u30A8\u30B9\u30C8\u3092\u9001\u4FE1\u3057\u3001\u30D8\u30C3\u30C0\u30FC\u3092\u8FFD\u52A0\nresponse = requests.get(url, headers=headers)\n\n# \u30EA\u30AF\u30A8\u30B9\u30C8\u304C\u6210\u529F\u3057\u305F\u304B\u78BA\u8A8D\nif response.status_code == 200:\n    # BeautifulSoup\u3067HTML\u3092\u89E3\u6790\n    soup = BeautifulSoup(response.text, "html.parser")\n\n    # \u3059\u3079\u3066\u306E<a>\u30BF\u30B0\u3092\u691C\u7D22\u3057\u3001href\u5C5E\u6027\u304C\u5BFE\u8C61\u5F62\u5F0F\u306B\u4E00\u81F4\u3059\u308B\u30EA\u30F3\u30AF\u3092\u62BD\u51FA\n    target_links = []\n    for link in soup.find_all("a"):\n        href = link.get("href")\n        if href and href.endswith(target_format): # \u3053\u3053\u3067\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u3059\u308B\u30D5\u30A1\u30A4\u30EB\u5F62\u5F0F\u3092\u6307\u5B9A\n            target_links.append(urljoin(url, href))\n\n    # \u30D5\u30A1\u30A4\u30EB\u3092\u4FDD\u5B58\u3059\u308B\u30D5\u30A9\u30EB\u30C0\u3092\u4F5C\u6210\n    os.makedirs("downloads", exist_ok=True)\n\n    # \u5404\u30D5\u30A1\u30A4\u30EB\u3092\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\n    for url in target_links:\n        file_name = url.split("/")[-1]  # URL\u304B\u3089\u30D5\u30A1\u30A4\u30EB\u540D\u3092\u62BD\u51FA\n        file_path = os.path.join("downloads", file_name)\n\n        # \u30EA\u30AF\u30A8\u30B9\u30C8\u3092\u9001\u4FE1\u3057\u3066\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\n        response = requests.get(url, headers=headers)  # \u30D8\u30C3\u30C0\u30FC\u3092\u540C\u69D8\u306B\u8FFD\u52A0\n        if response.status_code == 200:\n            with open(file_path, "wb") as f:\n                f.write(response.content)\n            print(f"\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u5B8C\u4E86: {file_name}")\n        else:\n            print(f"\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u5931\u6557: {url}")\nelse:\n    print(f"\u30A6\u30A7\u30D6\u30DA\u30FC\u30B8\u306B\u30A2\u30AF\u30BB\u30B9\u3067\u304D\u307E\u305B\u3093\u3002\u30B9\u30C6\u30FC\u30BF\u30B9\u30B3\u30FC\u30C9: {response.status_code}")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"\u30D7\u30ED\u30B0\u30E9\u30E0\u306E\u5B9F\u884C",children:"\u30D7\u30ED\u30B0\u30E9\u30E0\u306E\u5B9F\u884C"}),"\n",(0,i.jsx)(n.p,{children:"\u30B3\u30FC\u30C9\u304C\u5B8C\u6210\u3057\u305F\u3089\u3001\u30D7\u30ED\u30B0\u30E9\u30E0\u3092\u5B9F\u884C\u3057\u3066\u3001\u5BFE\u8C61\u5F62\u5F0F\u306E\u3059\u3079\u3066\u306E\u30D5\u30A1\u30A4\u30EB\u3092\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u3067\u304D\u307E\u3059\u3002"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python file_crawler.py\n"})})]})}function c(e={}){let{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},50065:function(e,n,t){t.d(n,{Z:function(){return a},a:function(){return l}});var r=t(67294);let i={},s=r.createContext(i);function l(e){let n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),r.createElement(s.Provider,{value:n},e.children)}},86315:function(e){e.exports=JSON.parse('{"permalink":"/ja/blog/file-crawler-python-implementation","source":"@site/i18n/ja/docusaurus-plugin-content-blog/2024/09-23-file-crawler/index.md","title":"\u30A6\u30A7\u30D6\u30DA\u30FC\u30B8\u306E\u30D5\u30A1\u30A4\u30EB\u3092\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u3059\u308BPython\u5B9F\u88C5","description":"\u30B7\u30F3\u30D7\u30EB\u306A\u30A6\u30A7\u30D6\u30D5\u30A1\u30A4\u30EB\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u30D7\u30ED\u30B0\u30E9\u30E0\u3002","date":"2024-09-23T00:00:00.000Z","tags":[{"inline":true,"label":"Python","permalink":"/ja/blog/tags/python"},{"inline":true,"label":"File Crawler","permalink":"/ja/blog/tags/file-crawler"}],"readingTime":2.37,"hasTruncateMarker":true,"authors":[{"name":"Z. Yuan","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Z. Yuan","page":null}],"frontMatter":{"slug":"file-crawler-python-implementation","title":"\u30A6\u30A7\u30D6\u30DA\u30FC\u30B8\u306E\u30D5\u30A1\u30A4\u30EB\u3092\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u3059\u308BPython\u5B9F\u88C5","authors":"Z. Yuan","image":"/ja/img/2024/0923.webp","tags":["Python","File Crawler"],"description":"\u30B7\u30F3\u30D7\u30EB\u306A\u30A6\u30A7\u30D6\u30D5\u30A1\u30A4\u30EB\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u30D7\u30ED\u30B0\u30E9\u30E0\u3002"},"unlisted":false,"prevItem":{"title":"Docusaurus\u30923.6.0\u306B\u30A2\u30C3\u30D7\u30C7\u30FC\u30C8","permalink":"/ja/blog/update-docusaurus-to-3-6-0"},"nextItem":{"title":"Docusaurus\u306E\u30B5\u30A4\u30C9\u30D0\u30FC\u306B\u8A18\u4E8B\u6570\u3092\u81EA\u52D5\u8A08\u7B97\u3055\u305B\u308B","permalink":"/ja/blog/customized-docusaurus-sidebars-auto-count"}}')}}]);