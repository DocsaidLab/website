<!doctype html><html lang=zh-hant dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-object-detection/yolov4/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.8.1"><title data-rh=true>[20.04] YOLOv4 | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/papers/object-detection/yolov4/><meta data-rh=true property=og:locale content=zh_hant><meta data-rh=true property=og:locale:alternate content=en><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=zh-hant><meta data-rh=true name=docsearch:language content=zh-hant><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[20.04] YOLOv4 | DOCSAID"><meta data-rh=true name=description content=模型設計顧問><meta data-rh=true property=og:description content=模型設計顧問><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/papers/object-detection/yolov4/><link data-rh=true rel=alternate href=https://docsaid.org/papers/object-detection/yolov4/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/object-detection/yolov4/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/object-detection/yolov4/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/object-detection/yolov4/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://docsaid.org/papers/category/object-detection-14","name":"Object Detection (14)","position":1},{"@type":"ListItem","item":"https://docsaid.org/papers/object-detection/yolov4/","name":"[20.04] YOLOv4","position":2}]}</script><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/assets/css/styles.8e7b88e9.css><script src=/assets/js/runtime~main.67c06492.js defer></script><script src=/assets/js/main.f164eaa1.js defer></script><body class=navigation-with-keyboard><svg xmlns=http://www.w3.org/2000/svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light",e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label=跳至主要内容><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>跳至主要内容</a></div><nav aria-label=主導航 class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label=切換導覽列 aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><div class=navbar__logo><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/docs/>開源專案</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/papers/intro>論文筆記</a><a class="navbar__item navbar__link" href=/blog>部落格</a><a class="navbar__item navbar__link" href=/playground/intro>遊樂場</a><a class="navbar__item navbar__link" href=/services>技術服務</a><a class="navbar__item navbar__link" href=/aboutus>關於我們</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>繁體中文</a><ul class=dropdown__menu><li><a href=/papers/object-detection/yolov4/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=zh-hant>繁體中文</a><li><a href=/en/papers/object-detection/yolov4/ target=_self rel="noopener noreferrer" class=dropdown__link lang=en>English</a><li><a href=/ja/papers/object-detection/yolov4/ target=_self rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="搜尋 (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>搜尋</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-mc1tut ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label=回到頂部 class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label=文件側邊欄 class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/papers/intro>論文筆記</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="展開側邊欄分類 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/contrastive-learning-14>Contrastive Learning (14)</a><button aria-label="展開側邊欄分類 'Contrastive Learning (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/deepseek-5>DeepSeek (5)</a><button aria-label="展開側邊欄分類 'DeepSeek (5)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/face-anti-spoofing-42>Face Anti-Spoofing (42)</a><button aria-label="展開側邊欄分類 'Face Anti-Spoofing (42)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="展開側邊欄分類 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/feature-fusion-10>Feature Fusion (10)</a><button aria-label="展開側邊欄分類 'Feature Fusion (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/image-generation-1>Image Generation (1)</a><button aria-label="展開側邊欄分類 'Image Generation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="展開側邊欄分類 'Lightweight (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/mamba-4>Mamba (4)</a><button aria-label="展開側邊欄分類 'Mamba (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/model-tuning-8>Model Tuning (8)</a><button aria-label="展開側邊欄分類 'Model Tuning (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/multimodality-24>Multimodality (24)</a><button aria-label="展開側邊欄分類 'Multimodality (24)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/normalization-1>Normalization (1)</a><button aria-label="展開側邊欄分類 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/papers/category/object-detection-14>Object Detection (14)</a><button aria-label="收起側邊欄分類 'Object Detection (14)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/yolov1/>[15.06] YOLOv1</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/ssd/>[15.12] SSD</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/yolov2/>[16.12] YOLOv2</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/retinanet/>[17.08] RetinaNet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/yolov3/>[18.04] YOLOv3</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/papers/object-detection/yolov4/>[20.04] YOLOv4</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/detr/>[20.05] DETR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/deformable-detr/>[20.10] Deformable DETR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/smca-detr/>[21.01] SMCA DETR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/h-detr/>[22.07] H-DETR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/yolov7/>[22.07] YOLOv7</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/yolov6/>[22.09] YOLOv6</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/yolo-world/>[24.01] YOLO-World</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/object-detection/yolo-tiny/>[24.12] YOLO-Tiny</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/reparameterization-8>Reparameterization (8)</a><button aria-label="展開側邊欄分類 'Reparameterization (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/retail-product-2>Retail Product (2)</a><button aria-label="展開側邊欄分類 'Retail Product (2)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="展開側邊欄分類 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-detection-14>Text Detection (14)</a><button aria-label="展開側邊欄分類 'Text Detection (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="展開側邊欄分類 'Text Recognition (20)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="展開側邊欄分類 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/transformers-17>Transformers (17)</a><button aria-label="展開側邊欄分類 'Transformers (17)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/vision-transformers-13>Vision Transformers (13)</a><button aria-label="展開側邊欄分類 'Vision Transformers (13)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/papers/intro>All Notes: 227 entries</a></ul></nav><button type=button title=收起側邊欄 aria-label=收起側邊欄 class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=頁面路徑><ul class=breadcrumbs><li class=breadcrumbs__item><a aria-label=主頁面 class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li class=breadcrumbs__item><a class=breadcrumbs__link href=/papers/category/object-detection-14><span>Object Detection (14)</span></a><li class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>[20.04] YOLOv4</span></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">本頁導覽</button></div><div class="theme-doc-markdown markdown"><header><h1>[20.04] YOLOv4</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt="Z. Yuan" class=docAuthorImg_vlJe><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Z. Yuan</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a href=https://www.linkedin.com/in/ze-yuan-sh7/ target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 448 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=模型設計顧問>模型設計顧問<a href=#模型設計顧問 class=hash-link aria-label=模型設計顧問的直接連結 title=模型設計顧問的直接連結>​</a></h2>
<p><a href=https://arxiv.org/abs/2004.10934 target=_blank rel="noopener noreferrer"><strong>YOLOv4: Optimal Speed and Accuracy of Object Detection</strong></a></p>
<hr>
<p>這篇論文走的是工業風，讀起來像是一份針對「物件偵測」模型的使用說明書。</p>
<p>我們就從整體設計開始，來學習一下該如何做好一個物件偵測模型。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>YOLO 模型的原始作者只做到 v3，而後都是其他流派的繼承者，因此後續的編號之間不一定存在關聯，發表年份也沒有嚴格先後順序。<p>YOLOv4 是來自臺灣的開發團隊。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=模型的架構觀>模型的架構觀<a href=#模型的架構觀 class=hash-link aria-label=模型的架構觀的直接連結 title=模型的架構觀的直接連結>​</a></h2>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=object-detection src=/assets/images/img2-617b6c380cf668d031bc474aa9bd9e93.jpg width=1588 height=770 class=img_ev3q></figure></div>
<p>一個物件偵測器，通常包含四個主要模組：<code>Input</code>、<code>Backbone</code>、<code>Neck</code>、<code>Head</code>。</p>
<p>每一段都各司其職，彼此銜接又能自由組合，就像堆積木一樣。</p>
<ul>
<li>
<p><strong>Input</strong></p>
<p>除了單純的圖像輸入之外，還可能加入各種強化訊號，像是多尺度影像金字塔、資料增強、圖像裁切（patching）或改變解析度，目的是從輸入端就強化模型對目標的識別能力。</p>
</li>
<li>
<p><strong>Backbone</strong></p>
<p>主要的特徵提取模組，多數來自影像分類的經典架構，如 VGG、ResNet、DenseNet，也有為偵測任務量身打造的 CSPDarknet、DetNet 等變形版本。目標是將輸入影像轉換為具備語意與視覺資訊的深層特徵圖。</p>
</li>
<li>
<p><strong>Neck</strong></p>
<p>試圖整合來自不同層級的特徵圖，平衡淺層的定位資訊與深層的語意特徵。從 FPN 到 PAN，再到 BiFPN、NAS-FPN，每一代設計都力求資訊流的更佳融合與傳遞效率。</p>
</li>
<li>
<p><strong>Head</strong></p>
<p>最終進行分類與框選的模組，區分為密集預測（如 YOLO、SSD）與稀疏預測（如 R-CNN 系列）兩大類，也正是效能與精度的主要戰場。</p>
</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=兩個設計路線>兩個設計路線<a href=#兩個設計路線 class=hash-link aria-label=兩個設計路線的直接連結 title=兩個設計路線的直接連結>​</a></h2>
<p>物件偵測架構在發展過程中，逐漸分化為兩種主流策略：雙階段與單階段。</p>
<ul>
<li><strong>雙階段架構</strong>（Two-stage），如 Faster R-CNN、Libra R-CNN 等，先產生候選區域（Region Proposals），再進行分類與邊界框回歸。這種方法具備較高的精度與較強的區域建模能力，適合需要精確偵測的任務。後續也出現如 RepPoints 的 anchor-free 版本，以緩解錨點設計的限制。</li>
<li><strong>單階段架構</strong>（One-stage），如 YOLO、SSD、RetinaNet，則直接對整張圖進行密集預測，不經候選區域產生，換取更高的效率與更快的推論速度。這類方法隨著 anchor-free 設計（如 CenterNet、FCOS、CornerNet）的出現，也開始挑戰過往雙階段架構的精度優勢。</li>
</ul>
<p>這兩條路線的分歧，其實體現了「速度」與「精度」之間的權衡，而 YOLOv4 的設計就是試圖在這條光譜上取得最佳平衡點。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=特徵融合的-neck>特徵融合的 Neck<a href=#特徵融合的-neck class=hash-link aria-label="特徵融合的 Neck的直接連結" title="特徵融合的 Neck的直接連結">​</a></h2>
<p>隨著 Backbone 的深度與廣度提升，如何有效整合多層次特徵成為後續預測的關鍵。</p>
<p>這就是 Neck 模組的設計初衷，也就是為了讓語意資訊與定位資訊互補融合，為 Head 提供兼具語意與空間細節的輸入。一些常見的方式像是：</p>
<ul>
<li><strong>FPN</strong>（Feature Pyramid Network）開創 top-down 融合結構，逐層上採樣並融合高層語意訊號。</li>
<li><strong>PAN</strong>（Path Aggregation Network）則補上 bottom-up 路徑，增強淺層資訊的反饋能力。</li>
<li><strong>BiFPN / NAS-FPN</strong> 進一步追求效率與效能的極致，以可學習權重的雙向融合與 NAS 尋找最優配置。</li>
<li><strong>ASPP / RFB / SAM</strong> 這類模組則透過空間金字塔、感受野設計或注意力機制來強化特徵表徵能力。</li>
</ul>
<p>這些設計背後的核心問題是：如何在不過度犧牲速度的前提下，提升多尺度理解與特徵表達能力。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=為偵測而生的-backbone>為偵測而生的 Backbone<a href=#為偵測而生的-backbone class=hash-link aria-label="為偵測而生的 Backbone的直接連結" title="為偵測而生的 Backbone的直接連結">​</a></h2>
<p>在模型設計邁向模組化、可替換的同時，也有研究者回頭從骨幹網路本身出發，重新設計專屬於物件偵測任務的特徵提取器。</p>
<ul>
<li><strong>DetNet</strong> 與 <strong>DetNAS</strong> 開始將分類導向的主幹改為偵測導向，注重保持高解析度與偵測感知能力。</li>
<li><strong>SpineNet</strong> 強調資料流動的多樣性與特徵組合的靈活性，結合 NAS 尋找最佳網路配置。</li>
<li><strong>HitDetector</strong> 則直接從任務需求出發，規劃從輸入到預測的整體設計，使各模組協同發揮效益。</li>
</ul>
<p>這個方向的發展，意味著任務需求從影像分類轉向定位與框選，光是套用分類架構已無法滿足偵測的複雜性，因此從骨幹重新設計可能是更高效的解決方案。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=訓練優化技巧>訓練優化技巧<a href=#訓練優化技巧 class=hash-link aria-label=訓練優化技巧的直接連結 title=訓練優化技巧的直接連結>​</a></h2>
<p>在物件偵測的訓練過程中，有一類技巧被統稱為「Bag of Freebies」。</p>
<p>意思指的是那些「<strong>只會增加訓練成本，而不會影響推論效能的技術</strong>」。換句話說，它們的存在目的是在不影響推論速度的前提下，提高模型的準確度與泛化能力。</p>
<p>這類技巧可以分成三大類型：資料增強、標籤處理，以及損失函數的優化。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=資料增強>資料增強<a href=#資料增強 class=hash-link aria-label=資料增強的直接連結 title=資料增強的直接連結>​</a></h3>
<p>物件偵測模型的泛化能力，很大程度取決於輸入資料的多樣性。為了讓模型能夠適應不同環境下的影像輸入，資料增強成為最常見且有效的策略。</p>
<ul>
<li><strong>像素層級變化</strong>：包括亮度、對比、飽和度、色相與雜訊等光度失真，以及隨機縮放、裁切、翻轉、旋轉等幾何變換，這些方法保留了原始像素資訊，僅僅改變了其排列與視覺呈現。</li>
<li><strong>遮蔽式增強</strong>：為了模擬遮擋場景，像是 Random Erase、CutOut、Hide-and-Seek 與 GridMask 等方法會隨機遮蔽影像區域，讓模型學習在遮擋情境下也能辨識目標。</li>
<li><strong>特徵遮蔽法</strong>：類似概念也可應用在特徵圖上，例如 DropOut、DropConnect 與 DropBlock 等方法，以增強模型對中間表徵的容錯與穩定性。</li>
<li><strong>混合多張影像</strong>：MixUp 與 CutMix 等策略，將兩張影像進行融合或拼接，並對標籤進行加權調整或面積比例分配，進一步提升模型對複雜場景的理解能力。</li>
<li><strong>風格轉換</strong>：Style Transfer GAN 也被用來產生不同風格的影像版本，以降低 CNN 對特定材質與紋理的過度依賴。</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=標籤平滑與知識蒸餾>標籤平滑與知識蒸餾<a href=#標籤平滑與知識蒸餾 class=hash-link aria-label=標籤平滑與知識蒸餾的直接連結 title=標籤平滑與�知識蒸餾的直接連結>​</a></h3>
<p>除了輸入影像的處理，對標籤的操作也是免費優化的一環。</p>
<p>在分類任務中，標籤通常以 one-hot 的方式呈現，這種「硬標籤」雖然清晰，但缺乏語意層級的模糊彈性。為此，Label Smoothing 被提出來將原始標籤轉為「軟標籤」，讓模型不會過度自信於某一類別，提高其在未知資料上的穩定性。</p>
<p>進一步的作法是引入知識蒸餾，由一個性能較高的 Teacher 模型提供更細緻的輸出分布，透過 Label Refinement Network 引導學生模型學習類別之間的相對關係。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=損失函數的優化>損失函數的優化<a href=#損失函數的優化 class=hash-link aria-label=損失函數的優化的直接連結 title=損失函數的優化的直接連結>​</a></h3>
<p>最後，針對物件偵測任務中極為關鍵的邊界框回歸問題，傳統做法是使用 MSE 或 L1/L2 Loss 直接對座標值（如中心點或對角線）進行回歸。然而這類做法會忽略整體框的幾何結構，也容易受物件尺度變化所影響。</p>
<p>因此，IoU Loss 成為近年主流選擇，將預測框與真實框的重疊區域作為損失函數的核心，具備尺度不變性與語意一致性的優勢。</p>
<p>其後又出現多種改進版本：</p>
<ul>
<li><strong>GIoU (Generalized IoU)</strong>：納入最小包圍框，解決 IoU 在完全不重疊時無梯度的問題。</li>
<li><strong>DIoU (Distance IoU)</strong>：加入中心點距離，強化定位精度。</li>
<li><strong>CIoU (Complete IoU)</strong>：同時考慮重疊率、中心距離與長寬比，綜合性最佳，也具有更快的收斂速度。</li>
</ul>
<p>這些回歸損失的改良，不僅提升了收斂穩定性，也讓模型在定位精度上邁向更高水準，成為高性能偵測器不可或缺的一環。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=精巧模組設計>精巧模組設計<a href=#精巧模組設計 class=hash-link aria-label=精巧模組設計的直接連結 title=精巧模組設計的直接連結>​</a></h2>
<p>與 Bag of Freebies 相對，另一類提升準確率的策略被稱為 <strong>Bag of Specials</strong>。</p>
<p>這類方法通常會略微增加推論成本，但<strong>所帶來的準確率提升遠大於其額外計算開銷</strong>，是物件偵測中極具 CP 值的技巧。</p>
<p>這些技巧可以分為四個面向：<strong>感受野擴張、注意力機制、特徵整合模組、非極大值抑制（NMS）後處理</strong>，再加上一個常被忽略但極具影響力的面向：<strong>激活函數設計</strong>。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=擴張感受野>擴張感受野<a href=#擴張感受野 class=hash-link aria-label=擴張感受野的直接連結 title=擴張感受野的直接連結>​</a></h3>
<p>為了讓模型更早感知上下文訊息並提升空間理解力，許多模組被設計來擴張感受野：</p>
<ul>
<li><strong>SPP（Spatial Pyramid Pooling）</strong> 模組源自傳統的 SPM 概念，原先在圖像分類中用來建立不同尺度的區塊表示。YOLOv3 將其整合至卷積網路中，改為多尺度的 MaxPooling 後串接（例如 k = 1, 5, 9, 13），不改變空間維度卻能大幅擴張感受野。在 YOLOv3-608 上僅增加 0.5% 計算量，卻能提升 AP50 2.7%。</li>
<li><strong>ASPP（Atrous Spatial Pyramid Pooling）</strong> 使用多個不同膨脹率的 3×3 膨脹卷積，以等價於多尺度感受野的方式進行空間感知。</li>
<li><strong>RFB（Receptive Field Block）</strong> 更進一步使用多組不同膨脹率的卷積並行計算，獲得更綿密且廣域的空間覆蓋效果。在 SSD 架構上只增加 7% 推論時間，卻帶來 5.7% 的 AP50 提升。</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=注意力機制>注意力機制<a href=#注意力機制 class=hash-link aria-label=注意力機制�的直接連結 title=注意力機制的直接連結>​</a></h3>
<p>注意力模組能幫助模型動態調整重要訊號的強度，是近年廣泛應用於各項視覺任務的核心技術：</p>
<ul>
<li><strong>SE（Squeeze-and-Excitation）</strong> 模組專注於通道層級的重新加權，能夠幫助模型更集中在有判別性的特徵維度上，但在 GPU 上的推論開銷相對較高。</li>
<li><strong>SAM（Spatial Attention Module）</strong> 則是在空間層級引入注意力，針對輸入特徵圖進行空間加權，成本極低且幾乎不影響 GPU 上的推論速度。</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=跨尺度整合>跨尺度整合<a href=#跨尺度整合 class=hash-link aria-label=跨尺度整合的直接連結 title=跨尺度整合的直接連結>​</a></h3>
<p>傳統使用 skip connection 或 hypercolumn 將淺層與深層特徵拼接。隨著 FPN 為代表的多尺度融合架構興起，更多高效的融合模組被提出：</p>
<ul>
<li><strong>SFAM</strong>：基於 SE 模組進行通道注意力強化。</li>
<li><strong>ASFF（Adaptive Spatial Feature Fusion）</strong>：透過 point-wise softmax 決定不同尺度的特徵融合權重。</li>
<li><strong>BiFPN</strong>：提出 multi-input weighted residual connection，實現尺度層級的學習式融合，在準確度與效率間取得良好平衡。</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=激活函數的演進>激活函數的演進<a href=#激活函數的演進 class=hash-link aria-label=激活函數的演進的直接連結 title=激活函數的演進的直接連結>​</a></h3>
<p>一個好的啟用函數能讓梯度更穩定傳遞，又不造成額外負擔：</p>
<ul>
<li><strong>ReLU</strong> 解決了早期 sigmoid/tanh 的梯度消失問題。</li>
<li><strong>LReLU / PReLU</strong> 解決了負區間無梯度的問題。</li>
<li><strong>ReLU6 / hard-Swish</strong> 則是為量化網路量身打造。</li>
<li><strong>SELU</strong> 支援自我正規化（self-normalization）。</li>
<li><strong>Swish / Mish</strong> 為平滑且可導的函數，能提升深層網路的收斂性與精度。</li>
</ul>
<p>這些啟用函數雖屬微觀設計，但往往能在大型網路中累積顯著的效能優勢。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=nms-後處理>NMS 後處理<a href=#nms-後處理 class=hash-link aria-label="NMS 後處理的直接連結" title="NMS 後處理的直接連結">​</a></h3>
<p>非極大值抑制（NMS）用來篩除重複預測框，是物件偵測的最後一道程序：</p>
<ul>
<li><strong>傳統 NMS</strong> 依據 IoU 和置信度排序保留最佳框，但無法處理遮擋物件時的信心退化問題。</li>
<li><strong>Soft-NMS</strong> 嘗試以懲罰分數的方式減少「過於強硬」的篩除。</li>
<li><strong>DIoU-NMS</strong> 則引入中心距離資訊，使篩選更具幾何直覺。</li>
</ul>
<p>然而，隨著 anchor-free 架構的興起，有些架構（如 FCOS）已將 NMS 移除，直接藉由設計 loss 或後處理條件約束來完成預測選擇。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=解決問題>解決問題<a href=#解決問題 class=hash-link aria-label=解決問題的直接連結 title=解決問題的直接連結>​</a></h2>
<p>我們終於可以來看 YOLOv4 本人了。</p>
<p>有了上面各種方法的介紹，可以知道作者就是想找出一個又快又好的架構。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=架構選擇>架構選擇<a href=#架構選擇 class=hash-link aria-label=架構選擇的直接連結 title=架構選擇的直接連結>​</a></h3>
<p>在設計 Backbone 時，作者從「分類模型 ≠ 偵測模型」的核心觀念出發，重新評估各種架構在不同任務下的效能表現。</p>
<p>他們發現儘管 <strong>CSPResNeXt50</strong> 在 ImageNet 上表現優異，但在 MS COCO 偵測任務中，<strong>CSPDarknet53</strong> 的表現更勝一籌。這是因為偵測任務相較分類任務，需求更加嚴苛：</p>
<ul>
<li><strong>更高輸入解析度</strong>：為了可以辨識小型目標。</li>
<li><strong>更深的層數與更大的感受野</strong>：可以涵蓋更廣泛的上下文關係。</li>
<li><strong>更多參數容量</strong>：可以同時應對多目標、多尺度的場景需求。</li>
</ul>
<p>以感受野為例，CSPResNeXt50 僅有 16 層 3×3 卷積，感受野為 425×425；CSPDarknet53 則有 29 層，感受野達 725×725，搭配較大的參數量（27.6M），更能應對複雜的偵測場景。</p>
<p><img decoding=async loading=lazy alt=arch-choose src=/assets/images/img3-20fd8ec8a502602b1f1adf73ba9755eb.jpg width=1634 height=258 class=img_ev3q></p>
<p>因此，YOLOv4 選擇以 <strong>CSPDarknet53</strong> 作為骨幹，並在其上加入 <strong>SPP 模組</strong> 增強感受野，再透過 <strong>PANet</strong> 進行多層特徵聚合，最終連接至 <strong>YOLOv3 Head</strong> 完成預測。</p>
<p>這個架構的核心配置為：</p>
<ul>
<li><strong>Backbone</strong>：CSPDarknet53</li>
<li><strong>Neck</strong>：SPP + PANet</li>
<li><strong>Head</strong>：YOLOv3（anchor-based）</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=訓練策略選擇>訓練策略選擇<a href=#訓練策略選擇 class=hash-link aria-label=訓練策略選擇的直接連結 title=訓練策略選擇的直接連結>​</a></h3>
<p>YOLOv4 的訓練策略建構在兩個經典概念之上：</p>
<ul>
<li><strong>Bag of Freebies (BoF)</strong>：只增加訓練成本，不增加推論負擔</li>
<li><strong>Bag of Specials (BoS)</strong>：略增推論成本，顯著提升準確率</li>
</ul>
<p>在訓練架構上，YOLOv4 拋棄了不易收斂的 activation（如 PReLU, SELU）與針對量化設計的 ReLU6，改用效果平衡的 <strong>Mish activation</strong>；正規化方面則放棄需多卡訓練的 SyncBN，轉而設計更適合單卡訓練的 <strong>Cross mini-Batch Normalization (CmBN)</strong>。</p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=cmbn src=/assets/images/img5-caa9f54d9cc87b3e41001d71b8d0bea2.jpg width=936 height=664 class=img_ev3q></figure></div>
<p>在深度學習中，Batch Normalization（BN）是極為關鍵的穩定訓練手段。</p>
<p>但這個技巧有一個隱性假設：每個 mini-batch 都足夠大，才能取得代表性的均值與變異數統計量。然而，當模型規模增大、顯存受限或僅能使用單張 GPU 時，mini-batch size 常常偏小，導致 BN 的效果急劇下降，甚至產生不穩定收斂問題。</p>
<p>過往為了解決這個問題，有人提出 SyncBN（Cross-GPU BN），讓多張 GPU 之間共享統計資訊，提升統計穩定性。但這需要多卡硬體資源，不適合單卡訓練場景。</p>
<p>CmBN 則引入「跨 mini-batch」統計聚合機制：</p>
<p>假設我們訓練時設計了某種資料增強方式，如 Mosaic，一次性將 4 張圖組成一張訓練影像。CmBN 會將這組由不同來源圖像構成的 batch，看成一個「擴展樣本集合」。並在 BN 計算時針對這些子樣本分開統計，再進行合併平均。</p>
<p>也就是說，一個 batch 中包含多個 mini-batch 的統計線索，讓 BN 不再受限於單一子樣本的資料偏態。這種策略類似於對小 batch size 作資料層面的「聚合修正」，在不需要同步多卡的前提下，改善 BN 的泛化穩定性</p>
<p>此外，DropBlock 被選為主要的正則化方法，搭配 CutMix、MixUp、Label Smoothing 等增強策略，構成訓練中最具代表性的免費提升工具包。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=額外增強設計>額外增強設計<a href=#額外增強設計 class=hash-link aria-label=額外增強設計的直接連結 title=額外增強設計的直接連結>​</a></h3>
<p>YOLOv4 對於訓練過程還進行了三項關鍵優化：</p>
<ol>
<li>
<p><strong>Mosaic 資料增強</strong>：</p>
<p>將四張影像混合為一，擴增場景多樣性，並讓 BatchNorm 同步處理更多圖像資訊，提升小 Batch 下的穩定性。</p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=mosaic src=/assets/images/img4-aea38baff57d8f2756b5a4cd8193aca1.jpg width=928 height=572 class=img_ev3q></figure></div>
</li>
<li>
<p><strong>SAT（Self-Adversarial Training）</strong>：</p>
<p>訓練初期模型對自身圖像進行對抗性修改，再學習辨識這些偽裝後的圖像，增強對遮蔽與偽裝攻擊的穩健性。</p>
</li>
<li>
<p><strong>模組改良</strong>：</p>
<ul>
<li>
<p>SAM 改為 point-wise 注意力，提升對細節資訊的關注力。</p>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt=sam src=/assets/images/img6-9d0a27036a4b6585933ac15bf5728997.jpg width=932 height=620 class=img_ev3q></figure></div>
</li>
<li>
<p>PANet 的 shortcut 改為 concat，強化特徵融合完整性。</p>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt=pan src=/assets/images/img6_1-c7ed42bb754d25de6b2a0855ef37aba9.jpg width=936 height=456 class=img_ev3q></figure></div>
</li>
</ul>
</li>
</ol>
<p>這些設計，從增強資料表現力、擴展模型辨識邊界，到重塑訓練穩定性，構成一整套適應單卡訓練與推論環境的完整優化策略。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=組件總覽與技術選型>組件總覽與技術選型<a href=#組件總覽與技術選型 class=hash-link aria-label=組件總覽與技術選型的直接連結 title=組件總覽與技術選型的直接連結>​</a></h3>
<p>整合上述設計，YOLOv4 最終的模組選擇如下：</p>
<p><strong>架構組成：</strong></p>
<ul>
<li><strong>Backbone</strong>：CSPDarknet53</li>
<li><strong>Neck</strong>：SPP、PAN</li>
<li><strong>Head</strong>：YOLOv3 Head</li>
</ul>
<p><strong>訓練技巧（BoF for Backbone & Detector）：</strong></p>
<ul>
<li>CutMix / Mosaic 資料增強</li>
<li>DropBlock 正則化</li>
<li>Label smoothing</li>
<li>CIoU Loss</li>
<li>CmBN</li>
<li>SAT</li>
<li>Grid sensitivity 消除策略</li>
<li>多 Anchor 對應單一 ground truth</li>
<li>Cosine annealing scheduler</li>
<li>隨機訓練解析度</li>
<li>最佳化參數組合（使用基因演算法）</li>
</ul>
<p><strong>推論技巧（BoS for Backbone & Detector）：</strong></p>
<ul>
<li>Mish activation</li>
<li>CSP 模組</li>
<li>Multi-input weighted residual connections</li>
<li>SPP 模組</li>
<li>改良版 SAM</li>
<li>PAN path aggregation</li>
<li>DIoU-NMS 後處理策略</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=實驗配置>實驗配置<a href=#實驗配置 class=hash-link aria-label=實驗配置的直接連結 title=實驗配置的直接連結>​</a></h3>
<p>為了驗證各種訓練策略對模型性能的實際影響，作者在兩個標準資料集上進行了大規模實驗，分別針對分類與偵測任務進行訓練與評估。</p>
<p>在 <strong>ImageNet（ILSVRC 2012 val）</strong> 影像分類實驗中，採用以下預設訓練設定：</p>
<ul>
<li><strong>訓練步數</strong>：8,000,000 steps</li>
<li><strong>Batch size / mini-batch size</strong>：128 / 32</li>
<li><strong>學習率排程策略</strong>：Polynomial decay，初始學習率為 0.1</li>
<li><strong>warm-up 步數</strong>：1,000</li>
<li><strong>Momentum / Weight decay</strong>：0.9 / 0.005</li>
</ul>
<p>對於 <strong>Bag of Freebies (BoF)</strong> 的設定中，作者驗證了以下策略：</p>
<ul>
<li>MixUp</li>
<li>CutMix</li>
<li>Mosaic</li>
<li>模糊處理（Blurring）</li>
<li>標籤平滑正則化（Label Smoothing）</li>
</ul>
<p>在 <strong>MS COCO（test-dev 2017）</strong> 物件偵測實驗中，作者採用以下預設訓練設定：</p>
<ul>
<li>
<p><strong>訓練步數</strong>：500,500 steps</p>
</li>
<li>
<p><strong>學習率排程策略</strong>：Step decay</p>
<ul>
<li>初始學習率：0.01</li>
<li>於第 400,000 與 450,000 步時，各乘上 0.1</li>
</ul>
</li>
<li>
<p><strong>Momentum / Weight decay</strong>：0.9 / 0.0005</p>
</li>
<li>
<p><strong>Batch size / mini-batch size</strong>：64 / 8 或 4（依模型與記憶體容量調整）</p>
</li>
</ul>
<p>除部分使用基因演算法搜尋最佳超參數的實驗外，其他所有實驗均使用相同預設設定。</p>
<p>在超參數搜尋實驗中，作者使用 YOLOv3-SPP 架構與 GIoU loss，在 min-val 5k 子集上進行 300 個 epoch 的搜尋。最終採用的最佳組合如下：</p>
<ul>
<li><strong>學習率</strong>：0.00261</li>
<li><strong>Momentum</strong>：0.949</li>
<li><strong>IoU 分配門檻</strong>：0.213</li>
<li><strong>損失正規化係數</strong>：0.07</li>
</ul>
<p>所有實驗均在 <strong>單張 GPU 上進行</strong>，並未使用如 syncBN 等多卡優化技術。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=討論>討論<a href=#討論 class=hash-link aria-label=討論的直接連結 title=討論的直接連結>​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=分類器訓練中不同特徵的影響>分類器訓練中不同特徵的影響<a href=#分類器訓練中不同特徵的影響 class=hash-link aria-label=分類器訓練中不同特徵的影響的直接連結 title=分類器訓練中不同特徵的影響的直接連結>​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt="different classifier" src=/assets/images/img8-a960ee1d79a88fdb1ac53cd38f23af88.jpg width=956 height=508 class=img_ev3q></figure></div>
<p>作者首先探討在分類器訓練過程中，不同訓練策略對最終準確率的影響，特別聚焦於幾個常見的訓練強化技巧：<strong>標籤平滑（Class label smoothing）</strong>、各類資料增強方法（如 <strong>模糊處理、MixUp、CutMix、Mosaic</strong>），以及不同類型的激活函數（<strong>Leaky ReLU、Swish、Mish</strong>）對模型學習的實質影響。</p>
<p>實驗結果如上表，在分類器訓練過程中，以下特徵明顯提升了模型準確率：</p>
<ul>
<li><strong>CutMix 資料增強</strong></li>
<li><strong>Mosaic 資料增強</strong></li>
<li><strong>Class label smoothing 標籤平滑正則化</strong></li>
<li><strong>Mish 激活函數</strong></li>
</ul>
<p>因此，在 YOLOv4 的分類器訓練策略中，作者最終選擇的 <strong>BoF-backbone（Bag of Freebies for classifier）</strong> 包含以下項目：</p>
<ul>
<li><strong>CutMix</strong></li>
<li><strong>Mosaic</strong></li>
<li><strong>Class label smoothing</strong></li>
</ul>
<p>同時，根據實驗結果，<strong>Mish activation</strong> 被納入作為補充性的激活函數選項，與上述策略協同使用，進一步提升分類準確率表現。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=偵測器訓練中不同特徵的影響>偵測器訓練中不同特徵的影響<a href=#偵測器訓練中不同特徵的影響 class=hash-link aria-label=偵測器訓練中不同特徵的影響的直接連結 title=偵測器訓練中不同特徵的影響的直接連結>​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt="different feat" src=/assets/images/img10-9a0bab56bddc1ffb65d994542b7ba98d.jpg width=1224 height=668 class=img_ev3q></figure></div>
<p>作者進一步評估不同訓練策略對偵測器準確率的影響，特別是針對 <strong>Bag of Freebies for detector（BoF-detector）</strong> 所進行的系統性實驗，如上表所示。</p>
<p>YOLOv4 大幅擴充了 BoF 的選項清單，專注於那些<strong>能在不犧牲推論速度（FPS）的前提下提升準確率</strong>的訓練技術。</p>
<p>以下經過驗證的 BoF-detector 項目：</p>
<ul>
<li>
<p><strong>S: Grid Sensitivity Elimination</strong></p>
<p>在 YOLOv3 中，目標座標由 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>b</mi><mi>x</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy=false>(</mo><msub><mi>t</mi><mi>x</mi></msub><mo stretchy=false>)</mo><mo>+</mo><msub><mi>c</mi><mi>x</mi></msub></mrow><annotation encoding=application/x-tex>b_x = σ(t_x) + c_x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">b</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.03588em>σ</span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">t</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">c</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 所定義，其中 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>c</mi><mi>x</mi></msub></mrow><annotation encoding=application/x-tex>c_x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">c</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 為整數。當 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>t</mi><mi>x</mi></msub></mrow><annotation encoding=application/x-tex>t_x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7651em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">t</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 值極大或極小時，才能使 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>b</mi><mi>x</mi></msub></mrow><annotation encoding=application/x-tex>b_x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">b</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 接近格點邊緣（<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>c</mi><mi>x</mi></msub></mrow><annotation encoding=application/x-tex>c_x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">c</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 或 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>c</mi><mi>x</mi></msub><mo>+</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>c_x+1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">c</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span></span></span></span>），這造成某些邊緣目標難以被檢出。</p>
<p>為此，作者將 sigmoid 結果乘上一個大於 1 的因子，有效解除格點對偵測可行性的限制。</p>
</li>
<li>
<p><strong>M: Mosaic 資料增強</strong>
將四張影像拼接為訓練輸入，使模型同時學習不同場景與比例下的目標，強化泛化能力。</p>
</li>
<li>
<p><strong>IT: IoU Threshold</strong>
為每個 ground truth 配對多個 anchor，條件為 IoU(anchor, truth) > threshold，以增加樣本使用率。</p>
</li>
<li>
<p><strong>GA: Genetic Algorithms</strong>
於訓練初期（前 10% 時間）使用基因演算法搜尋最適超參數，提升收斂穩定度與模型表現。</p>
</li>
<li>
<p><strong>LS: Class Label Smoothing</strong>
對分類任務套用 label smoothing，降低模型過度自信，提升對類別間模糊界線的辨識力。</p>
</li>
<li>
<p><strong>CBN: Cross mini-Batch Normalization (CmBN)</strong>
在整個 batch 間彙總統計值，而非僅限於單一 mini-batch，提升小 batch 訓練的穩定性。</p>
</li>
<li>
<p><strong>CA: Cosine Annealing Scheduler</strong>
採用餘弦函數動態調整學習率，達到更平滑的學習曲線與收斂效果。</p>
</li>
<li>
<p><strong>DM: Dynamic mini-batch Size</strong>
在小解析度訓練階段，動態增加 mini-batch size，配合隨機輸入尺寸的訓練設計。</p>
</li>
<li>
<p><strong>OA: Optimized Anchors</strong>
根據輸入解析度（如 512×512）最佳化 anchor 位置與尺寸，提高 anchor 分配效率。</p>
</li>
<li>
<p><strong>BBox Regression Loss</strong>
比較多種邊界框損失函數，包括 GIoU、CIoU、DIoU 與傳統 MSE，驗證其在不同場景下的回歸品質。</p>
</li>
</ul>
<hr>
<p>此外，作者也針對 <strong>Bag of Specials for detector</strong> 的設計進行驗證，如下表所示：</p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=bos-detector src=/assets/images/img7-f147f96dfd51b07e810af6aef5ff2ce7.jpg width=964 height=312 class=img_ev3q></figure></div>
<p>實驗項目包含：</p>
<ul>
<li><strong>PAN</strong>：參數聚合與特徵流通性提升</li>
<li><strong>RFB</strong>：多尺度膨脹卷積以擴展感受野</li>
<li><strong>SAM</strong>：空間注意力機制</li>
<li><strong>Gaussian YOLO (G)</strong>：預測框不再為單點估計，而是高斯分布</li>
<li><strong>ASFF</strong>：跨尺度注意力式融合策略</li>
</ul>
<p>根據實驗結果，當模型同時採用 <strong>SPP、PAN、SAM</strong> 時，能取得最佳整體性能表現。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=不同-backbone-的影響>不同 Backbone 的影響<a href=#不同-backbone-的影響 class=hash-link aria-label="不同 Backbone 的影響的直接連結" title="不同 Backbone 的影響的直接連結">​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=diff-backbone src=/assets/images/img9-d85f1976bf64e98971f602e38656c880.jpg width=1000 height=484 class=img_ev3q></figure></div>
<p>作者探討不同 Backbone 對偵測器準確率的影響，如上表所示。</p>
<p>實驗結果顯示：<strong>分類器表現最好的模型，並不代表在物件偵測任務中同樣優秀</strong>。</p>
<p>首先，即使在分類任務中，採用各種訓練技巧後的 <strong>CSPResNeXt50</strong> 模型其準確率普遍高於 <strong>CSPDarknet53</strong>，但一旦將這些模型用作偵測器的骨幹，整體偵測表現卻反而以 CSPDarknet53 為優。</p>
<p>具體來說，<strong>CSPResNeXt50</strong> 搭配 BoF 與 Mish activation 可進一步提升分類準確率，但當使用這組預訓練權重初始化偵測器後，偵測精度反而下降。相對地，<strong>CSPDarknet53</strong> 同樣搭配 BoF 與 Mish 進行分類訓練，不僅提升了分類器本身的準確率，後續作為偵測器骨幹使用時，<strong>偵測表現也隨之提升</strong>。</p>
<p>這項發現說明了<strong>分類任務與偵測任務在特徵學習需求上具有本質差異</strong>。</p>
<p>CSPDarknet53 所具備的結構特性與感受野設計，更適合作為物件偵測任務的特徵提取器。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=不同-mini-batch-size-的影響>不同 mini-batch size 的影響<a href=#不同-mini-batch-size-的影響 class=hash-link aria-label="不同 mini-batch size 的影響的直接連結" title="不同 mini-batch size 的影響的直接連結">​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=diff-batchsize src=/assets/images/img11-27d305262d83be0d9f354ff04ab81ca6.jpg width=988 height=448 class=img_ev3q></figure></div>
<p>最後，作者分析在不同 mini-batch size 設定下訓練所產生的影響，對應結果如上表所示。</p>
<p>從結果中可以明確觀察到：<strong>在導入 BoF 與 BoS 訓練策略之後，mini-batch size 幾乎不再影響偵測器的最終性能表現</strong>。</p>
<p>這項發現具有重要實務意義。</p>
<p>過去為了提升訓練穩定性與模型效能，往往需依賴大量 GPU 記憶體來支援較大的 batch size。但本研究顯示，在 YOLOv4 中結合了如 Mosaic、CmBN、DropBlock、Label smoothing、SPP、PAN 等訓練與架構優化策略後，<strong>即便在小型 mini-batch 下仍能維持穩定且優異的學習效果</strong>。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=benchmark>Benchmark<a href=#benchmark class=hash-link aria-label=Benchmark的直接連結 title=Benchmark的直接連結>​</a></h3>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=benchmark src=/assets/images/img12-3d60e09de8eac6845341f4d3350b0b17.jpg width=1160 height=1080 class=img_ev3q></figure></div>
<p>YOLOv4 的最終成果與其他最先進的物件偵測器相比，如上圖所示，位於速度與準確率之間的 Pareto 最佳曲線上，展現出在效率與精度之間取得最優平衡點的能力。</p>
<p>相較於目前主流的快速模型與高精度模型，YOLOv4 <strong>同時優於兩者</strong>，在保持高推論速度的同時，也達成了媲美甚至超越先前高準確率模型的性能指標。</p>
<p>考慮到不同研究方法在推論時間測試上使用的 GPU 架構可能有所不同，作者分別在常見的三大 GPU 架構上測試 YOLOv4 的效能，包括：</p>
<ul>
<li><strong>Maxwell 架構</strong>：GTX Titan X（Maxwell）、Tesla M40</li>
<li><strong>Pascal 架構</strong>：Titan X（Pascal）、Titan Xp、GTX 1080 Ti、Tesla P100</li>
<li><strong>Volta 架構</strong>：Titan Volta、Tesla V100</li>
</ul>
<p>這些實驗結果進一步驗證了 YOLOv4 的可擴展性與普遍適用性。</p>
<p>無論在老舊架構還是最新硬體上，YOLOv4 都能保持良好的運算效率與穩定表現，充分體現其設計中對硬體親和力的重視。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=結論>結論<a href=#結論 class=hash-link aria-label=結論的直接連結 title=結論的直接連結>​</a></h2>
<p>YOLOv4 在 MS COCO 的 AP50 評估指標上<strong>超越了所有現有主流模型</strong>，並在推論速度（FPS）上保持領先。更重要的是，YOLOv4 可以在僅具備 8~16GB VRAM 的一般消費級 GPU 上完成訓練與部署，大幅降低技術門檻，具備廣泛應用的可行性。</p>
<p>每個想做物件偵測的開發者，都可以來翻一翻這篇論文，絕對值回票價。</header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>最後<!-- -->由 <b>zephyr-sh</b> <!-- -->於 <b><time datetime=2025-06-11T13:46:29.000Z itemprop=dateModified>2025年6月11日</time></b> <!-- -->更新</span></div></div><section class=ctaSection_iCjC><div class="
        simpleCta_ji_Y
        simple-cta__coffee_YwC8
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>☕ 一杯咖啡，就是我創作的燃料！</h3><p class=simple-cta__subtitle_ol86>贊助我持續分享 AI 實作、全端架構與開源經驗，讓好文章不斷更新。<div class=simple-cta__buttonWrapper_jk1Y><img src=/img/bmc-logo.svg alt=cta-button class=simple-cta__buttonImg_Q9VV></div></div><div class="ant-row ant-row-stretch cardsSection_wRaP css-mc1tut" style=margin-left:-8px;margin-right:-8px;row-gap:16px><div style=padding-left:8px;padding-right:8px;display:flex class="ant-col ant-col-xs-24 css-mc1tut"><div class="ant-card ant-card-bordered card_gKx9 fadeInUp_n33J hoverTransform_Mozy css-mc1tut" style=flex:1;display:flex;flex-direction:column><div class=ant-card-body><div style=text-align:center;margin-top:1rem><img src=/img/icons/all_in.svg alt="AI / 全端 / 客製 一次搞定 icon" style=width:48px;height:48px></div><span class="ant-tag ant-tag-orange card__tag_PLj3 css-mc1tut">ALL</span><h4 class=card__title_SQBY>AI / 全端 / 客製 一次搞定</h4><p class=card__concept_Ak8F>從構想到上線，涵蓋顧問、開發與部署，全方位支援你的技術實作。<div class=card__bulletHeader_b6cf><h5 class=card__bulletTitle_R_wg>包含內容</h5></div><ul class=card__bulletList_SrNN><li class=card__bulletItem_wCRd>顧問服務 + 系統建置 + 客製開發<li class=card__bulletItem_wCRd>長期維運與擴充規劃</ul></div></div></div></div><div class="
        simpleCta_ji_Y
        simple-cta__outro_AXbn
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>🚀 你的專案準備好了嗎？</h3><p class=simple-cta__subtitle_ol86>如果你需要客製服務或長期顧問，歡迎與我聯繫！</div></section><div style=margin-top:3rem> </div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label=文件選項卡><a class="pagination-nav__link pagination-nav__link--prev" href=/papers/object-detection/yolov3/><div class=pagination-nav__sublabel>上一頁</div><div class=pagination-nav__label>[18.04] YOLOv3</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/papers/object-detection/detr/><div class=pagination-nav__sublabel>下一頁</div><div class=pagination-nav__label>[20.05] DETR</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#模型設計顧問 class="table-of-contents__link toc-highlight">模型設計顧問</a><li><a href=#模型的架構觀 class="table-of-contents__link toc-highlight">模型的架構觀</a><li><a href=#兩個設計路線 class="table-of-contents__link toc-highlight">兩個設計路線</a><li><a href=#特徵融合的-neck class="table-of-contents__link toc-highlight">特徵融合的 Neck</a><li><a href=#為偵測而生的-backbone class="table-of-contents__link toc-highlight">為偵測而生的 Backbone</a><li><a href=#訓練優化技巧 class="table-of-contents__link toc-highlight">訓練優化技巧</a><ul><li><a href=#資料增強 class="table-of-contents__link toc-highlight">資料增強</a><li><a href=#標籤平滑與知識蒸餾 class="table-of-contents__link toc-highlight">標籤平滑與知識蒸餾</a><li><a href=#損失函數的優化 class="table-of-contents__link toc-highlight">損失函數的優化</a></ul><li><a href=#精巧模組設計 class="table-of-contents__link toc-highlight">精巧模組設計</a><ul><li><a href=#擴張感受野 class="table-of-contents__link toc-highlight">擴張感受野</a><li><a href=#注意力機制 class="table-of-contents__link toc-highlight">注意力機制</a><li><a href=#跨尺度整合 class="table-of-contents__link toc-highlight">跨尺度整合</a><li><a href=#激活函數的演進 class="table-of-contents__link toc-highlight">激活函數的演進</a><li><a href=#nms-後處理 class="table-of-contents__link toc-highlight">NMS 後處理</a></ul><li><a href=#解決問題 class="table-of-contents__link toc-highlight">解決問題</a><ul><li><a href=#架構選擇 class="table-of-contents__link toc-highlight">架構選擇</a><li><a href=#訓練策略選擇 class="table-of-contents__link toc-highlight">訓練策略選擇</a><li><a href=#額外增強設計 class="table-of-contents__link toc-highlight">額外增強設計</a><li><a href=#組件總覽與技術選型 class="table-of-contents__link toc-highlight">組件總覽與技術選型</a><li><a href=#實驗配置 class="table-of-contents__link toc-highlight">實驗配置</a></ul><li><a href=#討論 class="table-of-contents__link toc-highlight">討論</a><ul><li><a href=#分類器訓練中不同特徵的影響 class="table-of-contents__link toc-highlight">分類器訓練中不同特徵的影響</a><li><a href=#偵測器訓練中不同特徵的影響 class="table-of-contents__link toc-highlight">偵測器訓練中不同特徵的影響</a><li><a href=#不同-backbone-的影響 class="table-of-contents__link toc-highlight">不同 Backbone 的影響</a><li><a href=#不同-mini-batch-size-的影響 class="table-of-contents__link toc-highlight">不同 mini-batch size 的影響</a><li><a href=#benchmark class="table-of-contents__link toc-highlight">Benchmark</a></ul><li><a href=#結論 class="table-of-contents__link toc-highlight">結論</a></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/docs>開源專案</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/papers/intro>論文筆記</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/blog>部落格</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/terms-of-service>使用條款</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/privacy-policy>隱私政策</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/become-an-author>成為作者</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/worklog>工作日誌</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2025 DOCSAID.</div></div></div></footer></div>