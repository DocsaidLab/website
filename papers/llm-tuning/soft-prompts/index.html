<!doctype html>
<html lang="zh-hant" dir="ltr" class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-llm-tuning/soft-prompts/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">[21.04] Soft Prompts | DOCSAID</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://docsaid.org/img/docsaid-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://docsaid.org/img/docsaid-social-card.jpg"><meta data-rh="true" property="og:url" content="https://docsaid.org/papers/llm-tuning/soft-prompts/"><meta data-rh="true" property="og:locale" content="zh_hant"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh-hant"><meta data-rh="true" name="docsearch:language" content="zh-hant"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-papers-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-papers-current"><meta data-rh="true" property="og:title" content="[21.04] Soft Prompts | DOCSAID"><meta data-rh="true" name="description" content="小弦切切如私語"><meta data-rh="true" property="og:description" content="小弦切切如私語"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docsaid.org/papers/llm-tuning/soft-prompts/"><link data-rh="true" rel="alternate" href="https://docsaid.org/papers/llm-tuning/soft-prompts/" hreflang="zh-hant"><link data-rh="true" rel="alternate" href="https://docsaid.org/en/papers/llm-tuning/soft-prompts/" hreflang="en"><link data-rh="true" rel="alternate" href="https://docsaid.org/papers/llm-tuning/soft-prompts/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://S9NC0RYCHF-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="DOCSAID RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="DOCSAID Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script>


<link rel="search" type="application/opensearchdescription+xml" title="DOCSAID" href="/opensearch.xml">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.ddd83665.css">
<script src="/assets/js/runtime~main.45a6f983.js" defer="defer"></script>
<script src="/assets/js/main.7e00d821.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳至主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳至主要内容</a></div><nav aria-label="主導航" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切換導覽列" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/docsaid_logo.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/docsaid_logo_white.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href="/docs/">開源專案</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/papers/intro">論文筆記</a><a class="navbar__item navbar__link" href="/blog">部落格</a><a class="navbar__item navbar__link" href="/playground/intro">遊樂場</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>繁體中文</a><ul class="dropdown__menu"><li><a href="/papers/llm-tuning/soft-prompts/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-hant">繁體中文</a></li><li><a href="/en/papers/llm-tuning/soft-prompts/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li></ul></div><a href="https://buymeacoffee.com/zephyr_docsaid" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">支持我們<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://github.com/DocsaidLab" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切換淺色/深色模式（當前為淺色模式）" aria-label="切換淺色/深色模式（當前為淺色模式）" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜尋"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜尋</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到頂部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/"><img src="/img/docsaid_logo.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/docsaid_logo_white.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="文件側邊欄" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/papers/intro">論文筆記</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/classic-cnns-11">Classic CNNs (11)</a><button aria-label="展開側邊欄分類 &#x27;Classic CNNs (11)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/face-anti-spoofing-1">Face Anti-Spoofing (1)</a><button aria-label="展開側邊欄分類 &#x27;Face Anti-Spoofing (1)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/face-recognition-4">Face Recognition (4)</a><button aria-label="展開側邊欄分類 &#x27;Face Recognition (4)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/feature-fusion-7">Feature Fusion (7)</a><button aria-label="展開側邊欄分類 &#x27;Feature Fusion (7)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/lightweight-10">Lightweight (10)</a><button aria-label="展開側邊欄分類 &#x27;Lightweight (10)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/papers/category/llm-tuning-5">LLM Tuning (5)</a><button aria-label="收起側邊欄分類 &#x27;LLM Tuning (5)&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/llm-tuning/adapter/">[19.02] Adapter</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/llm-tuning/autoprompt/">[20.10] AutoPrompt</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/llm-tuning/prefix-tuning/">[21.01] Prefix-Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/papers/llm-tuning/soft-prompts/">[21.04] Soft Prompts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/llm-tuning/lora/">[21.06] LoRA</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/multimodality-20">Multimodality (20)</a><button aria-label="展開側邊欄分類 &#x27;Multimodality (20)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/normalization-1">Normalization (1)</a><button aria-label="展開側邊欄分類 &#x27;Normalization (1)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/object-detection-8">Object Detection (8)</a><button aria-label="展開側邊欄分類 &#x27;Object Detection (8)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/reparameterization-7">Reparameterization (7)</a><button aria-label="展開側邊欄分類 &#x27;Reparameterization (7)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/segmentation-1">Segmentation (1)</a><button aria-label="展開側邊欄分類 &#x27;Segmentation (1)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/text-recognition-10">Text Recognition (10)</a><button aria-label="展開側邊欄分類 &#x27;Text Recognition (10)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/text-spotting-3">Text Spotting (3)</a><button aria-label="展開側邊欄分類 &#x27;Text Spotting (3)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/text-detection-10">Text Detection (10)</a><button aria-label="展開側邊欄分類 &#x27;Text Detection (10)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/transformers-15">Transformers (15)</a><button aria-label="展開側邊欄分類 &#x27;Transformers (15)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/vision-transformers-11">Vision Transformers (11)</a><button aria-label="展開側邊欄分類 &#x27;Vision Transformers (11)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/papers/intro">All Notes: 124 entries</a></li></ul></nav><button type="button" title="收起側邊欄" aria-label="收起側邊欄" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="頁面路徑"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主頁面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/papers/category/llm-tuning-5"><span itemprop="name">LLM Tuning (5)</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">[21.04] Soft Prompts</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本頁導覽</button></div><div class="theme-doc-markdown markdown"><header><h1>[21.04] Soft Prompts</h1></header>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="小弦切切如私語">小弦切切如私語<a href="#小弦切切如私語" class="hash-link" aria-label="小弦切切如私語的直接連結" title="小弦切切如私語的直接連結">​</a></h2>
<p><a href="https://arxiv.org/abs/2104.08691" target="_blank" rel="noopener noreferrer"><strong>The Power of Scale for Parameter-Efficient Prompt Tuning</strong></a></p>
<hr>
<p>我們剛看完 Prefix-Tuning 不久，現在來看另外一個新的方法：<strong>Prompt Tuning</strong>。</p>
<p>如果你還沒看過 Prefix-Tuning，不妨先去看一下我們之前寫的文章：</p>
<ul>
<li><a href="/papers/llm-tuning/prefix-tuning/"><strong>[21.01] Prefix-Tuning: 是他？不是他？</strong></a></li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="定義問題">定義問題<a href="#定義問題" class="hash-link" aria-label="定義問題的直接連結" title="定義問題的直接連結">​</a></h2>
<p>Prefix-Tuning 在設計的時候，需要在模型的輸入最前面加上一個叫做 Prefix 的 Token，來引導模型產生結果。這個 Prefix 必須深入到模型的每一層，這樣才能讓模型在每一層都能受到引導。</p>
<p>那我們能不能把事情簡化一下？只要在輸入層對模型進行引導就好了？</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>這裡說的的「引導」和另外我們常聽到的「Prompt Engineering」不是同一件事情，Prompt Engineering 還是使用自然語言的方式來引導模型，從頭到尾都沒有改變模型的輸入特徵，沒有改參數，也沒有改架構。</p><p>而「Prompt Tuning」指的是在模型的輸入層加上一個特殊的 Token，這個 Token 是可以訓練的，這樣就可以讓模型在訓練的時候自己學習到最適合的引導方式。</p></div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="解決問題">解決問題<a href="#解決問題" class="hash-link" aria-label="解決問題的直接連結" title="解決問題的直接連結">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="prompt-tuning">Prompt Tuning<a href="#prompt-tuning" class="hash-link" aria-label="Prompt Tuning的直接連結" title="Prompt Tuning的直接連結">​</a></h3>
<div align="center"><figure style="width:80%"><p><img decoding="async" loading="lazy" alt="model arch" src="/assets/images/img1-03e4bbd9625e2ff48bffb2de21f56a1f.jpg" width="1184" height="640" class="img_ev3q"></p></figure></div>
<p>為了更好地理解 Prompt Tuning 的概念，作者從 T5（Raffel et al., 2020）的「<strong>text-to-text</strong>」架構開始。T5 將所有任務視為文本生成問題，無論是翻譯、摘要還是分類，都可以表示為從輸入文本生成輸出文本。</p>
<p>傳統的分類模型使用概率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>r</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Pr(y|X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mclose">)</span></span></span></span>，將輸入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span> 映射到輸出類別 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span>。這意味著模型直接預測輸入屬於哪個類別。</p>
<p>然而，在 T5 的架構中，我們關注的是<strong>條件生成</strong>問題，目標是計算：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><msub><mi>r</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Pr_\theta(Y | X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mclose">)</span></span></span></span></span>
<p>其中：</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span></span></span></span> 是代表類別的<strong>文本序列</strong>（例如，&quot;positive&quot; 或 &quot;negative&quot;）。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span></span></span></span> 是 Transformer 模型的參數。</li>
</ul>
<p>這種方法的優點是模型可以直接生成更豐富的文本輸出，而不僅僅是單一的類別標籤。</p>
<p>提示（Prompting）是添加在輸入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span> 前的一段文本，用於引導模型生成正確的輸出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span></span></span></span>。提示為模型提供了任務的上下文或指令，幫助模型理解應該如何處理輸入。</p>
<p>例如在情感分析任務中，我們可以使用以下提示：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">&quot;請判斷以下句子的情感傾向：&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="複製程式碼至剪貼簿" title="複製" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>然後將用戶的輸入句子接在提示後面，形成模型的最終輸入。</p>
<p>在 GPT-3 等模型中，提示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>p</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>p</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>p</mi><mi>n</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">P = \{p_1, p_2, ..., p_n\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span> 是模型詞嵌入表中的一部分，由凍結的參數 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span></span></span></span> 表徵。傳統上的提示人工成本高，效果不穩定，且不可微分。</p>
<p>所以作者提出了 Prompt Tuning（Prompt Tuning）的方法。</p>
<p>Prompt Tuning 引入了可更新的提示詞嵌入參數 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>P</mi></msub></mrow><annotation encoding="application/x-tex">\theta_P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>，這些參數不再受限於模型的詞嵌入表，可以通過訓練數據自動學習。</p>
<p>新的條件生成公式為：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><msub><mi>r</mi><mrow><mi>θ</mi><mo separator="true">;</mo><msub><mi>θ</mi><mi>P</mi></msub></mrow></msub><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mo stretchy="false">[</mo><mi>P</mi><mo separator="true">;</mo><mi>X</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Pr_{\theta; \theta_P}(Y | [P; X])</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span><span class="mpunct mtight">;</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3567em;margin-left:-0.0278em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mord">∣</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mclose">])</span></span></span></span></span>
<p>其中：</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>P</mi><mo separator="true">;</mo><mi>X</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[P; X]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mclose">]</span></span></span></span> 表示將提示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span> 和輸入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span> 進行拼接。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span></span></span></span> 是凍結的模型參數。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>P</mi></msub></mrow><annotation encoding="application/x-tex">\theta_P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 是可訓練的提示參數。</li>
</ul>
<p>在訓練過程中，使用反向傳播算法，只更新提示參數 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>P</mi></msub></mrow><annotation encoding="application/x-tex">\theta_P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>，而保持模型主體的參數 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span></span></span></span> 不變。</p>
<p>具體的實現細節大致上可以分為幾個步驟：</p>
<ol>
<li><strong>輸入嵌入</strong>：將輸入的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span> 個 token 嵌入為矩陣 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>e</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>n</mi><mo>×</mo><mi>e</mi></mrow></msup></mrow><annotation encoding="application/x-tex">X_e \in \mathbb{R}^{n \times e}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7713em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">e</span></span></span></span></span></span></span></span></span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">e</span></span></span></span> 是嵌入維度。</li>
<li><strong>提示嵌入</strong>：提示詞嵌入為矩陣 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>e</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>p</mi><mo>×</mo><mi>e</mi></mrow></msup></mrow><annotation encoding="application/x-tex">P_e \in \mathbb{R}^{p \times e}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7713em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">e</span></span></span></span></span></span></span></span></span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span></span></span></span> 是提示的長度。</li>
<li><strong>拼接操作</strong>：將提示嵌入和輸入嵌入拼接為：<!-- -->
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>P</mi><mi>e</mi></msub><mo separator="true">;</mo><msub><mi>X</mi><mi>e</mi></msub><mo stretchy="false">]</mo><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo stretchy="false">(</mo><mi>p</mi><mo>+</mo><mi>n</mi><mo stretchy="false">)</mo><mo>×</mo><mi>e</mi></mrow></msup></mrow><annotation encoding="application/x-tex">[P_e; X_e] \in \mathbb{R}^{(p + n) \times e}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.938em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">p</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">e</span></span></span></span></span></span></span></span></span></span></span></span></span>
</li>
<li><strong>模型處理</strong>：將拼接後的嵌入輸入到編碼器-解碼器架構中進行計算。</li>
</ol>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>假設我們希望模型判斷句子 &quot;I love this movie!&quot; 的情感。</p><p><strong>傳統方法</strong>：</p><ul>
<li><strong>手動提示</strong>：&quot;請判斷以下句子的情感：&quot;</li>
<li><strong>模型輸入</strong>：&quot;請判斷以下句子的情感：I love this movie!&quot;</li>
</ul><p><strong>Prompt Tuning 方法</strong>：</p><ol>
<li><strong>初始化提示</strong>：<!-- -->
<ul>
<li>設定提示長度為 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">p=5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">5</span></span></span></span>，即有 5 個可訓練的提示向量。</li>
<li>這些提示向量可以隨機初始化或從詞嵌入表中選取。</li>
</ul>
</li>
<li><strong>模型輸入</strong>：將提示向量與輸入句子的嵌入拼接，形成模型的輸入。</li>
<li><strong>訓練過程</strong>：<!-- -->
<ul>
<li>使用大量已標註的情感分析數據。</li>
<li>通過反向傳播，只更新提示參數 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>P</mi></msub></mrow><annotation encoding="application/x-tex">\theta_P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>。</li>
<li>模型學習到在看到這些提示時，如何生成正確的情感標籤  。</li>
</ul>
</li>
<li><strong>模型輸出</strong>：對於輸入 &quot;I love this movie!&quot;，模型可能生成 &quot;positive&quot;。</li>
</ol></div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="討論">討論<a href="#討論" class="hash-link" aria-label="討論的直接連結" title="討論的直接連結">​</a></h2>
<p><img decoding="async" loading="lazy" alt="ablation" src="/assets/images/img2-1cc24cd284d57491ab8144c1d1e311d9.jpg" width="1292" height="984" class="img_ev3q"></p>
<p>作者做了一系列的消融研究，來探討 Prompt Tuning 的一些關鍵問題：</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="提示長度要多長">提示長度要多長？<a href="#提示長度要多長" class="hash-link" aria-label="提示長度要多長？的直接連結" title="提示長度要多長？的直接連結">​</a></h3>
<p>如上圖 (a)，作者對不同模型規模（Small、Base、Large、XL、XXL）的提示長度進行了實驗，提示長度分別為 {1, 5, 20, 100, 150}。</p>
<p>結果顯示，對大多數模型而言，提示長度增加到多於 1 個 token 對性能表現有明顯提升。但對於 T5-XXL 模型，即使只使用單一 token 作為提示，也能達到不錯的表現，表明大模型對提示訊號的需求較低。</p>
<p>超過 20 個 token 後，性能提升趨於平緩，只帶來微小的增益。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="提示初始化策略的影響">提示初始化策略的影響？<a href="#提示初始化策略的影響" class="hash-link" aria-label="提示初始化策略的影響？的直接連結" title="提示初始化策略的影響？的直接連結">​</a></h3>
<p>如上圖 (b)，作者比較了三種不同的初始化策略：</p>
<ol>
<li><strong>隨機初始化</strong>：從範圍 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo>−</mo><mn>0.5</mn><mo separator="true">,</mo><mn>0.5</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[-0.5, 0.5]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">−</span><span class="mord">0.5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.5</span><span class="mclose">]</span></span></span></span> 中均勻隨機取樣。</li>
<li><strong>詞彙嵌入初始化</strong>：從 T5 的 <strong>5,000 個最常見詞彙</strong>中選取詞嵌入進行初始化。</li>
<li><strong>類別標籤初始化</strong>：將下游任務中的類別標籤轉換為詞嵌入，若標籤為多個 token，則對嵌入取平均值。當提示長度超過類別數時，剩餘的 token 使用詞彙嵌入填充。</li>
</ol>
<p>結果顯示，類別標籤初始化在所有模型規模下表現最佳，特別是對於小模型來說，初始化策略的差異非常明顯。T5-XXL 模型對初始化策略較不敏感，無論使用何種初始化，其性能都相對穩定。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="預訓練目標的影響">預訓練目標的影響？<a href="#預訓練目標的影響" class="hash-link" aria-label="預訓練目標的影響？的直接連結" title="預訓練目標的影響？的直接連結">​</a></h3>
<p>如上圖 (c)，作者探討了不同的預訓練目標對 Prompt Tuning 的影響：</p>
<ol>
<li><strong>Span Corruption</strong>：使用預設的 T5 span corruption 預訓練目標。</li>
<li><strong>Span Corruption + Sentinel</strong>：在下游任務的目標輸出中添加哨兵符號，以模擬預訓練時的輸出格式。</li>
<li><strong>LM 調適</strong>：延續 T5 的預訓練，但改為<strong>語言模型（LM）目標</strong>，進行額外的 100,000 步調適。</li>
</ol>
<p>結果顯示，Span Corruption 預訓練的模型不適合用於凍結模型的 Prompt Tuning，因為模型習慣了讀取和輸出帶有哨兵符號的文本。即使透過 <strong>「Span Corruption + Sentinel」</strong> 模擬預訓練格式，效果仍然有限。</p>
<p><strong>LM Adaptation</strong> 在所有模型規模上都顯著提升性能。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="lm-調適時長的影響">LM 調適時長的影響？<a href="#lm-調適時長的影響" class="hash-link" aria-label="LM 調適時長的影響？的直接連結" title="LM 調適時長的影響？的直接連結">​</a></h3>
<p>如上圖 (d)，作者探討了 LM 調適時長對 Prompt Tuning 的影響。</p>
<p>結果顯示，延長 LM 調適步數會帶來額外的增益，並在 100,000 步左右達到最佳效果。Span Corruption 預訓練轉換為 LM 目標不是一個簡單的過程，需要投入相當的訓練資源（相當於原始 T5 預訓練步數的 10%）。</p>
<p>T5-XXL 在各種非理想配置下仍表現良好，顯示其對模型設定具有高韌性。在 Span Corruption 配置下，模型表現不穩定，小模型甚至超越了 Base、Large 和 XL 模型。這些問題並非隨機波動造成，因為在 3 次重複實驗中觀察到一致的低變異。</p>
<p>與 Span Corruption 預訓練的模型相比，LM 調適後的模型在所有規模下都表現穩定，大幅降低了性能不穩定的風險。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="和其他方法比較">和其他方法比較<a href="#和其他方法比較" class="hash-link" aria-label="和其他方法比較的直接連結" title="和其他方法比較的直接連結">​</a></h3>
<div align="center"><figure style="width:80%"><p><img decoding="async" loading="lazy" alt="comparison" src="/assets/images/img3-6f570e3deede22c97b6c84c904cda64e.jpg" width="792" height="716" class="img_ev3q"></p></figure></div>
<ul>
<li>
<p><strong>Prefix Tuning</strong>：</p>
<ul>
<li><a href="https://arxiv.org/abs/2101.00190" target="_blank" rel="noopener noreferrer"><strong>[21.01] Prefix-Tuning: Optimizing Continuous Prompts for Generation</strong></a></li>
</ul>
<p>在 Transformer 的每一層前置可學習的前綴 (prefix)，相當於為每層網路固定激活值。這方法適用於 GPT-2 和 BART，而本研究的 Prompt Tuning 專注於 T5。在 BART 上，Prefix Tuning 需要同時在「編碼器和解碼器」加入前綴，而 Prompt Tuning 只需在編碼器加入提示。</p>
<p>Prompt Tuning 只需在輸入層加上一個單一提示詞，而非在每層加入前綴，因此參數需求更少。而且 Prompt Tuning 允許 Transformer 根據輸入例子更新其中間層的任務表徵，而 Prefix Tuning 需要重參數化來穩定訓練。</p>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>WARP</strong></p>
<ul>
<li><a href="https://arxiv.org/abs/2101.00121" target="_blank" rel="noopener noreferrer"><strong>[21.01] WARP: Word-level Adversarial ReProgramming</strong></a></li>
</ul>
<p>WARP 將提示參數添加至輸入層，並使用 [MASK] token 和可學習的輸出層，將遮蔽部分映射至類別預測。這種方法只能產生單一輸出，因此受限於分類任務。</p>
<p>Prompt Tuning 不需要對輸入進行特殊設計或使用任務專屬的輸出層，適用於更廣泛的任務。性能也更接近完整的模型微調。</p>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>P-tuning</strong></p>
<ul>
<li><a href="https://arxiv.org/abs/2103.10385" target="_blank" rel="noopener noreferrer"><strong>[21.03] GPT Understands, Too</strong></a></li>
</ul>
<p>P-tuning 將可學習的連續提示嵌入於輸入之間，並基於人類設計的模式進行排列。為了達到良好的 SuperGLUE 表現，P-tuning 必須與模型微調結合，即同時調整提示和主模型的參數。</p>
<p>Pompt Tuning 只需更新提示參數，而主語言模型保持凍結，避免模型微調的成本。</p>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>Soft Words</strong></p>
<ul>
<li>
<p><a href="https://arxiv.org/abs/2104.06599" target="_blank" rel="noopener noreferrer"><strong>[21.04] Learning How to Ask: Querying LMs with Mixtures of Soft Prompts</strong></a></p>
<p>Soft Words 學習的提示基於手工設計的提示範本，並為每層添加可學習的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Δ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\Delta_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord">Δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 參數，使得參數需求隨模型深度增加。</p>
<p>Pompt Tuning 不需要隨層數增加而添加額外參數，因此在參數規模上更具效率。</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>Adapters</strong></p>
<ul>
<li>
<p><a href="https://arxiv.org/abs/1902.00751" target="_blank" rel="noopener noreferrer"><strong>[19.02] Parameter-Efficient Transfer Learning for NLP</strong></a></p>
<p>Adapters 是插入於凍結模型層之間的小型瓶頸層，用以減少任務專屬參數。在 BERT-Large 上微調 Adapter 層，僅增加 2–4% 的參數，且性能接近完整模型微調。</p>
<p>Adapters 透過重寫中間層的激活值來修改模型行為，而 Pompt Tuning 則是透過調整輸入表示，保留了模型內部的運算不變。</p>
</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="到底提示了什麼">到底提示了什麼？<a href="#到底提示了什麼" class="hash-link" aria-label="到底提示了什麼？的直接連結" title="到底提示了什麼？的直接連結">​</a></h3>
<p>Prompt Tuning 是透過在連續嵌入空間調整提示向量，來引導語言模型生成預期的輸出。然而，由於這些提示是在連續空間中操作，而非明確的詞彙空間，我們難以直接理解這些提示是如何影響模型的行為。因此，為了深入解析 Prompt Tuning 的運作方式，作者採用了以下方法來分析提示的效果。</p>
<p>作者透過計算每個提示 token 與模型詞彙表中各 token 的<strong>餘弦相似度</strong>，找出最相近的詞彙。這讓我們可以看到每個提示 token 對應的「最近鄰詞彙」，從而揭示提示 token 在語義上的含義。</p>
<p><strong>研究發現：</strong></p>
<ol>
<li>
<p><strong>語義緊密的群聚</strong>：
提示 token 的前五個最近鄰詞彙往往形成語義密切相關的群組，顯示出 Prompt Tuning 已成功學習到「類似詞語」的表徵。</p>
</li>
<li>
<p><strong>隨機向量的對比</strong>：
當使用隨機生成的向量代替經過訓練的提示 token，則無法形成相似的語義群聚。這表明 Prompt Tuning 並非隨機效果，而是能有效捕捉語言模型中的語義結構。</p>
</li>
</ol>
<p>在長提示序列的情況下，作者發現多個提示 token 可能共享相同的最近鄰詞彙。</p>
<p>這些現象顯示了兩個潛在問題：</p>
<ol>
<li><strong>冗餘容量</strong>：提示中可能存在重複或多餘的資訊，無法進一步提升模型效能。</li>
<li><strong>缺乏序列結構</strong>：提示 token 的表徵未能精確反映序列中的位置資訊，導致模型難以準確地定位和解析關鍵訊息。</li>
</ol>
<p>另一個重要的觀察是，提示 token 的最近鄰詞彙中，經常包含「下游任務的類別標籤」。這暗示 Prompt Tuning 能在模型內部儲存預期的輸出類別，作為生成輸出的參考依據。</p>
<p>儘管學習到的提示序列難以用傳統語言解釋，但 Prompt Tuning 能夠有效構建具有語義意涵的表徵，並在模型內部形成有意義的調整機制。這些發現展示了 Prompt Tuning 不僅能引導模型生成特定輸出，還具備調整模型上下文的潛力。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="結論">結論<a href="#結論" class="hash-link" aria-label="結論的直接連結" title="結論的直接連結">​</a></h2>
<p>Prompt Tuning 在各類實驗中的表現與傳統模型微調相當，且隨著模型規模的擴大，這種性能差距逐漸縮小。</p>
<p>在零樣本領域遷移任務中，Prompt Tuning 展現出更好的泛化能力，表示凍結語言模型中的通用理解參數並將學習範圍限制於輕量化的提示向量，可以有效避免過度擬合於特定領域。</p>
<p>除了性能上的優勢外，Prompt Tuning 在存儲與服務成本上的吸引力。藉由凍結預訓練模型，能夠更高效地支援多任務處理，同時也促進高效的提示集成。</p>
<p>在未來，將「任務定義的參數與語言建模的通用參數分離」或許是個嶄新的研究方向。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">最後<!-- -->由 <b>zephyr-sh</b> <!-- -->於 <b><time datetime="2024-10-30T13:41:56.000Z" itemprop="dateModified">2024年10月30日</time></b> <!-- -->更新</span></div></div></footer><div style="margin-top:3rem"> </div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件選項卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/papers/llm-tuning/prefix-tuning/"><div class="pagination-nav__sublabel">上一頁</div><div class="pagination-nav__label">[21.01] Prefix-Tuning</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/papers/llm-tuning/lora/"><div class="pagination-nav__sublabel">下一頁</div><div class="pagination-nav__label">[21.06] LoRA</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#小弦切切如私語" class="table-of-contents__link toc-highlight">小弦切切如私語</a></li><li><a href="#定義問題" class="table-of-contents__link toc-highlight">定義問題</a></li><li><a href="#解決問題" class="table-of-contents__link toc-highlight">解決問題</a><ul><li><a href="#prompt-tuning" class="table-of-contents__link toc-highlight">Prompt Tuning</a></li></ul></li><li><a href="#討論" class="table-of-contents__link toc-highlight">討論</a><ul><li><a href="#提示長度要多長" class="table-of-contents__link toc-highlight">提示長度要多長？</a></li><li><a href="#提示初始化策略的影響" class="table-of-contents__link toc-highlight">提示初始化策略的影響？</a></li><li><a href="#預訓練目標的影響" class="table-of-contents__link toc-highlight">預訓練目標的影響？</a></li><li><a href="#lm-調適時長的影響" class="table-of-contents__link toc-highlight">LM 調適時長的影響？</a></li><li><a href="#和其他方法比較" class="table-of-contents__link toc-highlight">和其他方法比較</a></li><li><a href="#到底提示了什麼" class="table-of-contents__link toc-highlight">到底提示了什麼？</a></li></ul></li><li><a href="#結論" class="table-of-contents__link toc-highlight">結論</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class="footer__links"><a class="footer__link-item" href="/docs">開源專案</a><span class="footer__link-separator">·</span><a class="footer__link-item" href="/papers/intro">論文筆記</a><span class="footer__link-separator">·</span><a class="footer__link-item" href="/blog">部落格</a><span class="footer__link-separator">·</span><a href="https://buymeacoffee.com/zephyr_docsaid" target="_blank" rel="noopener noreferrer" class="footer__link-item">支持我們<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><span class="footer__link-separator">·</span><a href="https://docsaid.org/blog/terms-of-service" target="_blank" rel="noopener noreferrer" class="footer__link-item">使用條款<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><span class="footer__link-separator">·</span><a href="https://docsaid.org/blog/privacy-policy" target="_blank" rel="noopener noreferrer" class="footer__link-item">隱私政策<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 DOCSAID.</div></div></div></footer></div>
</body>
</html>