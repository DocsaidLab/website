# [16.03] Hourglass

## 被遺忘的長者

**[Stacked Hourglass Networks for Human Pose Estimation](https://arxiv.org/abs/1603.06937)**

---

:::info
以下內容由 ChatGPT-4 彙整，並經過人工校對編輯與補充說明。
:::

---

如果你是時常在不同論文間徘徊的開發者，Hourglass 架構就算說不上熟悉，也肯定是不陌生的。我們先快速地介紹一下這個架構：

Hourglass 架構是專為人體姿勢估計任務而設計。這個架構通過全面處理和整合所有尺度的特徵，致力於最佳地捕捉與人體相關的多種空間關係。研究團隊顯示，通過將自下而上和自上而下的處理方法重複應用，並結合中間的監督訓練，可以極大地提升網絡的性能。因此，他們將這一新架構命名為「堆疊沙漏」網絡。該網絡基於連續的池化和上採樣步驟，用於生成最終的預測結果。

這篇論文提出來的時間比 FPN 還要早了半年多，但為什麼他們的名氣差異如此巨大呢？最直觀的感覺就是論文的引用數，截至 2023.08，FPN 引用數為 20816；Hourglass 引用數為 5365。怎麼都一樣的架構設計，引用數卻可以差距四倍之多？

- **等一下，你說它們有一樣？**

## 模型架構

我們之前已經聊過 FPN 的話題了，它的架構想必你也很熟悉了。而本次要討論的 Hourglass 架構，如下：

![hourglass_1](./img/hourglass_1.jpg)

乍看之下，他們是截然不同的架構，但我們實際來順著論文的敘述，把這個模型走過一次：

1. **捕捉不同尺度的信息**

   想像你在觀察一張圖片，上面有一個人的全身。要準確地理解這個人的姿勢，我們需要同時關注整個身體以及細節的部分，比如臉部和手部。但這些信息可能位於不同的尺度上。沙漏設計的目的就是能夠同時捕捉這些不同尺度的信息。

2. **沙漏結構的設計**

   這個模型的結構就像這個沙漏一樣。它由一系列的卷積層（用來提取特徵）和最大池化層（用來減少圖像的分辨率）組成。這樣可以在每個分辨率下保留空間信息，不讓細節丟失。

3. **上下採樣和特徵組合**

   當網絡處理完較低的分辨率後，它會開始進行上採樣，就像把畫面放大一樣。同時，它會將不同尺度的特徵組合在一起，這樣就能夠將全身的信息和細節結合起來。

4. **最終預測**

   最後，網絡會通過一些處理來生成最終的預測。這個預測是一組熱圖，就像地圖上不同位置的顏色表示不同的特徵。這裡，網絡試圖預測在圖像中哪些地方存在著人體的關節，比如手肘、膝蓋等。

最後第四個部分是屬於特定分支領域的應用，先不管他。

我們先把模型架構圖重畫一次：

![hourglass_2](./img/hourglass_2.jpg)

綠色框起來的地方，屬於 Backbone 的範疇，他做了 N 個階段的降採樣。論文中有提到這裡的降採樣方式為一連串的卷積層搭配最大池化操作。接著進入上採樣的流程，逐層放大特徵圖的解析度並相加。通道對齊的操作是透過 1×1 到卷積來達成。

看到這邊，應該很明顯了吧？

就以特徵融合的方式來看的話，Hourglass 就是 FPN，FPN 就是 Hourglass 呀！

當然，他們的應用場景是不一樣的，Hourglass 實際上只拿解析度最高的那層特徵圖（P1），並重複堆疊多層已達到萃取關鍵點的效果；而 FPN 並沒有特別提到他們堆疊很多層（實務上是可行的），而主要是著重在使用不同解析度的特徵圖（P3, P4, P5），透過不同感受野（Receptive Field）的特徵圖來達成多尺度物件偵測的目的。

那到底為什麼這兩篇論文的引用數差這麼多呢？

其實我們也只能給一個推測的答案，因為應用場景不一樣，物件偵測比較熱門，這是其一。另外一個可能的原因是因為論文敘事的結構：在 Hourglass 的論文當中，主要強調的是「堆疊很多層」和「中間監督」。

## Hourglass 的最初？

仔細翻閱 Hourglass 的論文，其實可以找到更早的一篇參考文獻，裡面有著非常像的結構：

**[Bottom-Up and Top-Down Reasoning with Hierarchical Rectified Gaussians (2015.07)](https://arxiv.org/abs/1507.05699)**

在這篇文獻中並沒有稱呼該架構為「Hourglass」，他只是說這是一個「Bottom-Up」和「Top-Down」的架構，以下節錄一段論文的原話：

> 本文主要的目的是為了探索了一種「雙向」的結構，同時考慮了自上而下的反饋：神經元受到上層和下層神經元的影響。該文獻將通過將神經元視為具有修正的潛在變數，在一個二次能量函數中進行操作，這可以看作是一個階層修正高斯模型（RGs）的方法。作者展示了 RGs 可以通過一個二次規劃（QP）進行優化，而 QP 則可以通過一個具有修正線性單元的循環神經網絡進行優化。這使得 RGs 可以使用 GPU 進行優化的梯度下降來進行訓練。

欸不是，等等，他這是在說什麼？

那試著講簡單一點：

這篇論文探討了一種新的方法，以更貼近修正的方式處理神經元，就像是對它們進行了微調，使其更適應特定任務。這種方法被應用在一個數學模型中，該模型能夠更好地處理圖像等資料。研究人員展示了這個方法可以透過解決一個特殊的數學問題來進行最佳化，而這個問題可以透過一種特殊的循環神經網絡來求解。這樣的結構使得我們能夠在運算中更有效地使用硬體資源。

如果還是看不懂也沒關係，反正這不是本文想討論的內容，別忘了我們只是想要找一下最早提出這個架構的文獻而已，下圖就是他們所使用的模型架構：

![hourglass_3](./img/hourglass_3.jpg)

相信看到這個似曾相似的結構，應該也可以認同它可能就是 Hourglass 的靈感來源，但這真的是最早的架構設計了嗎？

實話說，也不一定。

因為比這篇論文再更早半年前 ——

- **[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)**

已經被提出來了，而 U-Net 的多尺度連接的結構其實也是長這樣，差別只在於 U-Net 使用 concat 操作。但可惜的是這篇論文沒有引用 U-Net，因此也沒辦法看到作者對於這篇前作的總結與評價。

## 結論

雖然 Hourglass 和 FPN 是在不同領域中應用的兩種架構。

但，他們在特徵融合網路的本質其實是一樣的，就只是同一種架構的不同用法而已。

在同樣的基礎架構上，為了去解決不同的問題，進而發展出不同的應用流程。其中，FPN 通過特徵金字塔來處理不同尺度的信息，主要用於對象檢測和分割等任務。相比之下，Hourglass 網絡則透過多層次的結構在不同細節層次上進行特徵提取，特別適用於密集預測任務，例如姿態估計等任務。

如果你也曾經對這兩個架構的本質感到困惑，那麼希望本篇文章可以讓你得到解答。
