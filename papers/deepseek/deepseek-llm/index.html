<!doctype html><html lang=zh-hant dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-deepseek/deepseek-llm/index" data-has-hydrated=false><head><meta charset=UTF-8><meta name=generator content="Docusaurus v3.9.1"><title data-rh=true>[24.01] DeepSeek LLM | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"/><meta data-rh=true name=twitter:card content=summary_large_image /><meta data-rh=true property=og:image content=https://docsaid.org/img/docsaid-social-card.jpg /><meta data-rh=true name=twitter:image content=https://docsaid.org/img/docsaid-social-card.jpg /><meta data-rh=true property=og:url content=https://docsaid.org/papers/deepseek/deepseek-llm/ /><meta data-rh=true property=og:locale content=zh_hant /><meta data-rh=true property=og:locale:alternate content=en /><meta data-rh=true property=og:locale:alternate content=ja /><meta data-rh=true name=docusaurus_locale content=zh-hant /><meta data-rh=true name=docsearch:language content=zh-hant /><meta data-rh=true name=docusaurus_version content=current /><meta data-rh=true name=docusaurus_tag content=docs-papers-current /><meta data-rh=true name=docsearch:version content=current /><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current /><meta data-rh=true property=og:title content="[24.01] DeepSeek LLM | DOCSAID"/><meta data-rh=true name=description content=新・模型縮放律 /><meta data-rh=true property=og:description content=新・模型縮放律 /><link data-rh=true rel=icon href=/img/favicon.ico /><link data-rh=true rel=canonical href=https://docsaid.org/papers/deepseek/deepseek-llm/ /><link data-rh=true rel=alternate href=https://docsaid.org/papers/deepseek/deepseek-llm/ hreflang=zh-hant /><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/deepseek/deepseek-llm/ hreflang=en /><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/deepseek/deepseek-llm/ hreflang=ja /><link data-rh=true rel=alternate href=https://docsaid.org/papers/deepseek/deepseek-llm/ hreflang=x-default /><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous /><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://docsaid.org/papers/category/deepseek","name":"DeepSeek (5)","position":1},{"@type":"ListItem","item":"https://docsaid.org/papers/deepseek/deepseek-llm/","name":"[24.01] DeepSeek LLM","position":2}]}</script><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/assets/css/styles.3c4edfe1.css /><script src=/assets/js/runtime~main.cbda81ee.js defer></script><script src=/assets/js/main.cf7ed88a.js defer></script></head><body class=navigation-with-keyboard><svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t;document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label=跳至主要内容><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>跳至主要内容</a></div><nav aria-label=主導航 class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label=切換導覽列 aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><div class=navbar__logo><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"/><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"/></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/docs/>開源專案</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/papers/intro>論文筆記</a><a class="navbar__item navbar__link" href=/blog>部落格</a><a class="navbar__item navbar__link" href=/playground/intro>遊樂場</a><a class="navbar__item navbar__link" href=/services>技術服務</a><a class="navbar__item navbar__link" href=/aboutus>關於我們</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>繁體中文</a><ul class=dropdown__menu><li><a href=/papers/deepseek/deepseek-llm/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=zh-hant>繁體中文</a><li><a href=/en/papers/deepseek/deepseek-llm/ target=_self rel="noopener noreferrer" class=dropdown__link lang=en>English</a><li><a href=/ja/papers/deepseek/deepseek-llm/ target=_self rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="搜尋 (Meta+k)" aria-keyshortcuts=Meta+k><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 24 24" aria-hidden=true><circle cx=11 cy=11 r=8 stroke=currentColor fill=none stroke-width=1.4 /><path d="m21 21-4.3-4.3" stroke=currentColor fill=none stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>搜尋</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-mc1tut ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label=回到頂部 class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"/><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"/><b></b></a><nav aria-label=文件側邊欄 class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/papers/intro><span title=論文筆記 class=linkLabel_WmDU>論文筆記</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/classic-cnns><span title="Classic CNNs (11)" class=categoryLinkLabel_W154>Classic CNNs (11)</span></a><button aria-label="展開側邊欄分類 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/contrastive-learning><span title="Contrastive Learning (14)" class=categoryLinkLabel_W154>Contrastive Learning (14)</span></a><button aria-label="展開側邊欄分類 'Contrastive Learning (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href=/papers/category/deepseek><span title="DeepSeek (5)" class=categoryLinkLabel_W154>DeepSeek (5)</span></a><button aria-label="收起側邊欄分類 'DeepSeek (5)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/papers/deepseek/deepseek-llm/><span title="[24.01] DeepSeek LLM" class=linkLabel_WmDU>[24.01] DeepSeek LLM</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/deepseek/deepseek-vl/><span title="[24.03] DeepSeek-VL" class=linkLabel_WmDU>[24.03] DeepSeek-VL</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/deepseek/deepseek-v2/><span title="[24.05] DeepSeek-V2" class=linkLabel_WmDU>[24.05] DeepSeek-V2</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/deepseek/deepseek-v3/><span title="[24.12] DeepSeek-V3" class=linkLabel_WmDU>[24.12] DeepSeek-V3</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/deepseek/deepseek-r1/><span title="[25.01] DeepSeek-R1" class=linkLabel_WmDU>[25.01] DeepSeek-R1</span></a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/face-antispoofing><span title="Face Anti-Spoofing (43)" class=categoryLinkLabel_W154>Face Anti-Spoofing (43)</span></a><button aria-label="展開側邊欄分類 'Face Anti-Spoofing (43)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/face-recognition><span title="Face Recognition (4)" class=categoryLinkLabel_W154>Face Recognition (4)</span></a><button aria-label="展開側邊欄分類 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/feature-fusion><span title="Feature Fusion (10)" class=categoryLinkLabel_W154>Feature Fusion (10)</span></a><button aria-label="展開側邊欄分類 'Feature Fusion (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/image-generation><span title="Image Generation (1)" class=categoryLinkLabel_W154>Image Generation (1)</span></a><button aria-label="展開側邊欄分類 'Image Generation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/lightweight><span title="Lightweight (10)" class=categoryLinkLabel_W154>Lightweight (10)</span></a><button aria-label="展開側邊欄分類 'Lightweight (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/mamba><span title="Mamba (4)" class=categoryLinkLabel_W154>Mamba (4)</span></a><button aria-label="展開側邊欄分類 'Mamba (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/model-tuning><span title="Model Tuning (8)" class=categoryLinkLabel_W154>Model Tuning (8)</span></a><button aria-label="展開側邊欄分類 'Model Tuning (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/multimodality><span title="Multimodality (24)" class=categoryLinkLabel_W154>Multimodality (24)</span></a><button aria-label="展開側邊欄分類 'Multimodality (24)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/normalization><span title="Normalization (1)" class=categoryLinkLabel_W154>Normalization (1)</span></a><button aria-label="展開側邊欄分類 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/object-detection><span title="Object Detection (21)" class=categoryLinkLabel_W154>Object Detection (21)</span></a><button aria-label="展開側邊欄分類 'Object Detection (21)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/reparameterization><span title="Reparameterization (8)" class=categoryLinkLabel_W154>Reparameterization (8)</span></a><button aria-label="展開側邊欄分類 'Reparameterization (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/retail-product><span title="Retail Product (6)" class=categoryLinkLabel_W154>Retail Product (6)</span></a><button aria-label="展開側邊欄分類 'Retail Product (6)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/segmentation><span title="Segmentation (1)" class=categoryLinkLabel_W154>Segmentation (1)</span></a><button aria-label="展開側邊欄分類 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/text-detection><span title="Text Detection (14)" class=categoryLinkLabel_W154>Text Detection (14)</span></a><button aria-label="展開側邊欄分類 'Text Detection (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/text-recognition><span title="Text Recognition (20)" class=categoryLinkLabel_W154>Text Recognition (20)</span></a><button aria-label="展開側邊欄分類 'Text Recognition (20)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/text-spotting><span title="Text Spotting (4)" class=categoryLinkLabel_W154>Text Spotting (4)</span></a><button aria-label="展開側邊欄分類 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/transformers><span title="Transformers (17)" class=categoryLinkLabel_W154>Transformers (17)</span></a><button aria-label="展開側邊欄分類 'Transformers (17)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/papers/category/vision-transformers><span title="Vision Transformers (13)" class=categoryLinkLabel_W154>Vision Transformers (13)</span></a><button aria-label="展開側邊欄分類 'Vision Transformers (13)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/papers/intro><span title="All Notes: 240 entries" class=linkLabel_WmDU>All Notes: 240 entries</span></a></ul></nav><button type=button title=收起側邊欄 aria-label=收起側邊欄 class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=頁面路徑><ul class=breadcrumbs><li class=breadcrumbs__item><a aria-label=主頁面 class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li class=breadcrumbs__item><a class=breadcrumbs__link href=/papers/category/deepseek><span>DeepSeek (5)</span></a><li class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>[24.01] DeepSeek LLM</span></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">本頁導覽</button></div><div class="theme-doc-markdown markdown"><header><h1>[24.01] DeepSeek LLM</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt="Z. Yuan" class=docAuthorImg_vlJe /><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Z. Yuan</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a href=https://www.linkedin.com/in/ze-yuan-sh7/ target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 448 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=新模型縮放律>新・模型縮放律<a href=#新模型縮放律 class=hash-link aria-label=新・模型縮放律的直接連結 title=新・模型縮放律的直接連結 translate=no>​</a></h2>
<p><a href=https://arxiv.org/abs/2401.02954 target=_blank rel="noopener noreferrer"><strong>DeepSeek LLM: Scaling Open-Source Language Models with Longtermism</strong></a></p>
<hr/>
<p>最近 DeepSeek 的新聞鬧得沸沸揚揚，連 OpenAI 都忍不住跳出來要說上兩句。</p>
<p>既然他們引起了這麼大的迴響，我們花點時間把他們近年發表的論文都看上一遍。</p>
<p>這篇論文有 48 頁，其中有大量的實驗數據和技術細節，所以我們挑重點看。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=定義問題>定義問題<a href=#定義問題 class=hash-link aria-label=定義問題的直接連結 title=定義問題的直接連結 translate=no>​</a></h2>
<p>開源模型和閉源模型間的性能差距一直是一個熱門話題。過去的研究表明，開源模型在大多數基準測試中的表現明顯落後於閉源模型，這主要是由於開源模型的規模和資源限制所致。</p>
<p>為了拉近這兩者之間的差距，研究團隊提出了 DeepSeek LLM 系列模型，這是一系列大小從 7B 到 67B 的開源語言模型。為了訓練這些模型，研究團隊針對現有的 Scaling Law 提出質疑，認為過去的研究結果不盡然正確，因此他們提出了自己的 Scaling Law，並以此作為整篇論文的主軸，探討模型規模、數據規模和計算預算之間的關係。</p>
<p>這裡我們專注於 Scaling Law 的討論，並對 DeepSeek LLM 的設計和實驗結果進行簡要介紹。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=解決問題>解決問題<a href=#解決問題 class=hash-link aria-label=解決問題的直接連結 title=解決問題的直接連結 translate=no>​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=資料處理策略>資料處理策略<a href=#資料處理策略 class=hash-link aria-label=資料處理策略的直接連結 title=資料處理策略的直接連結 translate=no>​</a></h3>
<p>研究團隊採取「去重複 → 篩選 → 混合」的三階段策略：</p>
<ul>
<li>
<p><strong>去重複 (Deduplication)</strong>：</p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=decup src=/assets/images/img1-416d1b1da253361b4c2392042febf92d.jpg width=1224 height=160 class=img_ev3q /></figure></div>
<p>將整個 Common Crawl 語料庫作為去重範圍。從上表可見，跨多個 dumps 的去重比僅對單一 dump 來得更徹底，這為模型提供了更多獨特的學習樣本。</p>
</li>
<li>
<p><strong>篩選 (Filtering)</strong>：設計嚴謹的文檔品質評估標準，結合語言和語義層面的分析，從局部與全局角度確保數據品質。</p>
</li>
<li>
<p><strong>混合 (Remixing)</strong>：為解決數據分佈不均問題，特別增強低代表性領域的數據，確保數據集更均衡且包容多元信息。</p>
</li>
</ul>
<p>在 Tokenizer 的設計上，研究團隊採用 Byte-level Byte-Pair Encoding（BBPE），並利用預分詞避免不同字符類別（如換行、標點、CJK符號）混合；同時，將數字拆分為單個數位。詞彙表初步設定為 100000，再加上 15 個特殊 token，並預留額外空間至 102400，兼顧了模型訓練的計算效率與未來擴充的需求。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=模型架構設計>模型架構設計<a href=#模型架構設計 class=hash-link aria-label=模型架構設計的直接連結 title=模型架構設計的直接連結 translate=no>​</a></h3>
<p>模型基本沿襲 LLaMA 架構，採用 Pre-Norm 結構搭配 RMSNorm，以及 SwiGLU 作為 FFN 的激活函數。位置編碼採用 Rotary Embedding 方法，增強序列處理能力。</p>
<p>為降低推理成本，67B 模型使用 Grouped-Query Attention（GQA）取代傳統的 Multi-Head Attention。</p>
<p>大小兩種模型（7B 與 67B）的層數分別為 30 層與 95 層，這樣的調整不僅保持與其他開源模型的參數一致性，同時也利於模型流水線劃分，優化訓練與推理流程。與傳統僅擴大 FFN 寬度的做法不同，研究團隊選擇通過增加網絡深度來擴展 67B 模型參數，有助於提升模型整體性能。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>這裡有幾個關鍵詞，需要閱讀其他論文：<ol>
<li>Rotary Embedding: 旋轉位置編碼，可以參考我們之前讀過的文章<!-- -->
<ul>
<li><a href=/papers/transformers/roformer/><strong>[21.04] RoFormer: 旋轉位置編碼</strong></a></li>
</ul>
</li>
<li>Grouped-Query Attention: 分組多頭注意力，參考 GQA 論文<!-- -->
<ul>
<li><a href=https://arxiv.org/abs/2305.13245 target=_blank rel="noopener noreferrer"><strong>[23.05] GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints</strong></a></li>
</ul>
</li>
</ol><p>之後等我們看過這些論文之後再補上對應的筆記。</div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=參數配置>參數配置<a href=#參數配置 class=hash-link aria-label=參數配置的直接連結 title=參數配置的直接連結 translate=no>​</a></h3>
<p>模型初始化標準差設定為 0.006，使用 AdamW 優化器：</p>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn></mrow><annotation encoding=application/x-tex>\beta_1=0.9</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05278em>β</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.0528em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.9</span></span></span></span></li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>0.95</mn></mrow><annotation encoding=application/x-tex>\beta_2=0.95</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05278em>β</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.0528em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.95</span></span></span></span></li>
<li>weight_decay=0.1</li>
</ul>
<p>學習率調度器採用多步配置，經過 2000 步的 warmup 後達到峰值，隨後在 80% 與 90% 的訓練 token 處分別降至最大值的 31.6% 和 10%。該策略允許在固定模型大小下調整訓練規模，並能重用前一階段的訓練成果，為持續訓練帶來便利。整體實驗表明，雖然損失下降曲線有所不同，但最終性能與 cosine 調度器基本一致。</p>
<p>梯度裁剪值設定為 1.0，以防止梯度爆炸並穩定訓練。</p>
<p>訓練採用 HAI-LLM 框架，該框架整合了數據、張量、序列以及管線並行技術，類似於 Megatron 的設計，能有效分攤大規模模型的計算負擔。</p>
<p>另外引入 flash attention 技術以提升硬件利用率；利用 ZeRO-1 技術對優化器狀態進行分割，進一步降低記憶體消耗。通過融合部分層（如 LayerNorm、GEMM 及 Adam 更新）加速訓練；採用混合精度（bf16 訓練、fp32 梯度累積）及原位交叉熵計算以優化記憶體使用。</p>
<p>模型權重與優化器狀態每 5 分鐘自動保存，保證在硬件或網絡故障時最多損失 5 分鐘的訓練；同時支持從不同 3D 並行配置中恢復訓練，應對計算資源動態變化。</p>
<p>評估策略的部分則是在生成任務中採用 vLLM，而非生成任務則採用連續批次處理，以減少手動調整批次大小和 token 填充問題。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=scaling-laws>Scaling Laws<a href=#scaling-laws class=hash-link aria-label="Scaling Laws的直接連結" title="Scaling Laws的直接連結" translate=no>​</a></h2>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>過去兩篇有名的 Scaling Laws，如果沒看過的讀者可以先去看看我們之前寫的筆記：<ul>
<li><a href=/papers/transformers/scaling_laws/><strong>[20.01] Scaling Laws: 模型的縮放律</strong></a></li>
<li><a href=/papers/transformers/chinchilla/><strong>[22.03] Chinchilla: 栗鼠之眼</strong></a></li>
</ul></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=超參數配置>超參數配置<a href=#超參數配置 class=hash-link aria-label=超參數配置的直接連結 title=超參數配置的直接連結 translate=no>​</a></h3>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt="scaling laws" src=/assets/images/img2-a447fb337a5fea99d4cba6558574759f.jpg width=1444 height=584 class=img_ev3q /></figure></div>
<p>研究團隊首先在計算預算 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>C</mi><mo>=</mo><mn>1</mn><mi mathvariant=normal>e</mi><mn>17</mn></mrow><annotation encoding=application/x-tex>C = 1\mathrm{e}17</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span><span class="mord mathrm">e</span><span class=mord>17</span></span></span></span> 下，針對特定模型規模（177M FLOPs/token）進行了 grid search，探索不同批次大小 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>B</mi></mrow><annotation encoding=application/x-tex>B</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span></span></span></span> 與學習率 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>η</mi></mrow><annotation encoding=application/x-tex>\eta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>η</span></span></span></span> 的組合。</p>
<p>根據上圖實驗結果，研究團隊觀察到在較廣的 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>B</mi></mrow><annotation encoding=application/x-tex>B</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span></span></span></span> 與 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>η</mi></mrow><annotation encoding=application/x-tex>\eta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>η</span></span></span></span> 範圍內，模型的泛化誤差都保持穩定。這意味著在這個較大參數空間中，都能找到接近最優性能的超參數組合，即「近似最優」參數區域。</p>
<p>為了進一步探索更大計算預算範圍（從 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>1</mn><mi mathvariant=normal>e</mi><mn>17</mn></mrow><annotation encoding=application/x-tex>1\mathrm{e}17</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span><span class="mord mathrm">e</span><span class=mord>17</span></span></span></span> 到 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>2</mn><mi mathvariant=normal>e</mi><mn>19</mn></mrow><annotation encoding=application/x-tex>2\mathrm{e}19</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6444em></span><span class=mord>2</span><span class="mord mathrm">e</span><span class=mord>19</span></span></span></span>），研究團隊採用了多步學習率調度器。這種調度器允許在第一階段訓練完成後重複利用已有訓練成果，從而高效地訓練多組超參數配置的模型。由於參數空間存在冗餘，研究團隊定義當模型的泛化誤差超出最小值不超過 0.25% 時，所使用的超參數可視為「近似最優」的。</p>
<p>經過大量實驗與數據擬合，結果顯示：</p>
<ul>
<li><strong>最佳批次大小 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>B</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=application/x-tex>B_{opt}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05017em>B</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0502em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>：</strong> 隨著計算預算 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>C</mi></mrow><annotation encoding=application/x-tex>C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>C</span></span></span></span> 的增加而逐漸增加。這與直覺一致，即在更多計算資源下，可以採用更大的批次。</li>
<li><strong>最佳學習率 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>η</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=application/x-tex>\eta_{opt}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7167em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>η</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>：</strong> 隨著 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>C</mi></mrow><annotation encoding=application/x-tex>C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>C</span></span></span></span> 增加而逐漸下降。也就是說，當模型規模變大、計算預算提高時，需要較低的學習率來保持穩定性。</li>
</ul>
<p>最後研究團隊在論文中給出了以下兩個公式來描述這一關係：</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>η</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><mo>=</mo><mn>0.3118</mn><mo>⋅</mo><msup><mi>C</mi><mrow><mo>−</mo><mn>0.1250</mn></mrow></msup></mrow><annotation encoding=application/x-tex>\eta_{opt} = 0.3118 \cdot C^{-0.1250}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7167em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>η</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.3118</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.8641em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8641em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">0.1250</span></span></span></span></span></span></span></span></span></span></span></span></span>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>B</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><mo>=</mo><mn>0.2920</mn><mo>⋅</mo><msup><mi>C</mi><mn>0.3271</mn></msup></mrow><annotation encoding=application/x-tex>B_{opt} = 0.2920 \cdot C^{0.3271}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05017em>B</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0502em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.2920</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.8641em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8641em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0.3271</span></span></span></span></span></span></span></span></span></span></span></span></span>
<p>這兩個公式分別量化了最佳學習率和最佳批次大小與計算預算 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>C</mi></mrow><annotation encoding=application/x-tex>C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>C</span></span></span></span> 的冪律關係。</p>
<p>為了驗證這些公式的有效性，研究團隊在更大的計算預算 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>C</mi><mo>=</mo><mn>1</mn><mi mathvariant=normal>e</mi><mn>20</mn></mrow><annotation encoding=application/x-tex>C = 1\mathrm{e}20</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span><span class="mord mathrm">e</span><span class=mord>20</span></span></span></span> 下，以模型規模為 2.94B FLOPs/token 的模型進行驗證，實驗結果如上圖(右)，結果表明擬合得到的超參數正好位於最優參數空間的中心位置，進一步驗證了公式的準確性。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=最佳模型與數據縮放估計>最佳模型與數據縮放估計<a href=#最佳模型與數據縮放估計 class=hash-link aria-label=最佳模型與數據縮放估計的直接連結 title=最佳模型與數據縮放估計的直接連結 translate=no>​</a></h3>
<p>在完成了近似最優超參數公式的擬合之後，研究團隊開始研究如何對模型規模與數據規模進行最優分配：</p>
<blockquote>
<p><strong>即確定在給定計算預算 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>C</mi></mrow><annotation encoding=application/x-tex>C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>C</span></span></span></span> 下，如何選擇最佳的模型規模和數據規模以達到最低的誤差。</strong></p>
</blockquote>
<p>核心目標是尋找兩個冪律關係，其中模型最優規模 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>N</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=application/x-tex>N_{opt}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span> 與計算預算滿足</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>N</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><mo>∝</mo><msup><mi>C</mi><mi>a</mi></msup></mrow><annotation encoding=application/x-tex>N_{opt} \propto C^{a}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∝</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.7144em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.7144em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span></span></span></span></span></span></span></span></span></span></span></span></span>
<p>而數據最優規模 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>D</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=application/x-tex>D_{opt}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>（以數據中 token 數量表示）滿足</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>D</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><mo>∝</mo><msup><mi>C</mi><mi>b</mi></msup></mrow><annotation encoding=application/x-tex>D_{opt} \propto C^{b}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∝</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8991em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8991em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span></span></span></span></span></span></span></span></span></span></span></span></span>
<p>這裡，<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>a</mi></mrow><annotation encoding=application/x-tex>a</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">a</span></span></span></span> 和 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>b</mi></mrow><annotation encoding=application/x-tex>b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span></span></span></span> 分別是模型和數據的 Scaling 指數。</p>
<p>早期工作通常用模型參數數量來表示模型規模，計算預算與模型與數據規模的關係近似為</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>C</mi><mo>=</mo><mn>6</mn><mi>N</mi><mo>⋅</mo><mi>D</mi></mrow><annotation encoding=application/x-tex>C = 6N \cdot D</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6833em></span><span class=mord>6</span><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span></span></span></span></span>
<p>可以用 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>6</mn><msub><mi>N</mi><mn>1</mn></msub></mrow><annotation encoding=application/x-tex>6N_1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord>6</span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 或 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>6</mn><msub><mi>N</mi><mn>2</mn></msub></mrow><annotation encoding=application/x-tex>6N_2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord>6</span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 來近似模型規模。但是這兩種表示法都沒有充分反映注意力運算所帶來的計算負擔，這兩種方法在不同模型規模下可能會出現高達 50% 的誤差，特別是在小規模模型上更為明顯，這些都會對後續 Scaling 曲線的擬合產生顯著的統計誤差。</p>
<p>為了克服上述問題，研究團隊提出了新的模型規模表示方法 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>M</mi></mrow><annotation encoding=application/x-tex>M</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.10903em>M</span></span></span></span>，其中包含了注意力運算的計算開銷，但不包括詞彙計算，公式為</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>M</mi><mo>=</mo><mn>72</mn><mtext> </mtext><msub><mi>n</mi><mrow><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi></mrow></msub><mtext> </mtext><msubsup><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow><mn>2</mn></msubsup><mo>+</mo><mn>12</mn><mtext> </mtext><msub><mi>n</mi><mrow><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi></mrow></msub><mtext> </mtext><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mtext> </mtext><msub><mi>l</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi></mrow></msub></mrow><annotation encoding=application/x-tex>M = 72\, n_{layer}\, d_{model}^2 + 12\, n_{layer}\, d_{model}\, l_{seq}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.1502em;vertical-align:-0.2861em></span><span class=mord>72</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">n</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style=margin-right:0.02778em>yer</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">d</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8641em><span style=top:-2.453em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span></span></span></span><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.247em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.9805em;vertical-align:-0.2861em></span><span class=mord>12</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">n</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style=margin-right:0.02778em>yer</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">d</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.01968em>l</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0197em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight" style=margin-right:0.03588em>q</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span></span>
<p>其中：</p>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>n</mi><mrow><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi></mrow></msub></mrow><annotation encoding=application/x-tex>n_{layer}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7167em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal">n</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style=margin-right:0.02778em>yer</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>：層數</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding=application/x-tex>d_{model}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">d</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>：模型寬度</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>l</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi></mrow></msub></mrow><annotation encoding=application/x-tex>l_{seq}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9805em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.01968em>l</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0197em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight" style=margin-right:0.03588em>q</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>：序列長度</li>
</ul>
<p>採用 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>M</mi></mrow><annotation encoding=application/x-tex>M</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.10903em>M</span></span></span></span> 後，計算預算可以簡化表示為</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>C</mi><mo>=</mo><mi>M</mi><mo>⋅</mo><mi>D</mi></mrow><annotation encoding=application/x-tex>C = M \cdot D</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span></span></span></span></span>
<p>這使得在不同配置下更容易對模型與數據進行最優分配的估計。</p>
<p>在引入 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>M</mi></mrow><annotation encoding=application/x-tex>M</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.10903em>M</span></span></span></span> 之後，研究團隊將目標明確化為：</p>
<blockquote>
<p><strong>在給定 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>C</mi><mo>=</mo><mi>M</mi><mo>⋅</mo><mi>D</mi></mrow><annotation encoding=application/x-tex>C = M \cdot D</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span></span></span></span> 的條件下，尋找最佳模型規模 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>M</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=application/x-tex>M_{opt}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span> 與最佳數據規模 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>D</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=application/x-tex>D_{opt}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>，使得模型的泛化誤差 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>L</mi><mo stretchy=false>(</mo><mi>N</mi><mo separator=true>,</mo><mi>D</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>L(N, D)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">L</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=mclose>)</span></span></span></span> 最小。</strong></p>
</blockquote>
<p>這可以表示為：</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>M</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><mo stretchy=false>(</mo><mi>C</mi><mo stretchy=false>)</mo><mo separator=true>,</mo><mtext> </mtext><msub><mi>D</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><mo stretchy=false>(</mo><mi>C</mi><mo stretchy=false>)</mo><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mrow><mi>M</mi><mo separator=true>,</mo><mi>D</mi><mtext> </mtext><mtext>s.t.</mtext><mtext> </mtext><mi>C</mi><mo>=</mo><mi>M</mi><mo>⋅</mo><mi>D</mi></mrow></munder><mi>L</mi><mo stretchy=false>(</mo><mi>N</mi><mo separator=true>,</mo><mi>D</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>M_{opt}(C),\, D_{opt}(C) = \arg\min_{M,D \, \text{s.t.} \, C = M \cdot D} L(N,D)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0361em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=mclose>)</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.6304em;vertical-align:-0.8804em></span><span class=mop>ar<span style=margin-right:0.01389em>g</span></span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.6679em><span style=top:-2.3557em;margin-left:0em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.10903em>M</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.02778em>D</span><span class="mspace mtight" style=margin-right:0.1952em></span><span class="mord text mtight"><span class="mord mtight">s.t.</span></span><span class="mspace mtight" style=margin-right:0.1952em></span><span class="mord mathnormal mtight" style=margin-right:0.07153em>C</span><span class="mrel mtight">=</span><span class="mord mathnormal mtight" style=margin-right:0.10903em>M</span><span class="mbin mtight">⋅</span><span class="mord mathnormal mtight" style=margin-right:0.02778em>D</span></span></span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span><span class=mop>min</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.8804em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">L</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=mclose>)</span></span></span></span></span>
<p>為了降低實驗成本與擬合難度，研究團隊採用了 Chinchilla 中提出的 <strong>IsoFLOP profile</strong> 方法：</p>
<ul>
<li>選取 8 個不同的計算預算，範圍從 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>1</mn><mi mathvariant=normal>e</mi><mn>17</mn></mrow><annotation encoding=application/x-tex>1\mathrm{e}17</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span><span class="mord mathrm">e</span><span class=mord>17</span></span></span></span> 到 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>3</mn><mi mathvariant=normal>e</mi><mn>20</mn></mrow><annotation encoding=application/x-tex>3\mathrm{e}20</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6444em></span><span class=mord>3</span><span class="mord mathrm">e</span><span class=mord>20</span></span></span></span>。</li>
<li>對於每個預算，設計大約 10 種不同的模型與數據規模配置。</li>
<li>每個配置的超參數由前述公式決定，並在一個獨立的驗證集上（包含 100M tokens）計算泛化誤差。</li>
</ul>
<p>利用上述數據，研究團隊繪製了 IsoFLOP 曲線與模型/數據 Scaling 曲線：</p>
<p><img decoding=async loading=lazy alt="scaling laws" src=/assets/images/img3-4617742ab8437afa1ece51ef8e9441de.jpg width=1398 height=512 class=img_ev3q /></p>
<p>並最終得到最優模型與數據的 Scaling 公式：</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>M</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>M</mi><mrow><mi>b</mi><mi>a</mi><mi>s</mi><mi>e</mi></mrow></msub><mo>⋅</mo><msup><mi>C</mi><mi>a</mi></msup></mrow><annotation encoding=application/x-tex>M_{opt} = M_{base} \cdot C^{a}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ba</span><span class="mord mathnormal mtight">se</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.7144em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.7144em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span></span></span></span></span></span></span></span></span></span></span></span></span>
<ul>
<li>其中 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>M</mi><mrow><mi>b</mi><mi>a</mi><mi>s</mi><mi>e</mi></mrow></msub><mo>=</mo><mn>0.1715</mn><mo separator=true>,</mo><mtext>  </mtext><mi>a</mi><mo>=</mo><mn>0.5243</mn></mrow><annotation encoding=application/x-tex>M_{base} = 0.1715,\; a = 0.5243</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ba</span><span class="mord mathnormal mtight">se</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8389em;vertical-align:-0.1944em></span><span class=mord>0.1715</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">a</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.5243</span></span></span></span>。</li>
</ul>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>D</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>D</mi><mrow><mi>b</mi><mi>a</mi><mi>s</mi><mi>e</mi></mrow></msub><mo>⋅</mo><msup><mi>C</mi><mi>b</mi></msup></mrow><annotation encoding=application/x-tex>D_{opt} = D_{base} \cdot C^{b}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ba</span><span class="mord mathnormal mtight">se</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.8991em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8991em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span></span></span></span></span></span></span></span></span></span></span></span></span>
<ul>
<li>其中 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>D</mi><mrow><mi>b</mi><mi>a</mi><mi>s</mi><mi>e</mi></mrow></msub><mo>=</mo><mn>5.8316</mn><mo separator=true>,</mo><mtext>  </mtext><mi>b</mi><mo>=</mo><mn>0.4757</mn></mrow><annotation encoding=application/x-tex>D_{base} = 5.8316,\; b = 0.4757</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ba</span><span class="mord mathnormal mtight">se</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class=mord>5.8316</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.4757</span></span></span></span>。</li>
</ul>
<p>根據這些擬合結果，研究團隊成功預測了 DeepSeek LLM 7B 與 67B 模型的泛化誤差，如下圖：</p>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt="scaling laws testing" src=/assets/images/img4-350dd2d632fd75ddfe74daf9de718396.jpg width=944 height=576 class=img_ev3q /></figure></div>
<p>實驗結果顯示小規模實驗的結果可以準確預測 1000 倍計算預算下的模型表現，這為大規模模型訓練提供了有力的支持。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=數據品質的影響>數據品質的影響<a href=#數據品質的影響 class=hash-link aria-label=數據品質的影響的直接連結 title=數據品質的影響的直接連結 translate=no>​</a></h3>
<p>研究團隊選用了三種數據集進行比較分析：</p>
<ul>
<li><strong>Early Data:</strong> 早期的內部數據。</li>
<li><strong>Current Data:</strong> 目前的內部數據。</li>
<li><strong>OpenWebText2:</strong> 先前研究 scaling laws 時採用的數據集。</li>
</ul>
<p>透過比較，評估顯示目前的內部數據品質優於早期數據，而 OpenWebText2 由於規模較小，可進行更為細緻的處理，其數據品質甚至超過了當前內部數據。</p>
<p>利用上一節的 Scaling Laws 公式，研究團隊計算了不同數據集下的 Scaling 指數，結果如下表：</p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt="scaling laws data" src=/assets/images/img5-e88004af16723278a3ead5da5c34e127.jpg width=1086 height=428 class=img_ev3q /></figure></div>
<p>具體而言，OpenAI（使用 OpenWebText2）的係數為 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>a</mi><mo>=</mo><mn>0.73</mn></mrow><annotation encoding=application/x-tex>a=0.73</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">a</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.73</span></span></span></span> 與 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>b</mi><mo>=</mo><mn>0.27</mn></mrow><annotation encoding=application/x-tex>b=0.27</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.27</span></span></span></span>；Chinchilla（MassiveText）的係數為 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>a</mi><mo>=</mo><mn>0.49</mn></mrow><annotation encoding=application/x-tex>a=0.49</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">a</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.49</span></span></span></span> 與 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>b</mi><mo>=</mo><mn>0.51</mn></mrow><annotation encoding=application/x-tex>b=0.51</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.51</span></span></span></span>；而在他們自己的資料中，早期內部資料的係數為 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>a</mi><mo>=</mo><mn>0.450</mn></mrow><annotation encoding=application/x-tex>a=0.450</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">a</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.450</span></span></span></span>500. <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>b</mi><mo>=</mo><mn>0.476</mn></mrow><annotation encoding=application/x-tex>b=0.476</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.476</span></span></span></span>，經過 OpenWebText2 處理後的資料則為 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>a</mi><mo>=</mo><mn>0.578</mn></mrow><annotation encoding=application/x-tex>a=0.578</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">a</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.578</span></span></span></span> 與 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>b</mi><mo>=</mo><mn>0.422</mn></mrow><annotation encoding=application/x-tex>b=0.422</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0.422</span></span></span></span>。</p>
<p>從這些結果可以看出，隨著資料品質的提升，模型擴展指數 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>a</mi></mrow><annotation encoding=application/x-tex>a</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">a</span></span></span></span> 會逐漸增大，而資料擴展指數 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>b</mi></mrow><annotation encoding=application/x-tex>b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span></span></span></span> 則會相應減少。這顯示「<strong>在相同的計算預算下，資料品質越高，就越要將更多的資源用於模型擴展，而非單純增加資料量</strong>」。這同時也解釋了早期研究中不同資料集下最優模型與資料分配策略有較大差異的原因。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>直覺上我們可能會認為高品質資料因為邏輯清晰、雜訊少，可以讓較小的模型就達到不錯的效果；也就是說，用更高品質的資料可以「省」下模型容量。<p>但是研究團隊告訴我們：不對唷！<p><strong>由於高品質的資料降低了預測難度，意味著資料中的信號更強、更穩定。進而使得模型能夠利用額外的容量來捕捉更細緻的模式，進一步提高性能</strong>。<p>換句話說，當資料品質較高時，模型不再受限於學習「噪音」，而能充分發揮其規模效應，從而在增加模型參數後獲得更大提升。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=模型對齊>模型對齊<a href=#模型對齊 class=hash-link aria-label=模型對齊的直接連結 title=模型對齊的直接連結 translate=no>​</a></h2>
<p>模型對齊（Alignment）流程的主要目標在於讓模型在生成回應時，不僅能夠提供有用的資訊，同時避免產生有害的內容。</p>
<p>在資料方面，研究團隊共收集了約 150 萬筆中英文指令數據，涵蓋了廣泛的主題。其中，有 120 萬筆屬於有幫助性的資料，其內部分佈為：一般語言任務佔 31.2%、數學問題佔 46.6%、程式編寫練習佔 22.2%；另外有 30 萬筆數據則專注於安全性議題，包含各類敏感主題。</p>
<p>對齊流程分為兩個階段：</p>
<ul>
<li>第一階段是監督式微調（Supervised Fine-Tuning, SFT）</li>
<li>第二階段採用直接偏好優化（Direct Preference Optimization, DPO）。</li>
</ul>
<p>在監督式微調階段，針對不同模型規模採用了不同的訓練 epoch，原因在於後者較容易發生過擬合現象。實驗中使用了 GSM8K 和 HumanEval 等基準，發現 7B 模型的表現能持續提升，但 67B 模型則較快達到性能上限。</p>
<p>在第二階段，即 DPO 部分，研究團隊利用直接偏好優化演算法進一步增強模型對齊效果。DPO 被證實是一種簡單而有效的方法，其核心在於利用偏好數據來調整模型生成回應的方向。</p>
<p>在此階段，他們分別針對有幫助性與無害性構建了偏好資料。具體作法是先收集涵蓋創意寫作、問答、指令遵循等多種範疇的多語言提示，然後利用 DeepSeek Chat 模型生成候選回應，並以此構建有幫助性偏好數據；無害性偏好數據則採用相似的流程。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=討論>討論<a href=#討論 class=hash-link aria-label=討論的直接連結 title=討論的直接連結 translate=no>​</a></h2>
<p>對於 DeepSeek LLM 的實驗結果非常多，我們主要看一下模型在開放領域和開放式問題上的生成能力，因為這裡比較貼近實際使用情境，讓我們可以了解模型在多回合對話、跨語言任務等非結構化應用下的真實表現。</p>
<p>其他部分，感興趣的讀者可以參考原始論文。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=中文開放式評測>中文開放式評測<a href=#中文開放式評測 class=hash-link aria-label=中文開放式評測的直接連結 title=中文開放式評測的直接連結 translate=no>​</a></h3>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=results src=/assets/images/img6-80892a2c97f572e3f892f812e863537a.jpg width=1392 height=866 class=img_ev3q /></figure></div>
<p>研究團隊針對中英文任務來測試模型的開放式生成能力。</p>
<p>針對中文評測部分，他們採用了 AlignBench 測試集，該測試集涵蓋了 8 個主要類別、36 個次要類別，共計 683 個問題。每個問題不僅提供了提示，還附有專業的參考答案以及評分模板，利用 GPT-4 進行回應品質的評分，從而保證了評測的客觀性與專業性。</p>
<p>在評測過程中，研究團隊使用了 AlignBench 官方 GitHub 代碼庫來實現模型評測，並嚴格按照原始設定調整生成溫度參數。具體而言，對於角色扮演、寫作能力和開放式問題這些任務，生成溫度設定為 0.7；而其他任務則設定為 0.1，以確保生成結果既有足夠多樣性，又能保持穩定。</p>
<p>從 AlignBench 的排行榜可以看出，DeepSeek 67B Chat 模型在多項中文任務上超越了 ChatGPT 和其他基準模型，僅次於兩個版本的 GPT-4，顯示出其在處理中文開放性問題上的優異表現。進一步來看，經過 DPO（直接偏好優化）訓練後，模型在幾乎所有評分指標上都有顯著提升，這證明了 DPO 在改善模型對齊方面的正面效果。</p>
<p>在中文語言任務中，其基本中文能力甚至超越了最新版本的 GPT-4；而在更複雜的中文邏輯推理和數學計算任務上，模型的表現明顯領先於其他中文大型語言模型。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=英文開放式評測>英文開放式評測<a href=#英文開放式評測 class=hash-link aria-label=英文開放式評測的直接連結 title=英文開放式評測的直接連結 translate=no>​</a></h3>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=results src=/assets/images/img7-a7bf02e885d09f5268f943bcbe27b355.jpg width=1616 height=480 class=img_ev3q /></figure></div>
<p>在英語開放式評測中，研究團隊採用了 MT-Bench 這個基準，該基準包含了 8 個不同類別的多回合對話問題，專門用以測試模型在持續對話中的生成能力。這個基準能夠全面評估模型在各種開放式情境下的應對表現，尤其在多回合交互中檢視模型是否能保持一致性與連貫性。</p>
<p>實驗結果顯示，DeepSeek LLM 67B Chat 在此評測上超越了其他多個開源模型，如 LLaMA-2-Chat 70B、Xwin 70b v0.1 以及 TÜLU 2+DPO 70B，並且其得分達到 8.35，與 GPT-3.5-turbo 的表現相當。這代表在多回合英語對話生成上，DeepSeek LLM 的表現已接近主流商用模型的水平。</p>
<p>此外，在進一步應用 DPO 訓練後，DeepSeek LLM 67B Chat 的平均得分進一步提升至 8.76，僅次於 GPT-4 的表現。這說明 DPO 不僅能夠進一步調整模型生成的偏好，還能有效增強模型在開放式多回合對話中的表現。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=其他有趣的發現>其他有趣的發現<a href=#其他有趣的發現 class=hash-link aria-label=其他有趣的發現的直接連結 title=其他有趣的發現的直接連結 translate=no>​</a></h3>
<p>跑完一整套評估流程之後，研究團隊在最後提出了幾個有趣的發現：</p>
<ul>
<li>
<p><strong>（1）模型安全評估：</strong></p>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt=do-not-answer src=/assets/images/img8-c0563b88aba42cbbbdd42c554e325836.jpg width=1108 height=652 class=img_ev3q /></figure></div>
<p>首先，研究團隊使用「Do-Not-Answer Score」用來評估模型在面對敏感或不適合回答的問題時，能否正確拒絕回答。分數越高代表模型在安全性上越好。</p>
<p>從數據上看 DeepSeek-67B-Chat 在安全性上表現優異，屬於較安全的模型之一。</p>
</li>
<li>
<p><strong>（2）分階段微調策略：</strong></p>
<p>在微調過程中，研究團隊發現對於較小型模型（例如 7B）而言，長時間在數學與程式碼資料上進行微調能夠提升其專業能力，但可能會損害對話表現，導致回答出現重複現象。</p>
<p>為此，他們提出了分階段微調的策略：第一階段使用所有可用資料進行微調；第二階段則專注於對話資料進行微調。實驗結果證明這種分階段微調能有效平衡專業任務與對話流暢性之間的需求。</p>
</li>
<li>
<p><strong>（3）多選題資料的影響：</strong></p>
<p>在對齊階段，研究團隊嘗試加入 2000 萬筆中文多選題資料，以期提升模型在多選題類任務上的表現。</p>
<p>加入多選題資料後，在 MMLU、C-Eval、CMMLU 等多選題基準上的得分都有顯著提升，但這種提升並未延伸到 TriviaQA 和中文問答等生成式評測上。也就是說，儘管多選題資料能夠提升模型解題能力，但在實際對話生成中並不會讓使用者感覺模型更「智能」。</p>
<p>因此，為了避免模型過度適應多選題形式而損害整體智能表現，他們最終決定在預訓練和微調階段都不加入多選題資料。</p>
</li>
<li>
<p><strong>（4）預訓練階段的指令資料：</strong></p>
<p>此外，研究團隊試驗在預訓練後期（最後 10%）加入 500 萬筆主要以多選題為主的指令資料，觀察其對基礎模型表現的影響。</p>
<p>結果顯示，這樣做確實可以提升模型在基準任務上的表現，但最終效果與在監督式微調階段加入相同資料後幾乎沒有差異。</p>
<p>因此，若指令資料量相當龐大，預訓練中加入也是可行的；不過，由於研究團隊傾向排除多選題資料，加上非多選題資料相對有限，故最終決定不在預訓練階段納入指令資料。</p>
</li>
<li>
<p><strong>（5）系統提示（System Prompt）的影響：</strong></p>
<p>系統提示是用來引導模型生成既有幫助性又有禮貌、正面的回答。</p>
<p>研究團隊採用了類似 LLaMA-2 的系統提示，例如明確告知模型「你是 DeepSeek Chat，一個有幫助、尊重且誠實的 AI 助手」，並說明知識截止日期等。</p>
<p>有趣的是，他們發現對於 7B 模型而言，加入系統提示反而會略微降低評測得分（從 7.15 下降至 7.11），而對於 67B 模型，系統提示則能顯著提升表現（從 8.35 提升至 8.58）。這可能是因為較大模型更能理解和遵循系統提示所傳遞的意圖，而較小模型則可能因為理解不足，反而受到訓練與測試之間不一致的影響。</p>
</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=結論>結論<a href=#結論 class=hash-link aria-label=結論的直接連結 title=結論的直接連結 translate=no>​</a></h2>
<p>DeepSeek LLM 是一套從零開始訓練的大型語言模型，基於涵蓋中英文共計 2 兆 tokens 的語料建構而成。論文不僅詳細記錄了模型訓練過程中的超參數選擇與 Scaling Laws 校準，還深入比較了多種微調策略，並提出一套兼顧訓練效率與資源分配的方法論。</p>
<p>這不只是模型本身的發布，更標誌著 DeepSeek-AI 正式進軍開源 LLM 的一個重要里程碑。</p>
<p>目前 DeepSeek 系列已釋出多篇核心論文，我們找時間依序讀過後續幾篇研究，繼續深入探索其完整的技術佈局與演進路線。</header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>最後<!-- -->由 <b>zephyr-sh</b> <!-- -->於 <b><time datetime=2025-07-19T11:04:19.000Z itemprop=dateModified>2025年7月19日</time></b> <!-- -->更新</span></div></div><section class=ctaSection_iCjC><div class="
        simpleCta_ji_Y
        simple-cta__coffee_YwC8
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>☕ 一杯咖啡，就是我創作的燃料！</h3><p class=simple-cta__subtitle_ol86>贊助我持續分享 AI 實作、全端架構與開源經驗，讓好文章不斷更新。<div class=simple-cta__buttonWrapper_jk1Y><img src=/img/bmc-logo.svg alt=cta-button class=simple-cta__buttonImg_Q9VV /></div></div><div class="ant-row ant-row-stretch cardsSection_wRaP css-mc1tut" style=margin-left:-8px;margin-right:-8px;row-gap:16px><div style=padding-left:8px;padding-right:8px;display:flex class="ant-col ant-col-xs-24 css-mc1tut"><div class="ant-card ant-card-bordered card_gKx9 fadeInUp_n33J hoverTransform_Mozy css-mc1tut" style=flex:1;display:flex;flex-direction:column><div class=ant-card-body><div style=text-align:center;margin-top:1rem><img src=/img/icons/all_in.svg alt="AI / 全端 / 客製 一次搞定 icon" style=width:48px;height:48px /></div><span class="ant-tag ant-tag-orange card__tag_PLj3 css-mc1tut">ALL</span><h4 class=card__title_SQBY>AI / 全端 / 客製 一次搞定</h4><p class=card__concept_Ak8F>從構想到上線，涵蓋顧問、開發與部署，全方位支援你的技術實作。<div class=card__bulletHeader_b6cf><h5 class=card__bulletTitle_R_wg>包含內容</h5></div><ul class=card__bulletList_SrNN><li class=card__bulletItem_wCRd>顧問服務 + 系統建置 + 客製開發<li class=card__bulletItem_wCRd>長期維運與擴充規劃</ul></div></div></div></div><div class="
        simpleCta_ji_Y
        simple-cta__outro_AXbn
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>🚀 你的專案準備好了嗎？</h3><p class=simple-cta__subtitle_ol86>如果你需要客製服務或長期顧問，歡迎與我聯繫！</div></section><div style=margin-top:3rem> </div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label=文件選項卡><a class="pagination-nav__link pagination-nav__link--prev" href=/papers/category/deepseek><div class=pagination-nav__sublabel>上一頁</div><div class=pagination-nav__label>DeepSeek (5)</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/papers/deepseek/deepseek-vl/><div class=pagination-nav__sublabel>下一頁</div><div class=pagination-nav__label>[24.03] DeepSeek-VL</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#新模型縮放律 class="table-of-contents__link toc-highlight">新・模型縮放律</a><li><a href=#定義問題 class="table-of-contents__link toc-highlight">定義問題</a><li><a href=#解決問題 class="table-of-contents__link toc-highlight">解決問題</a><ul><li><a href=#資料處理策略 class="table-of-contents__link toc-highlight">資料處理策略</a><li><a href=#模型架構設計 class="table-of-contents__link toc-highlight">模型架構設計</a><li><a href=#參數配置 class="table-of-contents__link toc-highlight">參數配置</a></ul><li><a href=#scaling-laws class="table-of-contents__link toc-highlight">Scaling Laws</a><ul><li><a href=#超參數配置 class="table-of-contents__link toc-highlight">超參數配置</a><li><a href=#最佳模型與數據縮放估計 class="table-of-contents__link toc-highlight">最佳模型與數據縮放估計</a><li><a href=#數據品質的影響 class="table-of-contents__link toc-highlight">數據品質的影響</a></ul><li><a href=#模型對齊 class="table-of-contents__link toc-highlight">模型對齊</a><li><a href=#討論 class="table-of-contents__link toc-highlight">討論</a><ul><li><a href=#中文開放式評測 class="table-of-contents__link toc-highlight">中文開放式評測</a><li><a href=#英文開放式評測 class="table-of-contents__link toc-highlight">英文開放式評測</a><li><a href=#其他有趣的發現 class="table-of-contents__link toc-highlight">其他有趣的發現</a></ul><li><a href=#結論 class="table-of-contents__link toc-highlight">結論</a></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/docs>開源專案</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/papers/intro>論文筆記</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/blog>部落格</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/terms-of-service>使用條款</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/privacy-policy>隱私政策</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/become-an-author>成為作者</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/worklog>工作日誌</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2025 DOCSAID.</div></div></div></footer></div></body>