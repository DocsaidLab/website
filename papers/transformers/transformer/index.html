<!doctype html><html lang=zh-hant dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-transformers/transformer/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.6.3"><title data-rh=true>[17.06] Transformer | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width,initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/papers/transformers/transformer/><meta data-rh=true property=og:locale content=zh_hant><meta data-rh=true property=og:locale:alternate content=en><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=zh-hant><meta data-rh=true name=docsearch:language content=zh-hant><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[17.06] Transformer | DOCSAID"><meta data-rh=true name=description content=新世界的起點><meta data-rh=true property=og:description content=新世界的起點><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/papers/transformers/transformer/><link data-rh=true rel=alternate href=https://docsaid.org/papers/transformers/transformer/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/transformers/transformer/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/transformers/transformer/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/transformers/transformer/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin><link rel=stylesheet href=/assets/css/styles.1cc926cb.css><script src=/assets/js/main.57d122af.js defer></script><script src=/assets/js/runtime~main.aeebf736.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label=跳至主要内容><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>跳至主要内容</a></div><nav aria-label=主導航 class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class=navbar__inner><div class=navbar__items><button aria-label=切換導覽列 aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><div class=navbar__logo><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/docs/>開源專案</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/papers/intro>論文筆記</a><a class="navbar__item navbar__link" href=/blog>部落格</a><a class="navbar__item navbar__link" href=/playground/intro>遊樂場</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>繁體中文</a><ul class=dropdown__menu><li><a href=/papers/transformers/transformer/ rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=zh-hant>繁體中文</a><li><a href=/en/papers/transformers/transformer/ rel="noopener noreferrer" class=dropdown__link lang=en>English</a><li><a href=/ja/papers/transformers/transformer/ rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><a href=https://buymeacoffee.com/zephyr_docsaid target=_blank rel="noopener noreferrer" class="navbar__item navbar__link">支持我們<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a><a href=https://github.com/DocsaidLab target=_blank rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type=button disabled title=切換淺色/深色模式（當前為淺色模式） aria-label=切換淺色/深色模式（當前為淺色模式） aria-live=polite aria-pressed=false><svg viewBox="0 0 24 24" width=24 height=24 class=lightToggleIcon_pyhR><path fill=currentColor d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"/></svg><svg viewBox="0 0 24 24" width=24 height=24 class=darkToggleIcon_wfgR><path fill=currentColor d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"/></svg></button></div><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="搜尋 (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>搜尋</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label=回到頂部 class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label=文件側邊欄 class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/papers/intro>論文筆記</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="展開側邊欄分類 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/face-anti-spoofing-1>Face Anti-Spoofing (1)</a><button aria-label="展開側邊欄分類 'Face Anti-Spoofing (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="展開側邊欄分類 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/feature-fusion-7>Feature Fusion (7)</a><button aria-label="展開側邊欄分類 'Feature Fusion (7)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="展開側邊欄分類 'Lightweight (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/mamba-1>Mamba (1)</a><button aria-label="展開側邊欄分類 'Mamba (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/model-tuning-7>Model Tuning (7)</a><button aria-label="展開側邊欄分類 'Model Tuning (7)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/multimodality-22>Multimodality (22)</a><button aria-label="展開側邊欄分類 'Multimodality (22)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/normalization-1>Normalization (1)</a><button aria-label="展開側邊欄分類 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/object-detection-8>Object Detection (8)</a><button aria-label="展開側邊欄分類 'Object Detection (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/reparameterization-7>Reparameterization (7)</a><button aria-label="展開側邊欄分類 'Reparameterization (7)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="展開側邊欄分類 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-detection-10>Text Detection (10)</a><button aria-label="展開側邊欄分類 'Text Detection (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="展開側邊欄分類 'Text Recognition (20)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="展開側邊欄分類 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/papers/category/transformers-15>Transformers (15)</a><button aria-label="收起側邊欄分類 'Transformers (15)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/papers/transformers/transformer/>[17.06] Transformer</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/gpt_1/>[18.06] GPT-1</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/bert/>[18.10] BERT</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/transformer-xl/>[19.01] Transformer-XL</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/gpt_2/>[19.02] GPT-2</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/sparse-transformer/>[19.04] Sparse Transformer</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/xlnet/>[19.06] XLNet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/roberta/>[19.07] RoBERTa</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/albert/>[19.09] ALBERT</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/mqa/>[19.11] MQA</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/scaling_laws/>[20.01] Scaling Laws</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/longformer/>[20.04] Longformer</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/gpt_3/>[20.05] GPT-3</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/bigbird/>[20.07] BigBird</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/roformer/>[21.04] RoFormer</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/vision-transformers-11>Vision Transformers (11)</a><button aria-label="展開側邊欄分類 'Vision Transformers (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/papers/intro>All Notes: 140 entries</a></ul></nav><button type=button title=收起側邊欄 aria-label=收起側邊欄 class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=頁面路徑><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label=主頁面 class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/papers/category/transformers-15><span itemprop=name>Transformers (15)</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>[17.06] Transformer</span><meta itemprop=position content=2></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">本頁導覽</button></div><div class="theme-doc-markdown markdown"><header><h1>[17.06] Transformer</h1></header>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=新世界的起點>新世界的起點<a href=#新世界的起點 class=hash-link aria-label=新世界的起點的直接連結 title=新世界的起點的直接連結>​</a></h2>
<p><a href=https://arxiv.org/abs/1706.03762 target=_blank rel="noopener noreferrer"><strong>Attention Is All You Need</strong></a></p>
<hr>
<p>有別於過去的時序列模型，Transformer 模型的提出，開啟了自注意力機制的新紀元。</p>
<p>這個模型不再依賴序列的遞歸計算，而是通過注意力機制來實現序列建模，使得模型的訓練和推理過程更加高效。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=定義問題>定義問題<a href=#定義問題 class=hash-link aria-label=定義問題的直接連結 title=定義問題的直接連結>​</a></h2>
<p>在過去的序列建模任務中，RNN 和 LSTM 模型是主流。</p>
<p>然而，這些模型在訓練和推理過程中存在著一些問題：</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=1-遞歸計算的限制>1. 遞歸計算的限制<a href=#1-遞歸計算的限制 class=hash-link aria-label="1. 遞歸計算的限制的直接連�結" title="1. 遞歸計算的限制的直接連結">​</a></h3>
<p>RNN 和 LSTM 模型在訓練過程中需要逐步計算序列中的每個元素，這導致了計算的串行化，使得模型難以進行高效的並行計算。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=2-長距離依賴問題>2. 長距離依賴問題<a href=#2-長距離依賴問題 class=hash-link aria-label="2. 長距離依賴問題的直接連結" title="2. 長距離依賴問題的直接連結">​</a></h3>
<p>由於 RNN 和 LSTM 模型的遞歸計算方式，導致了模型在處理長序列時，難以捕捉到序列中較遠位置的依賴關係。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=解決問題>解決問題<a href=#解決問題 class=hash-link aria-label=解決問題的直接連結 title=解決問題的直接連結>​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=模型設計>模型設計<a href=#模型設計 class=hash-link aria-label=模型設計的直接連結 title=模型設計的直接連結>​</a></h3>
<p><img decoding=async loading=lazy alt="Transformer 模型架構" src=/assets/images/img1-2fb089a5c6c4d595f9fca68049e2231f.jpg width=756 height=1080 class=img_ev3q></p>
<p>這是原始論文提供的 Transformer 模型架構示意圖。</p>
<p>雖然這個架構圖畫得非常簡潔（？？？），但大多數的人通常不會第一次就能理解它。</p>
<p>你別不信，這真的很簡潔了！</p>
<p>我們直接寫個簡單的程式碼，來看看這個模型的實際運作：</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=輸入層>輸入層<a href=#輸入層 class=hash-link aria-label=輸入層的直接連結 title=輸入層的直接連結>​</a></h3>
<p>這裡的輸入是一個時序列資料，為一個張量（Tensor）。</p>
<ul>
<li>第一個維度：批次大小（Batch Size），以下簡稱 <code>B</code>。</li>
<li>第二個維度：序列長度（Sequence Length），以下簡稱 <code>T</code>。</li>
<li>第三個維度：特徵維度（Feature Dimension），以下簡稱 <code>D</code>。</li>
</ul>
<p>首先來個簡單的例子：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">input_text </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> </span><span class="token punctuation" style=color:#393A34>[</span><span class="token string" style=color:#e3116c>'你'</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token string" style=color:#e3116c>'好'</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token string" style=color:#e3116c>'啊'</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token string" style=color:#e3116c>'。'</span><span class="token punctuation" style=color:#393A34>]</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">input_text_mapping </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> </span><span class="token punctuation" style=color:#393A34>{</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token string" style=color:#e3116c>'你'</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>0</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token string" style=color:#e3116c>'好'</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token string" style=color:#e3116c>'啊'</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token string" style=color:#e3116c>'。'</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>3</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token punctuation" style=color:#393A34>}</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>在這個例子中，輸入內容為：「你好啊。」，總共有 4 個字元。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p>這裡我們對整個訓練過程進行大量地簡化，僅僅是為了讓你更容易理解。</div></div>
<p>接著把這個輸入轉換成張量：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token keyword" style=color:#00009f>import</span><span class="token plain"> torch</span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>import</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">nn </span><span class="token keyword" style=color:#00009f>as</span><span class="token plain"> nn</span><br></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#393A34><span class="token plain">input_tensor </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">tensor</span><span class="token punctuation" style=color:#393A34>(</span><span class="token punctuation" style=color:#393A34>[</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    input_text_mapping</span><span class="token punctuation" style=color:#393A34>[</span><span class="token plain">token</span><span class="token punctuation" style=color:#393A34>]</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token keyword" style=color:#00009f>for</span><span class="token plain"> token </span><span class="token keyword" style=color:#00009f>in</span><span class="token plain"> input_text</span><span class="token punctuation" style=color:#393A34>]</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">input_tensor</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> tensor([0, 1, 2, 3])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>接著，我們把每個元素進行 Embedding。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">embedding </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">Embedding</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">num_embeddings</span><span class="token operator" style=color:#393A34>=</span><span class="token number" style=color:#36acaa>4</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> embedding_dim</span><span class="token operator" style=color:#393A34>=</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">embedded_input </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> embedding</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">input_tensor</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">embedded_input</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> tensor([[ 0.1,  0.2,  0.3,  ...,  0.4],</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic>#             [ 0.5,  0.6,  0.7,  ...,  0.8],</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic>#             [ 0.9,  1.0,  1.1,  ...,  1.2],</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic>#             [ 1.3,  1.4,  1.5,  ...,  1.6]])</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">embedded_input</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([4, 512])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>Embedding 不是什麼高深的技術，就是把每個元素投影到一個更高維度的空間，裡面只包含一個線性轉換層而已。</div></div>
<p>最後，別忘記我們需要的輸入是一個 3D 張量，所以我們需要再增加一個批次數量的維度，在這個例子中，批次數量為 1。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">embedded_input </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> embedded_input</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">unsqueeze</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>0</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">embedded_input</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 4, 512])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=位置編碼>位置編碼<a href=#位置編碼 class=hash-link aria-label=位置編碼的直接連結 title=位置編碼的直接連結>​</a></h3>
<p>在原始的 RNN 和 LSTM 模型中，模型可以通過序列中元素的位置來捕捉序列中的依賴關係。</p>
<p>所以我們不需要特別設計位置編碼，模型在每個 For-Loop 迭代中都隱含了位置信息。</p>
<p>但是在 Transformer 架構內並不具備這種隱含的位置信息，這裡有的只有線性轉換層。在線性轉換層中，每個元素都是獨立的，沒有任何關聯性，內部不帶有任何關聯資訊。因此，我們需要額外的位置編碼來幫助模型捕捉序列中的位置信息。</p>
<p>在本論文中，作者提出了一種簡單的位置編碼方式，即：使用正弦和餘弦函數來生成位置編碼：</p>
<p><img decoding=async loading=lazy alt=位置編碼公式 src=/assets/images/img2-cbe3382cb0317923940c18f68c30396a.jpg width=1036 height=180 class=img_ev3q></p>
<p>我們根據上面的公式，來實現一個位置編碼的函數：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token keyword" style=color:#00009f>import</span><span class="token plain"> math</span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>import</span><span class="token plain"> torch</span><br></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>def</span><span class="token plain"> </span><span class="token function" style=color:#d73a49>sinusoidal_positional_encoding</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">length</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> dim</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token triple-quoted-string string" style=color:#e3116c>""" Sinusoidal positional encoding for non-recurrent neural networks.</span><br></span><span class=token-line style=color:#393A34><span class="token triple-quoted-string string" style=color:#e3116c>        REFERENCES: Attention Is All You Need</span><br></span><span class=token-line style=color:#393A34><span class="token triple-quoted-string string" style=color:#e3116c>        URL: https://arxiv.org/abs/1706.03762</span><br></span><span class=token-line style=color:#393A34><span class="token triple-quoted-string string" style=color:#e3116c>    """</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token keyword" style=color:#00009f>if</span><span class="token plain"> dim </span><span class="token operator" style=color:#393A34>%</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>2</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>!=</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>0</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">        </span><span class="token keyword" style=color:#00009f>raise</span><span class="token plain"> ValueError</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">            </span><span class="token string" style=color:#e3116c>'Cannot use sin/cos positional encoding with '</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">            </span><span class="token string-interpolation string" style=color:#e3116c>f'odd dim (got dim=</span><span class="token string-interpolation interpolation punctuation" style=color:#393A34>{</span><span class="token string-interpolation interpolation">dim</span><span class="token string-interpolation interpolation punctuation" style=color:#393A34>}</span><span class="token string-interpolation string" style=color:#e3116c>)'</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token comment" style=color:#999988;font-style:italic># position embedding</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    pe </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">zeros</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">length</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> dim</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    position </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">arange</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>0</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> length</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">unsqueeze</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    div_term </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">exp</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">        </span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">arange</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>0</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> dim</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> dtype</span><span class="token operator" style=color:#393A34>=</span><span class="token plain">torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token builtin">float</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>*</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>-</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">math</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">log</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>10000.0</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>/</span><span class="token plain"> dim</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    pe</span><span class="token punctuation" style=color:#393A34>[</span><span class="token punctuation" style=color:#393A34>:</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>0</span><span class="token punctuation" style=color:#393A34>:</span><span class="token punctuation" style=color:#393A34>:</span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>]</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">sin</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">position</span><span class="token punctuation" style=color:#393A34>.</span><span class="token builtin">float</span><span class="token punctuation" style=color:#393A34>(</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>*</span><span class="token plain"> div_term</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    pe</span><span class="token punctuation" style=color:#393A34>[</span><span class="token punctuation" style=color:#393A34>:</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>:</span><span class="token punctuation" style=color:#393A34>:</span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>]</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">cos</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">position</span><span class="token punctuation" style=color:#393A34>.</span><span class="token builtin">float</span><span class="token punctuation" style=color:#393A34>(</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>*</span><span class="token plain"> div_term</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token keyword" style=color:#00009f>return</span><span class="token plain"> pe</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>這個函數同時考慮了序列的長度和特徵維度，給予每個位置一個固定的位置編碼。</p>
<p>我們把位置編碼可視化一下，假設序列長度為 256，特徵維度為 512：</p>
<div class="language-pytho codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-pytho codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">import cv2</span><br></span><span class=token-line style=color:#393A34><span class="token plain">import numpy as np</span><br></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#393A34><span class="token plain">pos_mask = sinusoidal_positional_encoding(256, 512)</span><br></span><span class=token-line style=color:#393A34><span class="token plain">pos_mask = pos_mask.numpy()</span><br></span><span class=token-line style=color:#393A34><span class="token plain">pos_mask = (pos_mask-pos_mask.max()) / (pos_mask.max()-pos_mask.min())</span><br></span><span class=token-line style=color:#393A34><span class="token plain">pos_mask = np.array(pos_mask * 255).astype(np.uint8)</span><br></span><span class=token-line style=color:#393A34><span class="token plain">pos_mask = cv2.applyColorMap(pos_mask, cv2.COLORMAP_JET)</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p><img decoding=async loading=lazy alt=位置編碼可視化 src=/assets/images/img3-033caff830afdc9ee3b7c37bff128b69.jpg width=1024 height=256 class=img_ev3q></p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p><strong>那個數學式中的 10000 是什麼？</strong><p>這個 10000 的物理意義可以被解釋為位置編碼的尺度。我們將位置編碼的尺度限制在一個合適的範圍內，以便它能夠有效地捕捉到不同位置之間的關係，同時避免了太高或太低的頻率造成的不良影響。<p>如果將位置編碼中的 10000 改為 100，將會改變正弦和餘弦函數的頻率，正弦和餘弦函數的頻率將增加，每個位置的位置編碼將在更短的距離內週期性地重複。這可能會導致模型對於較遠位置之間的關係感知能力下降，因為它們的位置編碼會顯示出更大的相似性。</div></div>
<p>得到位置編碼後，我們需要將它加到輸入的 Embedding 張量上：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">pos_emb </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> sinusoidal_positional_encoding</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>4</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">embedded_input </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> embedded_input </span><span class="token operator" style=color:#393A34>+</span><span class="token plain"> pos_emb</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=自注意力機制>自注意力機制<a href=#自注意力機制 class=hash-link aria-label=自注意力機制的直接連結 title=自注意力機制的直接連結>​</a></h3>
<p>取得輸入編碼後，我們就可以進入 Transformer 模型的核心部分：自注意力機制。</p>
<p>這裡需要準備三個轉換矩陣：</p>
<ol>
<li>
<p><strong>Query 矩陣 <code>W_q</code>。</strong></p>
<p>先宣告一組權重 <code>W_q</code>，然後把輸入的 Embedding 張量乘上 Query 矩陣，得到 Query 張量。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">W_q </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">query </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> W_q</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">embedded_input</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">query</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"> </span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 4, 512])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
</li>
<li>
<p><strong>Key 矩陣 <code>W_k</code>。</strong></p>
<p>同樣地，宣告一組權重 <code>W_k</code>，然後把輸入的 Embedding 張量乘上 Key 矩陣，得到 Key 張量。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">W_k </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">key </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> W_k</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">embedded_input</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">key</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 4, 512])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
</li>
<li>
<p><strong>Value 矩陣 <code>W_v</code>。</strong></p>
<p>最後，宣告一組權重 <code>W_v</code>，然後把輸入的 Embedding 張量乘上 Value 矩陣，得到 Value 張量。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">W_v </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">value </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> W_v</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">embedded_input</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">value</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 4, 512])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
</li>
</ol>
<p>所以這到底是在 QKV 個什麼玩意兒？</p>
<p>你可以想像轉換矩陣就是：投影。</p>
<p>所謂的投影，也就是「換個角度」看的意思。</p>
<p>剛才提到的 QKV 就是先把輸入進行三種不同的投影，然後再進行自注意力機制的運算。</p>
<hr>
<p>自注意力機制的第二步：計算關聯分數。</p>
<p><img decoding=async loading=lazy alt=自注意力機制 src=/assets/images/img4-e327434cd6cf917afa84de0cd0782f82.jpg width=1092 height=200 class=img_ev3q></p>
<p>在這一步中，將 Query 張量和 Key 張量進行點積運算。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">attn_maps </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">matmul</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">query</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> key</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">transpose</span><span class="token punctuation" style=color:#393A34>(</span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">attn_maps</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 4, 4])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>這樣我們就得到了一個注意力分數矩陣，大小為 4x4。</p>
<p>在這個例子中，就是要探討 [你, 好, 啊, 。] 這四個字元之間的關聯性。</p>
<p>你在公式中還會看到 <code>1/sqrt(d_k)</code>，這是為了對注意力分數進行縮放，以避免分數過大或過小。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">attn_maps </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> attn_maps </span><span class="token operator" style=color:#393A34>/</span><span class="token plain"> math</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">sqrt</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>接著是 Softmax 操作：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">attn_maps </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> F</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">softmax</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">attn_maps</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> dim</span><span class="token operator" style=color:#393A34>=</span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>)</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p><strong>為什麼用 Softmax？用 Sigmoid 也可以啊？</strong><p>這是因為 Softmax 函數可以將所有的注意力分數轉換為一個概率分佈，這樣可以保證所有的注意力分數總和為 1，這樣可以更好地對每個位置進行加權。此外，Softmax 函數中有競爭機制，可以讓模型更好地對不同位置進行區分。</div></div>
<p>算完注意力圖之後，我們就可以進行 Value 張量的加權求和：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">attn_output </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">matmul</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">attn_maps</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> value</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">attn_output</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 4, 512])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>最後進行殘差連接：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">attn_output </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> embedded_input </span><span class="token operator" style=color:#393A34>+</span><span class="token plain"> attn_output</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=多頭注意力機制>多頭注意力機制<a href=#多頭注意力機制 class=hash-link aria-label=多頭注意力機制的直接連結 title=多頭注意力機制的直接連結>​</a></h3>
<p>看完上面的章節，你下個問題可能就是：「這樣算出來每個位置的注意力只是一個，那如果我們想要多個注意力分數怎麼辦？」</p>
<p>這個問題作者也想到了，所以他們提出了<strong>多頭注意力機制</strong>。</p>
<p>在多頭注意力機制中，我們需要準備多組 QKV 矩陣，然後對每一組 QKV 矩陣進行自注意力機制的運算。</p>
<p><img decoding=async loading=lazy alt=多頭注意力機制 src=/assets/images/img5-6d96f0be8d115cecfdd7d74da29ce155.jpg width=1224 height=668 class=img_ev3q></p>
<p>雖然多頭的概念上是這樣，但是在真正的實作中，我們不會真的準備多組 QKV 矩陣，而是把原本 QKV 矩陣拆成多個子矩陣，然後對每個子矩陣進行自注意力機制的運算，像是這樣：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token comment" style=color:#999988;font-style:italic># Split into multiple heads</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">Q </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> Q</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">view</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">Q</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">size</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>0</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> Q</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">size</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> self</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">num_heads</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> self</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">head_dim</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">transpose</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">K </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> K</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">view</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">K</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">size</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>0</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> K</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">size</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> self</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">num_heads</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> self</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">head_dim</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">transpose</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">V </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> V</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">view</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">V</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">size</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>0</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> V</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">size</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> self</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">num_heads</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> self</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">head_dim</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">transpose</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>)</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>不過這個太工程了，也沒有新的概念，我們就不在這邊深入了。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=跨注意力機制>跨注意力機制<a href=#跨注意力機制 class=hash-link aria-label=跨注意力機制的直接連結 title=跨注意力機制的直接連結>​</a></h3>
<p>在 Transformer 架構中，Encoder 和 Decoder 之間的注意力機制類似，但有些地方不同。</p>
<p>在 Encoder 中，我們需要對序列中的每個位置進行自注意力機制的運算；在 Decoder 中，我們除了需要對序列中的每個位置進行自注意力機制的運算之外，同時還需要對 Encoder 的輸出進行注意力機制的運算，也就是所謂的<strong>跨注意力機制（Cross-Attention）</strong>。</p>
<p>所以 Decoder 包含了兩個部分：第一個部分是對於自己序列的自注意力機制，第二個部分是對 Encoder 輸出的跨注意力機制。自注意力剛才講過了，現在講一下跨注意力機制的計算。</p>
<p>這裡同樣需要準備三個轉換矩陣：</p>
<ol>
<li>
<p><strong>Query 矩陣 <code>W_q</code>。</strong></p>
<p>先宣告一組權重 <code>W_q</code>，把 Decoder 的輸入 Embedding 張量乘上 Query 矩陣，得到 Query 張量。其中 <code>decoder_input</code> 的長度，可以和 <code>encoder_output</code> 的長度不同，假設我們遇到的是翻譯的問題，這個長度可能為 10。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain"> W_q </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"> decoder_query </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> W_q</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">decoder_input</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"> </span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">decoder_query</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"> </span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 10, 512])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>這裡輸入為： <code>decoder_input</code>。</div></div>
</li>
<li>
<p><strong>Key 矩陣 <code>W_k</code>。</strong></p>
<p>同樣地，宣告一組權重 <code>W_k</code>，把 Encoder 的輸出 Embedding 張量乘上 Key 矩陣，得到 Key 張量。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain"> W_k </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"> encoder_key </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> W_k</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">encoder_output</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"> </span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">encoder_key</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"> </span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 4, 512])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>這裡輸入為： <code>encoder_input</code>。</div></div>
</li>
<li>
<p><strong>Value 矩陣 <code>W_v</code>。</strong></p>
<p>最後，宣告一組權重 <code>W_v</code>，把 Encoder 的輸出 Embedding 張量乘上 Value 矩陣，得到 Value 張量。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain"> W_v </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"> encoder_value </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> W_v</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">encoder_output</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"> </span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">encoder_value</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"> </span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 4, 512])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>這裡輸入為： <code>encoder_input</code>。</div></div>
</li>
</ol>
<p>後面的步驟和自注意力機制是一樣的，先算注意力圖：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">attn_maps </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">matmul</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">decoder_query</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> encoder_key</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">transpose</span><span class="token punctuation" style=color:#393A34>(</span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">attn_maps</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 10, 4])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>然後進行縮放和 Softmax：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">attn_maps </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> attn_maps </span><span class="token operator" style=color:#393A34>/</span><span class="token plain"> math</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">sqrt</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">attn_maps </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> F</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">softmax</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">attn_maps</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> dim</span><span class="token operator" style=color:#393A34>=</span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>)</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>最後進行 Value 張量的加權求和：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">attn_output </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">matmul</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">attn_maps</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> encoder_value</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">attn_maps</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 10, 4])</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">encoder_value</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 4, 512])</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">attn_output</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 10, 512])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p>在 Decoder 的自注意力階段，通常會加入遮罩操作，確保在解碼的過程中，不能看到未來的資訊。這個遮罩通常是一個上三角矩陣，這樣可以確保 Decoder 在解碼的過程中，只能看到已經生成的部分。<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token keyword" style=color:#00009f>def</span><span class="token plain"> </span><span class="token function" style=color:#d73a49>_generate_square_subsequent_mask</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    sz</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"> </span><span class="token builtin">int</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    device</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">device </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">device</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">_C</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">_get_default_device</span><span class="token punctuation" style=color:#393A34>(</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain">  </span><span class="token comment" style=color:#999988;font-style:italic># torch.device('cpu'),</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    dtype</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">dtype </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">get_default_dtype</span><span class="token punctuation" style=color:#393A34>(</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>-</span><span class="token operator" style=color:#393A34>></span><span class="token plain"> Tensor</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token triple-quoted-string string" style=color:#e3116c>r"""Generate a square causal mask for the sequence.</span><br></span><span class=token-line style=color:#393A34><span class="token triple-quoted-string string" style=display:inline-block;color:#e3116c></span><br></span><span class=token-line style=color:#393A34><span class="token triple-quoted-string string" style=color:#e3116c>    The masked positions are filled with float('-inf'). Unmasked positions are filled with float(0.0).</span><br></span><span class=token-line style=color:#393A34><span class="token triple-quoted-string string" style=color:#e3116c>    """</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token keyword" style=color:#00009f>return</span><span class="token plain"> torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">triu</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">        torch</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">full</span><span class="token punctuation" style=color:#393A34>(</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">sz</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> sz</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token builtin">float</span><span class="token punctuation" style=color:#393A34>(</span><span class="token string" style=color:#e3116c>'-inf'</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> dtype</span><span class="token operator" style=color:#393A34>=</span><span class="token plain">dtype</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> device</span><span class="token operator" style=color:#393A34>=</span><span class="token plain">device</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">        diagonal</span><span class="token operator" style=color:#393A34>=</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token punctuation" style=color:#393A34>)</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=feed-forward-網路>Feed-Forward 網路<a href=#feed-forward-網路 class=hash-link aria-label="Feed-Forward 網路的直接連結" title="Feed-Forward 網路的直接連結">​</a></h3>
<p>在經過自注意力機制之後，我們還需要經過一個簡單的 Feed-Forward 網路，來進行特徵的提取。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">ffn </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">Sequential</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>2048</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">ReLU</span><span class="token punctuation" style=color:#393A34>(</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">Linear</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>2048</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">ffn_output </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> ffn</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">attn_output</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">output </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> attn_output </span><span class="token operator" style=color:#393A34>+</span><span class="token plain"> ffn_output</span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">output</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">shape</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># >>> torch.Size([1, 4, 512])</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>這個 Feed-Forward 網路就是一個典型的全連接網路，這裡我們使用了兩層全連接層，中間加了一個 ReLU 啟動函數。</p>
<p>此外，模組中間有一個 Expand-Dim 操作，通常這個膨脹係數為 4，這個操作和之後 MobileNet-V2 所提出的 Inverted Residual Bottleneck Block 是類似的概念，主要目的都是透過膨脹維度再壓縮的方式，來提高模型的非線性表達能力。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=layer-normalization>Layer Normalization<a href=#layer-normalization class=hash-link aria-label="Layer Normalization的直接連結" title="Layer Normalization的直接連結">​</a></h3>
<p>我們剛才都沒有提到 <code>LayerNorm</code>。</p>
<p>因為這個操作沒有太難的地方，在你了解了上面的所有操作之後，這裡就是幾句話的事情。</p>
<p>在剛才的每個步驟中，我們應該對每個輸出進行 <code>LayerNorm</code>。這裡其實還可以區分 Norm-First 和 Norm-Last，這個取決於你的模型架構，之後遇到其他論文的時候，我們再來討論這個問題。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">norm1 </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">LayerNorm</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">attn_output </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> norm1</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">embedded_input </span><span class="token operator" style=color:#393A34>+</span><span class="token plain"> attn_output</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># ...</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#393A34><span class="token plain">norm2 </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> nn</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">LayerNorm</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>512</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">output </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> norm2</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">attn_output </span><span class="token operator" style=color:#393A34>+</span><span class="token plain"> ffn_output</span><span class="token punctuation" style=color:#393A34>)</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p><strong>為什麼不用 Batch Normalization？</strong><p>序列資料更多會依賴於本身的特性，而不是來自於批次資料的特性。因此在這裡使用 LayerNorm 會比 BatchNorm 更加適合。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=討論>討論<a href=#討論 class=hash-link aria-label=討論的直接連結 title=討論的直接連結>​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=為什麼要用自注意力機制>為什麼要用自注意力機制？<a href=#為什麼要用自注意力機制 class=hash-link aria-label=為什麼要用自注意力機制？的直接連結 title=為什麼要用自注意力機制？的直接連結>​</a></h3>
<p><img decoding=async loading=lazy alt=Attention src=/assets/images/img6-704528b56ee6c919f91f628dacf509df.jpg width=1224 height=400 class=img_ev3q></p>
<p>簡單來說，就是快。</p>
<hr>
<p>作者彙整 RNN、CNN 和 Self-Attention 的計算複雜度，如上圖所示。</p>
<ol>
<li>
<p><strong>自注意力層（無限制）</strong>：</p>
<ul>
<li><strong>每層複雜度： O(n^2·d)</strong>：在自注意力機制中，每個輸入的 Token（序列長度為 n）都需要與其他所有的 Token 進行注意力計算，形成一個 ( n * n ) 的完整注意力矩陣。每個矩陣元素都需要進行基於 (d) 維嵌入的計算，因此整個注意力矩陣的計算複雜度為 O(n^2·d)。</li>
<li><strong>順序運算：O(1)</strong>：完整的注意力矩陣可以並行計算，所有的比較可以同時進行。</li>
<li><strong>最大路徑長度：O(1)</strong>：由於每個 token 都可以通過注意力機制直接與其他任何 Token 互相聯繫，因此最大路徑長度僅為一步。</li>
</ul>
</li>
<li>
<p><strong>RNN</strong>：</p>
<ul>
<li><strong>每層複雜度：O(n·d^2)</strong>：循環層需要按順序處理每個 Token。每個 Token 的計算需要結合目前的 Token 嵌入（d 維）和隱藏狀態（同樣是 d 維），因此操作成本為 O(d^2) 。由於需要處理 n 個 Token，總體複雜度為 O(n·d^2)。</li>
<li><strong>順序運算：O(n)</strong>：由於 RNN 的順序特性，每個 Token 需要等待前一個 Token 的計算完成才能處理下一個。</li>
<li><strong>最大路徑長度：O(n)</strong>：在 RNN 中，兩個 Token 之間的路徑長度需要通過所有位於它們之間的中間 Token。</li>
</ul>
</li>
<li>
<p><strong>CNN</strong>：</p>
<ul>
<li><strong>每層複雜度：O(k·n·d^2)</strong>：在卷積層中，寬度為 k 的卷積核會在整個序列上滑動以計算局部特徵。每 n 個 Token 都需要在 d 維嵌入上進行計算，每次卷積操作的成本與 d^2 成正比。因此，總體複雜度為 O(k·n·d^2)。</li>
<li><strong>順序運算：O(1)</strong>：每個卷積濾波器可以同時應用於整個序列。</li>
<li><strong>最大路徑長度：O(log_k(n))</strong>：透過堆疊具有膨脹效果的卷積層，網路可以按 k 的對數方式連接較遠的 Token。</li>
</ul>
</li>
<li>
<p><strong>限制型自注意力層</strong>：</p>
<ul>
<li><strong>每層複雜度：O(r·n·d)</strong>：在這種情況下，每個 Token 只能關注一個大小為 r 的鄰域。注意力矩陣的大小變為 (n·r)，但每個矩陣元素依然需要進行基於 d 維嵌入的計算，總體複雜度為 O(r·n·d)。</li>
<li><strong>順序運算：O(1)</strong>：與無限制的自注意力層相似，所有比較可以同時進行。</li>
<li><strong>最大路徑長度：O(n/r)</strong>：由於每個 Token 只能關注到較小的鄰域，因此兩個距離較遠的 Token 之間的路徑長度增加至 O(n/r)。</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=實驗結果機器翻譯>實驗結果：機器翻譯<a href=#實驗結果機器翻譯 class=hash-link aria-label=實驗結果：機器翻譯的直接連結 title=實驗結果：機器翻譯的直接連結>​</a></h3>
<p><img decoding=async loading=lazy alt=機器翻譯結果 src=/assets/images/img7-b159f5ad9d164a16131418d0142b8972.jpg width=1224 height=564 class=img_ev3q></p>
<p>在 WMT 2014 英德翻譯任務中，Transformer (big) 相比於先前最佳的模型（包括集成模型）提高了 2.0 以上的 BLEU 分數，創造了新的 28.4 分的 BLEU 記錄。此模型訓練耗時 3.5 天，使用 8 塊 P100 GPU。即便是基礎模型，也在訓練成本遠低於其他競爭對手的前提下超越了所有先前發表的模型及集成模型。</p>
<p>在 WMT 2014 英法翻譯任務中，Transformer (big) 取得了 41.0 的 BLEU 分數，在訓練成本僅為先前最佳模型的四分之一的情況下，仍然優於所有已發表的單一模型。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=結論>結論<a href=#結論 class=hash-link aria-label=結論的直接連結 title=結論的直接連結>​</a></h2>
<p>Transformer 是個跨時代的架構，它的提出不僅解決了 RNN 和 LSTM 模型的一些問題，同時也提高了模型的訓練和推理效率。</p>
<p>這個架構在一開始被提出時，其實沒有造成太大的波瀾。</p>
<p>雖然 Transformer 在學術圈內持續不斷而且熱烈地討論了好幾年，從自然語言到電腦視覺領域內人盡皆知。反觀工業界的人們可能只有工程師和研究員會關心這個議題。</p>
<hr>
<p>但是，當 OpenAI 的 ChatGPT 問世之後，這個世界就不一樣了。</p>
<p>對。</p>
<p>一切都不一樣了。</div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>最後<!-- -->由 <b>zephyr-sh</b> <!-- -->於 <b><time datetime=2024-10-11T08:45:49.000Z itemprop=dateModified>2024年10月11日</time></b> <!-- -->更新</span></div></div></footer><div style=margin-top:3rem> </div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label=文件選項卡><a class="pagination-nav__link pagination-nav__link--prev" href=/papers/category/transformers-15><div class=pagination-nav__sublabel>上一頁</div><div class=pagination-nav__label>Transformers (15)</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/papers/transformers/gpt_1/><div class=pagination-nav__sublabel>下一頁</div><div class=pagination-nav__label>[18.06] GPT-1</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#新世界的起點 class="table-of-contents__link toc-highlight">新世界的起點</a><li><a href=#定義問題 class="table-of-contents__link toc-highlight">定義問題</a><ul><li><a href=#1-遞歸計算的限制 class="table-of-contents__link toc-highlight">1. 遞歸計算的限制</a><li><a href=#2-長距離依賴問題 class="table-of-contents__link toc-highlight">2. 長距離依賴問題</a></ul><li><a href=#解決問題 class="table-of-contents__link toc-highlight">解決問題</a><ul><li><a href=#模型設計 class="table-of-contents__link toc-highlight">模型設計</a><li><a href=#輸入層 class="table-of-contents__link toc-highlight">輸入層</a><li><a href=#位置編碼 class="table-of-contents__link toc-highlight">位置編碼</a><li><a href=#自注意力機制 class="table-of-contents__link toc-highlight">自注意力機制</a><li><a href=#多頭注意力機制 class="table-of-contents__link toc-highlight">多頭注意力機制</a><li><a href=#跨注意力機制 class="table-of-contents__link toc-highlight">跨注意力機制</a><li><a href=#feed-forward-網路 class="table-of-contents__link toc-highlight">Feed-Forward 網路</a><li><a href=#layer-normalization class="table-of-contents__link toc-highlight">Layer Normalization</a></ul><li><a href=#討論 class="table-of-contents__link toc-highlight">討論</a><ul><li><a href=#為什麼要用自注意力機制 class="table-of-contents__link toc-highlight">為什麼要用自注意力機制？</a><li><a href=#實驗結果機器翻譯 class="table-of-contents__link toc-highlight">實驗結果：機器翻譯</a></ul><li><a href=#結論 class="table-of-contents__link toc-highlight">結論</a></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/docs>開源專案</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/papers/intro>論文筆記</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/blog>部落格</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/terms-of-service>使用條款</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/privacy-policy>隱私政策</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/worklog>工作日誌</a><span class=footer__link-separator>·</span><a href=https://buymeacoffee.com/zephyr_docsaid target=_blank rel="noopener noreferrer" class=footer__link-item>支持我們<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>