<!doctype html><html lang=zh-hant dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-transformers/bigbird/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.6.3"><title data-rh=true>[20.07] BigBird | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width,initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/papers/transformers/bigbird/><meta data-rh=true property=og:locale content=zh_hant><meta data-rh=true property=og:locale:alternate content=en><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=zh-hant><meta data-rh=true name=docsearch:language content=zh-hant><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[20.07] BigBird | DOCSAID"><meta data-rh=true name=description content=大鳥注意力機制><meta data-rh=true property=og:description content=大鳥注意力機制><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/papers/transformers/bigbird/><link data-rh=true rel=alternate href=https://docsaid.org/papers/transformers/bigbird/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/transformers/bigbird/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/transformers/bigbird/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/transformers/bigbird/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin><link rel=stylesheet href=/assets/css/styles.857e8899.css><script src=/assets/js/main.6cd2601f.js defer></script><script src=/assets/js/runtime~main.b7003113.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label=跳至主要内容><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>跳至主要内容</a></div><nav aria-label=主導航 class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class=navbar__inner><div class=navbar__items><button aria-label=切換導覽列 aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><div class=navbar__logo><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/docs/>開源專案</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/papers/intro>論文筆記</a><a class="navbar__item navbar__link" href=/blog>部落格</a><a class="navbar__item navbar__link" href=/playground/intro>遊樂場</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>繁體中文</a><ul class=dropdown__menu><li><a href=/papers/transformers/bigbird/ rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=zh-hant>繁體中文</a><li><a href=/en/papers/transformers/bigbird/ rel="noopener noreferrer" class=dropdown__link lang=en>English</a><li><a href=/ja/papers/transformers/bigbird/ rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><a href=https://buymeacoffee.com/zephyr_docsaid target=_blank rel="noopener noreferrer" class="navbar__item navbar__link">支持我們<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a><a href=https://github.com/DocsaidLab target=_blank rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type=button disabled title=切換淺色/深色模式（當前為淺色模式） aria-label=切換淺色/深色模式（當前為淺色模式） aria-live=polite aria-pressed=false><svg viewBox="0 0 24 24" width=24 height=24 class=lightToggleIcon_pyhR><path fill=currentColor d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"/></svg><svg viewBox="0 0 24 24" width=24 height=24 class=darkToggleIcon_wfgR><path fill=currentColor d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"/></svg></button></div><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="搜尋 (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>搜尋</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label=回到頂部 class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label=文件側邊欄 class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/papers/intro>論文筆記</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="展開側邊欄分類 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/face-anti-spoofing-1>Face Anti-Spoofing (1)</a><button aria-label="展開側邊欄分類 'Face Anti-Spoofing (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="展開側邊欄分類 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/feature-fusion-7>Feature Fusion (7)</a><button aria-label="展開側邊欄分類 'Feature Fusion (7)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="展開側邊欄分類 'Lightweight (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/mamba-1>Mamba (1)</a><button aria-label="展開側邊欄分類 'Mamba (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/model-tuning-8>Model Tuning (8)</a><button aria-label="展開側邊欄分類 'Model Tuning (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/multimodality-22>Multimodality (22)</a><button aria-label="展開側邊欄分類 'Multimodality (22)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/normalization-1>Normalization (1)</a><button aria-label="展開側邊欄分類 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/object-detection-8>Object Detection (8)</a><button aria-label="展開側邊欄分類 'Object Detection (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/reparameterization-7>Reparameterization (7)</a><button aria-label="展開側邊欄分類 'Reparameterization (7)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="展開側邊欄分類 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-detection-11>Text Detection (11)</a><button aria-label="展開側邊欄分類 'Text Detection (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="展開側邊欄分類 'Text Recognition (20)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="展開側邊欄分類 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/papers/category/transformers-15>Transformers (15)</a><button aria-label="收起側邊欄分類 'Transformers (15)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/transformer/>[17.06] Transformer</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/gpt_1/>[18.06] GPT-1</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/bert/>[18.10] BERT</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/transformer-xl/>[19.01] Transformer-XL</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/gpt_2/>[19.02] GPT-2</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/sparse-transformer/>[19.04] Sparse Transformer</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/xlnet/>[19.06] XLNet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/roberta/>[19.07] RoBERTa</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/albert/>[19.09] ALBERT</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/mqa/>[19.11] MQA</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/scaling_laws/>[20.01] Scaling Laws</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/longformer/>[20.04] Longformer</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/gpt_3/>[20.05] GPT-3</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/papers/transformers/bigbird/>[20.07] BigBird</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/transformers/roformer/>[21.04] RoFormer</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/vision-transformers-11>Vision Transformers (11)</a><button aria-label="展開側邊欄分類 'Vision Transformers (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/papers/intro>All Notes: 142 entries</a></ul></nav><button type=button title=收起側邊欄 aria-label=收起側邊欄 class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=頁面路徑><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label=主頁面 class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/papers/category/transformers-15><span itemprop=name>Transformers (15)</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>[20.07] BigBird</span><meta itemprop=position content=2></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">本頁導覽</button></div><div class="theme-doc-markdown markdown"><header><h1>[20.07] BigBird</h1></header>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=大鳥注意力機制>大鳥注意力機制<a href=#大鳥注意力機制 class=hash-link aria-label=大鳥注意力機制的直接連結 title=大鳥注意力機制的直接連結>​</a></h2>
<p><a href=https://arxiv.org/abs/2007.14062 target=_blank rel="noopener noreferrer"><strong>Big Bird: Transformers for Longer Sequences</strong></a></p>
<hr>
<p>Transformer 的自注意力機制的計算複雜度為 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>O</mi><mo stretchy=false>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>O(n^2)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0641em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.02778em>O</span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">n</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8141em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>。</p>
<p>當任何一個演算法的計算複雜度出現這種情況時，都意味著其中有非常大量的優化空間。</p>
<p>恩？怎麼又是這個開頭？</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=定義問題>定義問題<a href=#定義問題 class=hash-link aria-label=定義問題的直接連結 title=定義問題的直接連結>​</a></h2>
<p>Transformer 模型，如 BERT，在各種自然語言處理任務中表現優異，主要由於自注意力機制的並行計算能力和現代硬體的支援。但是該機制帶來的計算和記憶體需求是序列長度的平方，這限制了其在需要較長上下文的任務中的直接應用。</p>
<p>在 <strong>Longformer</strong> 提出後不久，Google Brain 團隊也提出了 BigBird，這是一種專為處理長序列而設計的 Transformer 變體。</p>
<ul>
<li><a href=/papers/transformers/longformer/><strong>Longformer: 長注意力機制</strong></a></li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=基礎理論不足>基礎理論不足<a href=#基礎理論不足 class=hash-link aria-label=基礎理論不足的直接連結 title=基礎理論不足的直接連結>​</a></h3>
<p>除此之外，作者認為過去的研究都是啟發式的研究，並未提供對自注意力模型的理論分析。他們指出，過去的研究對自注意力模型的表現關鍵因素和表達能力理解不足。儘管過去已有研究顯示 Transformer 具有圖靈完備性，但在減少計算複雜度的同時是否能維持這種能力仍不清楚。</p>
<p>基於上述動機，作者提出了 BigBird 模型，透過稀疏注意力機制在長序列任務上實現了優異的性能，同時保持了理論上的表達能力。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>圖靈完備性是指一個系統具備與圖靈機相同的運算能力，能夠模擬任何可計算的任務。<p>這意味著圖靈完備的系統可以執行任何演算法或電腦程序，理論上具備無限的計算潛力，只要有足夠的時間和資源。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=解決問題>解決問題<a href=#解決問題 class=hash-link aria-label=解決問題的直接連結 title=解決問題的直接連結>​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=模型架構>模型架構<a href=#模型架構 class=hash-link aria-label=模型架構的直接連結 title=模型架構的直接連結>​</a></h3>
<p><img decoding=async loading=lazy alt="BigBird Architecture" src=/assets/images/img1-88b7491685393d09b10d279836ff6397.jpg width=1584 height=434 class=img_ev3q></p>
<p>這篇論文的概念很簡單，同樣是看到這張圖就差不多了。</p>
<p>在 BigBird 的架構中，作者設計了三種元件，最終組成稀疏架構：</p>
<ul>
<li>上圖 (a) 是隨機注意力機制，在模型的每個層內的 Token 之間隨機建立連接。</li>
<li>上圖 (b) 是 Sliding Window Attention，每個 Token 只關注到前後固定範圍內的 Token。</li>
<li>上圖 (c) 是 Global Attention，特定的 Token 會關注到所有其他 Token；同時，其他 Token 也會關注到這個 Token。</li>
<li>上圖 (d) 是把上述三種機制組合起來，形成 BigBird 的注意力機制。</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=架構設計>架構設計<a href=#架構設計 class=hash-link aria-label=架構設計的直接連結 title=架構設計的直接連結>​</a></h3>
<p>作者設計了兩種不同的全域令牌選擇方式，在後續實驗中進行比較：</p>
<ul>
<li>
<p><strong>BIGBIRD-ITC（內部 Transformer 構造）</strong></p>
<ul>
<li><strong>全域令牌的選擇</strong>：在這種設計中，某些已存在的令牌被指定為“全域”令牌。這意味著這些令牌將能關注整個序列中的所有其他令牌。</li>
<li><strong>矩陣表示</strong>：對於選定為全域的令牌索引集合 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>G</mi></mrow><annotation encoding=application/x-tex>G</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">G</span></span></span></span>，對應的鄰接矩陣 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=application/x-tex>A</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">A</span></span></span></span> 被調整，使得每個全域令牌 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span> 在 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=application/x-tex>A</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">A</span></span></span></span> 中的行和列的所有元素都設為 1（即 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>A</mi><mo stretchy=false>(</mo><mi>i</mi><mo separator=true>,</mo><mo>:</mo><mo stretchy=false>)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>A(i, :) = 1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">A</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>:</span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span></span></span></span> 和 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>A</mi><mo stretchy=false>(</mo><mo>:</mo><mo separator=true>,</mo><mi>i</mi><mo stretchy=false>)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>A(:, i) = 1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">A</span><span class=mopen>(</span><span class=mrel>:</span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">i</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span></span></span></span>），這表示這些令牌可以與序列中的所有其他令牌進行互動。</li>
</ul>
</li>
<li>
<p><strong>BIGBIRD-ETC（擴展 Transformer 構造）</strong></p>
<ul>
<li><strong>額外的全域令牌</strong>：與 ITC 不同，ETC 設計引入了額外的全域令牌（例如 CLS 令牌），這些令牌專門設計來關注所有已存在的令牌。</li>
<li><strong>矩陣擴展</strong>：為了包括這些額外的全域令牌，原有的鄰接矩陣 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=application/x-tex>A</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">A</span></span></span></span> 被擴展成新的矩陣 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>B</mi></mrow><annotation encoding=application/x-tex>B</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span></span></span></span>。向 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=application/x-tex>A</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">A</span></span></span></span> 添加 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>g</mi></mrow><annotation encoding=application/x-tex>g</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>g</span></span></span></span> 行，使得新矩陣 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>B</mi></mrow><annotation encoding=application/x-tex>B</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span></span></span></span> 在這 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>g</mi></mrow><annotation encoding=application/x-tex>g</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>g</span></span></span></span> 行的所有元素設為 1（即 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>B</mi><mo stretchy=false>(</mo><mi>i</mi><mo separator=true>,</mo><mo>:</mo><mo stretchy=false>)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>B(i, :) = 1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>:</span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span></span></span></span>），並且在這些行對應的列也設為 1（即 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>B</mi><mo stretchy=false>(</mo><mo>:</mo><mo separator=true>,</mo><mi>i</mi><mo stretchy=false>)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>B(:, i) = 1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span><span class=mopen>(</span><span class=mrel>:</span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">i</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span></span></span></span>），其中 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span> 是全域令牌的索引。這樣，新的全域令牌就能夠關注整個序列。</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=證明之前>證明之前<a href=#證明之前 class=hash-link aria-label=證明之前的直接連結 title=證明之前的直接連結>​</a></h3>
<p>以下開始就是本論文中最艱澀的部分，作者開始證明 BigBird 的理論性質，並說明為什麼要採用「隨機注意力機制」。</p>
<p>雖然我們直接拿結論來用也無不可，但既然都來了，那就稍微看一下吧。</p>
<p>在證明之前，先看一下作者對於自注意力機制的理論描述：</p>
<ol>
<li>
<p><strong>廣義注意力機制</strong></p>
<ul>
<li>BigBird 模型使用了廣義注意力機制，這在每層的 Transformer 中對序列 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy=false>(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>X = (x_1, \ldots, x_n)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span> 進行處理。</li>
<li>注意力機制是透過有向圖 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>D</mi></mrow><annotation encoding=application/x-tex>D</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span></span></span></span> 描述，圖中的節點集為 <span class=katex><span class=katex-mathml><math><semantics><mrow><mo stretchy=false>[</mo><mi>n</mi><mo stretchy=false>]</mo><mo>=</mo><mo stretchy=false>{</mo><mn>1</mn><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><mi>n</mi><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>[n] = \{1, \ldots, n\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>[</span><span class="mord mathnormal">n</span><span class=mclose>]</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord>1</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">n</span><span class=mclose>}</span></span></span></span>，有向邊代表將被考慮的內積集合。</li>
</ul>
</li>
<li>
<p><strong>注意力輸出向量</strong></p>
<ul>
<li>對於圖中的每個節點 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>，產生的輸出向量 <span class=katex><span class=katex-mathml><math><semantics><mrow><mtext>ATTND</mtext><mo stretchy=false>(</mo><mi>X</mi><msub><mo stretchy=false>)</mo><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\text{ATTND}(X)_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>ATTND</span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=mclose><span class=mclose>)</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 由節點 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span> 和它的外鄰居 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>N</mi><mo stretchy=false>(</mo><mi>i</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>N(i)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mclose>)</span></span></span></span> 計算而來。</li>
<li>具體計算方式為 <span class=katex><span class=katex-mathml><math><semantics><mrow><msub><mtext>ATTN</mtext><mi>D</mi></msub><mo stretchy=false>(</mo><mi>X</mi><msub><mo stretchy=false>)</mo><mi>i</mi></msub><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><msubsup><mo>∑</mo><mrow><mi>h</mi><mo>=</mo><mn>1</mn></mrow><mi>H</mi></msubsup><mi>σ</mi><mrow><mo fence=true>(</mo><msub><mi>Q</mi><mi>h</mi></msub><mo stretchy=false>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=false>)</mo><msub><mi>K</mi><mi>h</mi></msub><mo stretchy=false>(</mo><msub><mi>X</mi><mrow><mi>N</mi><mo stretchy=false>(</mo><mi>i</mi><mo stretchy=false>)</mo></mrow></msub><msup><mo stretchy=false>)</mo><mi>T</mi></msup><mo fence=true>)</mo></mrow><mo>⋅</mo><msub><mi>V</mi><mi>h</mi></msub><mo stretchy=false>(</mo><msub><mi>X</mi><mrow><mi>N</mi><mo stretchy=false>(</mo><mi>i</mi><mo stretchy=false>)</mo></mrow></msub><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\text{ATTN}_{D}(X)_i = x_i + \sum_{h=1}^H \sigma \left(Q_h(x_i) K_h(X_{N(i)})^T\right) \cdot V_h(X_{N(i)})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord text"><span class=mord>ATTN</span></span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>D</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=mclose><span class=mclose>)</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.7333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.3364em;vertical-align:-0.3552em></span><span class=mop><span class="mop op-symbol small-op" style=position:relative;top:0em>∑</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.9812em><span style=top:-2.4003em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.2029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.08125em>H</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2997em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.03588em>σ</span><span class=mspace style=margin-right:0.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0em><span class="delimsizing size1">(</span></span><span class=mord><span class="mord mathnormal">Q</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>K</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3448em><span style=top:-2.5198em;margin-left:-0.0785em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.10903em>N</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3552em><span></span></span></span></span></span></span><span class=mclose><span class=mclose>)</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0em><span class="delimsizing size1">)</span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.1052em;vertical-align:-0.3552em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.22222em>V</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.2222em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3448em><span style=top:-2.5198em;margin-left:-0.0785em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.10903em>N</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3552em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>。</li>
<li><span class=katex><span class=katex-mathml><math><semantics><mrow><msub><mi>Q</mi><mi>h</mi></msub><mo separator=true>,</mo><msub><mi>K</mi><mi>h</mi></msub><mo separator=true>,</mo><msub><mi>V</mi><mi>h</mi></msub></mrow><annotation encoding=application/x-tex>Q_h, K_h, V_h</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8778em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal">Q</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>K</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.22222em>V</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.2222em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 分別為查詢、關鍵、值函數，將 <span class=katex><span class=katex-mathml><math><semantics><mrow><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding=application/x-tex>R^d</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8491em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.00773em>R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8491em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span> 映射到不同的空間。</li>
<li><span class=katex><span class=katex-mathml><math><semantics><mrow><mi>σ</mi></mrow><annotation encoding=application/x-tex>\sigma</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal" style=margin-right:0.03588em>σ</span></span></span></span> 是評分函數，如 softmax 或 hardmax。</li>
<li><span class=katex><span class=katex-mathml><math><semantics><mrow><mi>H</mi></mrow><annotation encoding=application/x-tex>H</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.08125em>H</span></span></span></span> 為頭數量。</li>
</ul>
</li>
<li>
<p><strong>全連接圖和稀疏化</strong>：</p>
<ul>
<li>如果 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>D</mi></mrow><annotation encoding=application/x-tex>D</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span></span></span></span> 是一個完全的有向圖，則恢復為 Vaswani 等人描述的完全二次注意力機制。</li>
<li>圖 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>D</mi></mrow><annotation encoding=application/x-tex>D</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span></span></span></span> 的稀疏化是通過節點間選取一定數量的隨機邊來實現，降低計算複雜度。</li>
</ul>
</li>
<li>
<p><strong>稀疏隨機圖</strong>：</p>
</li>
</ol>
<ul>
<li>利用隨機圖的概念來近似完整圖，這些圖在譜屬性上與完整圖相似，可以作為擴展器。</li>
<li>使用最簡單的 Erdos-Rényi 模型，其中每條邊都是獨立以固定機率選擇的。</li>
</ul>
<ol start=5>
<li><strong>局部性和滑動視窗</strong>：</li>
</ol>
<ul>
<li>考慮到在大多數 NLP 和計算生物學的背景中，大量的參考資訊表現出局部性，即從鄰近的令牌中提取信息。</li>
<li>BigBird 模型中使用滑動視窗注意力機制，以應對這種局部性。</li>
</ul>
<ol start=6>
<li><strong>全域令牌的使用</strong>：</li>
</ol>
<ul>
<li>引入全域令牌來模擬涉及序列中所有令牌的情況，這些令牌在注意力計算中扮演關鍵角色，它們會參與到整個序列的處理中。</li>
</ul>
<hr>
<p>上面這一段其實沒有新東西，只是透過這段描述，說明了原始的注意力機制其實就是廣義注意力機制中的「特例」。</p>
<p>這個「特例」就是完全有向圖，所以當你開始調整注意力圖為「特製」的有向圖時，就意味著走進稀疏注意力機制的領域。</p>
<p>另外，這裡也說明了為什麼會採用隨機注意力機制：</p>
<ul>
<li>因為我們需要「近似」完整圖。</li>
</ul>
<p>利用隨機圖的概念來近似完整圖，這些圖在譜屬性上與完整圖相似，可以作為擴展器。在這邊，作者使用最簡單的 Erdos-Rényi 模型，其中每條邊都是獨立以固定機率選擇的。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>如果你有做過圖卷積神經網路（GCN）或其他圖神經網路的相關研究，這裡可以對比一下，圖卷積中的「節點」指的就是這裡的 Token；「邊」指的就是這裡的注意力連接；「鄰接矩陣」指的就是這裡的注意力圖。<p>圖卷積的技術為什麼在注意力機制提出後就不再流行了？因為注意力機制其實就是更通用的圖卷積，不僅堆疊深度更簡單，而且更容易訓練。</div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=開始證明>開始證明<a href=#開始證明 class=hash-link aria-label=開始證明的直接連結 title=開始證明的直接連結>​</a></h3>
<p>Transformer 的編碼器堆疊本質上是一系列重複的單層編碼器，每個編碼器都有自己的一套參數。</p>
<p>這種結構允許通過多個階段處理輸入數據，每一層都在前一層的輸出基礎上進一步轉換數據。</p>
<ul>
<li>
<p><strong>參數化</strong>：</p>
<ul>
<li><strong>H</strong>：每個編碼器層中的注意力頭數量。</li>
<li><strong>m</strong>：每個注意力頭的大小。</li>
<li><strong>q</strong>：輸出網路中隱藏層的大小。</li>
</ul>
</li>
<li>
<p><strong>注意力機制</strong>：</p>
<ul>
<li>由有向圖 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>D</mi></mrow><annotation encoding=application/x-tex>D</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span></span></span></span> 定義。與傳統的注意力機制（例如 Vaswani 等人提出的）不同，這種配置在每個序列的開始添加了一個特殊的標記，記為 <span class=katex><span class=katex-mathml><math><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=application/x-tex>x_0</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>。這個標記可以用於各種目的，如代表序列的聚合信息或處理特定的上下文需求。圖 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>D</mi></mrow><annotation encoding=application/x-tex>D</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span></span></span></span> 的頂點集包括這個特殊標記，即 <span class=katex><span class=katex-mathml><math><semantics><mrow><mo stretchy=false>{</mo><mn>0</mn><mo stretchy=false>}</mo><mo>∪</mo><mo stretchy=false>[</mo><mi>n</mi><mo stretchy=false>]</mo><mo>=</mo><mo stretchy=false>{</mo><mn>0</mn><mo separator=true>,</mo><mn>1</mn><mo separator=true>,</mo><mn>2</mn><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><mi>n</mi><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>\{0\} \cup [n] = \{0, 1, 2, \ldots, n\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord>0</span><span class=mclose>}</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>∪</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>[</span><span class="mord mathnormal">n</span><span class=mclose>]</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord>0</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>1</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>2</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">n</span><span class=mclose>}</span></span></span></span>。</li>
</ul>
</li>
<li>
<p><strong>輸入和輸出處理</strong>：</p>
<ul>
<li>儘管在開始時添加了額外的節點 <span class=katex><span class=katex-mathml><math><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=application/x-tex>x_0</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>， Transformer 被概念化為將序列從 <span class=katex><span class=katex-mathml><math><semantics><mrow><msup><mi mathvariant=double-struck>R</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding=application/x-tex>\mathbb{R}^{n \times d}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8491em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8491em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span> 映射到 <span class=katex><span class=katex-mathml><math><semantics><mrow><msup><mi mathvariant=double-struck>R</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding=application/x-tex>\mathbb{R}^{n \times d}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8491em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8491em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>。</li>
<li>在最終輸出層，假設將額外的節點及其向量丟棄，確保輸出的維度與輸入匹配。</li>
<li>在輸入矩陣 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>X</mi></mrow><annotation encoding=application/x-tex>X</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07847em>X</span></span></span></span> 中追加位置嵌入 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>E</mi><mo>∈</mo><msup><mi mathvariant=double-struck>R</mi><mrow><mi>d</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding=application/x-tex>E \in \mathbb{R}^{d \times n}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7224em;vertical-align:-0.0391em></span><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8491em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8491em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>，增強模型基於元素在序列中的位置解釋序列數據的能力。</li>
</ul>
</li>
<li>
<p><strong>通用近似</strong>：</p>
<ul>
<li>
<p>函數類 <span class=katex><span class=katex-mathml><math><semantics><mrow><mtext>FCD</mtext></mrow><annotation encoding=application/x-tex>\text{FCD}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord text"><span class=mord>FCD</span></span></span></span></span> 被定義為連續函數集合 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>f</mi><mo>:</mo><mo stretchy=false>[</mo><mn>0</mn><mo separator=true>,</mo><mn>1</mn><msup><mo stretchy=false>]</mo><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup><mo>→</mo><msup><mi mathvariant=double-struck>R</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding=application/x-tex>f: [0, 1]^{n \times d} \to \mathbb{R}^{n \times d}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>:</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.0991em;vertical-align:-0.25em></span><span class=mopen>[</span><span class=mord>0</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>1</span><span class=mclose><span class=mclose>]</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8491em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>→</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8491em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8491em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>，其中連續性是根據特定 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>p</mi></mrow><annotation encoding=application/x-tex>p</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal">p</span></span></span></span>-範數定義的拓撲。</p>
</li>
<li>
<p>用來衡量函數近似質量的距離度量是 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>p</mi></mrow><annotation encoding=application/x-tex>p</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal">p</span></span></span></span>-範數距離 <span class=katex><span class=katex-mathml><math><semantics><mrow><msub><mi>d</mi><mi>p</mi></msub><mo stretchy=false>(</mo><msub><mi>f</mi><mn>1</mn></msub><mo separator=true>,</mo><msub><mi>f</mi><mn>2</mn></msub><mo stretchy=false>)</mo><mo>=</mo><msup><mrow><mo fence=true>(</mo><mo>∫</mo><mi mathvariant=normal>∥</mi><msub><mi>f</mi><mn>1</mn></msub><mo stretchy=false>(</mo><mi>X</mi><mo stretchy=false>)</mo><mo>−</mo><msub><mi>f</mi><mn>2</mn></msub><mo stretchy=false>(</mo><mi>X</mi><mo stretchy=false>)</mo><msup><mi mathvariant=normal>∥</mi><mi>p</mi></msup><mtext> </mtext><mi>d</mi><mi>X</mi><mo fence=true>)</mo></mrow><mrow><mn>1</mn><mi mathvariant=normal>/</mi><mi>p</mi></mrow></msup></mrow><annotation encoding=application/x-tex>d_p(f_1, f_2) = \left(\int \|f_1(X) - f_2(X)\|^p \, dX\right)^{1/p}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0361em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal">d</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.4779em;vertical-align:-0.35em></span><span class=minner><span class=minner><span class="mopen delimcenter" style=top:0em><span class="delimsizing size1">(</span></span><span class="mop op-symbol small-op" style=margin-right:0.19445em;position:relative;top:-0.0006em>∫</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>∥</span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=mclose>)</span><span class=mord><span class=mord>∥</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6644em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">d</span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class="mclose delimcenter" style=top:0em><span class="delimsizing size1">)</span></span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:1.1279em><span style=top:-3.3029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1/</span><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span></span></span></span></span>。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>想像你有一個很大的平面，這個平面上的每一點都可以用兩個數字來描述，這就像地圖上的經緯度一樣。<p>在這個例子中，這個平面被稱為 <span class=katex><span class=katex-mathml><math><semantics><mrow><mo stretchy=false>[</mo><mn>0</mn><mo separator=true>,</mo><mn>1</mn><msup><mo stretchy=false>]</mo><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding=application/x-tex>[0, 1]^{n \times d}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0991em;vertical-align:-0.25em></span><span class=mopen>[</span><span class=mord>0</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>1</span><span class=mclose><span class=mclose>]</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8491em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>，你可以把它想象成一個有很多行和很多列的大表格，其中每個格子的數字都在 0 和 1 之間。<p>函數 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>f</mi></mrow><annotation encoding=application/x-tex>f</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.10764em>f</span></span></span></span> 就像是一種特殊的規則，它可以將這個大表格中的每個點（或每行每列的數字）轉換成另一組新的數字，也就是輸出一個同樣大小的新表格。這個轉換過程需要符合一定的平滑度和連續性，這意味著輸出的數字不會突然劇烈變化，它們會是連貫和有序的變化。</div></div>
</li>
</ul>
</li>
<li>
<p><strong>定義：以 0 為中心的星形圖 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>S</mi></mrow><annotation encoding=application/x-tex>S</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05764em>S</span></span></span></span></strong></p>
<ul>
<li>在這裡，星形圖 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>S</mi></mrow><annotation encoding=application/x-tex>S</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05764em>S</span></span></span></span> 是一種特別的圖形結構，其中一個中心節點（0 號節點）與圖中的所有其他節點（1 至 n 號節點）都有直接連接。</li>
<li>這個結構非常關鍵，因為它讓中心節點能夠直接影響到其他所有節點，這是後面證明中將會用到的一個重要特性。</li>
</ul>
</li>
<li>
<p><strong>定理：稀疏注意力機制的通用逼近能力</strong></p>
<ul>
<li>定理聲明，只要一個圖包含了這種星形圖 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>S</mi></mrow><annotation encoding=application/x-tex>S</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05764em>S</span></span></span></span>，透過這個圖定義的稀疏注意力機制就可以被用作通用逼近器。</li>
<li>這意味著，這樣的 Transformer 模型能夠逼近任何在函數類 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>F</mi><mi>C</mi><mi>D</mi></mrow><annotation encoding=application/x-tex>FCD</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>FC</span><span class="mord mathnormal" style=margin-right:0.02778em>D</span></span></span></span> 中的連續函數。</li>
</ul>
</li>
<li>
<p><strong>證明步驟 1：用分段常數函數逼近 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>F</mi><mi>C</mi><mi>D</mi></mrow><annotation encoding=application/x-tex>FCD</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>FC</span><span class="mord mathnormal" style=margin-right:0.02778em>D</span></span></span></span></strong></p>
<p>首先，我們需要處理的函數 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>f</mi></mrow><annotation encoding=application/x-tex>f</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.10764em>f</span></span></span></span> 是定義在有界區域 [0, 1)<span class=katex><span class=katex-mathml><math><semantics><mrow><msup><mrow/><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding=application/x-tex>^{n \times d}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8491em></span><span class=mord><span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8491em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span> 的連續函數。要逼近這樣的函數，我們選擇用分段常數函數來逼近它。具體操作是將 [0, 1) 區間適當划分成小格子（粒度為 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>δ</mi></mrow><annotation encoding=application/x-tex>\delta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.03785em>δ</span></span></span></span>），這樣整個區域就變成了一個離散的點集 <span class=katex><span class=katex-mathml><math><semantics><mrow><msub><mi>G</mi><mi>δ</mi></msub></mrow><annotation encoding=application/x-tex>G_{\delta}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">G</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.03785em>δ</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>。在每個小格子內，我們假設函數的值是常數。這樣，我們就可以用一個新的分段常數函數 <span class=katex><span class=katex-mathml><math><semantics><mrow><mover accent=true><mi>f</mi><mo>ˉ</mo></mover></mrow><annotation encoding=application/x-tex>\bar{f}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0257em;vertical-align:-0.1944em></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8312em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:0.10764em>f</span></span><span style=top:-3.2634em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.0833em><span class=mord>ˉ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1944em><span></span></span></span></span></span></span></span></span> 來逼近原始函數 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>f</mi></mrow><annotation encoding=application/x-tex>f</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.10764em>f</span></span></span></span>。</p>
</li>
<li>
<p><strong>證明步驟 2：透過修改後的 Transformer 近似分段常數函數</strong></p>
<p>這是整個證明中最關鍵的一步。在這一步中，我們利用自注意力機制來產生輸入的上下文映射。每個矩陣 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>X</mi></mrow><annotation encoding=application/x-tex>X</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07847em>X</span></span></span></span> 和它的一列 <span class=katex><span class=katex-mathml><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>x_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 被映射成一個唯一的代碼，然後這個代碼被用來生成唯一的輸出列。由於我們僅使用稀疏的注意力機制，因此挑戰在於如何確保每個查詢能夠獲得足夠的信息來完成這種映射。解決方案是開發了一種稀疏的移位運算符，該運算符會根據輸入矩陣中數據的範圍進行調整，以保證每一列數據都能形成完整且唯一的映射。</p>
</li>
<li>
<p><strong>證明步驟 3：透過原始 Transformer 近似修改後的 Transformer</strong></p>
<p>最後一步是將修改後的 Transformer 模型用原始的 Transformer 模型（使用 ReLU 和 softmax 函數）來逼近。這一步確保了這些的修改不會偏離原始模型的基本功能和效率。</p>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=圖靈完備性>圖靈完備性<a href=#圖靈完備性 class=hash-link aria-label=圖靈完備性的直接連結 title=圖靈完備性的直接連結>​</a></h3>
<p>事實上，Pérez 等人的研究表明，基於完整注意力機制的 Transformer 模型是圖靈完備的，也就是說，它能模擬任何圖靈機的計算過程。</p>
<p>不過，這個結果建立在一個理論上的假設之上，即模型能「處理任意精確度的數據」。</p>
<p>在實際應用中，這個假設往往不成立，因為 Transformer 實際上是有限狀態機，並不能達到真正的圖靈完備。</p>
<ul>
<li>
<p><strong>稀疏注意力是否也足夠用來模擬任何圖靈機？</strong></p>
<p>本文中提到，透過適當的調整，使用稀疏編碼器和解碼器的 Transformer 同樣能夠實現圖靈完備。</p>
<p>這種稀疏注意力機制在實際操作中要求每個令牌只與前面的令牌相互作用，與 BERT 全注意力一次性應用不同，在解碼過程中，它是逐令牌運作的。</p>
<p>此外，Pérez 等人的方法中，每個令牌還充當了磁帶歷史的表示，全注意力用於移動和檢索磁帶上的正確符號。</p>
<p>對於稀疏注意力機制的實施，除了需要修改它們指向歷史記錄的位址方案外，其餘的架構大部分可以直接應用。</p>
<p>這顯示了即使在稀疏配置下，Transformer 也具有模擬任意計算過程的潛力，這為理解和擴展 Transformer 在各種複雜計算任務中的應用提供了理論基礎。</p>
</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>圖靈完備性（Turing Completeness）是指一種計算系統的能力，如果該系統能夠模擬任何圖靈機的計算過程，則被認為是圖靈完備的。圖靈機是由數學家艾倫·圖靈提出的一種抽象機器，它透過一套簡單的規則來讀寫無限長的紙帶上的符號。一個圖靈完備的系統可以實現任何可計算的函數，也就是說，它可以執行任何其他圖靈完備系統能夠執行的計算任務。這是評估計算系統能力的一個重要標準，例如程式語言和處理器架構。</div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=稀疏注意力的限制>稀疏注意力的限制<a href=#稀疏注意力的限制 class=hash-link aria-label=稀疏注意力的限制的直接連結 title=稀疏注意力的限制的直接連結>​</a></h3>
<p>這個任務要求給定 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> 個單位向量 <span class=katex><span class=katex-mathml><math><semantics><mrow><mo stretchy=false>{</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator=true>,</mo><mi mathvariant=normal>.</mi><mi mathvariant=normal>.</mi><mi mathvariant=normal>.</mi><mo separator=true>,</mo><msub><mi>u</mi><mi>n</mi></msub><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>\{u_1, ..., u_n\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord><span class="mord mathnormal">u</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>...</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">u</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>}</span></span></span></span>，對於每個向量 <span class=katex><span class=katex-mathml><math><semantics><mrow><msub><mi>u</mi><mi>j</mi></msub></mrow><annotation encoding=application/x-tex>u_j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7167em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal">u</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>，找到一個對應的最遠向量 <span class=katex><span class=katex-mathml><math><semantics><mrow><msubsup><mi>u</mi><mi>j</mi><mo>∗</mo></msubsup></mrow><annotation encoding=application/x-tex>u_j^*</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0835em;vertical-align:-0.3948em></span><span class=mord><span class="mord mathnormal">u</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.6887em><span style=top:-2.4413em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3948em><span></span></span></span></span></span></span></span></span></span>。</p>
<p>這裡的「最遠」是指在向量空間中，兩個向量之間的歐幾里得距離最大，這在實際中通常轉化為最小化內積。</p>
<p>在完整注意力機制下，這個任務相對容易解決，因為該機制允許對所有向量對進行內積計算。</p>
<p>換句話說，完整的自我注意機制可以同時評估所有向量對之間的關係，從而能在 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>O</mi><mo stretchy=false>(</mo><mn>1</mn><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>O(1)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.02778em>O</span><span class=mopen>(</span><span class=mord>1</span><span class=mclose>)</span></span></span></span> 層內找到每個向量的最遠向量。</p>
<p>對於稀疏注意力機制，情況則大不相同。</p>
<p>作者提到，根據正交向量猜想（Orthogonal Vector Conjecture，OVC），在稀疏注意力機制下，這個問題變得難以解決。定理表明，對於任何具有 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>O</mi><mo stretchy=false>(</mo><mi>n</mi><msup><mrow><mi>log</mi><mo>⁡</mo></mrow><mi>k</mi></msup><mi>n</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>O(n \log^k n)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.1834em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.02778em>O</span><span class=mopen>(</span><span class="mord mathnormal">n</span><span class=mspace style=margin-right:0.1667em></span><span class=mop><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.9334em><span style=top:-3.1473em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">n</span><span class=mclose>)</span></span></span></span>（用 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>O</mi><mover accent=true><mrow/><mo>~</mo></mover></mrow><annotation encoding=application/x-tex>O\tilde{}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.02778em>O</span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6679em><span style=top:-3em><span class=pstrut style=height:3em></span><span class=mord></span></span><span style=top:-3.35em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.25em><span class=mord>~</span></span></span></span></span></span></span></span></span></span> 表示隱藏了多對數因子）邊的稀疏注意力圖 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>D</mi></mrow><annotation encoding=application/x-tex>D</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span></span></span></span>，即使是解決這種看似簡單的最遠向量查找問題，也需要 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi mathvariant=normal>Ω</mi><mo stretchy=false>(</mo><msup><mover accent=true><mi>n</mi><mo>~</mo></mover><mrow><mn>1</mn><mo>−</mo><mi>o</mi><mo stretchy=false>(</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msup><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\Omega(\tilde{n}^{1-o(1)})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.138em;vertical-align:-0.25em></span><span class=mord>Ω</span><span class=mopen>(</span><span class=mord><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6679em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">n</span></span><span style=top:-3.35em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.25em><span class=mord>~</span></span></span></span></span></span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">o</span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span> 層。</p>
<p>這表明在稀疏注意力機制下，雖然能夠減少計算資源的消耗，但在解決某些類型的問題時，可能需要顯著更多的層次，這在實際應用中可能會成為一個限制。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>OVC 是精細計算複雜性理論中一個廣泛使用的假設，它指出在次二次時間內無法判斷 <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> 個布爾向量的最小內積是否為 0。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=討論>討論<a href=#討論 class=hash-link aria-label=討論的直接連結 title=討論的直接連結>​</a></h2>
<p>本節旨在展示在自然語言處理（NLP）任務中處理更長輸入序列的好處。我們選擇了三個代表性的任務來進行研究：掩碼語言模型（MLM）、帶有支持證據的問答（QA）、以及長文件分類。這些任務旨在探索通過利用長連續序列來學習更好的上下文表示的可能性。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=qa-dev>QA-dev<a href=#qa-dev class=hash-link aria-label=QA-dev的直接連結 title=QA-dev的直接連結>​</a></h3>
<p><img decoding=async loading=lazy alt="QA-dev Performance" src=/assets/images/img2-be74cb6d41a86f88b7c712091fb6ec95.jpg width=1512 height=376 class=img_ev3q></p>
<ul>
<li><strong>資料集</strong>：包括 HotpotQA、Natural Questions、TriviaQA 和 WikiHop。</li>
<li><strong>度量指標</strong>：使用基本尺寸的模型，報告了 WikiHop 的準確率以及 HotpotQA、Natural Questions 和 TriviaQA 的 F1 分數。</li>
</ul>
<p>這裡比較了包括 RoBERTa、Longformer、BIGBIRD-ITC 和 BIGBIRD-ETC 在內的多個模型性能。BIGBIRD-ETC 模型在擴展全域令牌的設計下，一致性地在所有其他模型中表現出色。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=qa-test-finttune>QA Test finttune<a href=#qa-test-finttune class=hash-link aria-label="QA Test finttune的直接連結" title="QA Test finttune的直接連結">​</a></h3>
<p><img decoding=async loading=lazy alt="QA Test finttune Performance" src=/assets/images/img3-a8edfebc95d1524f0232d43b2260b30a.jpg width=1224 height=472 class=img_ev3q></p>
<ul>
<li><strong>任務與資料集</strong>：同樣包括 HotpotQA、Natural Questions、TriviaQA 和 WikiHop。</li>
<li><strong>比較基準</strong>：將 BIGBIRD-ETC 模型與不包括 BIGBIRD 的排行榜前三名進行比較。</li>
</ul>
<p>在這個實驗中，BIGBIRD-ETC 在多個資料集上設立了新的 SoTA，特別是在 Natural Questions 的長答案、TriviaQA 和 WikiHop 測試中。與僅使用單一模型的 BIGBIRD 相比，其他領先條目多為集合模型，這可能解釋了在某些情況下 BIGBIRD 在精確答案選擇上準確率略低的原因。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=長文件摘要能力>長文件摘要能力<a href=#長文件摘要能力 class=hash-link aria-label=長文件摘要能力的直接連結 title=長文件摘要能力的直接連結>​</a></h3>
<p><img decoding=async loading=lazy alt="Long Document Summarization" src=/assets/images/img4-4d1f33b08fe07c9b16c846da64d9ea14.jpg width=1224 height=668 class=img_ev3q></p>
<p>在本段中，文章探討了使用 BIGBIRD 模型進行長文件抽象摘要的實驗設計與成果，特別是在處理需要深入上下文理解的長範圍文本時，模型如何表現出顯著的改進。實驗中使用了三個專為長文件設計的數據集。實驗結果如上表，證明了通過應用 BIGBIRD 的稀疏編碼器和完整解碼器來訓練這些長文件數據集時，模型能夠有效地提升摘要的質量和準確性。</p>
<p>這一提升得益於模型能夠處理更長的文本範圍，從而更好地理解和整合文件中分散的關鍵信息。</p>
<p>這些觀察結果凸顯了 BIGBIRD 在處理高度複雜的 NLP 任務中的潛力與實際效益，尤其是在需要深層次文本分析和理解的應用場景中。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>Pegasus（Pre-training with Extracted Gap-sentences for Abstractive SUmmarization Sequence-to-sequence models）是一種專為文本摘要任務設計的預訓練方法，由 Google Research 團隊開發。Pegasus 的核心創新在於其預訓練策略，該策略專門針對摘要任務的需求來優化。<p>Pegasus 的預訓練過程採用了一種稱為“gap sentences prediction”（GSP）的策略，即「間隙句子預測」。在這個過程中，從一個文件中隨機選擇若干句子並將其「遮蔽」（即移除），然後模型需要預測這些被遮蔽的句子。這與傳統的掩碼語言模型（如 BERT）略有不同，BERT 通常是隨機掩蔽單詞或 token，而 Pegasus 掩蔽整個句子。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=結論>結論<a href=#結論 class=hash-link aria-label=結論的直接連結 title=結論的直接連結>​</a></h2>
<p>比起過去的 Sparse Transformer 和 Longformer 等模型，我們認為本文的主要貢獻在於為稀疏注意力機制提供了一份詳細的數學理論證明。</p>
<p>並且指出若我們希望可以近似完整注意力機制，則需要使用隨機、滑動視窗、部分全域的方式來設計模型的注意力機制。</p>
<p>通過對 Transformer 模型的理論性質進行深入研究，作者展示了稀疏注意力機制的通用逼近能力，並證明了這種機制在處理長序列任務時的優越性。</p>
<p>關於詳細的證明方式，在該論文中的附錄有大約 20 頁的篇幅，讓我們看得頭昏眼花，有興趣的讀者歡迎自行翻閱原始論文。</div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>最後<!-- -->由 <b>zephyr-sh</b> <!-- -->於 <b><time datetime=2024-09-30T05:40:33.000Z itemprop=dateModified>2024年9月30日</time></b> <!-- -->更新</span></div></div></footer><div style=margin-top:3rem> </div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label=文件選項卡><a class="pagination-nav__link pagination-nav__link--prev" href=/papers/transformers/gpt_3/><div class=pagination-nav__sublabel>上一頁</div><div class=pagination-nav__label>[20.05] GPT-3</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/papers/transformers/roformer/><div class=pagination-nav__sublabel>下一頁</div><div class=pagination-nav__label>[21.04] RoFormer</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#大鳥注意力機制 class="table-of-contents__link toc-highlight">大鳥注意力機制</a><li><a href=#定義問題 class="table-of-contents__link toc-highlight">定義問題</a><ul><li><a href=#基礎理論不足 class="table-of-contents__link toc-highlight">基礎理論不足</a></ul><li><a href=#解決問題 class="table-of-contents__link toc-highlight">解決問題</a><ul><li><a href=#模型架構 class="table-of-contents__link toc-highlight">模型架構</a><li><a href=#架構設計 class="table-of-contents__link toc-highlight">架構設計</a><li><a href=#證明之前 class="table-of-contents__link toc-highlight">證明之前</a><li><a href=#開始證明 class="table-of-contents__link toc-highlight">開始證明</a><li><a href=#圖靈完備性 class="table-of-contents__link toc-highlight">圖靈完備性</a><li><a href=#稀疏注意力的限制 class="table-of-contents__link toc-highlight">稀疏注意力的限制</a></ul><li><a href=#討論 class="table-of-contents__link toc-highlight">討論</a><ul><li><a href=#qa-dev class="table-of-contents__link toc-highlight">QA-dev</a><li><a href=#qa-test-finttune class="table-of-contents__link toc-highlight">QA Test finttune</a><li><a href=#長文件摘要能力 class="table-of-contents__link toc-highlight">長文件摘要能力</a></ul><li><a href=#結論 class="table-of-contents__link toc-highlight">結論</a></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/docs>開源專案</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/papers/intro>論文筆記</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/blog>部落格</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/terms-of-service>使用條款</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/privacy-policy>隱私政策</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/worklog>工作日誌</a><span class=footer__link-separator>·</span><a href=https://buymeacoffee.com/zephyr_docsaid target=_blank rel="noopener noreferrer" class=footer__link-item>支持我們<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>