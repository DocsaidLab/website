<!doctype html><html lang=zh-hant dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-model-tuning/soft-prompts/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.7.0"><title data-rh=true>[21.04] Soft Prompts | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/papers/model-tuning/soft-prompts/><meta data-rh=true property=og:locale content=zh_hant><meta data-rh=true property=og:locale:alternate content=en><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=zh-hant><meta data-rh=true name=docsearch:language content=zh-hant><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[21.04] Soft Prompts | DOCSAID"><meta data-rh=true name=description content=小弦切切如私語><meta data-rh=true property=og:description content=小弦切切如私語><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/papers/model-tuning/soft-prompts/><link data-rh=true rel=alternate href=https://docsaid.org/papers/model-tuning/soft-prompts/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/model-tuning/soft-prompts/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/model-tuning/soft-prompts/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/model-tuning/soft-prompts/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/assets/css/styles.31895f42.css><script src=/assets/js/runtime~main.e4b860b9.js defer></script><script src=/assets/js/main.961a0ef1.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><link rel=preload as=image href=/img/docsaid_logo.png><link rel=preload as=image href=/img/docsaid_logo_white.png><link rel=preload as=image href=https://github.com/zephyr-sh.png><div role=region aria-label=跳至主要内容><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>跳至主要内容</a></div><nav aria-label=主導航 class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label=切換導覽列 aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><div class=navbar__logo><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/docs/>開源專案</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/papers/intro>論文筆記</a><a class="navbar__item navbar__link" href=/blog>部落格</a><a class="navbar__item navbar__link" href=/playground/intro>遊樂場</a><a class="navbar__item navbar__link" href=/aboutus>關於我們</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>繁體中文</a><ul class=dropdown__menu><li><a href=/papers/model-tuning/soft-prompts/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=zh-hant>繁體中文</a><li><a href=/en/papers/model-tuning/soft-prompts/ target=_self rel="noopener noreferrer" class=dropdown__link lang=en>English</a><li><a href=/ja/papers/model-tuning/soft-prompts/ target=_self rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="搜尋 (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>搜尋</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-7ny38l ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label=回到頂部 class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label=文件側邊欄 class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/papers/intro>論文筆記</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="展開側邊欄分類 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/contrastive-learning-13>Contrastive Learning (13)</a><button aria-label="展開側邊欄分類 'Contrastive Learning (13)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/deepseek-5>DeepSeek (5)</a><button aria-label="展開側邊欄分類 'DeepSeek (5)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/face-anti-spoofing-3>Face Anti-Spoofing (3)</a><button aria-label="展開側邊欄分類 'Face Anti-Spoofing (3)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="展開側邊欄分類 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/feature-fusion-10>Feature Fusion (10)</a><button aria-label="展開側邊欄分類 'Feature Fusion (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="展開側邊欄分類 'Lightweight (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/mamba-4>Mamba (4)</a><button aria-label="展開側邊欄分類 'Mamba (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/papers/category/model-tuning-8>Model Tuning (8)</a><button aria-label="收起側邊欄分類 'Model Tuning (8)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/model-tuning/adapter/>[19.02] Adapter</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/model-tuning/autoprompt/>[20.10] AutoPrompt</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/model-tuning/prefix-tuning/>[21.01] Prefix-Tuning</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/papers/model-tuning/soft-prompts/>[21.04] Soft Prompts</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/model-tuning/lora/>[21.06] LoRA</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/model-tuning/coop/>[21.09] CoOp</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/model-tuning/cocoop/>[22.03] CoCoOp</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/papers/model-tuning/blip2/>[23.01] BLIP-2</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/multimodality-24>Multimodality (24)</a><button aria-label="展開側邊欄分類 'Multimodality (24)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/normalization-1>Normalization (1)</a><button aria-label="展開側邊欄分類 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/object-detection-8>Object Detection (8)</a><button aria-label="展開側邊欄分類 'Object Detection (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/reparameterization-8>Reparameterization (8)</a><button aria-label="展開側邊欄分類 'Reparameterization (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="展開側邊欄分類 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-detection-14>Text Detection (14)</a><button aria-label="展開側邊欄分類 'Text Detection (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="展開側邊欄分類 'Text Recognition (20)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="展開側邊欄分類 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/transformers-17>Transformers (17)</a><button aria-label="展開側邊欄分類 'Transformers (17)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/papers/category/vision-transformers-12>Vision Transformers (12)</a><button aria-label="展開側邊欄分類 'Vision Transformers (12)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/papers/intro>All Notes: 177 entries</a></ul></nav><button type=button title=收起側邊欄 aria-label=收起側邊欄 class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=頁面路徑><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label=主頁面 class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/papers/category/model-tuning-8><span itemprop=name>Model Tuning (8)</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>[21.04] Soft Prompts</span><meta itemprop=position content=2></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">本頁導覽</button></div><div class="theme-doc-markdown markdown"><header><h1>[21.04] Soft Prompts</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt="Z. Yuan" class=docAuthorImg_vlJe><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Z. Yuan</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a href=https://www.linkedin.com/in/ze-yuan-sh7/ target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 448 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=小弦切切如私語>小弦切切如私語<a href=#小弦切切如私語 class=hash-link aria-label=小弦切切如私語的直接連結 title=小弦切切如私語的直接連結>​</a></h2>
<p><a href=https://arxiv.org/abs/2104.08691 target=_blank rel="noopener noreferrer"><strong>The Power of Scale for Parameter-Efficient Prompt Tuning</strong></a></p>
<hr>
<p>我們剛看完 Prefix-Tuning 不久，現在來看另外一個新的方法：<strong>Prompt Tuning</strong>。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>如果你還沒看過 Prefix-Tuning，不妨先去看一下我們之前讀的論文：<ul>
<li><a href=/papers/model-tuning/prefix-tuning/><strong>[21.01] Prefix-Tuning: 是他？不是他？</strong></a></li>
</ul></div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=定義問題>定義問題<a href=#定義問題 class=hash-link aria-label=定義問題的直接連結 title=定義問題的直接連結>​</a></h2>
<p>作者在論文中從 T5 的論文架構開始，來幫助讀者了解目前在調整模型上所面臨的困難。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>如果你沒看過 T5，可以參考以下論文：<ul>
<li><a href=https://arxiv.org/abs/1910.10683 target=_blank rel="noopener noreferrer"><strong>[19.10] Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</strong></a></li>
</ul></div></div>
<p>T5 將所有任務視為文本生成問題，無論是翻譯、摘要還是分類，都可以表示為從輸入文本生成輸出文本。</p>
<p>傳統的分類模型使用概率 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mtext>Pr</mtext><mo stretchy=false>(</mo><mi>y</mi><mi mathvariant=normal>∣</mi><mi>X</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\text{Pr}(y|X)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>Pr</span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=mord>∣</span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=mclose>)</span></span></span></span>，將輸入 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>X</mi></mrow><annotation encoding=application/x-tex>X</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07847em>X</span></span></span></span> 映射到輸出類別 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>y</mi></mrow><annotation encoding=application/x-tex>y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span></span></span></span>，然而，在 T5 的架構中，模型所關注的是<strong>條件生成</strong>問題，目標是計算：</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mtext>Pr</mtext><mi>θ</mi></msub><mo stretchy=false>(</mo><mi>Y</mi><mi mathvariant=normal>∣</mi><mi>X</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\text{Pr}_\theta(Y | X)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord text"><span class=mord>Pr</span></span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.22222em>Y</span><span class=mord>∣</span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=mclose>)</span></span></span></span></span>
<p>其中：</p>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>Y</mi></mrow><annotation encoding=application/x-tex>Y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.22222em>Y</span></span></span></span> 是代表類別的<strong>文本</strong>，例如：「positive」或「negative」，而不是 0, 1, 2 這種類別。</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>θ</mi></mrow><annotation encoding=application/x-tex>\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.02778em>θ</span></span></span></span> 是 Transformer 模型的參數。</li>
</ul>
<p>這種方法的優點是模型可以直接生成更豐富的文本輸出，而不僅僅是單一的類別標籤。</p>
<p>提示（Prompting）是添加在輸入 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>X</mi></mrow><annotation encoding=application/x-tex>X</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07847em>X</span></span></span></span> 前的一段文本，用於引導模型生成正確的輸出 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>Y</mi></mrow><annotation encoding=application/x-tex>Y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.22222em>Y</span></span></span></span>。提示為模型提供了任務的上下文或指令，幫助模型理解應該如何處理輸入。</p>
<p>例如在情感分析任務中，我們可以使用以下提示：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">"請判斷以下句子的情感傾向："</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>然後將用戶的輸入句子接在提示後面，形成模型的最終輸入：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">"請判斷以下句子的情感傾向：I love this movie!"</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>但是這種「傳統上」的提示，不僅人工成本高，而且效果不穩定又不可微分。不可微分的問題意味著我們無法通過反向傳播算法來更新提示的參數，這將導致模型無法自動學習到最佳的提示方式。</p>
<hr>
<p>為了解決這個問題，之前的研究：Prefix-Tuning 提出在模型的輸入最前面加上一個叫做 Prefix 的 Token，來引導模型產生結果。這個 Prefix 必須深入到模型的每一層，這樣才能讓模型在每一層都能受到引導。</p>
<p>那我們能不能把事情簡化一下？只要在輸入層對模型進行引導就好了？</p>
<p>所以就有了這篇論文：<strong>Prompt Tuning</strong>。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>這裡說的的「引導」和另外我們常聽到的「Prompt Engineering」不是同一件事情，Prompt Engineering 還是使用自然語言的方式來引導模型，從頭到尾都沒有改變模型的輸入特徵，沒有改參數，也沒有改架構。<p>而「Prompt Tuning」指的是在模型的輸入層加上一個特殊的 Token，這個 Token 是可以訓練的，這樣就可以讓模型在訓練的時候自己學習到最適合的引導方式。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=解決問題>解決問題<a href=#解決問題 class=hash-link aria-label=解決問題的直接連結 title=解決問題的直接連結>​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=prompt-tuning>Prompt Tuning<a href=#prompt-tuning class=hash-link aria-label="Prompt Tuning的直接連結" title="Prompt Tuning的直接連結">​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt="model arch" src=/assets/images/img1-03e4bbd9625e2ff48bffb2de21f56a1f.jpg width=1184 height=640 class=img_ev3q></figure></div>
<p>所以作者提出了 Prompt Tuning 的方法，引入了可更新的提示詞嵌入參數 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>θ</mi><mi>P</mi></msub></mrow><annotation encoding=application/x-tex>\theta_P</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>θ</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>P</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>，這些參數不再受限於模型的詞嵌入表，可以通過訓練數據自動學習。</p>
<p>新的條件生成公式為：</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mtext>Pr</mtext><mrow><mi>θ</mi><mo separator=true>;</mo><msub><mi>θ</mi><mi>P</mi></msub></mrow></msub><mo stretchy=false>(</mo><mi>Y</mi><mi mathvariant=normal>∣</mi><mo stretchy=false>[</mo><mi>P</mi><mo separator=true>;</mo><mi>X</mi><mo stretchy=false>]</mo><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\text{Pr}_{\theta; \theta_P}(Y | [P; X])</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0361em;vertical-align:-0.2861em></span><span class=mord><span class="mord text"><span class=mord>Pr</span></span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span><span class="mpunct mtight">;</span><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3448em><span style=top:-2.3567em;margin-left:-0.0278em;margin-right:0.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>P</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1433em><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.22222em>Y</span><span class=mord>∣</span><span class=mopen>[</span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mpunct>;</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=mclose>])</span></span></span></span></span>
<p>其中：</p>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>[</mo><mi>P</mi><mo separator=true>;</mo><mi>X</mi><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>[P; X]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>[</span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mpunct>;</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=mclose>]</span></span></span></span> 表示將提示 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>P</mi></mrow><annotation encoding=application/x-tex>P</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span></span></span></span> 和輸入 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>X</mi></mrow><annotation encoding=application/x-tex>X</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07847em>X</span></span></span></span> 進行拼接。</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>θ</mi></mrow><annotation encoding=application/x-tex>\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.02778em>θ</span></span></span></span> 是凍結的模型參數。</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>θ</mi><mi>P</mi></msub></mrow><annotation encoding=application/x-tex>\theta_P</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>θ</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>P</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 是可訓練的提示參數。</li>
</ul>
<p>在訓練過程中，使用反向傳播算法，只更新提示參數 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>θ</mi><mi>P</mi></msub></mrow><annotation encoding=application/x-tex>\theta_P</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>θ</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>P</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>，而保持模型主體的參數 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>θ</mi></mrow><annotation encoding=application/x-tex>\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.02778em>θ</span></span></span></span> 不變。</p>
<p>具體的實現細節大致上可以分為幾個步驟：</p>
<ol>
<li><strong>輸入嵌入</strong>：將輸入的 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> 個 token 嵌入為矩陣 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>X</mi><mi>e</mi></msub><mo>∈</mo><msup><mi mathvariant=double-struck>R</mi><mrow><mi>n</mi><mo>×</mo><mi>e</mi></mrow></msup></mrow><annotation encoding=application/x-tex>X_e \in \mathbb{R}^{n \times e}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0785em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.7713em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.7713em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">e</span></span></span></span></span></span></span></span></span></span></span></span>，其中 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>e</mi></mrow><annotation encoding=application/x-tex>e</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">e</span></span></span></span> 是嵌入維度。</li>
<li><strong>提示嵌入</strong>：提示詞嵌入為矩陣 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>e</mi></msub><mo>∈</mo><msup><mi mathvariant=double-struck>R</mi><mrow><mi>p</mi><mo>×</mo><mi>e</mi></mrow></msup></mrow><annotation encoding=application/x-tex>P_e \in \mathbb{R}^{p \times e}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.7713em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.7713em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">e</span></span></span></span></span></span></span></span></span></span></span></span>，其中 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>p</mi></mrow><annotation encoding=application/x-tex>p</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal">p</span></span></span></span> 是提示的長度。</li>
<li><strong>拼接操作</strong>：將提示嵌入和輸入嵌入拼接為：<!-- -->
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mo stretchy=false>[</mo><msub><mi>P</mi><mi>e</mi></msub><mo separator=true>;</mo><msub><mi>X</mi><mi>e</mi></msub><mo stretchy=false>]</mo><mo>∈</mo><msup><mi mathvariant=double-struck>R</mi><mrow><mo stretchy=false>(</mo><mi>p</mi><mo>+</mo><mi>n</mi><mo stretchy=false>)</mo><mo>×</mo><mi>e</mi></mrow></msup></mrow><annotation encoding=application/x-tex>[P_e; X_e] \in \mathbb{R}^{(p + n) \times e}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>[</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>;</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0785em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>]</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.938em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.938em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">p</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">e</span></span></span></span></span></span></span></span></span></span></span></span></span>
</li>
<li><strong>模型處理</strong>：將拼接後的嵌入輸入到編碼器-解碼器架構中進行計算。</li>
</ol>
<p>假設我們希望模型判斷句子 "I love this movie!" 的情感，基於傳統方法的模型輸入是：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">"請判斷以下句子的情感：I love this movie!"</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>而使用 Prompt Tuning 方法的模型輸入是：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_biex><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">[Token1] [Token2] [Token3] [Token4] [Token5] I love this movie!</span><br></span></code></pre><div class=buttonGroup__atx><button type=button aria-label=複製程式碼至剪貼簿 title=複製 class=clean-btn><span class=copyButtonIcons_eSgA aria-hidden=true><svg viewBox="0 0 24 24" class=copyButtonIcon_y97N><path fill=currentColor d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"/></svg><svg viewBox="0 0 24 24" class=copyButtonSuccessIcon_LjdS><path fill=currentColor d=M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z /></svg></span></button></div></div></div>
<p>其中，上面的每一個 Token 都是可以訓練的，模型必須自己學習如何最好地使用這些提示。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p><strong>這不就是 AutoPrompt？</strong><p>如果你之前有讀過 AutoPrompt 的話，你可能就會問出這個問題，如果沒看過，可以參考我們之前的文章：<ul>
<li><a href=/papers/model-tuning/autoprompt/><strong>[20.10] AutoPrompt: 模型語</strong></a></li>
</ul><hr><p>這兩者的差別在於：在 AutoPrompt 中，模型要從現有的詞彙表中找到最適合的提示，最後的結果都存在於詞彙表中。而在 Prompt Tuning 中，提示的輸入直接作用於特徵空間，不需要受限於詞彙表。<p>所以基於 Prompt Tuning 的結果，你只能透過計算餘弦相似度來看這和哪些詞彙比較接近，而不能直接看到提示的內容。</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=討論>討論<a href=#討論 class=hash-link aria-label=討論的直接連結 title=討論的直接連結>​</a></h2>
<p><img decoding=async loading=lazy alt=ablation src=/assets/images/img2-1cc24cd284d57491ab8144c1d1e311d9.jpg width=1292 height=984 class=img_ev3q></p>
<p>作者做了一系列的消融研究，來探討 Prompt Tuning 的一些關鍵問題：</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=提示長度要多長>提示長度要多長？<a href=#提示長度要多長 class=hash-link aria-label=提示長度要多長？的直接連結 title=提示長度要多長？的直接連結>​</a></h3>
<p>如上圖 (a)，作者對不同模型規模（Small、Base、Large、XL、XXL）的提示長度進行了實驗，提示長度分別為 {1, 5, 20, 100, 150}。</p>
<p>結果顯示，對大多數模型而言，提示長度增加到多於 1 個 token 對性能表現有明顯提升。但對於 T5-XXL 模型，即使只使用單一 token 作為提示，也能達到不錯的表現，表明大模型對提示訊號的需求較低。</p>
<p>超過 20 個 token 後，性能提升趨於平緩，只帶來微小的增益。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=提示初始化策略的影響>提示初始化策略的影響？<a href=#提示初始化策略的影響 class=hash-link aria-label=提示初始化策略的影響？的直接連結 title=提示初始化策略的影響？的直接連結>​</a></h3>
<p>如上圖 (b)，作者比較了三種不同的初始化策略：</p>
<ol>
<li><strong>隨機初始化</strong>：從範圍 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>[</mo><mo>−</mo><mn>0.5</mn><mo separator=true>,</mo><mn>0.5</mn><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>[-0.5, 0.5]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>[</span><span class=mord>−</span><span class=mord>0.5</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>0.5</span><span class=mclose>]</span></span></span></span> 中均勻隨機取樣。</li>
<li><strong>詞彙嵌入初始化</strong>：從 T5 的 <strong>5,000 個最常見詞彙</strong>中選取詞嵌入進行初始化。</li>
<li><strong>類別標籤初始化</strong>：將下游任務中的類別標籤轉換為詞嵌入，若標籤為多個 token，則對嵌入取平均值。當提示長度超過類別數時，剩餘的 token 使用詞彙嵌入填充。</li>
</ol>
<p>結果顯示，類別標籤初始化在所有模型規模下表現最佳，特別是對於小模型來說，初始化策略的差異非常明顯。T5-XXL 模型對初始化策略較不敏感，無論使用何種初始化，其性能都相對穩定。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=預訓練目標的影響>預訓練目標的影響？<a href=#預訓練目標的影響 class=hash-link aria-label=預訓練目標的影響？的直接連結 title=預訓練目標的影響？的直接連結>​</a></h3>
<p>如上圖 (c)，作者探討了不同的預訓練目標對 Prompt Tuning 的影響：</p>
<ol>
<li><strong>Span Corruption</strong>：使用預設的 T5 span corruption 預訓練目標。</li>
<li><strong>Span Corruption + Sentinel</strong>：在下游任務的目標輸出中添加哨兵符號，以模擬預訓練時的輸出格式。</li>
<li><strong>LM 調適</strong>：延續 T5 的預訓練，但改為<strong>語言模型（LM）目標</strong>，進行額外的 100,000 步調適。</li>
</ol>
<p>結果顯示，Span Corruption 預訓練的模型不適合用於凍結模型的 Prompt Tuning，因為模型習慣了讀取和輸出帶有哨兵符號的文本。即使透過 <strong>「Span Corruption + Sentinel」</strong> 模擬預訓練格式，效果仍然有限。</p>
<p><strong>LM Adaptation</strong> 在所有模型規模上都顯著提升性能。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=lm-調適時長的影響>LM 調適時長的影響？<a href=#lm-調適時長的影響 class=hash-link aria-label="LM 調適時長的影響？的直接連結" title="LM 調適時長的影響？的直接連結">​</a></h3>
<p>如上圖 (d)，作者探討了 LM 調適時長對 Prompt Tuning 的影響。</p>
<p>結果顯示，延長 LM 調適步數會帶來額外的增益，並在 100,000 步左右達到最佳效果。Span Corruption 預訓練轉換為 LM 目標不是一個簡單的過程，需要投入相當的訓練資源（相當於原始 T5 預訓練步數的 10%）。</p>
<p>T5-XXL 在各種非理想配置下仍表現良好，顯示其對模型設定具有高韌性。在 Span Corruption 配置下，模型表現不穩定，小模型甚至超越了 Base、Large 和 XL 模型。這些問題並非隨機波動造成，因為在 3 次重複實驗中觀察到一致的低變異。</p>
<p>與 Span Corruption 預訓練的模型相比，LM 調適後的模型在所有規模下都表現穩定，大幅降低了性能不穩定的風險。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=和其他方法比較>和其他方法比較<a href=#和其他方法比較 class=hash-link aria-label=和其他方法比較的直接連結 title=和其他方法比較的直接連結>​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=comparison src=/assets/images/img3-6f570e3deede22c97b6c84c904cda64e.jpg width=792 height=716 class=img_ev3q></figure></div>
<p>上圖中，作者將 Prompt Tuning 與其他相關方法進行了比較，由於方法眾多，下面會列出每個方法的簡要介紹和參考文獻。</p>
<hr>
<ul>
<li>
<p><strong>Prefix Tuning</strong>：</p>
<ul>
<li><a href=https://arxiv.org/abs/2101.00190 target=_blank rel="noopener noreferrer"><strong>[21.01] Prefix-Tuning: Optimizing Continuous Prompts for Generation</strong></a></li>
</ul>
<p>在 Transformer 的每一層前置可學習的前綴 (prefix)，相當於為每層網路固定激活值。這方法適用於 GPT-2 和 BART，而本研究的 Prompt Tuning 專注於 T5。在 BART 上，Prefix Tuning 需要同時在「編碼器和解碼器」加入前綴，而 Prompt Tuning 只需在編碼器加入提示。</p>
<p>Prompt Tuning 只需在輸入層加上一個單一提示詞，而非在每層加入前綴，因此參數需求更少。而且 Prompt Tuning 允許 Transformer 根據輸入例子更新其中間層的任務表徵，而 Prefix Tuning 需要重參數化來穩定訓練。</p>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>WARP</strong></p>
<ul>
<li><a href=https://arxiv.org/abs/2101.00121 target=_blank rel="noopener noreferrer"><strong>[21.01] WARP: Word-level Adversarial ReProgramming</strong></a></li>
</ul>
<p>WARP 將提示參數添加至輸入層，並使用 [MASK] token 和可學習的輸出層，將遮蔽部分映射至類別預測。這種方法只能產生單一輸出，因此受限於分類任務。</p>
<p>Prompt Tuning 不需要對輸入進行特殊設計或使用任務專屬的輸出層，適用於更廣泛的任務。性能也更接近完整的模型微調。</p>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>P-tuning</strong></p>
<ul>
<li><a href=https://arxiv.org/abs/2103.10385 target=_blank rel="noopener noreferrer"><strong>[21.03] GPT Understands, Too</strong></a></li>
</ul>
<p>P-tuning 將可學習的連續提示嵌入於輸入之間，並基於人類設計的模式進行排列。為了達到良好的 SuperGLUE 表現，P-tuning 必須與模型微調結合，即同時調整提示和主模型的參數。</p>
<p>Pompt Tuning 只需更新提示參數，而主語言模型保持凍結，避免模型微調的成本。</p>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>Soft Words</strong></p>
<ul>
<li>
<p><a href=https://arxiv.org/abs/2104.06599 target=_blank rel="noopener noreferrer"><strong>[21.04] Learning How to Ask: Querying LMs with Mixtures of Soft Prompts</strong></a></p>
<p>Soft Words 學習的提示基於手工設計的提示範本，並為每層添加可學習的 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=normal>Δ</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\Delta_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class=mord>Δ</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> 參數，使得參數需求隨模型深度增加。</p>
<p>Pompt Tuning 不需要隨層數增加而添加額外參數，因此在參數規模上更具效率。</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>Adapters</strong></p>
<ul>
<li>
<p><a href=https://arxiv.org/abs/1902.00751 target=_blank rel="noopener noreferrer"><strong>[19.02] Parameter-Efficient Transfer Learning for NLP</strong></a></p>
<p>Adapters 是插入於凍結模型層之間的小型瓶頸層，用以減少任務專屬參數。在 BERT-Large 上微調 Adapter 層，僅增加 2–4% 的參數，且性能接近完整模型微調。</p>
<p>Adapters 透過重寫中間層的激活值來修改模型行為，而 Pompt Tuning 則是透過調整輸入表示，保留了模型內部的運算不變。</p>
</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=到底提示了什麼>到底提示了什麼？<a href=#到底提示了什麼 class=hash-link aria-label=到底提示了什麼？的直接連結 title=到底提示了什麼？的直接連結>​</a></h3>
<p>如同剛才講到的，由於 Prompt Tuning 是在連續空間中操作，而非明確的詞彙空間，我們難以直接理解這些提示是如何影響模型的行為。</p>
<p>作者透過計算每個提示 token 與模型詞彙表中各 token 的「餘弦相似度」，找出最相近的詞彙。這讓我們可以看到每個提示 token 對應的「最近鄰詞彙」，藉此找到提示 token 在語義上的含義。</p>
<p>實驗結果顯示提示 token 的前五個最近鄰詞彙往往形成「語義密切相關的群組」。當使用隨機生成的向量代替經過訓練的提示 token，則無法形成相似的語義群聚。</p>
<p>這意味著 Prompt Tuning 不是隨機的，而是確實能夠捕捉到語言模型中的語義結構，此外在長提示序列的情況下，作者發現多個提示 token 可能共享相同的最近鄰詞彙。</p>
<p>但這又衍生出兩個潛在問題：</p>
<ol>
<li><strong>冗餘容量</strong>：提示中可能存在重複或多餘的資訊，無法進一步提升模型效能。</li>
<li><strong>缺乏序列結構</strong>：提示 token 的表徵未能精確反映序列中的位置資訊，導致模型難以準確地定位和解析關鍵訊息。</li>
</ol>
<p>另一個重要的觀察是，提示 token 的最近鄰詞彙中，經常包含「下游任務的類別標籤」，意思是 Prompt Tuning 能在模型內部儲存預期的輸出類別，作為生成輸出的參考依據。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=結論>結論<a href=#結論 class=hash-link aria-label=結論的直接連結 title=結論的直接連結>​</a></h2>
<p>Prompt Tuning 在各類實驗中的表現與傳統模型微調相當，且隨著模型規模的擴大，這種性能差距逐漸縮小。在零樣本領域遷移任務中，Prompt Tuning 展現出更好的泛化能力，表示凍結語言模型中的通用理解參數並將學習範圍限制於輕量化的提示向量，可以有效避免過度擬合於特定領域。</p>
<p>作者認為未來的研究方向，可能在於將「任務定義的參數」與「語言建模的通用參數分離」，這樣可以更好地控制模型的行為，並提高模型的可解釋性。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>後續的有不少的研究也都在 Prompt Tuning 的方向進行，我們可以繼續再來看幾篇論文。</div></div></header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>最後<!-- -->由 <b>zephyr-sh</b> <!-- -->於 <b><time datetime=2025-02-11T02:49:16.000Z itemprop=dateModified>2025年2月11日</time></b> <!-- -->更新</span></div></div><div style=margin-top:3rem> </div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label=文件選項卡><a class="pagination-nav__link pagination-nav__link--prev" href=/papers/model-tuning/prefix-tuning/><div class=pagination-nav__sublabel>上一頁</div><div class=pagination-nav__label>[21.01] Prefix-Tuning</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/papers/model-tuning/lora/><div class=pagination-nav__sublabel>下一頁</div><div class=pagination-nav__label>[21.06] LoRA</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#小弦切切如私語 class="table-of-contents__link toc-highlight">小弦切切如私語</a><li><a href=#定義問題 class="table-of-contents__link toc-highlight">定義問題</a><li><a href=#解決問題 class="table-of-contents__link toc-highlight">解決問題</a><ul><li><a href=#prompt-tuning class="table-of-contents__link toc-highlight">Prompt Tuning</a></ul><li><a href=#討論 class="table-of-contents__link toc-highlight">討論</a><ul><li><a href=#提示長度要多長 class="table-of-contents__link toc-highlight">提示長度要多長？</a><li><a href=#提示初始化策略的影響 class="table-of-contents__link toc-highlight">提示初始化策略的影響？</a><li><a href=#預訓練目標的影響 class="table-of-contents__link toc-highlight">預訓練目標的影響？</a><li><a href=#lm-調適時長的影響 class="table-of-contents__link toc-highlight">LM 調適時長的影響？</a><li><a href=#和其他方法比較 class="table-of-contents__link toc-highlight">和其他方法比較</a><li><a href=#到底提示了什麼 class="table-of-contents__link toc-highlight">到底提示了什麼？</a></ul><li><a href=#結論 class="table-of-contents__link toc-highlight">結論</a></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/docs>開源專案</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/papers/intro>論文筆記</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/blog>部落格</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/terms-of-service>使用條款</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/privacy-policy>隱私政策</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/become-an-author>成為作者</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/worklog>工作日誌</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2025 DOCSAID.</div></div></div></footer></div>