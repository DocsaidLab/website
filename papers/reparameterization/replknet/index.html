<!doctype html>
<html lang="zh-hant" dir="ltr" class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-reparameterization/replknet/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">[22.03] RepLKNet | DOCSAID</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://docsaid.org/img/docsaid-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://docsaid.org/img/docsaid-social-card.jpg"><meta data-rh="true" property="og:url" content="https://docsaid.org/papers/reparameterization/replknet/"><meta data-rh="true" property="og:locale" content="zh_hant"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh-hant"><meta data-rh="true" name="docsearch:language" content="zh-hant"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-papers-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-papers-current"><meta data-rh="true" property="og:title" content="[22.03] RepLKNet | DOCSAID"><meta data-rh="true" name="description" content="巨無霸卷積核"><meta data-rh="true" property="og:description" content="巨無霸卷積核"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docsaid.org/papers/reparameterization/replknet/"><link data-rh="true" rel="alternate" href="https://docsaid.org/papers/reparameterization/replknet/" hreflang="zh-hant"><link data-rh="true" rel="alternate" href="https://docsaid.org/en/papers/reparameterization/replknet/" hreflang="en"><link data-rh="true" rel="alternate" href="https://docsaid.org/papers/reparameterization/replknet/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://S9NC0RYCHF-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="DOCSAID RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="DOCSAID Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script>


<link rel="search" type="application/opensearchdescription+xml" title="DOCSAID" href="/opensearch.xml">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.3057f3b6.css">
<script src="/assets/js/runtime~main.9fb68cd2.js" defer="defer"></script>
<script src="/assets/js/main.c4d6b2af.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳至主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳至主要内容</a></div><nav aria-label="主導航" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切換導覽列" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/docsaid_logo.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/docsaid_logo_white.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href="/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/papers/intro">Papers</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>繁體中文</a><ul class="dropdown__menu"><li><a href="/papers/reparameterization/replknet/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-hant">繁體中文</a></li><li><a href="/en/papers/reparameterization/replknet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li></ul></div><a href="https://github.com/DocsaidLab" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切換淺色/深色模式（當前為淺色模式）" aria-label="切換淺色/深色模式（當前為淺色模式）" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜尋"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜尋</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到頂部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/"><img src="/img/docsaid_logo.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/docsaid_logo_white.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="文件側邊欄" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/papers/intro">論文筆記</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/classic-cnns-9">Classic CNNs (9)</a><button aria-label="展開側邊欄分類 &#x27;Classic CNNs (9)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/face-anti-spoofing-1">Face Anti-Spoofing (1)</a><button aria-label="展開側邊欄分類 &#x27;Face Anti-Spoofing (1)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/face-recognition-4">Face Recognition (4)</a><button aria-label="展開側邊欄分類 &#x27;Face Recognition (4)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/feature-fusion-7">Feature Fusion (7)</a><button aria-label="展開側邊欄分類 &#x27;Feature Fusion (7)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/lightweight-10">Lightweight (10)</a><button aria-label="展開側邊欄分類 &#x27;Lightweight (10)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/multimodality-18">Multimodality (18)</a><button aria-label="展開側邊欄分類 &#x27;Multimodality (18)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/normalization-1">Normalization (1)</a><button aria-label="展開側邊欄分類 &#x27;Normalization (1)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/object-detection-7">Object Detection (7)</a><button aria-label="展開側邊欄分類 &#x27;Object Detection (7)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/papers/category/reparameterization-7">Reparameterization (7)</a><button aria-label="收起側邊欄分類 &#x27;Reparameterization (7)&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/reparameterization/repvgg/">[21.01] RepVGG</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/papers/reparameterization/replknet/">[22.03] RepLKNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/reparameterization/mobileone/">[22.06] MobileOne</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/reparameterization/qarepvgg/">[22.12] QARepVGG</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/reparameterization/fastvit/">[23.03] FastViT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/reparameterization/vanillanet/">[23.05] VanillaNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/reparameterization/repvit/">[23.07] RepViT</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/segmentation-1">Segmentation (1)</a><button aria-label="展開側邊欄分類 &#x27;Segmentation (1)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/text-detection-10">Text Detection (10)</a><button aria-label="展開側邊欄分類 &#x27;Text Detection (10)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/transformers-13">Transformers (13)</a><button aria-label="展開側邊欄分類 &#x27;Transformers (13)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/papers/category/vision-transformers-11">Vision Transformers (11)</a><button aria-label="展開側邊欄分類 &#x27;Vision Transformers (11)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="收起側邊欄" aria-label="收起側邊欄" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="頁面路徑"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主頁面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/papers/category/reparameterization-7"><span itemprop="name">Reparameterization (7)</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">[22.03] RepLKNet</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本頁導覽</button></div><div class="theme-doc-markdown markdown"><header><h1>[22.03] RepLKNet</h1></header>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="巨無霸卷積核">巨無霸卷積核<a href="#巨無霸卷積核" class="hash-link" aria-label="巨無霸卷積核的直接連結" title="巨無霸卷積核的直接連結">​</a></h2>
<p><a href="https://arxiv.org/abs/2203.06717" target="_blank" rel="noopener noreferrer"><strong>Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs</strong></a></p>
<hr>
<p>近年來，CNN 架構受到 ViT 挑戰，地位顯得搖搖欲墜。</p>
<p>有人說，ViT 這麼強，是因為多頭注意力機制的加持，多頭注意力更靈活，更少歸納偏差，對扭曲更穩健等。</p>
<p>但是又有一派人把「多頭注意力」去除後，發現性能也相去不遠，於是把性能歸功於「架構」。</p>
<p>這篇論文跟他們都不同，它主要專注於一個觀點：大卷積核的設計。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="定義問題">定義問題<a href="#定義問題" class="hash-link" aria-label="定義問題的直接連結" title="定義問題的直接連結">​</a></h2>
<p>除了一些老式模型如 Inceptions 之外，大核模型在 VGG 之後不再流行。</p>
<p>VGG 已經得到了堆疊小核就能達到同樣效果的「感受野」，因此大核的設計逐漸乏人問津。</p>
<p>雖然近年也有一些對於大核的研究，但是這些研究沒有回答一個關鍵問題：</p>
<ul>
<li><strong>為什麼傳統 CNN 性能不如 ViT？建立大感受野的方式是縮小 CNN 和 ViT 表現差距的關鍵嗎？</strong></li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="大核卷積使用說明書">大核卷積使用說明書<a href="#大核卷積使用說明書" class="hash-link" aria-label="大核卷積使用說明書的直接連結" title="大核卷積使用說明書的直接連結">​</a></h2>
<p>為了回答這個問題，作者有系統地探索了 CNN 的大核心設計，並總結了五個經驗指南。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="深度大核卷積仍然高效">深度大核卷積仍然高效<a href="#深度大核卷積仍然高效" class="hash-link" aria-label="深度大核卷積仍然高效的直接連結" title="深度大核卷積仍然高效的直接連結">​</a></h3>
<p>我們總會認為大核卷積的計算成本很高，因為核心大小會成倍增加 FLOPs 數量。</p>
<p>但是你只要改成深度卷積的形式，就可以大大克服這個缺點。</p>
<p>另一方面，由於現代 GPU 等平行運 算裝置對於深度卷積的支援性不足，記憶體存取成本增加。</p>
<p>現成的深度學習工具對於深度卷積的支援也不夠，如下表所示，可以看到 PyTorch 的實作方式的推論延遲非常高。</p>
<p><img decoding="async" loading="lazy" alt="img1" src="/assets/images/img1-222d061bc955a73aa4af9101cc77b839.jpg" width="1460" height="322" class="img_ev3q"></p>
<p>為了解決這個問題，作者重新發佈了高效的 PyTorch 實作，在這個實作中深度卷積的延遲次 49.5% 減少到 12.3%，大概上與 FLOPs 佔用成正比：</p>
<ul>
<li><a href="https://github.com/DingXiaoH/RepLKNet-pytorch" target="_blank" rel="noopener noreferrer"><strong>RepLKNet-pytorch</strong></a></li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="大核卷積十分依賴殘差連接">大核卷積十分依賴殘差連接<a href="#大核卷積十分依賴殘差連接" class="hash-link" aria-label="大核卷積十分依賴殘差連接的直接連結" title="大核卷積十分依賴殘差連接的直接連結">​</a></h3>
<p><img decoding="async" loading="lazy" alt="img2" src="/assets/images/img2-28c80f7f6e53734a93305913f115564a.jpg" width="1200" height="344" class="img_ev3q"></p>
<p>作者使用 MobileNet-V2 進行基準測試，因為它大量使用 DW 層並且有兩個已發布的變體（有或沒有殘差連接）。對於大內核對應部分，只需將所有 DW 3×3 層替換為 13×13 層。</p>
<p>上表顯示大核心將使用捷徑的 MobileNet-V2 的準確率提高了 0.77%。然而，如果沒有捷徑，大核心會將準確率降低到只有 53.98%。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>一如我們之前看過的論文，捷徑使模型成為由具有不同感受野的眾多模型組成的隱式集合，因此它可以從更大的最大感受野中受益，同時又不失去捕獲小規模模式的能力。</p></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="大核卷積需要重新參數化">大核卷積需要重新參數化<a href="#大核卷積需要重新參數化" class="hash-link" aria-label="大核卷積需要重新參數化的直接連結" title="大核卷積需要重新參數化的直接連結">​</a></h3>
<p><img decoding="async" loading="lazy" alt="img3" src="/assets/images/img3-7577b785adb3ce0e46040fbbe83e3056.jpg" width="1788" height="282" class="img_ev3q"></p>
<p>上表顯示直接將核心大小從 9 增加到 13 會降低準確性，而重新參數化可以解決此問題。</p>
<p>眾所周知，ViT 在小資料集上存在最佳化問題。一個常見的解決方法是引入卷積先驗，例如，在每個自注意力區塊中添加一個 DW 3×3 卷積，這與我們的類似。這些策略在網路之前引入了額外的平移等方差和局部性，使得在小資料集上更容易優化而不失通用性。</p>
<p>同樣與 ViT 的行為類似，作者也發現當預訓練資料集增加到 7,300 萬張影像時，可以省略重新參數化而不會降低效能。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="大核卷積明顯提升下游任務性能">大核卷積明顯提升下游任務性能<a href="#大核卷積明顯提升下游任務性能" class="hash-link" aria-label="大核卷積明顯提升下游任務性能的直接連結" title="大核卷積明顯提升下游任務性能的直接連結">​</a></h3>
<p><img decoding="async" loading="lazy" alt="img4" src="/assets/images/img4-7b24555c5e3d38eff197e8090f5a1f4f.jpg" width="1116" height="426" class="img_ev3q"></p>
<p>上表顯示，將 MobileNet V2 的核心大小從 3×3 增加到 9×9 將 ImageNet 精度提高了 1.33%，但 Cityscapes mIoU 提高了 3.99%。</p>
<p><img decoding="async" loading="lazy" alt="img5" src="/assets/images/img5-9d9cb49c653b1ea12b4d0c5c9dc4323b.jpg" width="1536" height="528" class="img_ev3q"></p>
<p>另外一個實驗野顯示了類似的趨勢：隨著核心大小從 [3, 3, 3, 3] 增加到 [31, 29, 27, 13]，ImageNet 精度僅提高了 0.96%，而 ADE20K 上的 mIoU 提高了 3.12%。這種現象表明，相似 ImageNet 分數的模型在下游任務中可能具有非常不同的能力。</p>
<p>作者造成這種現象的原因有二：</p>
<ol>
<li>大內核設計顯著增加了有效感受野（ERF）。許多工作已經證明「上下文」資訊（這意味著大型 ERF）對於許多下游任務（例如物件檢測和語義分割）十分重要。</li>
<li>大內核設計為網路帶來了更多的形狀偏差。簡而言之，ImageNet 圖片可以根據紋理或形狀進行正確分類。然而，人類主要根據形狀線索而不是紋理來識別物體，因此具有更強形狀偏差的模型可能會更好地轉移到下游任務。</li>
</ol>
<p>此外，最近的研究指出 ViT 具有強烈的形狀偏差，這部分解釋了為什麼 ViT 在遷移任務中超級強大。相較之下，在 ImageNet 上訓練的傳統 CNN 往往偏向紋理。</p>
<ul>
<li><a href="https://arxiv.org/abs/2105.07197" target="_blank" rel="noopener noreferrer"><strong>[21.05] Are convolutional neural networks or transformers more like human vision?</strong></a></li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="大核卷積對於小特徵圖的效果依然很好">大核卷積對於小特徵圖的效果依然很好<a href="#大核卷積對於小特徵圖的效果依然很好" class="hash-link" aria-label="大核卷積  對於小特徵圖的效果依然很好的直接連結" title="大核卷積對於小特徵圖的效果依然很好的直接連結">​</a></h3>
<p><img decoding="async" loading="lazy" alt="img6" src="/assets/images/img6-c9b037aa23e2c85cfeedfff047fdb9ee.jpg" width="1548" height="366" class="img_ev3q"></p>
<p>作者將 MobileNet V2 最後階段的 DW 卷積放大到 7×7 或 13×13，因此核心大小等於甚至大於特徵圖大小（預設為 7×7）。從上表可以看出，雖然大核卷積在 ImageNet 上的性能沒有提升，但對於下游任務的幫助仍然很大，在 Cityscapes 上提高了 mIoU 至 74.62%。</p>
<p>其中原因，作者認為當內核尺寸變大時，CNN 的平移等變性並不嚴格成立，相鄰空間位置的兩個輸出僅共享核心權重的一部分，即透過不同的映射進行變換，如下圖，這種機制可能就是大核卷積對於小特徵圖的效果依然很好的原因。</p>
<p><img decoding="async" loading="lazy" alt="img7" src="/assets/images/img7-9f8a761150efe82a433cb51afa5d93ca.jpg" width="1318" height="428" class="img_ev3q"></p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="解決問題">解決問題<a href="#解決問題" class="hash-link" aria-label="解決問題的直接連結" title="解決問題的直接連結">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="網路架構">網路架構<a href="#網路架構" class="hash-link" aria-label="網路架構的直接連結" title="網路架構的直接連結">​</a></h3>
<p><img decoding="async" loading="lazy" alt="img8" src="/assets/images/img8-13c0ba4be7a10e75433f67ebbe642d30.jpg" width="1140" height="972" class="img_ev3q"></p>
<p>基於上述的總結，作者提出了一個新的網路架構，RepLKNet。</p>
<p>首先，RepLKNet 的架構設計在初始階段就注重捕捉更多細節。這是通過多個卷積層來實現的。在第一個 3×3 和降採樣後，安排了一個 3×3 深度可分離卷積（DW）層來捕捉低階模式，接著是 1×1 卷積層，然後再使用另一個 DW 3×3 層進行降採樣。這樣的設計確保了初始階段能夠充分提取圖像中的細節信息。</p>
<p>其次，在每個階段（1-4）中，RepLKNet 包含多個 RepLK 區塊。這些區塊利用捷徑和 DW 大核心卷積來提升性能。每個 DW 卷積層使用 5×5 內核進行重新參數化，以捕捉更多細節。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>這個部分在上圖中沒有畫出來，但對性能提升很重要。這些區塊的設計使得網路能夠在不同階段保持高效的特徵提取和處理能力。</p></div></div>
<p>此外，為了增強非線性和跨通道的資訊通信，RepLKNet 引入了 ConvFFN 區塊。這些區塊由捷徑、Batch Normalization（BN）、兩個 1×1 卷積層和 GELU 激活函數組成，類似於 Transformer 和 MLP 中的前饋網路（FFN）。</p>
<p>相比於經典 FFN 使用 Layer Normalization 的做法，BN 可以更有效地融合到卷積操作中，提升推理效率。這一設計靈感來自於 Transformer 和 MLP 網路，並在卷積神經網路中得到成功應用。</p>
<p>在不同階段之間，RepLKNet 使用 Transition Blocks 來調整通道尺寸和進行降採樣。這些塊首先透過 1×1 卷積增加通道尺寸，然後使用 DW 3×3 卷積進行降採樣，確保特徵的充分提取和轉 換。這些過渡塊的設計使得網路在不同階段之間能夠平滑地過渡，保持信息的一致性和完整性。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="討論">討論<a href="#討論" class="hash-link" aria-label="討論的直接連結" title="討論的直接連結">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="大核卷積評估">大核卷積評估<a href="#大核卷積評估" class="hash-link" aria-label="大核卷積評估的直接連結" title="大核卷積評估的直接連結">​</a></h3>
<p><img decoding="async" loading="lazy" alt="img9" src="/assets/images/img9-4c86c7455c6b73f91609117353d26cd8.jpg" width="1326" height="442" class="img_ev3q"></p>
<p>為了評估大內核對 RepLKNet 的影響，作者在固定一些超參數的情況下，改變內核大小，觀察其在分類和語意分割上的效能。</p>
<p>結果顯示，在 ImageNet 上，內核大小從 3 增加到 13 可以提高準確性，但進一步增大內核並未帶來顯著提升。然而，在 ADE20K 上，將內核從 13 擴展到 31 帶來了更高的 mIoU，凸顯了大內核在下游任務中的優勢。</p>
<p>這表明，雖然大內核對部分任務的提升有限，但在特定應用中仍然具有重要價值。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="imagenet-上的性能">ImageNet 上的性能<a href="#imagenet-上的性能" class="hash-link" aria-label="ImageNet 上的性能的直接連結" title="ImageNet 上的性能的直接連結">​</a></h3>
<p><img decoding="async" loading="lazy" alt="img10" src="/assets/images/img10-f10a0f047adff656d27d98343a13eec3.jpg" width="1392" height="870" class="img_ev3q"></p>
<p>由於 RepLKNet 與 Swin 模型架構相似，作者進行了詳細比較。</p>
<p>在 ImageNet-1K 上，作者將 RepLKNet-31B 的訓練計劃擴展至 300 個 epoch，以確保公平比較。隨後，作者在 384×384 的輸入解析度下進行了 30 個 epoch 的微調，這樣的訓練成本遠低於從頭開始使用 384×384 訓練的 Swin-B 模型。</p>
<p>此外，作者在 ImageNet-22K 上預訓練了 RepLKNet-B 和 RepLKNet-L 模型，並在 ImageNet-1K 上進行微調。RepLKNet-XL 則在作者的私人半監督資料集 MegData73M 上進行預訓練。</p>
<p>作者還在相同的 2080Ti GPU 上，以批次大小 64 測試了模型的吞吐量。</p>
<hr>
<p>結果顯示，雖然非常大的內核不適用於 ImageNet 分類，但 RepLKNet 模型在準確性和效率之間取得了良好的平衡。例如，RepLKNet-31B 在僅使用 ImageNet-1K 訓練的情況下，達到了 84.8% 的準確率，比 Swin-B 高 0.3%，且運行速度快 43%。儘管 RepLKNet-XL 的 FLOPs 比 Swin-L 更高，但運行速度更快，這強調了大內核設計在效率上的優勢。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="大核-cnn-比深度小核模型有更大的-erf">大核 CNN 比深度小核模型有更大的 ERF<a href="#大核-cnn-比深度小核模型有更大的-erf" class="hash-link" aria-label="大核 CNN 比深度小核模型有更大的 ERF的直接連結" title="大核 CNN 比深度小核模型有更大的 ERF的直接連結">​</a></h3>
<p>作者已經證明，大型核心設計可以顯著提升 CNN 的性能。雖然大內核可以通過一系列小卷積來表示，例如，7×7 卷積可以分解為三個 3×3 內核的堆疊。鑑於此，自然會出現一個問題：</p>
<ul>
<li><strong>為什麼包含數十或數百個小卷積層（例如 ResNets）的傳統 CNN 的表現仍然不如大內核網路？</strong></li>
</ul>
<p>作者認為，單一大內核在獲得大感受野（ERF）方面比許多小內核更有效。根據有效感受野（ERF）理論，ERF 與 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>K</mi><msqrt><mi>L</mi></msqrt><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(K\sqrt{L})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1767em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9267em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord mathnormal">L</span></span></span><span style="top:-2.8867em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1133em"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 成正比，其中 K 是核大小，L 是深度，即層數。</p>
<p>換句話說，<strong>ERF 主要受內核大小影響，其次才是深度</strong>。</p>
<hr>
<p>此外，深度的增加會帶來最佳化難度。</p>
<p>人們總以為 ResNets 克服了這一困境，但是沒有。一些研究表明，ResNets 的行為類似於淺層網路的集合，即使深度增加，ResNets 的 ERF 仍然非常有限。</p>
<p>口說無憑，作者對此做  了一個實驗：</p>
<p><img decoding="async" loading="lazy" alt="img11" src="/assets/images/img11-d5c2db9c884456b97a2ae5b9e253a464.jpg" width="1544" height="494" class="img_ev3q"></p>
<p>為了視覺化 ERF，作者使用了一種簡單而有效的方法。</p>
<p>簡單來說，作者產生了一個聚合貢獻得分矩陣 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo stretchy="false">(</mo><mn>1024</mn><mo>×</mo><mn>1024</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">A (1024×1024)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">A</span><span class="mopen">(</span><span class="mord">1024</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">1024</span><span class="mclose">)</span></span></span></span>，並測量輸入影像上對應像素對最後一層產生的特徵圖中心點的貢獻。</p>
<p>意思就是：<strong>特徵圖中心點的貢獻，是由輸入影像上的哪些像素決定的。</strong></p>
<p>實驗結果顯示，在 ResNet 上，ERF 非常有限，就算深度增加也一樣。反觀在 RepLKNet 上，高貢獻像素分佈更均勻，ERF 更大。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="形狀偏差">形狀偏差<a href="#形狀偏差" class="hash-link" aria-label="形狀偏差的直接連結" title="形狀偏差的直接連結">​</a></h3>
<p><img decoding="async" loading="lazy" alt="img12" src="/assets/images/img12-2b8671d93a2ef1c0c860a7796a1c85bd.jpg" width="996" height="1028" class="img_ev3q"></p>
<p>作者指出，大內核設計帶來了更強的形狀偏差，這對於下游任務非常 重要。</p>
<p>作者獲取在 ImageNet-1K 或 22K 上預先訓練的 RepLKNet-31B 和 Swin-B 的形狀偏差（例如，基於形狀而不是紋理進行的預測的比例），以及兩個小內核基線 RepLKNet-3 和 ResNet-152。</p>
<p>從上圖中可以看出 RepLKNet-31B 的形狀偏差比 Swin Transformer 和小核心 CNN 高得多。作者認為形狀偏差與有效感受野密切相關，而不是與自注意力，同時這也解釋了：</p>
<ol>
<li>ViT 的高形狀偏差，因為採用全局注意力</li>
<li>Swin Transformer 的低形狀偏差，因為採用局部窗口內的注意力</li>
</ol>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="限制">限制<a href="#限制" class="hash-link" aria-label="限制的直接連結" title="限制的直接連結">​</a></h3>
<p>儘管大核心設計顯著提升了 CNN 在 ImageNet 和下游任務上的效能，但隨著資料和模型規模的增加，RepLKNet 開始在某些方面落後於 Swin Transformers。</p>
<p>作者目前尚不清楚這種差距是由次優的超參數調整造成的，還是由於數據和模型規模擴大時 CNN 的一些基本缺陷所致。</p>
<p>這裡留給後續的研究。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="結論">結論<a href="#結論" class="hash-link" aria-label="結論的直接連結" title="結論的直接連結">​</a></h2>
<p>在本研究中，作者重新審視了在設計 CNN 架構時長期被忽視的大型捲積核。</p>
<p>通過實驗，作者證明了使用幾個大核心而不是許多小核心，可以更有效地獲得更大的有效感受野，從而大幅提高 CNN 的性能，這一發現有助於縮小 CNN 和 ViT 之間的性能差距。</p>
<p>對於 CNN 社群，研究結果表明應該特別關注 ERF，這可能是獲得高性能的關鍵。對於 ViT 社群，研究表明大卷積核可以取代具有類似行為的多頭自注意力機制，這可能有助於理解自注意力的內在機制。</p>
<p>作者希望這項工作能夠促進兩個社群  之間的互相理解和進步，並激發更多的研究，以探索和優化深度學習模型的架構設計。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">最後<!-- -->由 <b>zephyr-sh</b> <!-- -->於 <b><time datetime="2024-09-10T06:14:17.000Z" itemprop="dateModified">2024年9月10日</time></b> <!-- -->更新</span></div></div></footer><div style="margin-top:3rem"> </div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件選項卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/papers/reparameterization/repvgg/"><div class="pagination-nav__sublabel">上一頁</div><div class="pagination-nav__label">[21.01] RepVGG</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/papers/reparameterization/mobileone/"><div class="pagination-nav__sublabel">下一頁</div><div class="pagination-nav__label">[22.06] MobileOne</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#巨無霸卷積核" class="table-of-contents__link toc-highlight">巨無霸卷積核</a></li><li><a href="#定義問題" class="table-of-contents__link toc-highlight">定義問題</a></li><li><a href="#大核卷積使用說明書" class="table-of-contents__link toc-highlight">大核卷積使用說明書</a><ul><li><a href="#深度大核卷積仍然高效" class="table-of-contents__link toc-highlight">深度大核卷積仍然高效</a></li><li><a href="#大核卷積十分依賴殘差連接" class="table-of-contents__link toc-highlight">大核卷積十分依賴殘差連接</a></li><li><a href="#大核卷積需要重新參數化" class="table-of-contents__link toc-highlight">大核卷積需要重新參數化</a></li><li><a href="#大核卷積明顯提升下游任務性能" class="table-of-contents__link toc-highlight">大核卷積明顯提升下游任務性能</a></li><li><a href="#大核卷積對於小特徵圖的效果依然很好" class="table-of-contents__link toc-highlight">大核卷積對於小特徵圖的效果依然很好</a></li></ul></li><li><a href="#解決問題" class="table-of-contents__link toc-highlight">解決問題</a><ul><li><a href="#網路架構" class="table-of-contents__link toc-highlight">網路架構</a></li></ul></li><li><a href="#討論" class="table-of-contents__link toc-highlight">討論</a><ul><li><a href="#大核卷積評估" class="table-of-contents__link toc-highlight">大核卷積評估</a></li><li><a href="#imagenet-上的性能" class="table-of-contents__link toc-highlight">ImageNet 上的性能</a></li><li><a href="#大核-cnn-比深度小核模型有更大的-erf" class="table-of-contents__link toc-highlight">大核 CNN 比深度小核模型有更大的 ERF</a></li><li><a href="#形狀偏差" class="table-of-contents__link toc-highlight">形狀偏差</a></li><li><a href="#限制" class="table-of-contents__link toc-highlight">限制</a></li></ul></li><li><a href="#結論" class="table-of-contents__link toc-highlight">結論</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class="footer__links"><a class="footer__link-item" href="/docs">Docs</a><span class="footer__link-separator">·</span><a class="footer__link-item" href="/papers/intro">Papers</a><span class="footer__link-separator">·</span><a class="footer__link-item" href="/blog">Blog</a><span class="footer__link-separator">·</span><a href="https://github.com/DocsaidLab" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><span class="footer__link-separator">·</span><a href="https://docsaid.org/blog/terms-of-service" target="_blank" rel="noopener noreferrer" class="footer__link-item">使用條款<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><span class="footer__link-separator">·</span><a href="https://docsaid.org/blog/privacy-policy" target="_blank" rel="noopener noreferrer" class="footer__link-item">隱私政策<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 DOCSAID.</div></div></div></footer></div>
</body>
</html>