<!doctype html><html lang=zh-hant dir=ltr class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-mrzscanner/model_arch" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.7.0"><title data-rh=true>模型設計 | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/docs/mrzscanner/model_arch><meta data-rh=true property=og:locale content=zh_hant><meta data-rh=true property=og:locale:alternate content=en><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=zh-hant><meta data-rh=true name=docsearch:language content=zh-hant><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-default-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-default-current><meta data-rh=true property=og:title content="模型設計 | DOCSAID"><meta data-rh=true name=description content=天下本無事，庸人自擾之。><meta data-rh=true property=og:description content=天下本無事，庸人自擾之。><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/docs/mrzscanner/model_arch><link data-rh=true rel=alternate href=https://docsaid.org/docs/mrzscanner/model_arch hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/docs/mrzscanner/model_arch hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/docs/mrzscanner/model_arch hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/docs/mrzscanner/model_arch hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/assets/css/styles.31895f42.css><script src=/assets/js/runtime~main.f8db30aa.js defer></script><script src=/assets/js/main.d2ceb6bf.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><link rel=preload as=image href=/img/docsaid_logo.png><link rel=preload as=image href=/img/docsaid_logo_white.png><div role=region aria-label=跳至主要内容><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>跳至主要内容</a></div><nav aria-label=主導航 class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label=切換導覽列 aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><div class=navbar__logo><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/docs/>開源專案</a><a class="navbar__item navbar__link" href=/papers/intro>論文筆記</a><a class="navbar__item navbar__link" href=/blog>部落格</a><a class="navbar__item navbar__link" href=/playground/intro>遊樂場</a><a class="navbar__item navbar__link" href=/aboutus>關於我們</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>繁體中文</a><ul class=dropdown__menu><li><a href=/docs/mrzscanner/model_arch target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=zh-hant>繁體中文</a><li><a href=/en/docs/mrzscanner/model_arch target=_self rel="noopener noreferrer" class=dropdown__link lang=en>English</a><li><a href=/ja/docs/mrzscanner/model_arch target=_self rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="搜尋 (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>搜尋</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-7ny38l ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label=回到頂部 class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label=文件側邊欄 class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/docs/>開源專案</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/docs/model-training-guide/>模型訓練指南</a><button aria-label="展開側邊欄分類 '模型訓練指南'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/docs/autotraderx/>AutoTraderX</a><button aria-label="展開側邊欄分類 'AutoTraderX'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/docs/capybara/>Capybara</a><button aria-label="展開側邊欄分類 'Capybara'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/docs/docaligner/>DocAligner</a><button aria-label="展開側邊欄分類 'DocAligner'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/docs/docclassifier/>DocClassifier</a><button aria-label="展開側邊欄分類 'DocClassifier'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/docs/gmailsummary/>GmailSummary</a><button aria-label="展開側邊欄分類 'GmailSummary'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/docs/mrzscanner/>MRZScanner</a><button aria-label="收起側邊欄分類 'MRZScanner'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/docs/mrzscanner/intro>介紹</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/docs/mrzscanner/installation>安裝</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/docs/mrzscanner/quickstart>快速開始</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/docs/mrzscanner/advance>進階設定</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/docs/mrzscanner/model_arch>模型設計</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/docs/mrzscanner/benchmark>評估模型</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/docs/mrzscanner/dataset>資料集說明</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/docs/mrzscanner/summit_data>資料集提交</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/docs/mrzscanner/reference>參考文獻</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/docs/nginx-notes/>Nginx Notes</a><button aria-label="展開側邊欄分類 'Nginx Notes'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/docs/wordcanvas/>WordCanvas</a><button aria-label="展開側邊欄分類 'WordCanvas'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul></nav><button type=button title=收起側邊欄 aria-label=收起側邊欄 class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=頁面路徑><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label=主頁面 class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/docs/mrzscanner/><span itemprop=name>MRZScanner</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>模型設計</span><meta itemprop=position content=2></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">本頁導覽</button></div><div class="theme-doc-markdown markdown"><header><h1>模型設計</h1></header>
<p>天下本無事，庸人自擾之。</p>
<p>對，我們就是在找自己的麻煩，一邊覺得很煩，一邊又覺得有趣。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=二階段辨識模型>二階段辨識模型<a href=#二階段辨識模型 class=hash-link aria-label=二階段辨識模型的直接連結 title=二階段辨識模型的直接連結>​</a></h2>
<p>二階段模型指的是將 MRZ 辨識分為兩個階段：定位與辨識。</p>
<p>根據這個思路，我們可以開始著手設計相關模型，首先來看看定位模型。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=定位模型>定位模型<a href=#定位模型 class=hash-link aria-label=定位模型的直接連結 title=定位模型的直接連結>​</a></h3>
<p>MRZ 區域的定位大概可以分成兩個方向:</p>
<ol>
<li>
<p><strong>定位 MRZ 區域角點：</strong></p>
<div align=center><figure style=width:50%><p><img decoding=async loading=lazy alt="定位 MRZ 區域角點" src=/assets/images/img2-4c688adc6a2092ef627a98e50b3f3751.jpg width=1237 height=1384 class=img_ev3q>
<figcaption>圖片來源：<a href=http://l3i-share.univ-lr.fr/MIDV2020/midv2020.html target=_blank rel="noopener noreferrer"><strong>MIDV-2020 合成資料集</strong></a></figcaption><p></figure></div>
<p>這和之前我們做過的文件定位的專案類似，只是這裡把文件換成 MRZ 區域。</p>
<p>不同的地方在於文件定位的角點是「真實」存在於圖面上，不需要模型去「憑空想像」出一個角點。反觀 MRZ 區域，我們需要模型去「猜測」出這個角點。</p>
<p>事實證明，用這種方式做出來的模型很不穩定，只要你稍微晃動一下護照，模型預測的角點就會在 MRZ 區域周邊到處亂跑。</p>
<hr>
</li>
<li>
<p><strong>分割 MRZ 區域：</strong></p>
<div align=center><figure style=width:50%><p><img decoding=async loading=lazy alt="分割 MRZ 區域" src=/assets/images/img3-1e876a97bdc10e5af658d51578f1ca29.jpg width=1237 height=1384 class=img_ev3q>
<figcaption>圖片來源：<a href=http://l3i-share.univ-lr.fr/MIDV2020/midv2020.html target=_blank rel="noopener noreferrer"><strong>MIDV-2020 合成資料集</strong></a></figcaption><p></figure></div>
<p>這個方法就比較穩定了，因為我們可以直接用分割模型去預測 MRZ 區域的範圍。MRZ 區域上的文字也是真實存在於圖面上，不需要模型做「多餘」的臆測。這樣一來，我們就可以直接將 MRZ 區域分割出來，不需要再去擔心角點的問題。</p>
</li>
</ol>
<hr>
<p>我們採用的是分割的方法。</p>
<p>在真實使用的場景中，使用者所拿的護照必然帶有一些傾斜，因此我們需要對 MRZ 區域進行校正，使其變成一個正確的矩形。</p>
<p>損失函數的部分我們參考了一份綜述性的論文：</p>
<ul>
<li><a href=https://arxiv.org/abs/2006.14822 target=_blank rel="noopener noreferrer"><strong>[20.06] A survey of loss functions for semantic segmentation</strong></a></li>
</ul>
<p>在上面這篇論文中，針對過去幾年間所提出的各種用於分割的損失函數進行統一的比較和介紹，並且針對現有的問題提出一個解決方案，也就是：<strong>Log-Cosh Dice Loss</strong>。</p>
<p>有興趣的讀者可以參考這篇論文，這裡就不再贅述了。</p>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt="Log-Cosh Dice Loss" src=/assets/images/img4-e16824cd8031318fd44188fabe8737b6.jpg width=1224 height=720 class=img_ev3q></figure></div>
<p>在我們的實驗中，單純使用 <code>Log-Cosh Dice Loss</code> 的效果差強人意，最後還要搭配像素分類損失 <code>CrossEntropyLoss</code> 以及像素回歸損失 <code>SmoothL1Loss</code> 來進行訓練。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=辨識模型>辨識模型<a href=#辨識模型 class=hash-link aria-label=辨識模型的直接連結 title=辨識模型的直接連結>​</a></h3>
<p>辨識模型就比較簡單了，因為我們已經將 MRZ 區域分割出來，只需要將這個區域丟進文字辨識模型，就可以得到最終的結果。</p>
<p>在這個階段，我們可以有幾個設計方向：</p>
<ol>
<li>
<p><strong>切分字串，逐一辨識：</strong></p>
<p>有些 MRZ 是兩行文字，例如 TD2 和 TD3 格式；有些 MRZ 是三行文字，例如 TD1 格式。我們可以將這些文字逐一切分，然後進行辨識。</p>
<p>辨識模型需要處理的就是將一串文字影像轉成文字輸出，可以用的方法有很多，例如早期流行的 CRNN+CTC，或是現在比較流行的 CLIP4STR 之類的。</p>
<p>這個方法有很多缺點，例如 MRZ 區域還分成兩行或三行因此需要增加判定邏輯，或是某些證件的 MRZ 間距窄小，導致文字難以區分等問題。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>如果你對相關論文有興趣，可以參考我們之前讀過的文章：<ul>
<li><a href=https://docsaid.org/papers/text-recognition/crnn/ target=_blank rel="noopener noreferrer"><strong>[15.07] CRNN: 我全都要！</strong></a></li>
<li><a href=https://docsaid.org/papers/text-recognition/clip4str/ target=_blank rel="noopener noreferrer"><strong>[23.05] CLIP4STR: 多模態的祝福</strong></a></li>
</ul></div></div>
</li>
</ol>
<hr>
<ol start=2>
<li>
<p><strong>整張 MRZ 裁切影像一起辨識：</strong></p>
<p>由於 MRZ 區域的長寬比例差距不大，所以我們完全可以將整張 MRZ 區域裁切下來，然後一次辨識整張影像。這種情況下，特別適合使用 Transformer 的模型來解決這個問題。</p>
<p>舉例來說，如果你只要使用 Transformer Encoder 的架構，那模型設計可以是這樣：</p>
<div align=center><figure style=width:50%><p><img decoding=async loading=lazy alt="Transformer Encoder" src=/assets/images/img6-28f672ed73db01e2240821ea41a65085.jpg width=2108 height=2374 class=img_ev3q></figure></div>
<p>由於自注意力機制的關係，因此可能會有多個 Token 同時指向同一個文字的情況，這時候如果使用一般的解碼方式，可能會讓模型感到困惑：</p>
<blockquote>
<p>明明就是這個文字的影像，為什麼要解碼成另外一個文字？</p>
</blockquote>
<p>經過我們的實驗，在這裡使用 CTC 的方式進行文字解碼的效果會比較好，因為每個 Token 都來自於「某個」文字區域的影像，我們只需要在最後階段對輸出結果合併，就可以得到最終的文字結果。</p>
<hr>
<p>當然，考慮到你可能不喜歡 CTC，覺得那是個麻煩的東西，那也可以考慮採用 Encoder-Decoder 的架構，模型設計可以是這樣：</p>
<figure><p><img decoding=async loading=lazy alt="Transformer Encoder-Decoder" src=/assets/images/img7-9c8575fcb7e63fceaf879b803032fd90.jpg width=3281 height=2300 class=img_ev3q></figure>
<p>這種方式可以直接解碼字串，不需要再經過一層 CTC，因為輸入 Decoder 的 token 就是對文字的查詢，每個 token 都負責找出對應順序的文字。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>這裡的 Decoder 可以直接平行輸出，不需要用自回歸的方式。<p>仔細想想，我們使用自回歸的原因是因為我們需要「基於前一次的預測結果，來進行下一個預測」，但是在這裡顯然並不需要這種操作。<p>因為每個 MRZ 的文字都是獨立的，不論第一個位置預測的文字是什麼，都不會影響第二個位置的預測結果。所有客觀結果都已經在 Encoder 的輸出結果內，Decoder 的工作就是負責把他們查詢出來而已。<p>當然，光說不練是不行的，我們也有實際測試過平行輸出和自回歸的訓練方式，結果是平行輸出的方式收斂速度更快，跑分更高，泛化能力也更好。</div></div>
</li>
</ol>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=誤差傳播>誤差傳播<a href=#誤差傳播 class=hash-link aria-label=誤差傳播的直接連結 title=誤差傳播的直接連結>​</a></h3>
<p>這時候其實可以回過頭去討論角點的問題。</p>
<p>所有二階段的模型都會面臨到一個共同的問題：<strong>誤差傳播</strong>。</p>
<p>我們都相信這世界上不存在 100% 準確的模型，因為我們永遠都無法對統計母體進行建模，所以凡規則必有例外，凡模型必有誤差。不管上面選擇哪種方式，最後都會面臨到同樣的困難：</p>
<ul>
<li><strong>角點估計不準確</strong></li>
</ul>
<p>正因為角點估計不準確，導致校正後的 MRZ 區域不準確；又因為 MRZ 區域不準確，導致文字辨識的不準確，如此這般，成為一個誤差傳播的標準教材。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=單階段辨識模型>單階段辨識模型<a href=#單階段辨識模型 class=hash-link aria-label=單階段辨識模型的直接連結 title=單階段辨識模型的直接連結>​</a></h2>
<p>單階段的首要困難就是多尺度特徵。</p>
<p>MRZ 的區域會隨著使用者拍攝角度的不同而有所變化，這就意味著我們在開始偵測文字之前，必須先對圖片進行多尺度的處理。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=模型架構>模型架構<a href=#模型架構 class=hash-link aria-label=模型架構的直接連結 title=模型架構的直接連結>​</a></h3>
<p><img decoding=async loading=lazy alt=single-stage src=/assets/images/img9-b0fc93a05449de8d10a858a1664eb683.jpg width=8396 height=4221 class=img_ev3q></p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=backbone>Backbone<a href=#backbone class=hash-link aria-label=Backbone的直接連結 title=Backbone的直接連結>​</a></h3>
<p><img decoding=async loading=lazy alt=backbone src=/assets/images/img8-3d70aa43813018cb370af597d75d7001.jpg width=1324 height=504 class=img_ev3q></p>
<p>剛好最近 Google 發布了新論文：<strong>MobileNet-V4</strong>，這個模型有針對移動裝置上的效能進行優化，這對我們來說是一個很好的消息，直接拿來用。</p>
<p>這次我們就用它來做為我們的 Backbone，使用 timm 的預訓練權重，輸入影像尺寸設定為 512 x 512 的 RGB 影像。</p>
<ul>
<li><a href=https://docsaid.org/papers/lightweight/mobilenet-v4/ target=_blank rel="noopener noreferrer"><strong>[24.04] MobileNet-V4: 時隔五年的傳承</strong></a></li>
<li><a href=https://github.com/huggingface/pytorch-image-models target=_blank rel="noopener noreferrer"><strong>huggingface/pytorch-image-models</strong></a></li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>提示</div><div class=admonitionContent_BuS1><p>經過測試，輸入影像解析度為 512 x 512 時，每個 MRZ 的文字大小大約是 4~8 個像素，若持續降低解析度，MRZ 區域的文字會有模糊的情況，導致辨識效果不佳。</div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=neck>Neck<a href=#neck class=hash-link aria-label=Neck的直接連結 title=Neck的直接連結>​</a></h3>
<p><img decoding=async loading=lazy alt=neck src=/assets/images/img10-34e38a23a3eaa918e094bcba71530b38.jpg width=1322 height=500 class=img_ev3q></p>
<p>為了更好地融合多尺度的特徵，我們引入了 BiFPN。通過上下文信息的雙向流動，增強了特徵的表達能力。BiFPN 會產生一系列尺度豐富且語義強的特徵圖，這些特徵圖對於捕捉不同尺度的對象非常有效，並對最終的預測精度有正面影響。</p>
<p>我們在消融實驗的時候，有試著移除這個部分，改成直接使用 Backbone 輸出的特徵圖，但 Train 不起來。</p>
<ul>
<li><a href=https://docsaid.org/papers/feature-fusion/bifpn/ target=_blank rel="noopener noreferrer"><strong>[19.11] EfficientDet: BiFPN 才是本體</strong></a></li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=patchify>Patchify<a href=#patchify class=hash-link aria-label=Patchify的直接連結 title=Patchify的直接連結>​</a></h3>
<p>前面都是中規中矩的常規操作。</p>
<p>接著都是我們自己的天馬行空的嘗試了。</p>
<hr>
<p>首先我們得把每個階段的特徵圖轉換成 Transformer 的輸入格式，這裡我們使用一般的卷積操作，將特徵圖轉換成一個個的 Patch。</p>
<p>以下是我們的一些設定：</p>
<ol>
<li>
<p><strong>Patch Size: 4 x 4。</strong></p>
<p>我們手動測量一下 MRZ 區域內的文字大小，發現小字大概是 4~8 個像素，再小就看不清楚文字內容。大字的部分尺寸不固定，根據拍攝距離來決定。因此我們考量到這個因素，將 Patch Size 設定為 4 x 4。</p>
</li>
<li>
<p><strong>每個特徵圖有一組對應的 Patch Embedding 和 Position Embedding。</strong></p>
<p>由於每個特徵圖的尺度不一樣，所以不能共用同一組 Embedding，這樣會導致不同尺度的特徵圖無法正確地進行信息交換。我們有考慮過設計一組共享的 Embedding，但實作起來較複雜，我們暫時放棄這個想法。</p>
<p>Patch Embedding 的部分，我們有測試過 Shared Weighted 的方式，就是所有特徵圖都共用同一個 Conv2d 來進行 Embedding，但效果很差。</p>
</li>
</ol>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=cross-attention>Cross-Attention<a href=#cross-attention class=hash-link aria-label=Cross-Attention的直接連結 title=Cross-Attention的直接連結>​</a></h3>
<p>最後我們使用了 Cross-Attention 的方式來進行文字辨識。</p>
<p>我們隨機初始化了 93 個 Token。</p>
<ul>
<li><strong>為什麼是 93 個？</strong></li>
</ul>
<p>這是考慮到 MRZ 最長的格式為 TD1，共有 90 個字元。又 TD1 有三行，因此需要 2 個「分隔」字元。接著還需要一個「結束」字元，共 93 個。</p>
<p>連接字元的部分我們使用 <code>&</code>，結束字元的部分我們使用 <code>[EOS]</code>。如果有多餘的位置，我們會以 <code>[EOS]</code> 作為邊界，後續字元不進行監督，模型想怎麼預測就怎麼預測，我們不會再去理會。</p>
<hr>
<p>Transformer decoder 的部分，我們給的基本設定是這樣：</p>
<ul>
<li>維度： 256</li>
<li>層數： 6</li>
<li>注意力頭： 4</li>
<li>Dropout： 0</li>
<li>Normalization： Post-LN</li>
</ul>
<p>這個架構的主要設計理念：我們幫 Decoder 準備好一個「多尺度」的特徵空間，讓 Decoder 可以自由地選擇不同尺度的特徵來進行文字辨識。其中我們不需要關心文字在影像中的位置，這個問題全權交給模型自己想辦法解決。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=還有更多>還有更多<a href=#還有更多 class=hash-link aria-label=還有更多的直接連結 title=還有更多的直接連結>​</a></h3>
<p>在整個實驗過程中，我們有留下一點實驗紀錄，我們一併寫在這裡，或許能對你有所幫助。</p>
<ol>
<li>
<p><strong>維度 64 和 128 的模型都可以收斂，但每減半一次維度，模型的收斂速時間加倍。</strong></p>
<p>我們的訓練設備是 RTX4090，訓練一個 256 維度的模型需要 50 小時左右；訓練一個 128 維度的模型需要 100 小時左右；訓練一個 64 維度的模型需要 200 小時左右。</p>
<p>為什麼沒有試 512 維度？因為這樣會讓模型變得太大，就超過 100 MB 了，這個大的模型不是我們想要的。</p>
</li>
</ol>
<hr>
<ol start=2>
<li>
<p><strong>新增額外的分支，例如 Polygon 或是文字的中心點位置等，可以提升模型的收斂速度。</strong></p>
<p>但是不好用啊！收集資料已經很困難，還要找到資料的 MRZ 區域，還要標記這些資料，顯然不適合推廣。</p>
<p>最後收斂效果類似，對整體的貢獻不大。</p>
</li>
</ol>
<hr>
<ol start=3>
<li>
<p><strong>移除 Neck。</strong></p>
<p>還是可以收斂，但是時間多三倍，得仔細想想。</p>
</li>
</ol>
<hr>
<ol start=4>
<li>
<p><strong>移除位置編碼。</strong></p>
<p>不收斂。</p>
</li>
</ol>
<hr>
<ol start=5>
<li>
<p><strong>調整 Weight Decay 從 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msup><mn>10</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding=application/x-tex>10^{-5}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8141em></span><span class=mord>1</span><span class=mord><span class=mord>0</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8141em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span> 到 <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msup><mn>10</mn><mrow><mo>−</mo><mn>2</mn></mrow></msup></mrow><annotation encoding=application/x-tex>10^{-2}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8141em></span><span class=mord>1</span><span class=mord><span class=mord>0</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8141em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>。</strong></p>
<p>提早收斂，但是泛化能力降低。</p>
<p>小模型天生帶有一定的正規化效果，因此不需要太強的 Weight Decay。</p>
</li>
</ol>
<hr>
<ol start=6>
<li>
<p><strong>使用 Pre-LN。</strong></p>
<p>提早收斂，但是泛化能力降低。</p>
<p>Pre-LN 會一定程度地降低模型深度，因此對於小模型來說，不能再降了。</p>
</li>
</ol>
<hr>
<ol start=7>
<li>
<p><strong>增加更多影像增強。</strong></p>
<p>為了加快實驗的腳步，我們控制 MRZ 圖像的旋轉角度在正負 45 度之間。</p>
<p>我們嘗試使用全方位的旋轉和更多其他影像增強，但這個規模的模型承受不起這麼多的影像增強，直接導致不收斂。</p>
</li>
</ol>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=結論>結論<a href=#結論 class=hash-link aria-label=結論的直接連結 title=結論的直接連結>​</a></h2>
<p>我們認為目前單階段的模型設計，還少了一些關鍵性的元件，這個部分我們之後會持續閱讀更多的文獻，並且進行更多的實驗。</p>
<p>或許加大模型規模肯定是最有效的方式。難就難在該如何用「輕量」的參數規模，來滿足上面所有的需求，這也是我們接下來需要思考的問題。</p>
<p>但之前我們也說了，這個題目實際上用「二階段」的解決方案就可以穩定的解決幾乎所有場景。如果你真的想做的話，我們還是會建議你回過頭去開發一個二階段的模型，這樣會省去很多不必要的麻煩。</div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>最後<!-- -->由 <b>zephyr-sh</b> <!-- -->於 <b><time datetime=2025-02-23T03:20:01.000Z itemprop=dateModified>2025年2月23日</time></b> <!-- -->更新</span></div></div><div style=margin-top:3rem> </div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label=文件選項卡><a class="pagination-nav__link pagination-nav__link--prev" href=/docs/mrzscanner/advance><div class=pagination-nav__sublabel>上一頁</div><div class=pagination-nav__label>進階設定</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/docs/mrzscanner/benchmark><div class=pagination-nav__sublabel>下一頁</div><div class=pagination-nav__label>評估模型</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#二階段辨識模型 class="table-of-contents__link toc-highlight">二階段辨識模型</a><ul><li><a href=#定位模型 class="table-of-contents__link toc-highlight">定位模型</a><li><a href=#辨識模型 class="table-of-contents__link toc-highlight">辨識模型</a><li><a href=#誤差傳播 class="table-of-contents__link toc-highlight">誤差傳播</a></ul><li><a href=#單階段辨識模型 class="table-of-contents__link toc-highlight">單階段辨識模型</a><ul><li><a href=#模型架構 class="table-of-contents__link toc-highlight">模型架構</a><li><a href=#backbone class="table-of-contents__link toc-highlight">Backbone</a><li><a href=#neck class="table-of-contents__link toc-highlight">Neck</a><li><a href=#patchify class="table-of-contents__link toc-highlight">Patchify</a><li><a href=#cross-attention class="table-of-contents__link toc-highlight">Cross-Attention</a><li><a href=#還有更多 class="table-of-contents__link toc-highlight">還有更多</a></ul><li><a href=#結論 class="table-of-contents__link toc-highlight">結論</a></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/docs>開源專案</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/papers/intro>論文筆記</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/blog>部落格</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/terms-of-service>使用條款</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/privacy-policy>隱私政策</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/become-an-author>成為作者</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/worklog>工作日誌</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2025 DOCSAID.</div></div></div></footer></div>