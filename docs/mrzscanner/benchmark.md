---
sidebar_position: 6
---

# 評估模型

我們採用了兩個評估指標，用來檢視模型的性能：

## 標準化編輯距離

英文是 Average Normalized Levenshtein Similarity，簡稱 ANLS。這個指標用來衡量模型預測的文字與真實文字之間的相似度。

它基於 Levenshtein 編輯距離計算，即將預測結果轉換為真實值所需的最少編輯操作（插入、刪除、替換）的數量，並進行標準化，使其值介於 0 到 1 之間，數值越高代表預測結果越接近真實答案。

舉個例子：

- 真實文字：`hello`
- 預測文字：`helo`

Levenshtein 距離 = 1（少了一個 `l`），計算公式為：

$$
\text{ANLS} = 1 - \frac{\text{Levenshtein Distance}}{\max(\text{len}(y_{\text{true}}), \text{len}(y_{\text{pred}}))}
$$

- 標準化後的相似度計算後為 0.8，表示預測結果與真實值的相似度較高。

這個指標特別適用於 OCR 場景，當部分錯誤的辨識仍然可接受時，可作為評估標準。

## 全圖正確率

這就是我們常看到的 Accuracy，這個指標用來衡量模型對整張圖片的辨識正確率。如果模型預測的所有文字完全正確，則該圖片視為「正確辨識」，否則視為「錯誤」。

Accuracy 以百分比表示，計算方式為正確辨識圖片數除以總測試圖片數。

**範例**：

- 測試圖片數量：100 張
- 預測完全正確的圖片數量：85 張
- Accuracy = (85 / 100) × 100% = 85%

這個指標適合用於需要高精度的應用，例如表單處理或身份辨識，因為任何錯誤的字元都可能影響結果的可用性。

:::tip
**為什麼不使用「單字正確率」？**

另一種常見的評估方式是 **單字正確率**（Character Accuracy 或 Word Accuracy），即計算模型預測的文字與真實文字相比，單字級別的準確度。可是單字正確率在某些應用場景下並不理想：

1. **輕微錯誤導致評分極低**：

   - 真實文字：`hello world`
   - 預測文字：`helo world`

   由於 `hello` 被錯誤辨識為 `helo`，即使只有一個字母錯誤，這個單詞仍然被視為錯誤，導致單字正確率驟降。

   ***

2. **單字偏移影響極大**：

   - 真實文字：`hello world`
   - 預測文字：`ello horld`

   這種情況下，單字對齊發生錯誤，導致兩個詞都被判為錯誤，即使大部分字母仍然正確，導致評分過低。

   ***

3. **無法量化部分正確的預測**：

   - 真實文字：`123456`
   - 預測文字：`12345`

   在某些應用場景，我們更關心模型的輸出是否「接近」正確答案，而非完全相同。

   如果採用單字正確率，則會認為整個單詞 `123456` 錯誤，導致評分非常低。但在許多應用中，這樣的輸出仍然可接受。

   ***

因此，在我們的專案中，我們選擇不使用單字正確率，而是使用全圖正確率搭配 ANLS 作為評估指標。
:::

## 評估數據集

在這個專案中，模型的評估面臨極大的挑戰。

首先，這個題目沒有標準的數據集可供參考，因為涉及到個人隱私資料，沒有誰可以堂而皇之地提供一個公開的數據集。因此，我們只能自行蒐集數據並逐一標註，但自行蒐集的數據集缺乏公信力，無法作為權威標準：

> 若每個人都自行收集數據，然後聲稱模型準確度達到 100%，你敢信？

另外，在這個領域中有名的數據集不外乎就是 **MIDV**（Mobile Identity Document Video dataset）了，這是一個包含各種護照、居留證等機讀證件的數據集，但它還是有其局限性：

1. **數據量不足**：**MIDV** 數據集規模有限，且大多是基於合成樣本，無法代表真實世界的應用場景。
2. **不是針對 MRZ 辨識**：**MIDV** 包含了多種證件，主要目的用於證件定位，其中沒有提供 MRZ 的文字定位與辨識標註。

雖然在 **MIDV-2020** 版本中已經可以找到 MRZ 的文字標註，但仍缺乏定位區域資訊，無法作為完整的評估數據集。

目前，我們手上有一個小規模的私有測試集，主要來自認識的朋友，包含約 300 張護照與居留證。這個測試集用於內部測試，以幫助我們即時評估模型的表現。但如前所述，由於資料涉及個人隱私，無法公開完整的測試數據。

如果你有興趣，可以自行收集數據，並使用我們的模型進行測試。
