---
sidebar_position: 1
---

# 介紹

在過去的專案經驗中，分類模型可說是最常見的機器學習任務。

分類模型沒有什麼困難的地方，首先我們會搭建一個 Backbone，接著將最後的輸出映射至多個特定的類別，最後經過幾個評估的指標來評估模型的好壞，通常是準確率、召回率、F1-Score 等等。

儘管這聽起來直截了當，但在實際應用上，我們會遇到一些問題，這邊以本專案的題目來舉例：

- **類別定義**

  在分類任務中，如果我們定義的類別本身相似度很高，那麼模型可能會難以區分這些類別。例如：「某公司 A 保險文件」和「某公司 B 保險文件」。這兩個類別都是某公司的文件，其中的差異性可能不大，從而導致模型難以區分這兩個類別。

- **資料不平衡**

  在大部分的場景中，資料收集可能是最困難的問題，尤其是牽涉到個人資訊的文件。而資料不平衡又會導致模型對於少數類別的預測能力不足。

- **資料擴充**

  在我們的生活中，充斥著大量的文件，我們隨時都想新增更多的文件類別。

  但是每次新增一個類別，整個模型都需要重新訓練或微調，成本非常高，其中可能包含但不限於：資料收集、標記、重新訓練、重新評估、部署等，所有流程都需要重新進行。

- **類別子標籤**

  客戶的需求是天馬行空的。

  我們假設存在某個客戶，而該客戶先是定義了一種文件類型，先假設它叫做 A 文件。接著客戶希望針對 A 文件，提供更多的子標籤，例如：

  - 污損的 A 文件
  - 反光的 A 文件
  - 第一代格式的 A 文件
  - 第二代格式的 A 文件
  - ...

  先不論每次新增一個子標籤，都要重跑一次模型。

  以模型工程的角度來說，如果將這些標籤視為獨立的類別，那是「不合理」的，因為他們都是基於 A 文件；如果將這些標籤視為多類別的問題，那也是「不合理」的，因為不同主文件格式下對應的子標籤是不同的。

:::tip
於是你接著想：既然解決不了問題，那就解決提出問題的人！

> 不可以！

這是一個機器學習的問題。
:::

## 度量學習

跳出文件分類的題目，你會發現這個問題其實在講的就是：**度量學習（Metric Learning）**。

度量學習主要目的是透過學習最優的距離測量，來衡量樣本之間的相似性。在傳統的機器學習領域中，度量學習通常涉及將資料從原始特徵空間映射到一個新的特徵空間，在這個空間中，相似的對象距離更近，而不相似的對象距離更遠。這個過程通常是透過學習一個距離函數來實現的，這個距離函數能夠更好地反映樣本間的真實相似度。

如果你看完上段話，還是不明白，用一句話來總結：**度量學習是一種學習相似性的方法**。

### 應用場景

度量學習有個非常知名的應用場景：**人臉辨識（Face Recognition）**。

如同我們剛才提到的困境，人臉的數量持續增加，我們根本無法一直重新訓練模型。因此，使用度量學習的架構，可以幫助我們學習一個更好的距離函數，從而提高人臉辨識的準確性。

## 解決問題

雖然不是每個分類問題都適合將高度上升到度量學習的層面，但在這個專案中，度量學習這個武器，確實可以幫助我們彌平上面提到的那些障礙。

- **障礙一：類別定義**

  我們學習的目標是更好的距離函數，這個距離函數可以幫助我們更好地區分相似的類別。所以我們不再需要定義類別。那些我們想分類的對象，最後都只會成為一個註冊資料。

- **障礙二：類別資料不平衡**

  我們不再需要大量收集資料，因為我們的模型不再依賴於大量的樣本。我們只需要一個樣本，這個樣本就是我們的註冊資料。而其他部分可以透過其他訓練資料來進行訓練。

- **障礙三：類別擴充**

  擴充類別只需要註冊新的資料，而不需要重新訓練模型。這樣的設計可以大大減少訓練的成本。

- **障礙四：類別子標籤**

  這個問題在度量學習的框架下，可以很好地解決。我們可以將子標籤視為一個新的註冊資料，這樣就不會影響到原本的模型。子標籤和主標籤之間在特徵空間中的距離可能會很近，但又不完全一樣，因此可以很好地區分這兩個類別。

---

我們首先引入了度量學習的架構：[**PartialFC**](https://arxiv.org/abs/2203.15565)，這個架構結合了 [**CosFace**](https://arxiv.org/abs/1801.09414) 和 [**ArcFace**](https://arxiv.org/abs/1801.07698) 等技術，使其能在沒有預先設定大量分類的情況下，精準地進行分類。

接著，我們在更進一步的實驗中，引入了 [**ImageNet-1K 資料集**](https://www.image-net.org/) 和 [**CLIP 模型**](https://arxiv.org/abs/2103.00020)。我們使用 ImageNet-1K 資料集作為基底，將每張影像視為一個類別，透過這個操作，可以將分類的類別數量擴充到約 130 萬類，給予模型更豐富的圖面變化，增加資料多樣性。

在 TPR@FPR=1e-4 的比較基準中，比起原有的基線模型效果提高了約 4.1%（77.2%->81.3%）。若在 ImageNet-1K 的基礎上再引入 CLIP 模型，在訓練的過程中進行知識蒸餾，則效果可以在 TPR@FPR=1e-4 的比較基準中再往上提升約 4.6%（81.3%->85.9%）。

在最新的實驗中，我們嘗試結合 BatchNorm 和 LayerNorm，並且取得可喜的結果，在原本的 CLIP 蒸餾模型基礎上，將 TPR@FPR=1e-4 的效果提高了約 4.4%（85.9%->90.3%）。

## 為什麼不用對比學習？

對比學習（Contrastive Learning）和度量學習都是用來學習樣本之間相似性的方法。

那為什麼這次我們沒有選擇對比學習呢？

不是因為它不好，只是我們認為，這個階段先用度量學習比較合適。

### 對比學習的好處

對比學習最大的優勢是它能很好地處理無標籤的資料。對於資料標記困難或資料規模非常大的場景，它簡直就是「救命神器」。

另外，它還很擅長學到通用的特徵，這些特徵不僅能用在分類任務上，甚至還能跨任務應用，比如目標檢測、語義分割等等。

### 但也有缺點

首先，對比學習很依賴負樣本的設計。如果負樣本的選取不好，太簡單或者太複雜，模型的訓練效果都可能大打折扣。

另外，對比學習的資源需求也不低，因為需要大量的負樣本來幫助模型理解「什麼是不同」，這導致計算成本很高。特別是需要相對大的訓練批量來提供足夠多的負樣本，這對我們的硬體資源是個挑戰。

還有，對比學習也受限於無標籤的自監督設計，因此很難讓模型學到非常精確（例如萬分之一的比對錯誤率）的特徵。這個部分我們可以看到在人臉辨識的榜單上，度量學習的方法還是佔據了主導地位。

---

總之，我們只是先選了「度量學習」來解決問題，未來，我們會安排時間來探索對比學習的應用，甚至可能結合兩者的優點，讓模型既能學到通用特徵，又能具備強大的相似性判斷能力。

## 最後

在測試中，我們的模型在基於萬分之一（TPR@FPR=1e-4）錯誤率的條件下，展示了超過 90% 的準確率。而且在新增分類類型的過程中無需重新訓練。

簡單來說，我們就是把人臉辨識系統的那一套運作流程給搬過來啦！

我們自己在開發過程中，也常常發出「這樣搞真的可以嗎？」的笑鬧聲。如同前述，這個專案的第一代架構（第一作者）已經有了一定的效果，但仍不穩定。直到這個專案發佈時，已經是第三代模型（第二作者）了，整體效果也有了一定的提升，算是一個不錯的結果。

相比於我們之前發布的「規規矩矩」的專案，這個專案充滿了趣味性。

因此，我們決定將這個專案的架構和實驗結果公開，希望這個專案能夠帶給你一些啟發，如果你也能從本專案的設計理念中而找到了全新的應用場景，也歡迎與我們分享。
