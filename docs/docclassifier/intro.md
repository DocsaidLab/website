---
sidebar_position: 1
---

# 介紹

在過去的專案經驗中，分類模型可說是最常見的機器學習任務。

分類模型沒有什麼困難的地方，首先我們會搭建一個 Backbone，接著將最後的輸出映射至多個特定的類別，最後經過幾個評估的指標來評估模型的好壞，通常是準確率、召回率、F1-Score 等等。

儘管這聽起來直截了當，但在實際應用上，我們會遇到一些問題，這邊以本專案的題目來舉例：

### 類別定義

在任何分類任務中，明確並精確地定義類別是很重要的。但是如果我們定義的類別本身相似度很高，那麼模型可能會難以區分這些類別。

- 例如：某公司 A 保險文件 vs 某公司 B 保險文件。

這兩個類別都是某公司的文件，其中的差異性可能不大，從而導致模型難以區分這兩個類別。

### 資料不平衡

在大部分的場景中，資料收集都是很困難的問題，特別是牽涉到敏感資料的情況下。在這樣的情況下，我們可能會遇到資料不平衡的問題，這樣的問題可能會導致模型對於少數類別的預測能力不足。

### 資料擴充

在業界中，充斥著大量的文件，我們隨時都想新增更多的文件類別。但是每次新增一個類別，整個模型都需要重新訓練或微調，這樣的成本是非常高的。各種意義上的成本都是，包含但不限於：資料收集、標記、重新訓練、重新評估、部署等，所有流程都需要重新進行。

### 類別子標籤

客戶的需求是天馬行空的。

我們假設存在某個客戶，而該客戶先是定義了一種文件類型，先假設它叫做 A 文件。

接著客戶希望針對 A 文件，提供更多的子標籤，例如：

- 污損的 A 文件
- 反光的 A 文件
- 第一代格式的 A 文件
- 第二代格式的 A 文件
- ...

先不論每次新增一個子標籤，都要重跑一次模型。

以模型工程的角度來說，如果將這些標籤視為獨立的類別，那是「不合理」的，因為他們都是基於 A 文件；如果將這些標籤視為多類別的問題，那也是「不合理」的，因為不同主文件格式下對應的子標籤是不同的。

:::tip
你接著想：既然解決不了問題，那就解決提出問題的人。

- 不可以！

這是一個機器學習的問題。
:::

## 度量學習

跳出文件分類的題目，你會發現這個問題其實在講的就是：**度量學習（Metric Learning）**。

度量學習主要目的是透過學習最優的距離測量，來衡量樣本之間的相似性。在傳統的機器學習領域中，度量學習通常涉及將資料從原始特徵空間映射到一個新的特徵空間，在這個空間中，相似的對象距離更近，而不相似的對象距離更遠。這個過程通常是透過學習一個距離函數來實現的，這個距離函數能夠更好地反映樣本間的真實相似度。

如果你看完上段話，還是不明白，用一句話來總結：**度量學習是一種學習相似性的方法**。

### 應用場景

度量學習在兩個知名應用場景中非常重要：

- **人臉辨識（Face Recognition）**：如同我們剛才提到的困境，人臉的數量持續增加，我們根本無法一直重新訓練模型。因此，使用度量學習的架構，可以幫助我們學習一個更好的距離函數，從而提高人臉辨識的準確性。

- **推薦系統（Recommendation System）**：推薦系統的目的是根據用戶的歷史行為，為用戶推薦他們可能感興趣的商品。在這個過程中，我們需要度量用戶之間的相似性，從而找到相似用戶的行為，進而為用戶推薦商品。

在這些應用中，如何準確地度量兩個對象之間的相似性是提高系統性能的關鍵。

## 解決問題

雖然不是每個分類問題都適合將高度上升到度量學習的層面，但在這個專案中，度量學習這個武器，確實可以幫助我們彌平上面提到的那些障礙。

- **障礙一：類別定義**

  我們學習的目標是更好的距離函數，這個距離函數可以幫助我們更好地區分相似的類別。所以我們不再需要定義類別。那些我們想分類的對象，最後都只會成為一個註冊資料。

- **障礙二：類別資料不平衡**

  我們不再需要大量收集資料，因為我們的模型不再依賴於大量的樣本。我們只需要一個樣本，這個樣本就是我們的註冊資料。而其他部分可以透過其他訓練資料來進行訓練。

- **障礙三：類別擴充**

  擴充類別只需要註冊新的資料，而不需要重新訓練模型。這樣的設計可以大大減少訓練的成本。

- **障礙四：類別子標籤**

  這個問題在度量學習的框架下，可以很好地解決。我們可以將子標籤視為一個新的註冊資料，這樣就不會影響到原本的模型。子標籤和主標籤之間在特徵空間中的距離可能會很近，但又不完全一樣，因此可以很好地區分這兩個類別。

---

我們首先引入了度量學習的架構：[**PartialFC**](https://arxiv.org/abs/2203.15565)，這個架構結合了 [**CosFace**](https://arxiv.org/abs/1801.09414) 和 [**ArcFace**](https://arxiv.org/abs/1801.07698) 等技術，使其能在沒有預先設定大量分類的情況下，精準地進行分類。

接著，我們在更進一步的實驗中，引入了 [**ImageNet-1K 資料集**](https://www.image-net.org/) 和 [**CLIP 模型**](https://arxiv.org/abs/2103.00020)。我們使用 ImageNet-1K 資料集作為基底，將每張影像視為一個類別，透過這個操作，可以將分類的類別數量擴充到約 130 萬類，給予模型更豐富的圖面變化，增加資料多樣性。

在 TPR@FPR=1e-4 的比較基準中，比起原有的基線模型效果提高了約 4.1%（77.2%->81.3%）。若在 ImageNet-1K 的基礎上再引入 CLIP 模型，在訓練的過程中進行知識蒸餾，則效果可以在 TPR@FPR=1e-4 的比較基準中再往上提升約 4.6%（81.3%->85.9%）。

在最新的實驗中，我們嘗試結合 BatchNorm 和 LayerNorm，並且取得可喜的結果，在原本的 CLIP 蒸餾模型基礎上，將 TPR@FPR=1e-4 的效果提高了約 4.4%（85.9%->90.3%）。

## 最後

在測試中，我們的模型在基於萬分之一（TPR@FPR=1e-4）錯誤率的條件下，展示了超過 90% 的準確率。而且在新增分類類型的過程中無需重新訓練。

總之，我們就是把人臉辨識系統的那一套運作流程給搬過來啦！

我們自己在開發過程中，也常常發出「這樣搞真的可以嗎？」的笑鬧聲。如同前述，這個專案的第一代架構（第一作者）已經有了一定的效果，但仍不穩定。直到這個專案發佈時，已經是第三代模型（第二作者）了，整體效果也有了一定的提升，算是一個不錯的結果。

相比於我們之前發布的「規規矩矩」的專案，這個專案充滿了趣味性。

因此，我們決定將這個專案的架構和實驗結果公開，希望這個專案能夠帶給你一些啟發，如果你也能從本專案的設計理念中而找到了全新的應用場景，也歡迎與我們分享。
