---
sidebar_position: 1
---

# 介紹

這個任務其實算是 OCR 任務的「前導」。

到了近幾年，各種通用型的 OCR 模型已經相當成熟，甚至不需要任何前處理，就能在無受限的場景中找到所有文字並提供其辨識結果。

但，就是有點昂貴。

這個昂貴所指的目標，可以從各方面來切入：

### 推論成本

在實際場景中，文件辨識的任務在 OCR 領域中佔比很大，因為人們在生活中總是離不開文件。在這些活動中，通常你不會站在「主動」的角度，而是「被動」的接受掃描：

1. 銀行開戶是不是需要看證件？
2. 出國是不是需要看護照？
3. 申請簽證是不是需要看證明文件？
4. 買保險是不是需要看合約？

佔比很大卻不代表這是一件賺錢的生意，因為提供相關功能的廠商非常多，物美價廉的產品比比皆是。

也就是說，如果你用一個通用的 OCR 模型（通常是 LLM）來處理這個問題，光是推論成本就可以讓你虧到翻過去...

再翻過來。

:::tip
這裡我們撇除那些財富自由的人們。
:::

### 文字通常很密集

在文件中，文字通常是密集的，這意味著如果你不想錯過任何資訊，你必須使用極高的解析度來掃描文件。

舉例來說，一般我們做物件偵測的起手式是使用 $640 \times 640$ 的解析度，但在文件定位的場景中，這個解析度可能會被放大到 $896 \times 896$ 或 $1536 \times 1536$ 甚至更高。

如果我們不把模型功能進行拆分，直接在高解析度的環境下強推 LLM，先不提推論成本，你知道現在買一張 V100 訓練用的 GPU 要三萬到五萬美金嗎？LLM 真的貴到不行啊！

### 中文字數量龐大

中文字的分類，涵蓋簡繁兩種格式，字元數量高達十萬種。相比於拉丁語系的文字，分類數量多了三個數量級。

模型必須從複雜的背景中找到文字，接著又得從文字的細節（可能就只有幾個 pixel）中找到關鍵特徵，所需的參數量和計算量都會大幅增加。

我們當然嚮往端到端的解決方案，最好什麼都不用做，用一個模型就能解決所有問題。這樣的模型在現在有，以後也只會更多。

但推論昂貴，收益又低，不管怎麼看，在現階段都是個虧本的生意。

### 功能拆分

所以我們需要更經濟實惠的方式，模型拆分在這裡就成為必然的選擇。

這也是我們做這個專案的目的：

- **在嘈雜紛亂的場景中，精確地找到我們感興趣的文件區域，並將其攤平，以便後續的文字辨識或其他處理。**

有了文件定位，再接著使用文字定位，再來是文字辨識，最後是文意分析理解。

這樣的流程或許繁瑣，但是在成本和效益之間，這是一個相對平衡的選擇。

## 模型功能

此模型專門設計來辨識圖像中的文件，精確地找到文件的四個角點，讓使用者可以將其攤平，以便進行後續的文字辨識或其他處理。

這裡提供兩種不同的模型：「熱圖模型」和「點回歸模型」，各具特點和適用場景，這些將在後續章節中詳細介紹。

在技術層面，我們選擇了 PyTorch 作為訓練框架，並在推論時將模型轉換為 ONNX 格式，以便在不同平台上部署。此外，我們使用 ONNXRuntime 進行模型推論，這使得我們的模型能在 CPU 和 GPU 上高效運行。

我們的模型在性能上達到接近最先進（SoTA）水平，並在實際應用中展示了即時（Real-Time）的推論速度，使其能夠滿足大多數應用場景的需求。

:::info
在深度學習領域「以外」的領域，『Localization』通常指文件將文件翻譯成不同語言。

而我們在深度學習領域，則指的是定位圖像中的文件，並將其攤平的過程。
:::

:::tip
**攤平**：將三維空間中的歪斜文件，通過某種方式（如透視變換）投影到二維平面上，使其在平面上呈現。
:::

## 定義

我們遵循該領域的先行者的定義，將文件的座標點的：

- **起點定為左上角**
- **終點定為左下角**

並使用四個座標點來表示文件的位置，依序為：『左上 > 右上 > 右下 > 左下』。

:::danger
雖然在可視化的結果中，我們根據不同的座標點位使用不同的顏色，但該顏色並不代表文件本身的方向。

意思就是：**不管文字怎麼轉來轉去，模型永遠都會定義左上角為起點，左下角為終點。**
:::

## 遊樂場

我們有把這個模型放在這個網頁上，你可以到遊樂場中試試看。

- [**DocAligner-Demo**](https://docsaid.org/playground/docaligner-demo)

:::tip
不要放太大的圖片（長寬超過 4000 pixel），否則瀏覽器容易故障。
:::

## 最後

我們其實一開始想做的是一個 Zero-shot 的模型，並且能夠愉快地在移動設備上運行。也就是說可以泛化到全世界各式各樣的文件上，不需要任何標注和微調，就可以直接使用。

但後來發現模型規模的限制，使得這個目標變得有點遙遠。

這其實很難抉擇：如果加大模型規模，就違背了我們的初衷；不加大模型，那只能改架構，但改架構又會影響到模型的泛化能力。

最後，我們忙了好幾個月，還是向 Zero-shot 做出妥協，畢竟「準確」才是第一優先的目標。

如果你對這個題目感興趣，歡迎自行測試，我們期待你提供反饋給我們。

也歡迎你留下建議，我們很樂意與你交流。
