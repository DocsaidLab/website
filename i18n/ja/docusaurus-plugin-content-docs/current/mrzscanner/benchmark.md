---
sidebar_position: 6
---

# モデル評価

私たちは、モデルの性能を評価するために 2 つの評価指標を採用しています：

## 正規化編集距離

英語では、Average Normalized Levenshtein Similarity（略して ANLS）と呼ばれる指標です。この指標は、モデルの予測文字列と実際の文字列との類似度を測定するために使用されます。

これは、Levenshtein 編集距離に基づいて計算されます。Levenshtein 距離は、予測結果を実際の文字列に変換するために必要な最小編集操作（挿入、削除、置換）の数を表します。そして、これを正規化して、値が 0 から 1 の間に収まるようにします。値が高いほど、予測結果が実際の答えに近いことを意味します。

例を挙げます：

- 実際の文字列：`hello`
- 予測文字列：`helo`

Levenshtein 距離 = 1（`l` が欠けている）。計算式は以下の通りです：

$$
\text{ANLS} = 1 - \frac{\text{Levenshtein Distance}}{\max(\text{len}(y_{\text{true}}), \text{len}(y_{\text{pred}}))}
$$

- 正規化後の類似度は 0.8 であり、予測結果と実際の値の類似度が高いことを示しています。

この指標は、OCR シナリオに特に適しており、部分的な誤認識が許容される場合に評価基準として使用できます。

## 全画像精度

これは一般的に見られる Accuracy（精度）指標です。この指標は、モデルが画像全体をどれだけ正確に認識できたかを測定します。モデルがすべての文字を完全に正確に予測できた場合、その画像は「正しく認識された」と見なされ、それ以外は「誤認識」と見なされます。

Accuracy はパーセンテージで表示され、計算式は次の通りです：正しく認識された画像の数を総テスト画像数で割った値です。

**例**：

- テスト画像数：100 枚
- 完全に正確に予測された画像数：85 枚
- Accuracy = (85 / 100) × 100% = 85%

この指標は、高精度が要求されるアプリケーションに適しています。例えば、フォーム処理や本人確認などでは、誤った文字が結果の有用性に大きな影響を与える可能性があります。

:::tip
**なぜ「単語正確率」を使用しないのか？**

もう一つの一般的な評価方法は、**単語正確率**（Character Accuracy または Word Accuracy）です。これは、モデルの予測文字列と実際の文字列を比較して、単語単位での正確度を測定します。しかし、単語正確率は一部のアプリケーションシーンでは理想的ではありません：

1. **わずかな誤りで評価が極端に低くなる**：

   - 実際の文字列：`hello world`
   - 予測文字列：`helo world`

   `hello` が `helo` と誤認識されているため、1 文字の誤りでもその単語は誤りと見なされ、単語正確率が急激に低下します。

   ***

2. **単語のずれが大きな影響を与える**：

   - 実際の文字列：`hello world`
   - 予測文字列：`ello horld`

   このような場合、単語の整列が誤って行われ、両方の単語が誤りとして扱われます。大部分の文字が正しいにもかかわらず、評価が低くなります。

   ***

3. **部分的に正しい予測を定量化できない**：

   - 実際の文字列：`123456`
   - 予測文字列：`12345`

   一部のアプリケーションシーンでは、モデルの出力が「正解」にどれほど近いかを重視し、完全に一致するかどうかは重要ではありません。

   単語正確率を使用すると、`123456` 全体が誤りとして評価され、評価が非常に低くなります。しかし、多くのアプリケーションでは、こうした出力も許容されます。

   ***

そのため、私たちのプロジェクトでは、単語正確率ではなく、全画像精度と ANLS を評価指標として使用することに決定しました。
:::

## 評価データセット

このプロジェクトでは、モデルの評価に非常に大きな課題があります。

まず、個人情報が含まれているため、標準的なデータセットは存在しません。そのため、データは自分で収集し、1 枚 1 枚手動でラベル付けを行っていますが、収集したデータセットは信頼性に欠け、権威ある標準データセットとして使用することはできません：

> もし誰でも自分でデータを収集し、モデルの精度が 100％だと主張するなら、あなたは信じますか？

さらに、この分野で有名なデータセットといえば **MIDV**（Mobile Identity Document Video dataset）ですが、これにも限界があります：

1. **データ量が不足**：**MIDV** のデータセットは規模が限られており、ほとんどが合成サンプルに基づいており、実世界のアプリケーションシーンを代表するものではありません。
2. **MRZ 認識には特化していない**：**MIDV** にはさまざまな証明書が含まれており、主に証明書の位置検出を目的としていますが、MRZ の文字位置検出と認識のアノテーションは提供されていません。

**MIDV-2020** バージョンでは、MRZ の文字アノテーションが見つかりますが、位置情報が欠けており、完全な評価データセットとして使用することはできません。

現在、私たちは約 300 枚のパスポートと居住証の小規模なプライベートテストセットを持っています。このテストセットは、内部テストでモデルのパフォーマンスを評価するために使用されています。しかし、前述の通り、データは個人情報が含まれているため、テストデータを公開することはできません。

もし興味があれば、あなた自身でデータを収集し、私たちのモデルを使用してテストを行うことができます。
