# [20.05] DETR

## クロスドメインのパイオニア

[**End-to-End Object Detection with Transformers**](https://arxiv.org/abs/2005.12872)

---

物体検出はコンピュータビジョン分野の中心的な課題であり続けています。

いくつかのアンカーベースの手法、例えば Faster R-CNN、SSD、YOLOv2 などは、予め定義された境界ボックス（すなわちアンカー）を使って物体の位置を予測します。これらのアンカーのサイズやアスペクト比は手動で選ばれ、出現し得る物体の形状をカバーできることが期待されています。アンカーベースの手法には固有の利点があり、特に物体のマルチスケールや多様な形状を検出するのに優れています。これらの手法は、多スケールの物体や異なるアスペクト比に対して良好な汎化能力を持っています。

しかし、適切なアンカーのサイズや比率を選ぶには、しばしば先験的な知識や手動での調整が必要で、すべてのアプリケーションやデータセットには適さない場合があります。また、各位置で複数のアンカーを使用することが多く、特に物体がない背景領域では大量の冗長な予測を生み出す可能性があり、これには追加の非最大抑制（NMS）ステップが必要です。

同じタイムラインの中で、隣の棚（NLP）では、最新の Transformer アーキテクチャがすでに熱心に進展しており、多くの顕著な進歩を遂げていました。このような要因が、本文の著者に次のように決定させた理由です：

- **それなら、私たちも Transformer を使ってみようじゃないか！**

## 問題の定義

著者はこの記事で、現時点でのいくつかの問題を定義しています：

### アンカーベースは複雑すぎる

物体検出の分野で、アンカーベースの手法は近年非常に人気のある検出技術です。

これらの手法では、予め定義されたアンカーを使って境界ボックスとクラスを予測します。これらのアンカーは通常、異なるサイズと比率で、画像全体に均等に配置された定義された境界ボックスです。

しかし、アンカーを使用する方法にはいくつかの課題もあります：

1. **重複予測の問題**

   多くのアンカーが画像上に配置されるため、1 つの実物体が複数のアンカーによって検出され、同じ物体が何度も予測される可能性があります。これにより、システムは同じ物体を示す複数の似たような、または重なった境界ボックスを生成することになります。

2. **後処理の複雑さ**

   上記の重複予測の問題を解決するためには、いくつかの後処理技術を導入する必要があります。非最大抑制（NMS）は一般的な方法であり、重なった境界ボックスを削除し、最適な予測だけを保持します。これには追加の計算とパラメータ調整が必要で、モデルの複雑さが増します。

3. **アンカー設計とマッチング**

   アンカーのサイズや比率の設計は、モデルの性能に直接影響します。不適切なアンカー設計は、検出の精度を欠く原因となります。また、新しい予測が生成されるたびに、これらの予測を最も近いアンカーと一致させる必要があり、これは追加の計算ステップとなります。

気に入らなければ使わなければいい、アンカーなしでできないだろうか？

### アンカーなしではうまくいかない

人々は、正確であることを求めるだけでなく、やはり正確でなければなりません。

実際のシナリオでは、ユーザーは通常少し遅くても構いません（結局数秒の差ですし）；システムが少し複雑でも構いません（エンジニアが頑張るだけですし）。

- **しかし、モデルが正確でなければ、私はあなたにクレームを言います！**

物体検出の発展において、直接予測は常に魅力的な概念でした。アンカーを使う戦略とは異なり、直接予測は、他の中間的な代理や補助的な構造なしで、画像のピクセルから直接物体の境界ボックスとクラスラベルを予測しようとするものです。

直接予測の概念は理論的には魅力的ですが、実際のアプリケーションでは、過去の試みがしばしば性能の制限を受けていました。これは、これらの手法が一般的な物体検出基準で、特に現在の最先端の手法と比較して、うまくいかないことを意味します。

したがって、直接予測の手法は理論的な利点や簡略化されたモデル構造、少ない手動先験情報を持っていても、実際のアプリケーションにおける性能や競争力は向上の余地があるということです。これが、研究者たちがこれらの戦略を改善する方法を探し続けている理由でもあります。

## 解決問題

### DETR モデル設計

![DETR モデルアーキテクチャ](./img/detr_1.jpg)

1. **バックボーン**

   バックボーンは入力画像から特徴を抽出する部分です。通常、畳み込みニューラルネットワーク（CNN）構造を使用します。画像がこの層に入力されると、一連の特徴マップが生成されます。これらの特徴マップは、画像のさまざまな詳細や文脈情報をキャプチャしますが、元の画像の解像度は失われます。

2. **Transformer Encoder**

   Transformer Encoder は、バックボーンの出力特徴マップを受け取ります。Transformer が各特徴の相対位置を理解できるようにするために、位置エンコーディングを追加する必要があります。これは、CNN とは異なり、Transformer 自体は入力の順序に敏感でないためです。位置エンコーディングは位置情報を入力する方法を提供し、これにより Transformer は特徴間の相対的な位置を考慮できるようになります。

   入力特徴マップが 3 x 224 x 224 で、出力特徴マップが 512 x 7 x 7 の場合、この操作では出力マップを 7 x 7 の 49 個の入力トークンとして扱い、各トークンは 512 の特徴値を持ちます。論文では、著者は ResNet をバックボーンとして使用し、最終的な出力特徴は 2048 次元ですが、ここではまず$1 \times 1$の畳み込みで次元を$D$に減らし、$D$が最終的に Transformer に入力される次元です。

3. **Transformer Decoder**

   デコーダの入力は「物体クエリ」と呼ばれる固定ベクトルで、これらのクエリは物体検出の一般的な期待を表します。デコーダの複数の層を通じて、これらのクエリは Encoder の出力に注意を向け、特定の物体に対応する特徴を探し出します。

   ここでは簡単に、デコーダに入力する際、すべてのクエリ対象の物体を 1 つのトークンとして入力します。例えば、100 個の物体があれば、入力シーケンスの長さは 100 となり、特徴部分は固定された特定の内容が与えられ、モデルが異なる物体を区別できるようになります。

   さらに注意すべき点は、ここで各クエリ物体を For-loop で処理するのではなく、すべてのクエリを一度に処理することです。異なる物体間に依存関係がないため、ループによる反復は必要ありません。

4. **FFN**

   デコーダの各出力は FFN に入力されます。このネットワークの目的は、デコーダの出力を具体的な予測に変換することです。ここでの予測内容は：[物体の中心座標（x, y）、高さ（H）、幅（W）]で、個数は固定の N です。ここでの N は通常、画像中の実際の物体数よりもはるかに多くなります。物体が見つからない場合、特殊な「物体なし」クラスを出力することもできます。

   全体の実装アーキテクチャのフローチャートは以下の通りです：

   ![DETR モデルアーキテクチャ](./img/detr_3.jpg)

   :::tip
   ここで、論文中の Spatial positional encoding と一般的な Transformer との違いが気になり、論文の実装を確認しました。実際には、行（row）と列（col）に基づいて、学習可能なパラメータが与えられていました。

   ![DETR モデルアーキテクチャ](./img/detr_4.jpg)
   :::

### 損失関数設計

1. 集合予測損失

   これは、予測されたボックスと実際のボックスとの間の一意なマッチング損失を強制するために使用されます。

   - **マッチング損失 (L_match)**

     DETR は、N 個の固定サイズの予測を出力します。ここでの N は、画像中の物体の典型的な数よりも明らかに大きいと設定されています。損失は、予測された物体と実際の物体の間で最適な二分マッチングを生成します。例えば、1 枚の画像に 5 つの実際の物体があった場合、モデルが 8 つの物体を予測したとします。余分な予測があっても、これら 5 つの実際の物体を 8 つの予測物体と最適にマッチングしなければなりません。

   - **ハンガリアンアルゴリズム（Hungarian Algorithm）**

     ハンガリアンアルゴリズムを使用して、最適なマッチングを見つけます。マッチングコストは、予測されたクラスと、予測ボックスと実際のボックスとの類似性を考慮します。

     ハンガリアンアルゴリズムは、二部グラフの最大マッチングまたは最小マッチングの問題を解決するために使用され、通常は割り当て問題に適用されます。例えば、n 個のタスクと n 人の労働者があり、各タスクは 1 人の労働者によってのみ実行されます。各労働者が各タスクを完了するためのコストがあり、目標はすべての労働者がすべてのタスクを完了するための最小コストを見つけることです。

     もう一つの設定として、「物体なし」クラスの対数確率項の重みを 10 倍減らし、背景や非物体領域が訓練に干渉するのを防ぎます。

2. バウンディングボックス損失 (Bounding Box Loss)

   物体検出では、モデルが物体の位置と範囲を予測する必要があります。これは通常、1 つの「バウンディングボックス」として表されます。バウンディングボックスは通常、4 つの座標（例えば：左上と右下の x、y 座標）や中心点と幅高さで表現されます。バウンディングボックス損失は、予測されたバウンディングボックスと実際のバウンディングボックスとの間の差異を測定する方法です。

   - **バウンディングボックス損失（L_box）**

     DETR（DEtection TRansformer）は、最近注目されている物体検出手法で、従来の手法とは異なります。一部の伝統的な手法では候補ボックス（アンカーボックスや提案ボックスとも呼ばれる）の予測を基にし、最終的な予測バウンディングボックスを調整しますが、DETR は物体のバウンディングボックスを直接予測します。

     この方法の問題の 1 つは、物体のサイズが異なる場合、予測される相対位置の偏差が同じであっても、L1 損失のような一般的な損失を使用した場合、それらの損失値に大きな違いが生じることです。

     :::tip
     例えば、モデルが非常に小さな物体と非常に大きな物体を予測し、どちらも実際の位置から 10 ピクセルずれていたとしましょう。小さな物体では、この 10 ピクセルの偏差が大きな差を意味する可能性があり（例えば、物体の総サイズの 50%を占めるかもしれません）、しかし大きな物体では、これはわずかな偏差に過ぎないかもしれません。L1 損失のみを使用すると、この 2 つの状況の損失値には大きな違いが生じる可能性があります。
     :::

   - **問題があれば修正する**

     上記の問題を克服するために、DETR は`L1損失`と「一般化 IoU 損失（Generalized Intersection over Union Loss）」を組み合わせています。一般化 IoU 損失は、物体サイズが損失に与える影響を解決し、予測されたバウンディングボックスと実際のバウンディングボックスとの重なり具合を考慮し、それらの交差部分を最大化しようとします。この 2 つの損失を組み合わせることで、モデルは異なるサイズの物体に対して均等な損失尺度で学習でき、異なるサイズの物体のバウンディングボックスを均等に学習するのに役立ちます。

### データセット

- **使用したデータセット**：本研究では、COCO 2017 の検出および全景セグメンテーションデータセットを使用して実験を行いました。
- **データセットの規模**：データセットには、118,000 枚の訓練画像と 5,000 枚の検証画像が含まれています。
- **データのアノテーション**：各画像には、バウンディングボックスと全景セグメンテーションの情報がアノテーションされています。
- **画像の詳細**：平均して、各画像には 7 つの物体インスタンスがあります。訓練セットでは、1 枚の画像に最大 63 個のインスタンスが含まれており、これらのインスタンスはサイズが小さいものから大きいものまでさまざまです。
- **評価指標**：平均精度（Average Precision、AP）を評価指標として使用しました。デフォルトでは、AP はバウンディングボックス（bbox）に基づいています。Faster R-CNN との比較のために、論文では最終的な訓練時期の検証 AP を報告しています。

### 技術的な詳細

- **訓練最適化手法**：DETR モデルの訓練には AdamW を使用しました。
- **学習率設定**：
  - Transformer の初期学習率は 1e-4
  - バックボーンネットワークの学習率は 1e-5
  - 重み減衰は 1e-4 です。
- **重み初期化**：すべての Transformer の重みは Xavier 初期化を使用して初期化されます。バックボーンネットワークは ImageNet で事前学習された ResNet モデルを使用し、BatchNorm 層は凍結されました。
- **モデル構造**：研究では、異なる 2 種類のバックボーンネットワークの結果が報告されています：ResNet50 と ResNet-101 で、それぞれ DETR と DETR-R101 として命名されています。また、小物体の検出性能を向上させるために修正されたモデル DETR-DC5 と DETR-DC5-R101 もありますが、計算コストは相対的に増加します。
- **画像前処理**：スケール増強を使用して画像サイズを調整し、最短辺が 480〜800 ピクセルの範囲に収まり、最長辺は最大 1333 ピクセルに設定されます。モデルの学習を強化するために、訓練中にランダムクロッピング増強を使用し、これにより AP が約 1 ポイント向上しました。
- **その他の詳細**：デフォルトでドロップアウト率 0.1 を設定して訓練を行いました。推論時には、一部の予測が空である場合があり、AP を最適化するために、これらの空物体の予測には信頼度を使用して補正を行い、これにより AP が 2 ポイント増加しました。

## 討論

### これで行けるのか？

![DETR モデル評価](./img/detr_2.jpg)

小物体が全くダメ（AP 27.2 -> AP 23.7）ですが、他の部分はかなり良いです！

DETR と Faster R-CNN の比較を詳細に検討した結果、以下の主要な点が観察されました：

1. **訓練方法の違い**

   - DETR は Transformer 構造を使用し、通常は Adam や Adagrad オプティマイザーと共に使用されます。また、モデルがより深い表現を学習できるように、比較的長い訓練スケジュールとドロップアウトが採用されています。
   - Faster R-CNN は主に SGD を使用して訓練され、データ増強の量は比較的少なめです。

2. **Faster R-CNN のベースラインを強化する試み**

   - DETR とより一致させるために、研究者たちは Faster R-CNN の損失に広義 IoU を追加し、同様のランダムクロップ画像増強と長期間の訓練方法を適用しました。
   - これらの調整により、Faster R-CNN は COCO 検出タスクで 1-2 AP の向上を示しました。

3. **モデル結果の比較**

   - Faster R-CNN では、3x スケジュール訓練を使用したモデル結果と、増強機能を追加し 9x スケジュール訓練を使用したモデル結果が示されました。
   - DETR では、同じパラメータ量を持つモデルが考慮されており、これは DETR と Faster R-CNN が同様のモデル複雑さを持っていることを意味します。

4. **性能比較**

   - 結果から、DETR は同じパラメータ数で Faster R-CNN と競り合い、COCO val サブセットで 42 AP を達成できることがわかります。
   - DETR は全体的な性能を向上させるために、主に APL（大きな物体の検出性能）の向上によって達成されました。しかし、APS（小さな物体の検出性能）ではまだ遅れを取っています。
   - DETR-DC5 は、より高い全体 AP を持ちながらも、小さな物体の検出においては Faster R-CNN に大きく劣っています。
   - ResNet-101 をバックボーンに使用した Faster R-CNN と DETR は、性能において類似した傾向を示しています。

### モデルコンポーネントの分析

著者は DETR アーキテクチャ内の各コンポーネントの重要性について詳細に探求しました：

1. **エンコーダ層数**

   - エンコーダ層数を増加させると、グローバル画像レベルの自己注意に影響を与えます。
   - エンコーダ層がないと、全体の AP が 3.9 ポイント低下し、大きな物体に対する影響は特に 6.0 ポイントになります。
   - エンコーダは物体を解きほぐす重要なコンポーネントであり、グローバルなシーン推論を提供します。
   - エンコーダはインスタンスを分離することができ、これはデコーダの物体抽出と位置決定に有益である可能性があります。

2. **デコーダ層数**

   - デコーダ層数を増加させることは、AP および AP50 を改善するのに役立ちます。
   - 集合ベースの損失に基づいているため、DETR は NMS を必要としません。
   - ただし、最初のデコーダ層後に NMS を実行すると、性能が向上します。
   - 層数が増加するにつれて、NMS の改善効果は弱くなります。
   - デコーダの注意はローカルであり、物体の四肢（頭部や脚部）に主に関心を持ちます。

3. **FFN の重要性**

   - FFN は 1x1 畳み込み層として見ることができます。
   - FFN を完全に削除すると、性能が 2.3AP 低下し、FFN が良い結果を得るために非常に重要であることが示されています。

4. **位置エンコーディングの重要性**

   - モデルには、空間位置エンコーディングと出力位置エンコーディングの 2 種類があります。
   - 空間位置エンコーディングを完全に削除すると、性能が 7.8AP 低下します。
   - 正弦エンコーディングや学習エンコーディングを使用すると、AP がわずかに 1.3AP 低下します。
   - これにより、位置エンコーディングがモデルの性能にとって重要であることが示されました。

5. **Loss の重要性**

   - クラシフィケーション Loss は不可欠です。
   - GIoU Loss はモデル性能の大部分を占めており、これがないと 0.7AP の損失が発生します。
   - L1 Loss だけを使用すると、結果が悪化します。

### パノラマセグメンテーションの応用

パノラマセグメンテーションは、最近コンピュータビジョン界で広く注目されています。この論文では、この章は主要な議論の対象ではなく、著者は簡単に応用として説明しています。しかし、未来の観点から見ると、この章の応用は非常に重要であり、まるで新しい論文のような内容です。ですので、慎重に見ていきましょう。

- **実験設定**

  DETR は COCO データセットでパノラマセグメンテーションの実験を行いました。このデータセットには 80 の物体カテゴリがあり、さらに 53 の物体カテゴリも含まれています。DETR を訓練する際、モデルは COCO 上で物体と物体カテゴリの周囲のバウンディングボックスを予測する必要があります。バウンディングボックスの予測は訓練中に必要で、訓練に使用されるハンガリアンマッチングアルゴリズムは、ボックス間の距離計算に依存しています。

- **新たに追加されたマスクヘッド**

  ![DETR マスクアーキテクチャ](./img/detr_5.jpg)

  基本的な DETR アーキテクチャに加えて、マスクヘッドが追加され、このヘッドは各予測ボックスに対してバイナリマスクを予測します。このマスクヘッドは、各物体の Transformer デコーダ出力を入力として取り、これらのエンコーディングの多頭注意スコアを計算して、各物体に注意熱マップを生成します。最終的な予測を得るために、FPN に似たアーキテクチャも使用されています。

  訓練中、DETR はまずバウンディングボックスを予測するように訓練され、次にマスクヘッドが 25 エポックで訓練されます。このプロセスは一度に行うこともできますし、DETR を先に訓練してからマスクヘッドを訓練することもできます。実験結果では、この 2 つの方法での効果は似ていることが示されました。最終的なパノラマセグメンテーションを得るために、モデルは各ピクセルのマスクスコアに argmax を使用し、その後、対応するカテゴリを結果マスクに割り当てます。この方法により、最終的なマスク同士が重複しないことが保証されます。

- **結果の表示**

  ![DETR マスク結果1](./img/detr_6.jpg)

  DETR はパノラマセグメンテーションにおいてその強力な性能を示しました。特に、物体カテゴリにおいて優れた性能を示したことは、エンコーダのグローバル推論能力によるものかもしれません。物体カテゴリのマスク予測においては一定の性能差があるものの、DETR は競争力のある PQ スコアを達成しました。COCO テストセットでは、DETR は 46PQ スコアを達成しました。

  ![DETR マスク結果2](./img/detr_7.jpg)

## 結論

どんな技術にも完璧なものはありません。

DETR が直面している主な課題は小物体の検出であり、この点においてはまだ大きな改善の余地があります。

また、何年も改良が重ねられてきた Faster R-CNN と比較して、DETR は特定のシナリオでは同等の結果にとどまることがあり、最良の選択とは限らないことも示唆されています。

しかし、これが DETR の地位と重要性に影響を与えるわけではありません。DETR は単なる新しい技術ではなく、新しい思考方法を提案しています。Transformer 構造と二分マッチング損失を組み合わせることで、まったく新しい、直接的な集合予測方法を私たちに提供しました。

DETR の簡潔さと直感性は、大きな利点です。多くの目標検出方法では、複雑なラベル付けや特定の予設アンカーの選択が必要ですが、DETR はこれらの制限を取り払い、全体のプロセスをより簡単にしました。また、適用範囲が広いことも魅力です。目標検出だけでなく、パノラマセグメンテーションにも簡単に拡張でき、この点でも相当な結果を上げました。しかし、最も印象的なのは、大きな物体を処理する際に、その自己注意機構が画像内のグローバル情報を効果的に捉え、従来の方法よりも優れた性能を発揮する点です。
