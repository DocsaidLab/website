<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-retail-product/rpc/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.8.1"><title data-rh=true>[19.01] RPC Dataset | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/en/papers/retail-product/rpc/><meta data-rh=true property=og:locale content=en><meta data-rh=true property=og:locale:alternate content=zh_hant><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[19.01] RPC Dataset | DOCSAID"><meta data-rh=true name=description content="Check, Please!"><meta data-rh=true property=og:description content="Check, Please!"><link data-rh=true rel=icon href=/en/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/en/papers/retail-product/rpc/><link data-rh=true rel=alternate href=https://docsaid.org/papers/retail-product/rpc/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/retail-product/rpc/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/retail-product/rpc/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/retail-product/rpc/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://docsaid.org/en/papers/category/retail-product-5","name":"Retail Product (5)","position":1},{"@type":"ListItem","item":"https://docsaid.org/en/papers/retail-product/rpc/","name":"[19.01] RPC Dataset","position":2}]}</script><link rel=alternate type=application/rss+xml href=/en/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/en/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/en/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/en/assets/css/styles.e52f1f88.css><script src=/en/assets/js/runtime~main.2f0b58f1.js defer></script><script src=/en/assets/js/main.d41769a6.js defer></script><body class=navigation-with-keyboard><svg xmlns=http://www.w3.org/2000/svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light",e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/en/><div class=navbar__logo><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/en/docs/>Projects</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/en/papers/intro>Papers</a><a class="navbar__item navbar__link" href=/en/blog>Blog</a><a class="navbar__item navbar__link" href=/en/playground/intro>Playground</a><a class="navbar__item navbar__link" href=/en/services>Services</a><a class="navbar__item navbar__link" href=/en/aboutus>About Us</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>English</a><ul class=dropdown__menu><li><a href=/papers/retail-product/rpc/ target=_self rel="noopener noreferrer" class=dropdown__link lang=zh-hant>繁體中文</a><li><a href=/en/papers/retail-product/rpc/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=en>English</a><li><a href=/ja/papers/retail-product/rpc/ target=_self rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-mc1tut ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/en/><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>Paper Notes</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="Expand sidebar category 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/contrastive-learning-14>Contrastive Learning (14)</a><button aria-label="Expand sidebar category 'Contrastive Learning (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/deepseek-5>DeepSeek (5)</a><button aria-label="Expand sidebar category 'DeepSeek (5)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-anti-spoofing-43>Face Anti-Spoofing (43)</a><button aria-label="Expand sidebar category 'Face Anti-Spoofing (43)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="Expand sidebar category 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/feature-fusion-10>Feature Fusion (10)</a><button aria-label="Expand sidebar category 'Feature Fusion (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/image-generation-1>Image Generation (1)</a><button aria-label="Expand sidebar category 'Image Generation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="Expand sidebar category 'Lightweight (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/mamba-4>Mamba (4)</a><button aria-label="Expand sidebar category 'Mamba (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/model-tuning-8>Model Tuning (8)</a><button aria-label="Expand sidebar category 'Model Tuning (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/multimodality-24>Multimodality (24)</a><button aria-label="Expand sidebar category 'Multimodality (24)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/normalization-1>Normalization (1)</a><button aria-label="Expand sidebar category 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/object-detection-16>Object Detection (16)</a><button aria-label="Expand sidebar category 'Object Detection (16)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/reparameterization-8>Reparameterization (8)</a><button aria-label="Expand sidebar category 'Reparameterization (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/en/papers/category/retail-product-5>Retail Product (5)</a><button aria-label="Collapse sidebar category 'Retail Product (5)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/en/papers/retail-product/rpc/>[19.01] RPC Dataset</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/retail-product/sku-110k/>[19.04] SKU-110K</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/retail-product/dpsnet/>[20.11] DPSNet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/retail-product/retail-product-recognition-review/>[20.11] RPR: Review</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/retail-product/deepaco/>[22.06] DeepACO</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="Expand sidebar category 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-detection-14>Text Detection (14)</a><button aria-label="Expand sidebar category 'Text Detection (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="Expand sidebar category 'Text Recognition (20)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="Expand sidebar category 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/transformers-17>Transformers (17)</a><button aria-label="Expand sidebar category 'Transformers (17)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/vision-transformers-13>Vision Transformers (13)</a><button aria-label="Expand sidebar category 'Vision Transformers (13)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>All Notes: 233 entries</a></ul></nav><button type=button title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/en/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li class=breadcrumbs__item><a class=breadcrumbs__link href=/en/papers/category/retail-product-5><span>Retail Product (5)</span></a><li class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>[19.01] RPC Dataset</span></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>[19.01] RPC Dataset</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt="Z. Yuan" class=docAuthorImg_vlJe><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Z. Yuan</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a href=https://www.linkedin.com/in/ze-yuan-sh7/ target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 448 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=check-please>Check, Please!<a href=#check-please class=hash-link aria-label="Direct link to Check, Please!" title="Direct link to Check, Please!">​</a></h2>
<p><a href=https://arxiv.org/abs/1901.07249 target=_blank rel="noopener noreferrer"><strong>RPC: A Large-Scale Retail Product Checkout Dataset</strong></a></p>
<hr>
<p>This paper introduces a new dataset called RPC (Retail Product Checkout).</p>
<p>We found that many related papers use this dataset. Moreover, starting from this paper to search the literature allows faster discovery of the latest research achievements.</p>
<p>Such an important node—you definitely can’t miss it.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>info</div><div class=admonitionContent_BuS1><p><strong>Dataset Download</strong>: <a href=https://rpc-dataset.github.io/ target=_blank rel="noopener noreferrer"><strong>https://rpc-dataset.github.io/</strong></a><p><strong>Leaderboard</strong>: <a href="https://github.com/RPC-Dataset/RPC-Leaderboard?tab=readme-ov-file" target=_blank rel="noopener noreferrer"><strong>RPC-Leaderboard</strong></a></div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=problem-definition>Problem Definition<a href=#problem-definition class=hash-link aria-label="Direct link to Problem Definition" title="Direct link to Problem Definition">​</a></h2>
<p>In traditional retail, “product recognition” occupies a large portion of labor costs. As computer vision technology matures, the application scenario of Automatic Check-Out (ACO) has attracted attention. Its goal is: <strong>to automatically generate the corresponding shopping list from images of customers’ purchased products</strong>, replacing manual scanning, improving efficiency, and reducing cost.</p>
<p>However, this is not a simple classification or detection task. ACO simultaneously faces several challenging characteristics:</p>
<ul>
<li><strong>Large-scale</strong>: The number of product categories is huge; common supermarket SKUs often exceed thousands;</li>
<li><strong>Fine-grained</strong>: Many products look very similar, with differences only in small labels or packaging details;</li>
<li><strong>Few-shot</strong>: Most products have very limited training samples available;</li>
<li><strong>Cross-domain</strong>: Training data are usually clean single-product exemplar images, while test scenarios come from real checkout scenes with cluttered backgrounds, stacked products, unstable lighting, and severe occlusion, causing significant domain gaps.</li>
</ul>
<p>Each of these factors is a major challenge in computer vision alone, but ACO’s difficulty lies in: <strong>all these problems exist simultaneously!</strong></p>
<p>Some previous datasets try to address parts of these issues, for example:</p>
<ul>
<li><strong>SOIL-47</strong> tests lighting and viewpoint variations;</li>
<li><strong>Supermarket Produce Dataset</strong> focuses on fruit and vegetable classification;</li>
<li><strong>Grozi-120 / Grocery Products / Freiburg Dataset</strong> collect online images and store scenes;</li>
<li><strong>MVTec D2S</strong> provides pixel-level segmentation annotations for industrial object semantic segmentation.</li>
</ul>
<p>However, these datasets usually have limited category numbers or oversimplified shooting scenarios, far from real checkout workflows. They mostly address single subtasks and cannot simultaneously test the real-world challenges of “stacking, multiple classes, occlusion.”</p>
<p>Insufficient data volume also makes training models harder. Although traditional data augmentation methods (flip, translation, color jitter, etc.) can slightly expand data distribution, they cannot truly simulate noise and semantic combinations in test scenarios.</p>
<p>Therefore, the fundamental question is:</p>
<blockquote>
<p><strong>Can we build a dataset large and diverse enough to cover all the above challenges at once?</strong></p>
</blockquote>
<hr>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=dataset-design-philosophy>Dataset Design Philosophy<a href=#dataset-design-philosophy class=hash-link aria-label="Direct link to Dataset Design Philosophy" title="Direct link to Dataset Design Philosophy">​</a></h2>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=overview src=/en/assets/images/img0-e90b7636d9553a03eaed2b0aa7c9ab15.jpg width=1084 height=616 class=img_ev3q></figure></div>
<p>In real retail scenes, when customers place products on the checkout counter, the ideal goal of an ACO system is:</p>
<blockquote>
<p><strong>To recognize the types and quantities of products at a glance, and automatically generate the shopping list.</strong></p>
</blockquote>
<p>Rather than a “classification” or “detection” task, it is more like a <strong>combined multi-object counting and recognition task</strong>.</p>
<p>By definition, the input of ACO is an image taken at the checkout scene, which may contain any number and combination of products. However, the training data we have often consist only of single-product images.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p><strong>What is a single-product exemplar image?</strong><p>A single-product exemplar image refers to a photograph specifically taken of a single product. These images are typically used on e-commerce platforms or product catalogs to clearly showcase the product’s appearance and details.</div></div>
<p>The real difficulty is: product inventories constantly update, making it nearly impossible to collect checkout images covering all possible product combinations. Thus, a more practical approach is to train on these single-product images and enable the model to recognize multiple objects, categories, and quantities in chaotic scenes <strong>without ever seeing product stacks during training</strong>.</p>
<p>Formally, the problem can be defined as:</p>
<ul>
<li>Given a set of product categories <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>P</mi><mo>=</mo><mo stretchy=false>{</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>P = \{p_i\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord><span class="mord mathnormal">p</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>}</span></span></span></span> and a test image <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>I</mi><mi>t</mi></msub></mrow><annotation encoding=application/x-tex>I_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07847em>I</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0785em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>.</li>
<li>The goal is to predict the occurrence count <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mtext>count</mtext><mo stretchy=false>(</mo><mi>p</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\text{count}(p)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>count</span></span><span class=mopen>(</span><span class="mord mathnormal">p</span><span class=mclose>)</span></span></span></span> for every product <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>p</mi></mrow><annotation encoding=application/x-tex>p</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal">p</span></span></span></span> appearing in the image.</li>
<li>If a product does not appear, then <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mtext>count</mtext><mo stretchy=false>(</mo><mi>p</mi><mo stretchy=false>)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding=application/x-tex>\text{count}(p) = 0</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>count</span></span><span class=mopen>(</span><span class="mord mathnormal">p</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0</span></span></span></span>.</li>
</ul>
<p>Available training resources include:</p>
<ul>
<li>A set of single-product exemplar images <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>S</mi><mo>=</mo><mo stretchy=false>{</mo><mo stretchy=false>(</mo><msub><mi>I</mi><mi>s</mi></msub><mo separator=true>,</mo><msub><mi>y</mi><mi>s</mi></msub><mo stretchy=false>)</mo><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>S = \{(I_s, y_s)\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05764em>S</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.07847em>I</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0785em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)}</span></span></span></span>, each image corresponding to one product category;</li>
<li>An optional set of checkout images <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>C</mi><mo>=</mo><mo stretchy=false>{</mo><mo stretchy=false>(</mo><msub><mi>I</mi><mi>c</mi></msub><mo separator=true>,</mo><msub><mi>Y</mi><mi>c</mi></msub><mo stretchy=false>)</mo><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>C = \{(I_c, Y_c)\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.07847em>I</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0785em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.22222em>Y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.2222em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)}</span></span></span></span>, where <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>Y</mi><mi>c</mi></msub></mrow><annotation encoding=application/x-tex>Y_c</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.22222em>Y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.2222em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> may contain different levels of annotation.</li>
</ul>
<p>This setup is highly challenging and offers a space to explore the intersection of classification, counting, detection, weak supervision, and domain shift tasks.</p>
<hr>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=dataset-design>Dataset Design<a href=#dataset-design class=hash-link aria-label="Direct link to Dataset Design" title="Direct link to Dataset Design">​</a></h2>
<p>To address these challenges, the authors designed the RPC (Retail Product Checkout) dataset with six key features:</p>
<ol>
<li>
<p><strong>Large-scale product categories and sample size</strong></p>
<ul>
<li>
<p>Contains <strong>200 product categories (SKUs)</strong>, with about 4 physical items per category, totaling <strong>83,739 images</strong>.</p>
</li>
<li>
<p>Among these, there are 53,739 single-product exemplar images and 30,000 checkout images, far larger than existing public datasets.</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=dataset src=/en/assets/images/img1-20aeb8d848595ae630a6f92be0158d95.jpg width=1088 height=748 class=img_ev3q></figure></div>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt="dataset infos" src=/en/assets/images/img2-3e8c832ece3ec2c39a4ea392c93d5ed2.jpg width=1100 height=476 class=img_ev3q></figure></div>
</li>
</ul>
</li>
<li>
<p><strong>Two image types: exemplar and stacked images</strong></p>
<ul>
<li>Single-product exemplar images: clear product images taken from multiple angles, simulating e-commerce product photos.</li>
<li>Checkout images: captured on a simulated checkout counter, containing multiple products, fixed viewpoint, with stacking and real occlusion.</li>
</ul>
</li>
<li>
<p><strong>Scene realism</strong></p>
<ul>
<li>Products in checkout images are randomly selected, random quantities, and placed arbitrarily;</li>
<li>Contain heavy occlusion, rotation, and multiple object overlap, simulating real retail complexity.</li>
</ul>
</li>
<li>
<p><strong>Hierarchical product category structure</strong></p>
<ul>
<li>All products are divided into <strong>17 meta-categories</strong> such as bottle-shaped, box-shaped, bag-shaped, etc.</li>
<li>This helps models learn semantic structure between categories and can be used as auxiliary supervision signals or for hierarchical classification research.</li>
</ul>
</li>
<li>
<p><strong>Clutter level annotation</strong></p>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt="clutter levels" src=/en/assets/images/img7-1501aed4c494cb3334b9e0864623d429.jpg width=816 height=224 class=img_ev3q></figure></div>
<ul>
<li>Based on the number and variety of products in each checkout image, the clutter level is divided into three types, helping analyze model performance stability under different complexities.</li>
</ul>
</li>
<li>
<p><strong>Three supervision levels</strong></p>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt="weak to strong" src=/en/assets/images/img5-12e0eabb57ac664c0fca7e86096217df.jpg width=1104 height=428 class=img_ev3q></figure></div>
<ul>
<li><strong>Weak supervision</strong>: shopping list only (product types and counts);</li>
<li><strong>Medium supervision</strong>: point annotations (center points and categories of each product);</li>
<li><strong>Strong supervision</strong>: bounding boxes (complete bounding box and category annotation per product).</li>
</ul>
</li>
</ol>
<p>These designs make RPC a highly extensible benchmark, capable not only of evaluating recognition and counting abilities but also enabling research on weakly supervised detection, domain adaptation, multi-scale classification, and more.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=dataset-construction-process>Dataset Construction Process<a href=#dataset-construction-process class=hash-link aria-label="Direct link to Dataset Construction Process" title="Direct link to Dataset Construction Process">​</a></h2>
<p><img decoding=async loading=lazy alt=meta-categories src=/en/assets/images/img6-3eda4c6788813c9c88ed32a2d451df64.jpg width=1514 height=378 class=img_ev3q></p>
<p>This dataset contains <strong>200 retail product categories (SKUs)</strong>, grouped into <strong>17 meta-categories</strong> based on appearance and function, covering a diverse range from food to daily necessities:</p>
<blockquote>
<p>puffed food, dried fruit, dried food, instant drink, instant noodles, dessert, drink, alcohol, milk, canned food, chocolate, gum, candy, seasoner, personal hygiene, tissue, stationery.</p>
</blockquote>
<p>These categories encompass various forms such as bottles, boxes, cans, and bags.</p>
<p>SKUs within the same meta-category often exhibit high visual similarity. For example, different “juice” products may differ only by a word or label color, representing one of the most challenging fine-grained recognition problems in the ACO task.</p>
<hr>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=single-product-exemplar-images>Single-Product Exemplar Images<a href=#single-product-exemplar-images class=hash-link aria-label="Direct link to Single-Product Exemplar Images" title="Direct link to Single-Product Exemplar Images">​</a></h3>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt="dataset infos" src=/en/assets/images/img3-1521b5b48e909a5416f301811a8c4a61.jpg width=1096 height=712 class=img_ev3q></figure></div>
<p>To capture each product’s appearance from multiple viewpoints, the authors designed an automated photography process:</p>
<ul>
<li>Using <strong>four fixed-angle cameras</strong> corresponding to: top view, horizontal (side) view, 30° and 45° oblique views;</li>
<li>Each product is placed on a <strong>360-degree rotating turntable</strong>, photographed every 9 degrees for a total of 40 images;</li>
<li>Each camera takes 40 shots → generating <strong>160 viewpoint images per SKU</strong>;</li>
<li>If a product has different top and bottom appearances (e.g., box or bag), it is flipped and re-photographed to capture the underside features.</li>
</ul>
<p>In total, this phase produced <strong>53,739 exemplar images</strong>, all with <strong>clean backgrounds, multiple angles, and single products</strong>, corresponding to the typical source domain images used in training.</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt="dataset infos" src=/en/assets/images/img8-597d9c34b1dcab673206d9f95a0b9d57.jpg width=1076 height=520 class=img_ev3q></figure></div>
<hr>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=checkout-image-construction-process>Checkout Image Construction Process<a href=#checkout-image-construction-process class=hash-link aria-label="Direct link to Checkout Image Construction Process" title="Direct link to Checkout Image Construction Process">​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt="dataset infos" src=/en/assets/images/img4-7175c28f1f881256ebecc68c31fc07f0.jpg width=868 height=1080 class=img_ev3q></figure></div>
<p>Unlike exemplars, checkout images aim to simulate real checkout scenarios and deliberately introduce clutter and occlusion:</p>
<ul>
<li>Images are shot on an <strong>80cm × 80cm whiteboard</strong> background, with a camera positioned directly overhead at 1800 × 1800 resolution;</li>
<li>Product categories and quantities per image are randomly combined but controlled by preset “clutter levels”;</li>
<li>Products are randomly placed and rotated without manual alignment, further simulating realistic stacking scenarios.</li>
</ul>
<p>Based on occlusion and density, checkout images are divided into three clutter levels:</p>
<div style=white-space:nowrap;overflow-x:auto;font-size:1rem;line-height:0.8;justify-content:center;display:flex><table><thead><tr><th>Clutter Level<th>Number of Product Categories<th>Total Product Instances<th>Characteristics<tbody><tr><td>Easy<td>Few (e.g., 3–5 categories)<td>Low total count<td>Almost no occlusion, large gaps<tr><td>Medium<td>Moderate (e.g., 6–10 categories)<td>Moderate total count<td>Occasional occlusion, moderate density<tr><td>Hard<td>Many (over 10 categories)<td>High total count<td>Heavy stacking and occlusion, difficult recognition</table></div>
<p>Each clutter level contains 10,000 images, totaling <strong>30,000 checkout images</strong>.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=evaluation-metrics>Evaluation Metrics<a href=#evaluation-metrics class=hash-link aria-label="Direct link to Evaluation Metrics" title="Direct link to Evaluation Metrics">​</a></h2>
<p>The goal of the automatic checkout task is: <strong>to correctly predict the types and quantities of all products in an image</strong>.</p>
<p>To quantify model performance on this task, the RPC dataset proposes dedicated metrics designed specifically for ACO tasks, considering single-image accuracy, quantity error, category hierarchy performance, and semantic consistency.</p>
<p>Here are the four core metrics:</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=checkout-accuracy-cacc>Checkout Accuracy (cAcc)<a href=#checkout-accuracy-cacc class=hash-link aria-label="Direct link to Checkout Accuracy (cAcc)" title="Direct link to Checkout Accuracy (cAcc)">​</a></h3>
<p>cAcc represents the overall accuracy.</p>
<p>The ultimate goal of an ACO system is to <strong>perfectly predict the entire shopping list in a single image</strong>. Thus, the core metric is:</p>
<blockquote>
<p><strong>If the model’s predicted quantities for all product categories exactly match the ground truth, the image is counted as correct.</strong></p>
</blockquote>
<p>Formally:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>c</mi><mi>A</mi><mi>c</mi><mi>c</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>δ</mi><mrow><mo fence=true>(</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi mathvariant=normal>∣</mi><msub><mi>P</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub><mo>−</mo><mi>G</mi><msub><mi>T</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub><mi mathvariant=normal>∣</mi><mo separator=true>,</mo><mn>0</mn><mo fence=true>)</mo></mrow></mrow><annotation encoding=application/x-tex>cAcc = \frac{1}{N} \sum_{i=1}^{N} \delta \left( \sum_{k=1}^{K} |P_{i,k} - GT_{i,k}|, 0 \right)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">c</span><span class="mord mathnormal">A</span><span class="mord mathnormal">cc</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:3.1304em;vertical-align:-1.3021em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3214em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>N</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8723em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.10903em>N</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2777em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.03785em>δ</span><span class=mspace style=margin-right:0.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0em><span class="delimsizing size4">(</span></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8479em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.07153em>K</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.3021em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord>∣</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span><span class="mord mathnormal">G</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>T</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mord>∣</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>0</span><span class="mclose delimcenter" style=top:0em><span class="delimsizing size4">)</span></span></span></span></span></span></span>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub></mrow><annotation encoding=application/x-tex>P_{i,k}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>: predicted count of category <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>k</mi></mrow><annotation encoding=application/x-tex>k</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.03148em>k</span></span></span></span> in image <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>;</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>G</mi><msub><mi>T</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub></mrow><annotation encoding=application/x-tex>GT_{i,k}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class="mord mathnormal">G</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>T</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>: ground truth count;</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>δ</mi><mo stretchy=false>(</mo><mo>⋅</mo><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\delta(\cdot)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.03785em>δ</span><span class=mopen>(</span><span class=mord>⋅</span><span class=mclose>)</span></span></span></span>: returns 1 if the sum of absolute differences is zero (perfect prediction), else 0.</li>
</ul>
<p>This is a very strict metric — any single miscount causes the image to be considered incorrect.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=average-counting-distance-acd>Average Counting Distance (ACD)<a href=#average-counting-distance-acd class=hash-link aria-label="Direct link to Average Counting Distance (ACD)" title="Direct link to Average Counting Distance (ACD)">​</a></h3>
<p>ACD measures average counting error.</p>
<p>Instead of requiring perfect prediction, it evaluates how many counts the model is off on average:</p>
<blockquote>
<p><strong>Measures the total prediction error (L1 distance) over all categories in each image.</strong></p>
</blockquote>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>A</mi><mi>C</mi><mi>D</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi mathvariant=normal>∣</mi><msub><mi>P</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub><mo>−</mo><mi>G</mi><msub><mi>T</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub><mi mathvariant=normal>∣</mi></mrow><annotation encoding=application/x-tex>ACD = \frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} |P_{i,k} - GT_{i,k}|</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:3.1304em;vertical-align:-1.3021em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3214em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>N</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8723em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.10903em>N</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2777em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8479em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.07153em>K</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.3021em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord>∣</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.0361em;vertical-align:-0.2861em></span><span class="mord mathnormal">G</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>T</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mord>∣</span></span></span></span></span>
<p>This metric suits comparing model accuracy on quantity prediction, regardless of classification correctness — only how many items are missed or overcounted.</p>
<hr>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=mean-category-counting-distance-mccd>Mean Category Counting Distance (mCCD)<a href=#mean-category-counting-distance-mccd class=hash-link aria-label="Direct link to Mean Category Counting Distance (mCCD)" title="Direct link to Mean Category Counting Distance (mCCD)">​</a></h3>
<p>mCCD denotes the mean relative counting error per category, focusing on category-specific recognition difficulty:</p>
<blockquote>
<p><strong>Measures the ratio of prediction error to true count per category, averaged over all categories.</strong></p>
</blockquote>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>m</mi><mi>C</mi><mi>C</mi><mi>D</mi><mo>=</mo><mfrac><mn>1</mn><mi>K</mi></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi mathvariant=normal>∣</mi><msub><mi>P</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub><mo>−</mo><mi>G</mi><msub><mi>T</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub><mi mathvariant=normal>∣</mi></mrow><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>G</mi><msub><mi>T</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub></mrow></mfrac></mrow><annotation encoding=application/x-tex>mCCD = \frac{1}{K} \sum_{k=1}^{K} \frac{ \sum_{i=1}^{N} |P_{i,k} - GT_{i,k}| }{ \sum_{i=1}^{N} GT_{i,k} }</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style=margin-right:0.07153em>CC</span><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:3.1304em;vertical-align:-1.3021em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3214em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>K</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8479em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.07153em>K</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.3021em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.6709em><span style=top:-2.1288em><span class=pstrut style=height:3em></span><span class=mord><span class=mop><span class="mop op-symbol small-op" style=position:relative;top:0em>∑</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.9812em><span style=top:-2.4003em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.2029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.10903em>N</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2997em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">G</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>T</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.6897em><span class=pstrut style=height:3em></span><span class=mord><span class=mop><span class="mop op-symbol small-op" style=position:relative;top:0em>∑</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.9812em><span style=top:-2.4003em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.2029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.10903em>N</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2997em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord>∣</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span><span class="mord mathnormal">G</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>T</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mord>∣</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.1709em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>This metric reflects whether the model tends to over- or under-estimate certain categories (e.g., fine-grained products) and evaluates stability under class imbalance and long-tail distributions.</p>
<hr>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=mean-category-iou-mciou>Mean Category IoU (mCIoU)<a href=#mean-category-iou-mciou class=hash-link aria-label="Direct link to Mean Category IoU (mCIoU)" title="Direct link to Mean Category IoU (mCIoU)">​</a></h3>
<p>mCIoU measures shopping list similarity.</p>
<p>Finally, the authors define an IoU-like metric to assess semantic closeness between predicted and ground truth shopping lists:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>m</mi><mi>C</mi><mi>I</mi><mi>o</mi><mi>U</mi><mo>=</mo><mfrac><mn>1</mn><mi>K</mi></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>min</mi><mo>⁡</mo><mo stretchy=false>(</mo><msub><mi>P</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub><mo separator=true>,</mo><mi>G</mi><msub><mi>T</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub><mo stretchy=false>)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>max</mi><mo>⁡</mo><mo stretchy=false>(</mo><msub><mi>P</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub><mo separator=true>,</mo><mi>G</mi><msub><mi>T</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>k</mi></mrow></msub><mo stretchy=false>)</mo></mrow></mfrac></mrow><annotation encoding=application/x-tex>mCIoU = \frac{1}{K} \sum_{k=1}^{K} \frac{ \sum_{i=1}^{N} \min(P_{i,k}, GT_{i,k}) }{ \sum_{i=1}^{N} \max(P_{i,k}, GT_{i,k}) }</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class="mord mathnormal" style=margin-right:0.07847em>I</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style=margin-right:0.10903em>U</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:3.1304em;vertical-align:-1.3021em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3214em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>K</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8479em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.07153em>K</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.3021em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.6709em><span style=top:-2.1288em><span class=pstrut style=height:3em></span><span class=mord><span class=mop><span class="mop op-symbol small-op" style=position:relative;top:0em>∑</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.9812em><span style=top:-2.4003em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.2029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.10903em>N</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2997em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>max</span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">G</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>T</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.6897em><span class=pstrut style=height:3em></span><span class=mord><span class=mop><span class="mop op-symbol small-op" style=position:relative;top:0em>∑</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.9812em><span style=top:-2.4003em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.2029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.10903em>N</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2997em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>min</span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">G</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>T</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.1709em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<ul>
<li>The closer the predicted and actual counts for a category, the higher the ratio in numerator and denominator;</li>
<li>If either predicted or ground truth count is zero, the IoU tends to zero.</li>
</ul>
<p>mCIoU is a <strong>semantically oriented, error-tolerant metric</strong>, particularly suitable for analyzing whether the model can capture the main contents even without perfect correctness.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=baseline-method-experiments>Baseline Method Experiments<a href=#baseline-method-experiments class=hash-link aria-label="Direct link to Baseline Method Experiments" title="Direct link to Baseline Method Experiments">​</a></h2>
<p>Since the automatic checkout (ACO) problem itself is a complex task involving cross-domain, few-shot, and fine-grained challenges, there is currently no unified solution framework.</p>
<p>To establish benchmarks on the RPC dataset, the authors treat ACO as a <strong>cross-domain detection task</strong> and propose four progressively advanced baseline methods. All methods train solely on exemplar single-product images without relying on annotations from checkout images.</p>
<hr>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=single>Single<a href=#single class=hash-link aria-label="Direct link to Single" title="Direct link to Single">​</a></h3>
<p>This method directly trains an FPN on exemplar images.</p>
<p>The most straightforward approach is to use single-product exemplar images as supervised data to train an object detector. The authors choose the <strong>Feature Pyramid Network (FPN)</strong> as the backbone.</p>
<p>However, this baseline barely generalizes to checkout images because exemplars are clean, single-object images without occlusion, whereas test images contain multiple objects, stacked occlusions, and cluttered lighting—creating a domain gap. As a result, performance is very poor even on the easy clutter setting, making it the weakest baseline.</p>
<hr>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=syn>Syn<a href=#syn class=hash-link aria-label="Direct link to Syn" title="Direct link to Syn">​</a></h3>
<p>This strategy trains on synthetic checkout scenes.</p>
<p>To reduce the domain gap, the second method “cut-and-paste” exemplar product images to <strong>synthesize simulated checkout images</strong>. The process is:</p>
<ul>
<li>Obtain product masks via salient region segmentation and CRF (Conditional Random Fields) post-processing;</li>
<li>Randomly paste multiple products onto a blank background to build multi-object stacked scenes;</li>
<li>Generate <strong>100,000 synthetic checkout images</strong> for training according to different clutter level rules.</li>
</ul>
<p>This approach brings training data closer to test scenarios, significantly improving cAcc (about <strong>18% gain on easy clutter</strong>). However, performance remains limited on medium and hard clutter levels, indicating that synthetic images alone cannot fully bridge the style and noise domain gap.</p>
<hr>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=render>Render<a href=#render class=hash-link aria-label="Direct link to Render" title="Direct link to Render">​</a></h3>
<div align=center><figure style=width:50%><p><img decoding=async loading=lazy alt=cycle-gan src=/en/assets/images/img9-79b1e401827131c052c1c4e53e3aa436.jpg width=740 height=1080 class=img_ev3q></figure></div>
<p>This method employs Cycle-GAN for cross-domain style transfer.</p>
<p>As shown above, the left side depicts simple synthetic pasted images, while the right side shows images after Cycle-GAN style translation, which appear more natural and closer to real checkout scenes. The pipeline is:</p>
<ul>
<li>Perform Cycle-GAN translation on synthetic images to better match real checkout style;</li>
<li>Train the FPN detector using the translated images.</li>
</ul>
<p>This <strong>domain translation</strong> strategy significantly boosts generalization across clutter levels, proving Cycle-GAN effectively bridges visual style gaps and enhances cross-domain detection capability.</p>
<hr>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=synrender>Syn+Render<a href=#synrender class=hash-link aria-label="Direct link to Syn+Render" title="Direct link to Syn+Render">​</a></h3>
<p>The final strategy mixes data to increase sample diversity.</p>
<p>The authors combine <strong>rendered images</strong> and <strong>original synthetic images</strong> during training to leverage sample diversity and further improve model generalization. Results outperform using either Syn or Render alone.</p>
<p>This suggests that data style consistency (render) and sample diversity (syn) complement each other, helping the model learn more robust decision boundaries.</p>
<hr>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=detailed-evaluation-table>Detailed Evaluation Table<a href=#detailed-evaluation-table class=hash-link aria-label="Direct link to Detailed Evaluation Table" title="Direct link to Detailed Evaluation Table">​</a></h3>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=benchmark src=/en/assets/images/img10-089e3323dfdb4b568e55d102d4e1181b.jpg width=1526 height=702 class=img_ev3q></figure></div>
<p>Experiments report results on:</p>
<ul>
<li>ACO task metrics (cAcc, ACD, mCCD, mCIoU);</li>
<li>Standard detection metrics (mAP@50, mmAP).</li>
</ul>
<p>Training settings:</p>
<ul>
<li>Input images resized with shortest side = 800 px;</li>
<li>Synchronized SGD, batch size 2 images per GPU × 2 GPUs;</li>
<li>Maximum 512 RoIs per image;</li>
<li>Initial learning rate 0.02, decayed to 0.002 after 60K iterations;</li>
<li>For each clutter level, 2,000 images used for validation, 8,000 for testing.</li>
</ul>
<p>Results show that even the best “Syn+Render” baseline remains impractical on medium and hard clutter. This indicates that ACO difficulty stems not only from domain shift but also from stacking occlusion, fine-grained recognition, and long-tail distributions.</p>
<p>Despite good mAP results (e.g., <strong>72.72% mmAP</strong> on hard clutter), from a cAcc perspective the model still falls far short. <strong>Correctly recognizing the entire shopping list in one image remains a very strict requirement.</strong></p>
<p>Failure cases primarily arise from:</p>
<ol>
<li>Missed detections;</li>
<li>Dense arrangements causing occlusion;</li>
<li>Fine-grained product misclassification;</li>
<li>False positives.</li>
</ol>
<p>These challenges point to clear future research directions: <strong>weak supervision, multi-view fusion, semantic alignment, and increased sample diversity</strong>.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>The paper mentions that the architecture used is FPN but does not specify whether ResNet-50 or ResNet-101 was employed.<p>In another DPNet paper, it is stated that ResNet-101 was used in comparisons; therefore, we assume ResNet-101 here.<p>Reference: <a href=https://arxiv.org/abs/1904.04978 target=_blank rel="noopener noreferrer"><strong>[19.04] Data Priming Network for Automatic Check-Out</strong></a></div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=future-research-directions>Future Research Directions<a href=#future-research-directions class=hash-link aria-label="Direct link to Future Research Directions" title="Direct link to Future Research Directions">​</a></h2>
<p>Although this paper establishes RPC baselines from the cross-domain detection perspective, the ACO task’s nature is more open and diverse than a single solution. RPC provides a flexible structure and annotations, inspiring several potential research avenues:</p>
<ul>
<li>
<p><strong>Online learning and dynamic expansion</strong>:</p>
<p>In real scenarios, product lists are not fixed; new products keep appearing, requiring systems to <strong>learn and update incrementally in real time</strong>. Achieving quick inclusion of new products without retraining the entire model poses a typical online learning problem. The cross-domain and fine-grained nature of ACO complicates this, possibly demanding novel architectures and strategies.</p>
</li>
<li>
<p><strong>List prediction models skipping detection</strong>:</p>
<p>Another direction is to <strong>bypass bounding boxes or detection pipelines</strong> entirely, directly predicting shopping lists from checkout images, framing the problem as a multi-class, multi-instance <strong>object counting</strong> task.</p>
<p>Unlike traditional counting, ACO involves hundreds of object categories, very few samples, and high visual similarity, constituting a novel form of cross-category counting.</p>
</li>
<li>
<p><strong>Hybrid supervised learning frameworks</strong>:</p>
<p>RPC offers checkout annotations at three supervision levels (list-level, point-level, bbox-level). How to effectively combine these heterogeneous labels and design an <strong>adaptive, abstract hybrid supervision learning framework</strong> remains an open problem, especially critical when data collection costs are high.</p>
</li>
<li>
<p><strong>Extensions to other computer vision applications</strong>:</p>
<p>Although RPC targets automatic checkout, its image and annotation design support other research areas such as:</p>
<ul>
<li>Object retrieval;</li>
<li>Few-shot detection;</li>
<li>Weakly supervised detection;</li>
<li>Fully supervised detection.</li>
</ul>
<p>Particularly, complete bounding box and SKU annotations in checkout images enable training and evaluating detection models, making RPC a complementary dataset for general object detection research.</p>
</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=conclusion>Conclusion<a href=#conclusion class=hash-link aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>This paper was published in 2019; we review it in 2025.</p>
<p>In recent years, large vision-language models have rapidly developed, showing initial capabilities in product recognition and reasoning in images. Many have begun exploring their use in automatic checkout scenarios.</p>
<p>However, practical progress remains elusive, likely due to unresolved challenges in fine-grained recognition, occlusion handling, and cross-domain stability inherent to ACO.</p>
<p>This underscores the value of the RPC dataset: it is not only a past milestone but also a foundation for future research. We hope more researchers will build on this to propose innovative methods and solutions, driving the practical application of automatic checkout technology.</header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>Last updated<!-- --> on <b><time datetime=2025-07-07T04:54:51.000Z itemprop=dateModified>Jul 7, 2025</time></b> by <b>zephyr-sh</b></span></div></div><section class=ctaSection_iCjC><div class="
        simpleCta_ji_Y
        simple-cta__coffee_YwC8
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>☕ Fuel my writing with a coffee</h3><p class=simple-cta__subtitle_ol86>Your support keeps my AI & full-stack guides coming.<div class=simple-cta__buttonWrapper_jk1Y><img src=/en/img/bmc-logo.svg alt=cta-button class=simple-cta__buttonImg_Q9VV></div></div><div class="ant-row ant-row-stretch cardsSection_wRaP css-mc1tut" style=margin-left:-8px;margin-right:-8px;row-gap:16px><div style=padding-left:8px;padding-right:8px;display:flex class="ant-col ant-col-xs-24 css-mc1tut"><div class="ant-card ant-card-bordered card_gKx9 fadeInUp_n33J hoverTransform_Mozy css-mc1tut" style=flex:1;display:flex;flex-direction:column><div class=ant-card-body><div style=text-align:center;margin-top:1rem><img src=/en/img/icons/all_in.svg alt="AI / Full-Stack / Custom — All In icon" style=width:48px;height:48px></div><span class="ant-tag ant-tag-orange card__tag_PLj3 css-mc1tut">All-in</span><h4 class=card__title_SQBY>AI / Full-Stack / Custom — All In</h4><p class=card__concept_Ak8F>From idea to launch—efficient systems that are future-ready.<div class=card__bulletHeader_b6cf><h5 class=card__bulletTitle_R_wg>All-In Bundle</h5></div><ul class=card__bulletList_SrNN><li class=card__bulletItem_wCRd>Consulting + Dev + Deploy<li class=card__bulletItem_wCRd>Maintenance & upgrades</ul></div></div></div></div><div class="
        simpleCta_ji_Y
        simple-cta__outro_AXbn
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>🚀 Ready for your next project?</h3><p class=simple-cta__subtitle_ol86>Need a tech partner or custom solution? Let's connect.</div></section><div style=margin-top:3rem> </div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/en/papers/category/retail-product-5><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>Retail Product (5)</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/en/papers/retail-product/sku-110k/><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>[19.04] SKU-110K</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#check-please class="table-of-contents__link toc-highlight">Check, Please!</a><li><a href=#problem-definition class="table-of-contents__link toc-highlight">Problem Definition</a><li><a href=#dataset-design-philosophy class="table-of-contents__link toc-highlight">Dataset Design Philosophy</a><li><a href=#dataset-design class="table-of-contents__link toc-highlight">Dataset Design</a><li><a href=#dataset-construction-process class="table-of-contents__link toc-highlight">Dataset Construction Process</a><ul><li><a href=#single-product-exemplar-images class="table-of-contents__link toc-highlight">Single-Product Exemplar Images</a><li><a href=#checkout-image-construction-process class="table-of-contents__link toc-highlight">Checkout Image Construction Process</a></ul><li><a href=#evaluation-metrics class="table-of-contents__link toc-highlight">Evaluation Metrics</a><ul><li><a href=#checkout-accuracy-cacc class="table-of-contents__link toc-highlight">Checkout Accuracy (cAcc)</a><li><a href=#average-counting-distance-acd class="table-of-contents__link toc-highlight">Average Counting Distance (ACD)</a><li><a href=#mean-category-counting-distance-mccd class="table-of-contents__link toc-highlight">Mean Category Counting Distance (mCCD)</a><li><a href=#mean-category-iou-mciou class="table-of-contents__link toc-highlight">Mean Category IoU (mCIoU)</a></ul><li><a href=#baseline-method-experiments class="table-of-contents__link toc-highlight">Baseline Method Experiments</a><ul><li><a href=#single class="table-of-contents__link toc-highlight">Single</a><li><a href=#syn class="table-of-contents__link toc-highlight">Syn</a><li><a href=#render class="table-of-contents__link toc-highlight">Render</a><li><a href=#synrender class="table-of-contents__link toc-highlight">Syn+Render</a><li><a href=#detailed-evaluation-table class="table-of-contents__link toc-highlight">Detailed Evaluation Table</a></ul><li><a href=#future-research-directions class="table-of-contents__link toc-highlight">Future Research Directions</a><li><a href=#conclusion class="table-of-contents__link toc-highlight">Conclusion</a></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/en/docs>Projects</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/papers/intro>Papers</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/blog>Blog</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/terms-of-service>TermsOfUse</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/privacy-policy>Privacy Policy</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/become-an-author>Become an author</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/worklog>Worklog</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>