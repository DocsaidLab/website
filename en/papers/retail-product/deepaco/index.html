<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-retail-product/deepaco/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.8.1"><title data-rh=true>[22.06] DeepACO | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/en/papers/retail-product/deepaco/><meta data-rh=true property=og:locale content=en><meta data-rh=true property=og:locale:alternate content=zh_hant><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[22.06] DeepACO | DOCSAID"><meta data-rh=true name=description content="The Overhead Hunter"><meta data-rh=true property=og:description content="The Overhead Hunter"><link data-rh=true rel=icon href=/en/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/en/papers/retail-product/deepaco/><link data-rh=true rel=alternate href=https://docsaid.org/papers/retail-product/deepaco/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/retail-product/deepaco/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/retail-product/deepaco/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/retail-product/deepaco/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://docsaid.org/en/papers/category/retail-product-5","name":"Retail Product (5)","position":1},{"@type":"ListItem","item":"https://docsaid.org/en/papers/retail-product/deepaco/","name":"[22.06] DeepACO","position":2}]}</script><link rel=alternate type=application/rss+xml href=/en/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/en/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/en/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/en/assets/css/styles.e52f1f88.css><script src=/en/assets/js/runtime~main.806dadac.js defer></script><script src=/en/assets/js/main.1768e0fb.js defer></script><body class=navigation-with-keyboard><svg xmlns=http://www.w3.org/2000/svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light",e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/en/><div class=navbar__logo><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/en/docs/>Projects</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/en/papers/intro>Papers</a><a class="navbar__item navbar__link" href=/en/blog>Blog</a><a class="navbar__item navbar__link" href=/en/playground/intro>Playground</a><a class="navbar__item navbar__link" href=/en/services>Services</a><a class="navbar__item navbar__link" href=/en/aboutus>About Us</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>English</a><ul class=dropdown__menu><li><a href=/papers/retail-product/deepaco/ target=_self rel="noopener noreferrer" class=dropdown__link lang=zh-hant>繁體中文</a><li><a href=/en/papers/retail-product/deepaco/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=en>English</a><li><a href=/ja/papers/retail-product/deepaco/ target=_self rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-mc1tut ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/en/><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>Paper Notes</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="Expand sidebar category 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/contrastive-learning-14>Contrastive Learning (14)</a><button aria-label="Expand sidebar category 'Contrastive Learning (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/deepseek-5>DeepSeek (5)</a><button aria-label="Expand sidebar category 'DeepSeek (5)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-anti-spoofing-43>Face Anti-Spoofing (43)</a><button aria-label="Expand sidebar category 'Face Anti-Spoofing (43)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="Expand sidebar category 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/feature-fusion-10>Feature Fusion (10)</a><button aria-label="Expand sidebar category 'Feature Fusion (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/image-generation-1>Image Generation (1)</a><button aria-label="Expand sidebar category 'Image Generation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="Expand sidebar category 'Lightweight (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/mamba-4>Mamba (4)</a><button aria-label="Expand sidebar category 'Mamba (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/model-tuning-8>Model Tuning (8)</a><button aria-label="Expand sidebar category 'Model Tuning (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/multimodality-24>Multimodality (24)</a><button aria-label="Expand sidebar category 'Multimodality (24)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/normalization-1>Normalization (1)</a><button aria-label="Expand sidebar category 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/object-detection-16>Object Detection (16)</a><button aria-label="Expand sidebar category 'Object Detection (16)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/reparameterization-8>Reparameterization (8)</a><button aria-label="Expand sidebar category 'Reparameterization (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/en/papers/category/retail-product-5>Retail Product (5)</a><button aria-label="Collapse sidebar category 'Retail Product (5)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/retail-product/rpc/>[19.01] RPC Dataset</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/retail-product/sku-110k/>[19.04] SKU-110K</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/retail-product/dpsnet/>[20.11] DPSNet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/retail-product/retail-product-recognition-review/>[20.11] RPR: Review</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/en/papers/retail-product/deepaco/>[22.06] DeepACO</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="Expand sidebar category 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-detection-14>Text Detection (14)</a><button aria-label="Expand sidebar category 'Text Detection (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="Expand sidebar category 'Text Recognition (20)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="Expand sidebar category 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/transformers-17>Transformers (17)</a><button aria-label="Expand sidebar category 'Transformers (17)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/vision-transformers-13>Vision Transformers (13)</a><button aria-label="Expand sidebar category 'Vision Transformers (13)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>All Notes: 233 entries</a></ul></nav><button type=button title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/en/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li class=breadcrumbs__item><a class=breadcrumbs__link href=/en/papers/category/retail-product-5><span>Retail Product (5)</span></a><li class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>[22.06] DeepACO</span></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>[22.06] DeepACO</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt="Z. Yuan" class=docAuthorImg_vlJe><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Z. Yuan</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a href=https://www.linkedin.com/in/ze-yuan-sh7/ target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 448 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=the-overhead-hunter>The Overhead Hunter<a href=#the-overhead-hunter class=hash-link aria-label="Direct link to The Overhead Hunter" title="Direct link to The Overhead Hunter">​</a></h2>
<p><a href=https://openaccess.thecvf.com/content/CVPR2022W/AICity/papers/Pham_DeepACO_A_Robust_Deep_Learning-Based_Automatic_Checkout_System_CVPRW_2022_paper.pdf target=_blank rel="noopener noreferrer"><strong>DeepACO: A Robust Deep Learning-based Automatic Checkout System</strong></a></p>
<hr>
<p>This is a paper from a CVPR workshop. Let’s take a look together.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=problem-definition>Problem Definition<a href=#problem-definition class=hash-link aria-label="Direct link to Problem Definition" title="Direct link to Problem Definition">​</a></h2>
<p>In recent years, the retail industry has been undergoing a profound transformation driven by artificial intelligence and computer vision technologies. Among them, <strong>Automatic Checkout (ACO)</strong> is regarded as one of the most revolutionary application scenarios.</p>
<p>An ideal ACO system should be able to, at the very moment a customer places items on the checkout counter:</p>
<blockquote>
<p><strong>Instantly recognize all products and accurately output the shopping list without any human intervention throughout the entire process!</strong></p>
</blockquote>
<p>Is this really possible?</p>
<p>In reality, building such a system faces countless challenges:</p>
<ul>
<li><strong>Product occlusion and motion blur</strong>;</li>
<li><strong>Highly similar product appearances</strong>;</li>
<li><strong>The real cost caused by miss-detection and misclassification</strong>;</li>
<li><strong>A large variety of product categories with frequent restocking and replacement, making it difficult to collect training images that reflect real scenarios</strong>.</li>
</ul>
<p>Traditional methods such as background subtraction, SIFT, HOG features combined with SVM or random forest classifiers cannot effectively handle occlusion and lighting variations, resulting in limited accuracy.</p>
<p>Even with the advent of deep learning, models like Faster R-CNN, SSD, and YOLO series have made significant breakthroughs but still face many tough bottlenecks in practical deployment:</p>
<ul>
<li>Accurate detection on single images does not guarantee precise product counting across a video sequence;</li>
<li>To enhance stability and consistency, it is necessary to introduce Multi-Object Tracking (MOT) techniques;</li>
</ul>
<p>However, MOT itself faces challenges of high computational cost, real-time performance, and difficulty maintaining object IDs, especially under online tracking-by-detection schemes.</p>
<p>On the other hand, the data requirements for ACO differ from typical detection tasks, as it heavily relies on real-world scenes with “multiple objects in one frame,” “severe occlusion,” and “drastic viewpoint and lighting changes.” Existing datasets include:</p>
<ul>
<li><strong>RPC</strong>: 80,000 static and checkout scene images covering 200 product categories;</li>
<li><strong>RP2K</strong>: Over 2,000 product categories and 350,000 real photographed images focusing on fine-grained classification;</li>
<li><strong>AI City Challenge Checkout</strong>: Synthetic data generated via 3D scanning simulating physical product display and lighting variations, producing 116,500 images.</li>
</ul>
<p>Even so, these datasets still struggle to fully cover the constantly updating product appearances in real retail environments.</p>
<p>So, faced with this <strong>high occlusion, high confusion, high update frequency</strong> extreme scenario, is it possible to build a <strong>full-process ACO system capable of stable tracking and accurate counting</strong>?</p>
<p>The authors of this paper intend to solve this problem.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=proposed-solution>Proposed Solution<a href=#proposed-solution class=hash-link aria-label="Direct link to Proposed Solution" title="Direct link to Proposed Solution">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=data-synthesis>Data Synthesis<a href=#data-synthesis class=hash-link aria-label="Direct link to Data Synthesis" title="Direct link to Data Synthesis">​</a></h3>
<p>To do a good job, one must first sharpen the tools.</p>
<p>Therefore, solving the training data problem is the first step.</p>
<p>For an Automatic Checkout system (ACO), the core capability is:</p>
<blockquote>
<p><strong>Accurately predicting the category and quantity of every product in any arbitrary combination.</strong></p>
</blockquote>
<p>However, if training relies solely on real checkout footage, it will face dual challenges of massive data scale and high maintenance cost: many product categories, short update cycles, and almost impossible coverage of all combinations and occlusion scenarios.</p>
<p>Therefore, the authors adopt a more practical strategy here: <strong>Using single-product scans captured under controlled conditions, they synthesize realistic checkout images via data augmentation to train the model.</strong></p>
<p>The specific workflow is illustrated below:</p>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt="data synthesis" src=/en/assets/images/img1-b63bd61e6ccdf8653ac2100afa349447.jpg width=1224 height=404 class=img_ev3q></figure></div>
<p>They first collect a "single-sample" dataset for each product <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>S</mi><mo>=</mo><mo stretchy=false>{</mo><mo stretchy=false>(</mo><msub><mi>I</mi><mi>s</mi></msub><mo separator=true>,</mo><msub><mi>M</mi><mi>s</mi></msub><mo separator=true>,</mo><msub><mi>y</mi><mi>s</mi></msub><mo stretchy=false>)</mo><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>S = \{(I_s, M_s, y_s)\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05764em>S</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.07847em>I</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0785em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)}</span></span></span></span>, where:</p>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>I</mi><mi>s</mi></msub></mrow><annotation encoding=application/x-tex>I_s</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07847em>I</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0785em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>: product image;</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>M</mi><mi>s</mi></msub></mrow><annotation encoding=application/x-tex>M_s</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>: corresponding binary mask;</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>y</mi><mi>s</mi></msub></mrow><annotation encoding=application/x-tex>y_s</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>: product category ID.</li>
</ul>
<p>This study uses the <code>Saic</code> dataset provided by the 2022 AI City Challenge Track 4, covering:</p>
<ul>
<li>A total of <strong>116,500 images</strong>;</li>
<li>From <strong>116 product categories</strong>;</li>
<li>All products captured by 3D scanning.</li>
</ul>
<p>Using these exemplars, the system can generate a large number of synthesized checkout scene images <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=script>G</mi><mo>=</mo><mo stretchy=false>{</mo><msub><mi>g</mi><mi>i</mi></msub><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>\mathcal{G} = \{g_i\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7805em;vertical-align:-0.0972em></span><span class="mord mathcal" style=margin-right:0.0593em>G</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>}</span></span></span></span>, constructed as follows:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>g</mi><mi>i</mi></msub><mo>=</mo><mi>p</mi><mo stretchy=false>(</mo><mi>N</mi><mo separator=true>,</mo><mi>a</mi><mo separator=true>,</mo><mi>s</mi><mo separator=true>,</mo><mi>g</mi><mo separator=true>,</mo><mi>c</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>g_i = p(N, a, s, g, c)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">p</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">a</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">s</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">c</span><span class=mclose>)</span></span></span></span></span>
<p>where the parameters mean:</p>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>N</mi><mo>=</mo><mo stretchy=false>{</mo><mo stretchy=false>(</mo><msub><mi>I</mi><mi>n</mi></msub><mo separator=true>,</mo><msub><mi>M</mi><mi>n</mi></msub><mo separator=true>,</mo><msub><mi>y</mi><mi>n</mi></msub><mo stretchy=false>)</mo><mo stretchy=false>}</mo><mo>⊂</mo><mi>S</mi><mi>a</mi><mi>i</mi><mi>c</mi></mrow><annotation encoding=application/x-tex>N = \{(I_n, M_n, y_n)\} \subset Saic</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.10903em>N</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.07847em>I</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0785em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)}</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>⊂</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.05764em>S</span><span class="mord mathnormal">ai</span><span class="mord mathnormal">c</span></span></span></span>: randomly selected <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> exemplars;</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>(</mo><mi>a</mi><mo separator=true>,</mo><mi>s</mi><mo separator=true>,</mo><mi>g</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>(a, s, g)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>(</span><span class="mord mathnormal">a</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">s</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=mclose>)</span></span></span></span>: augmentation parameters applied to each exemplar including rotation angle, scale, and gamma correction;</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>c</mi></mrow><annotation encoding=application/x-tex>c</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">c</span></span></span></span>: clutter ratio controlling the maximum IoU overlap among objects in the synthesis.</li>
</ul>
<p>The complete process is:</p>
<ol>
<li>Perform bitwise-and on each exemplar to remove background according to <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>M</mi><mi>n</mi></msub></mrow><annotation encoding=application/x-tex>M_n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>;</li>
<li>Randomly apply data augmentation (rotation, scaling, brightness adjustment);</li>
<li>Generate masks via inverse thresholding;</li>
<li>Randomly paste these products onto background images extracted from real checkout video scenes;</li>
<li>Control occlusion so object overlaps do not exceed the IoU threshold defined by parameter <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>c</mi></mrow><annotation encoding=application/x-tex>c</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">c</span></span></span></span>, avoiding excessive overlap.</li>
</ol>
<p>This pipeline can quickly generate a large number of checkout scene samples simulating various angles, occlusions, and complex backgrounds.</p>
<p>The figure below shows synthesized results at three occlusion levels, demonstrating the flexibility and realism of this generation process to effectively support ACO model training.</p>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt="data synthesis examples" src=/en/assets/images/img2-bea987eff01699350ab019e3f2b1528c.jpg width=1224 height=260 class=img_ev3q>
<figcaption>From left to right: synthesized results with low, medium, and high occlusion levels.</figcaption><p></figure></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=model-architecture>Model Architecture<a href=#model-architecture class=hash-link aria-label="Direct link to Model Architecture" title="Direct link to Model Architecture">​</a></h3>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt="model architecture" src=/en/assets/images/img4-fdc4ebcce0902176cb0feff4acc3ea64.jpg width=1538 height=740 class=img_ev3q></figure></div>
<p>The overall design of DeepACO is shown in the figure above. The system consists of three main components:</p>
<ol>
<li><strong>Detector</strong></li>
<li><strong>Tracker</strong></li>
<li><strong>Counter</strong></li>
</ol>
<p>Additionally, to meet the specific requirements of the 2022 AI City Challenge Track 4, the system integrates a <strong>Hand Estimator module</strong> to enhance its ability to recognize products handled by customers.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=product-detection>Product Detection<a href=#product-detection class=hash-link aria-label="Direct link to Product Detection" title="Direct link to Product Detection">​</a></h3>
<p>DeepACO employs a flexible detection framework that supports multiple object detection models (hot-pluggable), as long as they comply with the <strong>batch input/output format</strong>:</p>
<ul>
<li>Input: RGB image sequence <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>I</mi><mo>=</mo><mo stretchy=false>{</mo><msub><mi>I</mi><mi>i</mi></msub><mi mathvariant=normal>∣</mi><mi>t</mi><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>t</mi><mo>+</mo><mi>B</mi><mo stretchy=false>}</mo><mo>∈</mo><msup><mi mathvariant=double-struck>R</mi><mrow><mi>B</mi><mo>×</mo><mi>C</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>W</mi></mrow></msup></mrow><annotation encoding=application/x-tex>I = \{I_i | t \leq i \leq t + B\} \in \mathbb{R}^{B \times C \times H \times W}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07847em>I</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord><span class="mord mathnormal" style=margin-right:0.07847em>I</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0785em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>∣</span><span class="mord mathnormal">t</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>≤</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.7955em;vertical-align:-0.136em></span><span class="mord mathnormal">i</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>≤</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6984em;vertical-align:-0.0833em></span><span class="mord mathnormal">t</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.05017em>B</span><span class=mclose>}</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8413em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05017em>B</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style=margin-right:0.07153em>C</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style=margin-right:0.08125em>H</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style=margin-right:0.13889em>W</span></span></span></span></span></span></span></span></span></span></span></span>;</li>
<li>Output: detection results <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>D</mi><mo>=</mo><mo stretchy=false>{</mo><msub><mi>D</mi><mi>i</mi></msub><mo>∈</mo><msup><mi mathvariant=double-struck>R</mi><mrow><mi>P</mi><mo>×</mo><mi>F</mi></mrow></msup><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>D = \{D_i \in \mathbb{R}^{P \times F}\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.0913em;vertical-align:-0.25em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>P</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style=margin-right:0.13889em>F</span></span></span></span></span></span></span></span></span><span class=mclose>}</span></span></span></span>, where <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>F</mi><mo>=</mo><mo stretchy=false>[</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=true>,</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator=true>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator=true>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo separator=true>,</mo><mtext>cls</mtext><mo separator=true>,</mo><mtext>conf</mtext><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>F = [x_1, y_1, x_2, y_2, \text{cls}, \text{conf}]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>F</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>[</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord text"><span class=mord>cls</span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord text"><span class=mord>conf</span></span><span class=mclose>]</span></span></span></span>.</li>
</ul>
<p>In this study, the authors select <strong>Scaled-YOLOv4-P5</strong> as the baseline, featuring:</p>
<ul>
<li>Continuation of the YOLOv4 architecture with CSPNet design;</li>
<li>Support for different scales (P5, P6, P7), achieving up to <strong>55.5% mAP</strong> on MS-COCO;</li>
<li>Deployable on cloud GPUs or low-power devices with good scalability.</li>
</ul>
<p>The training data consists of 15,642 synthesized images generated as described previously, fine-tuning an MS-COCO pretrained model with an 8:2 train-test split.</p>
<p>Training setup includes:</p>
<ul>
<li>Data augmentation: basic (rotation, translation, cropping); advanced (RandAugmentation, Mosaic);</li>
<li>Optimizer: SGD, trained for 50 epochs, selecting weights with best test performance.</li>
</ul>
<p>Both synthesis and training apply augmentation strategies, forming a “double augmentation” effect that helps prevent overfitting and improves model robustness to scale and occlusion variations.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=hand-estimation>Hand Estimation<a href=#hand-estimation class=hash-link aria-label="Direct link to Hand Estimation" title="Direct link to Hand Estimation">​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt="hand estimation" src=/en/assets/images/img6-5d00b0f679326232787cbe15861ad3b7.jpg width=1096 height=1080 class=img_ev3q></figure></div>
<p>To meet competition requirements, DeepACO introduces a hand perception module to detect <strong>customer-held products</strong>, enhancing detection accuracy and semantic understanding. This module uses Google MediaPipe framework and involves two stages, as shown above:</p>
<ol>
<li>
<p><strong>Palm Detection</strong>
Uses an SSD-based network to detect palms over the entire image. This outperforms directly detecting flexible hands because palms are rigid, less occluded, easier to handle, and allow a reduction of anchor points by 3–5 times using fixed square anchors.</p>
</li>
<li>
<p><strong>Hand Landmark Regression</strong>
Estimates 21 hand keypoints within detected palm regions, providing high-precision 3D landmark information. The method is robust to self-occlusion and partial occlusion, allowing tracking of hand regions frame-to-frame.</p>
</li>
</ol>
<p>This module runs in parallel with the detector, and their results are cross-validated to effectively <strong>filter out false positives of non-handheld products</strong>. Users may disable this module as needed to maintain system flexibility.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=multi-object-tracking>Multi-Object Tracking<a href=#multi-object-tracking class=hash-link aria-label="Direct link to Multi-Object Tracking" title="Direct link to Multi-Object Tracking">​</a></h3>
<p>Stable recognition in video requires <strong>tracking</strong>, a key step.</p>
<p>DeepACO uses <strong>SORT</strong> (Simple Online and Realtime Tracking) as an online multi-object tracker. It assigns unique IDs to each object and continuously tracks their movement within the ROI (Region of Interest), ensuring each product is detected and counted only once.</p>
<ul>
<li>
<p><strong>SORT: Lightweight Tracking Solution</strong>
Given the fixed overhead camera angle in the application (stable planar movement, controllable occlusion), SORT is chosen for its high computational efficiency and low memory usage. Compared to the heavier DeepSORT, SORT better fits practical deployment.</p>
<p>Core SORT workflow:</p>
<ul>
<li>Uses <strong>Kalman Filter</strong> for motion prediction;</li>
<li>Uses <strong>Hungarian Algorithm</strong> for matching detections to existing tracks;</li>
<li>Matching cost between predicted and current detection boxes is measured by <strong>IoU distance</strong>, with a matching threshold of IoU ≥ 0.3.</li>
</ul>
<p>Each track’s state vector is <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>(</mo><mi>u</mi><mo separator=true>,</mo><mi>v</mi><mo separator=true>,</mo><mi>s</mi><mo separator=true>,</mo><mi>r</mi><mo separator=true>,</mo><mover accent=true><mi>u</mi><mo>˙</mo></mover><mo separator=true>,</mo><mover accent=true><mi>v</mi><mo>˙</mo></mover><mo separator=true>,</mo><mover accent=true><mi>s</mi><mo>˙</mo></mover><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>(u, v, s, r, \dot{u}, \dot{v}, \dot{s})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>(</span><span class="mord mathnormal">u</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.03588em>v</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">s</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.02778em>r</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6679em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">u</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.1111em><span class=mord>˙</span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6679em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:0.03588em>v</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.1111em><span class=mord>˙</span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6679em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">s</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.0833em><span class=mord>˙</span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>:</p>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>(</mo><mi>u</mi><mo separator=true>,</mo><mi>v</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>(u, v)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>(</span><span class="mord mathnormal">u</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.03588em>v</span><span class=mclose>)</span></span></span></span>: object center coordinates;</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>s</mi></mrow><annotation encoding=application/x-tex>s</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">s</span></span></span></span>: bounding box area;</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>r</mi></mrow><annotation encoding=application/x-tex>r</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal" style=margin-right:0.02778em>r</span></span></span></span>: aspect ratio;</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>(</mo><mover accent=true><mi>u</mi><mo>˙</mo></mover><mo separator=true>,</mo><mover accent=true><mi>v</mi><mo>˙</mo></mover><mo separator=true>,</mo><mover accent=true><mi>s</mi><mo>˙</mo></mover><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>(\dot{u}, \dot{v}, \dot{s})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>(</span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6679em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">u</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.1111em><span class=mord>˙</span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6679em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:0.03588em>v</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.1111em><span class=mord>˙</span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6679em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">s</span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.0833em><span class=mord>˙</span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>: corresponding velocities.</li>
</ul>
<p>Using the Kalman filter’s linear motion model, DeepACO effectively predicts object positions per frame and maintains stable ID assignment.</p>
</li>
<li>
<p><strong>State Management and Counting Logic</strong></p>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt="tracking state machine" src=/en/assets/images/img7-2ce2a6b29dc1bda08dfc54f912355412.jpg width=720 height=536 class=img_ev3q></figure></div>
<p>DeepACO extends the original SORT framework by adding a <strong>tracking state machine</strong>. Each tracked object changes state over time from entering the ROI to final counting, as shown in the state transition diagram above.</p>
<p>The most critical transition is from <strong>“Counting” → “Counted”</strong>, which only occurs if the object is <strong>hand-held</strong>. The determination is made by:</p>
<ul>
<li>Using the 21 keypoints returned from the hand estimation module;</li>
<li>Checking if any keypoint lies inside the object bounding box;</li>
<li>Applying a <strong>ray-casting algorithm</strong> to verify if the point lies within the polygon.</li>
</ul>
<p>If conditions are met, the object transitions from “Counting” to “Counted” state, proceeding to the next statistical step.</p>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=product-counting>Product Counting<a href=#product-counting class=hash-link aria-label="Direct link to Product Counting" title="Direct link to Product Counting">​</a></h3>
<p>To satisfy the AI City Challenge evaluation criteria, DeepACO designs a simple yet effective counting module.</p>
<p>From the moment each object enters the ROI, its state is continuously monitored:</p>
<ul>
<li>When the object <strong>fully enters the ROI</strong> for the first time and is marked as “Confirmed,” the corresponding frame index is recorded;</li>
<li>Later, when the object transitions to “Counted” state, its</li>
</ul>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mtext>Timestamp</mtext><mo>=</mo><mfrac><mtext>frame index</mtext><mn>60</mn></mfrac></mrow><annotation encoding=application/x-tex>\text{Timestamp} = \frac{\text{frame index}}{60}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8778em;vertical-align:-0.1944em></span><span class="mord text"><span class=mord>Timestamp</span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.0574em;vertical-align:-0.686em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3714em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>60</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class="mord text"><span class=mord>frame index</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>is calculated as the final counting time (assuming 60 FPS). This counting mechanism balances accuracy and timeliness, ensuring each product is counted exactly once, avoiding duplicates or omissions.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=discussion>Discussion<a href=#discussion class=hash-link aria-label="Direct link to Discussion" title="Direct link to Discussion">​</a></h2>
<p>To validate the practicality and performance of the DeepACO framework, this paper conducts comprehensive evaluations on the test set provided by the 2022 AI City Challenge Track 4, examining accuracy, latency, and implementation architecture.</p>
<p>The entire system was built and tested on the following environment:</p>
<ul>
<li>CPU: Intel Core i7-7700</li>
<li>GPU: NVIDIA GeForce RTX 3090 24GB</li>
<li>RAM: 32GB</li>
</ul>
<p>The development platform is based on <strong>OpenCV, PyTorch, and MediaPipe</strong>, implementing two processing pipelines:</p>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt="processing pipeline" src=/en/assets/images/img5-11851d4d9bdee0b51c37397839d6016a.jpg width=1020 height=948 class=img_ev3q></figure></div>
<ul>
<li><strong>Synchronous pipeline</strong>: modules process sequentially;</li>
<li><strong>Asynchronous pipeline</strong>: each module runs in an independent thread (4 CPU threads + 1 GPU thread), communicating via queues to reduce inter-module blocking.</li>
</ul>
<p>The final competition version adopted the asynchronous pipeline, effectively improving overall performance, especially when multiple products appear simultaneously.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=test-data-and-evaluation-metrics>Test Data and Evaluation Metrics<a href=#test-data-and-evaluation-metrics class=hash-link aria-label="Direct link to Test Data and Evaluation Metrics" title="Direct link to Test Data and Evaluation Metrics">​</a></h3>
<p>This study uses five test videos provided by the AI City Challenge, each recorded by a fixed overhead camera simulating customers naturally performing checkout.</p>
<p>The evaluation metric is the <strong>F1 score</strong>, calculated as:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mn>0.5</mn><mo>×</mo><mo stretchy=false>(</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo stretchy=false>)</mo></mrow></mfrac></mrow><annotation encoding=application/x-tex>F_1 = \frac{TP}{TP + 0.5 \times (FP + FN)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>F</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.2963em;vertical-align:-0.936em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3603em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>TP</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span><span class=mord>0.5</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:0.2222em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.13889em>FP</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span><span class="mord mathnormal" style=margin-right:0.10903em>FN</span><span class=mclose>)</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>TP</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.936em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<ul>
<li>
<p><strong>TP (True Positive)</strong>: correctly recognized products;</p>
<ul>
<li>Defined as correct category, appearing within the ROI, and at the correct timing above the tray.</li>
</ul>
</li>
<li>
<p><strong>FP (False Positive)</strong>: detections incorrectly labeled as correct;</p>
</li>
<li>
<p><strong>FN (False Negative)</strong>: true products not detected.</p>
</li>
</ul>
<p>This metric balances precision and recall, providing a comprehensive measure of the ACO system’s practical performance.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=quantitative-results>Quantitative Results<a href=#quantitative-results class=hash-link aria-label="Direct link to Quantitative Results" title="Direct link to Quantitative Results">​</a></h3>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt="challenge results" src=/en/assets/images/img8-84267ca938af6f4e1fb4f8b211f7766b.jpg width=596 height=404 class=img_ev3q></figure></div>
<p>In the final challenge, DeepACO achieved <strong>F1 = 0.4745</strong>, securing second place with strong competitiveness.</p>
<p>Notably, the <strong>recall was only 0.5238</strong>, meaning roughly half of the products were successfully recognized. Possible causes include unnatural customer operation not considered valid “scanning” or timing misalignment causing counting failures.</p>
<p>Nonetheless, the results demonstrate clear potential for real-world deployment in complex scenes, validating the feasibility of the DeepACO architecture.</p>
<p>Beyond accuracy, <strong>real-time processing capability</strong> is a key design consideration.</p>
<p>Performance tests were conducted under the following conditions:</p>
<ul>
<li>GPUs: NVIDIA RTX 3090 and RTX A6000;</li>
<li>Models: Scaled-YOLOv4-P5 / P7;</li>
<li>Settings: resolution 448×448, batch size 16, queue size 1.</li>
</ul>
<p>Results show the <strong>asynchronous pipeline increases throughput by about 10 FPS on average</strong>. Even with queue size set to 1, wait times were greatly reduced. Overall, the system meets real-time processing requirements, suitable for deployment in practical checkout systems.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=conclusion>Conclusion<a href=#conclusion class=hash-link aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>This paper proposes a plug-and-play detect-and-track pipeline supporting multiple model combinations, enhanced by a hand perception module to improve recognition accuracy in physical interaction scenarios. A data synthesis pipeline generates a large variety of checkout images to alleviate the shortage of real data.</p>
<p>In the 2022 AI City Challenge Track 4, DeepACO ranked second with an F1 score of 0.4783, achieving a good balance between accuracy and real-time performance, averaging 30 FPS, demonstrating strong potential for practical deployment.</p>
<p>For engineers interested in automatic checkout or retail vision applications, this work provides a valuable reference case.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>info</div><div class=admonitionContent_BuS1><p>This paper’s ending might leave you, as a reader, quite puzzled.<p>What? Not puzzled? Maybe you didn’t read carefully? 💢<p>Go back and check that benchmark table again — the first place’s F1 score is <strong>1.0</strong>! Achieving a perfect 1.0 in such a complex scenario means all predictions are flawless, with zero mistakes. It’s practically supernatural.<p>But in fact, that 1.0 is only for the <strong>public test set (Test A)</strong>, and that team was eventually <strong>disqualified</strong>.<p>For reference, see here:<ul>
<li><a href=https://www.aicitychallenge.org/2022-challenge-winners/ target=_blank rel="noopener noreferrer"><strong>2022 AI CITY CHALLENGE Track 4</strong></a></li>
</ul><p>The AI City Challenge rules state that only teams who complete the <strong>Final Evaluation</strong> (hidden test set Test B + efficiency benchmark) <strong>and</strong> release their code/paper publicly are counted in the final rankings.<p>That team with perfect public leaderboard score (Team 16) allegedly failed to submit reproducible code or comply with open-source requirements, so they were removed by the organizers.<p>When DeepACO says “top-2,” it refers to the <strong>official final leaderboard after the Final Evaluation</strong>.<ul>
<li>
<p>Public LB: DeepACO’s F1 is about 0.478, temporarily ranked 2nd.</p>
</li>
<li>
<p>Final LB:</p>
<ul>
<li>
<p>The team ranked 1st, Team 55, didn’t submit a paper and was disqualified.</p>
</li>
<li>
<p>The 2nd place, Team 9, scored F1 = 0.0105 and secured 2nd place.</p>
<ul>
<li>Their paper: <a href=https://arxiv.org/pdf/2207.05422 target=_blank rel="noopener noreferrer"><strong>[22.07] Improving Domain Generalization by Learning without Forgetting: Application in Retail Checkout</strong></a></li>
</ul>
</li>
<li>
<p>DeepACO (Team 94) scored F1 = 0.0047 and placed 5th.</p>
</li>
</ul>
</li>
</ul><p>The Final leaderboard scores are almost meaningless, as all teams’ scores dropped to 0.0x.<p>This is because in the final phase, the domain shifted drastically: camera position, product combinations, lighting all changed. Models without strong generalization ability basically fail.<p>Additionally, efficiency counts toward the final score; slower models get penalized.<p>So, when looking at the competition results, make sure to distinguish between the Public Leaderboard and the Final Leaderboard.<p>They mean very different things!</div></div></header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>Last updated<!-- --> on <b><time datetime=2025-07-20T05:52:14.000Z itemprop=dateModified>Jul 20, 2025</time></b> by <b>zephyr-sh</b></span></div></div><section class=ctaSection_iCjC><div class="
        simpleCta_ji_Y
        simple-cta__coffee_YwC8
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>☕ Fuel my writing with a coffee</h3><p class=simple-cta__subtitle_ol86>Your support keeps my AI & full-stack guides coming.<div class=simple-cta__buttonWrapper_jk1Y><img src=/en/img/bmc-logo.svg alt=cta-button class=simple-cta__buttonImg_Q9VV></div></div><div class="ant-row ant-row-stretch cardsSection_wRaP css-mc1tut" style=margin-left:-8px;margin-right:-8px;row-gap:16px><div style=padding-left:8px;padding-right:8px;display:flex class="ant-col ant-col-xs-24 css-mc1tut"><div class="ant-card ant-card-bordered card_gKx9 fadeInUp_n33J hoverTransform_Mozy css-mc1tut" style=flex:1;display:flex;flex-direction:column><div class=ant-card-body><div style=text-align:center;margin-top:1rem><img src=/en/img/icons/all_in.svg alt="AI / Full-Stack / Custom — All In icon" style=width:48px;height:48px></div><span class="ant-tag ant-tag-orange card__tag_PLj3 css-mc1tut">All-in</span><h4 class=card__title_SQBY>AI / Full-Stack / Custom — All In</h4><p class=card__concept_Ak8F>From idea to launch—efficient systems that are future-ready.<div class=card__bulletHeader_b6cf><h5 class=card__bulletTitle_R_wg>All-In Bundle</h5></div><ul class=card__bulletList_SrNN><li class=card__bulletItem_wCRd>Consulting + Dev + Deploy<li class=card__bulletItem_wCRd>Maintenance & upgrades</ul></div></div></div></div><div class="
        simpleCta_ji_Y
        simple-cta__outro_AXbn
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>🚀 Ready for your next project?</h3><p class=simple-cta__subtitle_ol86>Need a tech partner or custom solution? Let's connect.</div></section><div style=margin-top:3rem> </div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/en/papers/retail-product/retail-product-recognition-review/><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>[20.11] RPR: Review</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/en/papers/category/segmentation-1><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>Segmentation (1)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#the-overhead-hunter class="table-of-contents__link toc-highlight">The Overhead Hunter</a><li><a href=#problem-definition class="table-of-contents__link toc-highlight">Problem Definition</a><li><a href=#proposed-solution class="table-of-contents__link toc-highlight">Proposed Solution</a><ul><li><a href=#data-synthesis class="table-of-contents__link toc-highlight">Data Synthesis</a><li><a href=#model-architecture class="table-of-contents__link toc-highlight">Model Architecture</a><li><a href=#product-detection class="table-of-contents__link toc-highlight">Product Detection</a><li><a href=#hand-estimation class="table-of-contents__link toc-highlight">Hand Estimation</a><li><a href=#multi-object-tracking class="table-of-contents__link toc-highlight">Multi-Object Tracking</a><li><a href=#product-counting class="table-of-contents__link toc-highlight">Product Counting</a></ul><li><a href=#discussion class="table-of-contents__link toc-highlight">Discussion</a><ul><li><a href=#test-data-and-evaluation-metrics class="table-of-contents__link toc-highlight">Test Data and Evaluation Metrics</a><li><a href=#quantitative-results class="table-of-contents__link toc-highlight">Quantitative Results</a></ul><li><a href=#conclusion class="table-of-contents__link toc-highlight">Conclusion</a></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/en/docs>Projects</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/papers/intro>Papers</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/blog>Blog</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/terms-of-service>TermsOfUse</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/privacy-policy>Privacy Policy</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/become-an-author>Become an author</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/worklog>Worklog</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>