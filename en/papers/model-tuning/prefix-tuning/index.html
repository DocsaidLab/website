<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-model-tuning/prefix-tuning/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.7.0"><title data-rh=true>[21.01] Prefix-Tuning | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/en/papers/model-tuning/prefix-tuning/><meta data-rh=true property=og:locale content=en><meta data-rh=true property=og:locale:alternate content=zh_hant><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[21.01] Prefix-Tuning | DOCSAID"><meta data-rh=true name=description content="Is it the Same or Different?"><meta data-rh=true property=og:description content="Is it the Same or Different?"><link data-rh=true rel=icon href=/en/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/en/papers/model-tuning/prefix-tuning/><link data-rh=true rel=alternate href=https://docsaid.org/papers/model-tuning/prefix-tuning/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/model-tuning/prefix-tuning/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/model-tuning/prefix-tuning/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/model-tuning/prefix-tuning/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><link rel=alternate type=application/rss+xml href=/en/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/en/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/en/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/en/assets/css/styles.14d14ca4.css><script src=/en/assets/js/runtime~main.94a0a445.js defer></script><script src=/en/assets/js/main.0eb592c5.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><link rel=preload as=image href=/en/img/docsaid_logo.png><link rel=preload as=image href=/en/img/docsaid_logo_white.png><link rel=preload as=image href=https://github.com/zephyr-sh.png><link rel=preload as=image href=/en/img/bmc-logo.svg><link rel=preload as=image href=/en/img/icons/all_in.svg><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/en/><div class=navbar__logo><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/en/docs/>Projects</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/en/papers/intro>Papers</a><a class="navbar__item navbar__link" href=/en/blog>Blog</a><a class="navbar__item navbar__link" href=/en/playground/intro>Playground</a><a class="navbar__item navbar__link" href=/en/services>Services</a><a class="navbar__item navbar__link" href=/en/aboutus>About Us</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>English</a><ul class=dropdown__menu><li><a href=/papers/model-tuning/prefix-tuning/ target=_self rel="noopener noreferrer" class=dropdown__link lang=zh-hant>繁體中文</a><li><a href=/en/papers/model-tuning/prefix-tuning/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=en>English</a><li><a href=/ja/papers/model-tuning/prefix-tuning/ target=_self rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-7ny38l ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/en/><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>Paper Notes</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="Expand sidebar category 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/contrastive-learning-13>Contrastive Learning (13)</a><button aria-label="Expand sidebar category 'Contrastive Learning (13)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/deepseek-5>DeepSeek (5)</a><button aria-label="Expand sidebar category 'DeepSeek (5)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-anti-spoofing-17>Face Anti-Spoofing (17)</a><button aria-label="Expand sidebar category 'Face Anti-Spoofing (17)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="Expand sidebar category 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/feature-fusion-10>Feature Fusion (10)</a><button aria-label="Expand sidebar category 'Feature Fusion (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="Expand sidebar category 'Lightweight (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/mamba-4>Mamba (4)</a><button aria-label="Expand sidebar category 'Mamba (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/en/papers/category/model-tuning-8>Model Tuning (8)</a><button aria-label="Collapse sidebar category 'Model Tuning (8)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/model-tuning/adapter/>[19.02] Adapter</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/model-tuning/autoprompt/>[20.10] AutoPrompt</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/en/papers/model-tuning/prefix-tuning/>[21.01] Prefix-Tuning</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/model-tuning/soft-prompts/>[21.04] Soft Prompts</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/model-tuning/lora/>[21.06] LoRA</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/model-tuning/coop/>[21.09] CoOp</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/model-tuning/cocoop/>[22.03] CoCoOp</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/model-tuning/blip2/>[23.01] BLIP-2</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/multimodality-24>Multimodality (24)</a><button aria-label="Expand sidebar category 'Multimodality (24)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/normalization-1>Normalization (1)</a><button aria-label="Expand sidebar category 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/object-detection-8>Object Detection (8)</a><button aria-label="Expand sidebar category 'Object Detection (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/reparameterization-8>Reparameterization (8)</a><button aria-label="Expand sidebar category 'Reparameterization (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="Expand sidebar category 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-detection-14>Text Detection (14)</a><button aria-label="Expand sidebar category 'Text Detection (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="Expand sidebar category 'Text Recognition (20)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="Expand sidebar category 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/transformers-17>Transformers (17)</a><button aria-label="Expand sidebar category 'Transformers (17)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/vision-transformers-12>Vision Transformers (12)</a><button aria-label="Expand sidebar category 'Vision Transformers (12)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>All Notes: 191 entries</a></ul></nav><button type=button title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/en/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/en/papers/category/model-tuning-8><span itemprop=name>Model Tuning (8)</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>[21.01] Prefix-Tuning</span><meta itemprop=position content=2></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>[21.01] Prefix-Tuning</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt="Z. Yuan" class=docAuthorImg_vlJe><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Z. Yuan</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a href=https://www.linkedin.com/in/ze-yuan-sh7/ target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 448 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=is-it-the-same-or-different>Is it the Same or Different?<a href=#is-it-the-same-or-different class=hash-link aria-label="Direct link to Is it the Same or Different?" title="Direct link to Is it the Same or Different?">​</a></h2>
<p><a href=https://arxiv.org/abs/2101.00190 target=_blank rel="noopener noreferrer"><strong>Prefix-Tuning: Optimizing Continuous Prompts for Generation</strong></a></p>
<hr>
<p>There are a few common ways to leverage pre-trained language models:</p>
<ol>
<li>
<p><strong>Fine-tuning</strong>: Adjusting the model’s parameters to adapt it to new tasks.</p>
<p>However, this approach isn’t accessible to most people since it requires large datasets and significant computational resources.</p>
</li>
<li>
<p><strong>Prompt-based methods</strong>: Designing prompts to guide the model in generating the desired outputs.</p>
<p>For example, if the task is to summarize a text, different models might require different prompts:</p>
<ol>
<li>GPT-3: <code>Summarize with 3 sentences about the following article:</code></li>
<li>T5: <code>summarize the following article:</code></li>
<li>BART: <code>Document summarization:</code></li>
<li>...</li>
</ol>
<p><strong>Drawback</strong>: Each model has a different way of interpreting prompts, so constant experimentation and fine-tuning are necessary.</p>
</li>
</ol>
<hr>
<p>Is there any other solution?</p>
<p>Of course! Creativity is never in short supply among researchers.</p>
<p>Recently, <strong>AutoPrompt</strong> introduced an automated approach to discover optimal prompts. This method combines the benefits of both fine-tuning and prompt-based techniques.</p>
<ul>
<li><a href=/en/papers/model-tuning/autoprompt/><strong>[20.10] AutoPrompt: Model Prompt Optimization</strong></a></li>
</ul>
<p>By using a set of learnable parameters, AutoPrompt enables the model to discover the prompts that work best with its structure.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=defining-the-problem>Defining the Problem<a href=#defining-the-problem class=hash-link aria-label="Direct link to Defining the Problem" title="Direct link to Defining the Problem">​</a></h2>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=problem src=/en/assets/images/img1-18073f29c21ac0b45dcd6d0c797e04e9.jpg width=1224 height=924 class=img_ev3q></figure></div>
<p>As mentioned earlier, the problem lies in the fact that pre-trained models are too large for most users to fine-tune, and prompt-based methods require constant testing.</p>
<p>To address this, the authors propose a new approach: <strong>Prefix-Tuning</strong>. The concept is simple: as shown in the diagram above, a <strong>prefix</strong> token is inserted at the beginning of the input to guide the model’s output generation.</p>
<p>Wait, isn’t this the same as what AutoPrompt does?</p>
<p>Exactly!</p>
<p>The difference lies in how the prompt is created. AutoPrompt selects and combines already <strong>pre-trained tokens</strong> to build a suitable prompt. In contrast, <strong>Prefix-Tuning trains new tokens directly in the feature space</strong> to achieve optimal results.</p>
<p>The authors argue that AutoPrompt may generate prompts with discontinuities since it relies on combining discrete, pre-trained tokens. On the other hand, Prefix-Tuning operates in the continuous feature space, resulting in smoother, more coherent prompts better suited to the task at hand.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=solving-the-problem>Solving the Problem<a href=#solving-the-problem class=hash-link aria-label="Direct link to Solving the Problem" title="Direct link to Solving the Problem">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=model-architecture>Model Architecture<a href=#model-architecture class=hash-link aria-label="Direct link to Model Architecture" title="Direct link to Model Architecture">​</a></h3>
<p><img decoding=async loading=lazy alt=model src=/en/assets/images/img2-3aa656efd174e890d42b29c1f8650817.jpg width=1834 height=620 class=img_ev3q></p>
<p>The diagram above illustrates the architecture of Prefix-Tuning. The model consists of the following key components:</p>
<ol>
<li>
<p><strong>Trainable Prefix Parameters <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>θ</mi></msub></mrow><annotation encoding=application/x-tex>P_\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span></strong>:
These are newly introduced parameters placed at the beginning of the input sequence. Their length and dimensionality can be configured. During training, these parameters are optimized to steer the model toward producing task-specific outputs.</p>
</li>
<li>
<p><strong>Frozen Pre-trained Language Model <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mtext>LM</mtext><mi>ϕ</mi></msub></mrow><annotation encoding=application/x-tex>\text{LM}_\phi</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord text"><span class=mord>LM</span></span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span></strong>:
This refers to a large language model, such as GPT-2 or GPT-3, whose parameters remain <strong>fixed</strong> during Prefix-Tuning. This approach avoids the heavy resource demands of full fine-tuning.</p>
</li>
<li>
<p><strong>Input Sequence <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span></strong>:
This is the task-specific input, such as an article for summarization or tabular data that needs to be described.</p>
</li>
<li>
<p><strong>Output Sequence <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>y</mi></mrow><annotation encoding=application/x-tex>y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span></span></span></span></strong>:
This is the output generated by the model, such as a summary of the article or a textual description of the table.</p>
</li>
</ol>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=implementation-details>Implementation Details<a href=#implementation-details class=hash-link aria-label="Direct link to Implementation Details" title="Direct link to Implementation Details">​</a></h3>
<p>The implementation of Prefix-Tuning involves several key steps:</p>
<ol>
<li>
<p><strong>Prefix Parameter Initialization</strong>:</p>
<ul>
<li>A matrix of trainable prefix parameters <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>θ</mi></msub></mrow><annotation encoding=application/x-tex>P_\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> is created with dimensions <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=normal>∣</mi><msub><mi>P</mi><mtext>idx</mtext></msub><mi mathvariant=normal>∣</mi><mo>×</mo><mtext>dim</mtext><mo stretchy=false>(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>|P_{\text{idx}}| \times \text{dim}(h_i)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>∣</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">idx</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>∣</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>dim</span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">h</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>, where <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=normal>∣</mi><msub><mi>P</mi><mtext>idx</mtext></msub><mi mathvariant=normal>∣</mi></mrow><annotation encoding=application/x-tex>|P_{\text{idx}}|</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>∣</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">idx</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>∣</span></span></span></span> is the length of the prefix and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mtext>dim</mtext><mo stretchy=false>(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\text{dim}(h_i)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>dim</span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">h</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span> is the hidden state dimension of the language model.</li>
</ul>
</li>
<li>
<p><strong>Reparameterization</strong>:</p>
<ul>
<li>
<p>Directly optimizing the high-dimensional matrix <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>θ</mi></msub></mrow><annotation encoding=application/x-tex>P_\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> can lead to instability. To address this, the authors introduce a reparameterization strategy:</p>
<ul>
<li><strong>Low-dimensional Representation <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi>P</mi><mi>θ</mi><mo mathvariant=normal lspace=0em rspace=0em>′</mo></msubsup></mrow><annotation encoding=application/x-tex>P'_\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.035em;vertical-align:-0.2831em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.7519em><span style=top:-2.4169em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2831em><span></span></span></span></span></span></span></span></span></span></strong>:
A smaller matrix <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi>P</mi><mi>θ</mi><mo mathvariant=normal lspace=0em rspace=0em>′</mo></msubsup></mrow><annotation encoding=application/x-tex>P'_\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.035em;vertical-align:-0.2831em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.7519em><span style=top:-2.4169em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2831em><span></span></span></span></span></span></span></span></span></span> with dimensions <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=normal>∣</mi><msub><mi>P</mi><mtext>idx</mtext></msub><mi mathvariant=normal>∣</mi><mo>×</mo><msup><mi>d</mi><mo mathvariant=normal lspace=0em rspace=0em>′</mo></msup></mrow><annotation encoding=application/x-tex>|P_{\text{idx}}| \times d'</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>∣</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">idx</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>∣</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.7519em></span><span class=mord><span class="mord mathnormal">d</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.7519em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>, where <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msup><mi>d</mi><mo mathvariant=normal lspace=0em rspace=0em>′</mo></msup><mo>&lt;</mo><mtext>dim</mtext><mo stretchy=false>(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>d' &lt; \text{dim}(h_i)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.791em;vertical-align:-0.0391em></span><span class=mord><span class="mord mathnormal">d</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.7519em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>&lt;</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>dim</span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">h</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>.</li>
<li><strong>Multi-Layer Perceptron (MLP)</strong>:
The MLP maps the smaller matrix to the original high-dimensional space:<!-- -->
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>P</mi><mi>θ</mi></msub><mo stretchy=false>[</mo><mi>i</mi><mo separator=true>,</mo><mo>:</mo><mo stretchy=false>]</mo><mo>=</mo><msub><mtext>MLP</mtext><mi>θ</mi></msub><mrow><mo fence=true>(</mo><msubsup><mi>P</mi><mi>θ</mi><mo mathvariant=normal lspace=0em rspace=0em>′</mo></msubsup><mo stretchy=false>[</mo><mi>i</mi><mo separator=true>,</mo><mo>:</mo><mo stretchy=false>]</mo><mo fence=true>)</mo></mrow></mrow><annotation encoding=application/x-tex>P_\theta[i, :] = \text{MLP}_\theta \left( P'_\theta[i, :] \right)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>[</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>:</span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mclose>]</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.0519em;vertical-align:-0.25em></span><span class=mord><span class="mord text"><span class=mord>MLP</span></span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0em>(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8019em><span style=top:-2.453em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.247em><span></span></span></span></span></span></span><span class=mopen>[</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>:</span><span class=mclose>]</span><span class="mclose delimcenter" style=top:0em>)</span></span></span></span></span></span>
</li>
<li><strong>Optimization Process</strong>:
During training, only the parameters of <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi>P</mi><mi>θ</mi><mo mathvariant=normal lspace=0em rspace=0em>′</mo></msubsup></mrow><annotation encoding=application/x-tex>P'_\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.035em;vertical-align:-0.2831em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.7519em><span style=top:-2.4169em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2831em><span></span></span></span></span></span></span></span></span></span> and the MLP weights <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>θ</mi></mrow><annotation encoding=application/x-tex>\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.02778em>θ</span></span></span></span> are optimized, while the parameters of the pre-trained language model <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding=application/x-tex>\phi</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class="mord mathnormal">ϕ</span></span></span></span> remain fixed.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Forward Propagation</strong>:</p>
<ul>
<li><strong>Prefix Activation</strong>:
For each position <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi><mo>∈</mo><msub><mi>P</mi><mtext>idx</mtext></msub></mrow><annotation encoding=application/x-tex>i \in P_{\text{idx}}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6986em;vertical-align:-0.0391em></span><span class="mord mathnormal">i</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">idx</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>, the activation value is directly taken from <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>θ</mi></msub><mo stretchy=false>[</mo><mi>i</mi><mo separator=true>,</mo><mo>:</mo><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>P_\theta[i, :]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>[</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>:</span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mclose>]</span></span></span></span>:<!-- -->
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>=</mo><msub><mi>P</mi><mi>θ</mi></msub><mo stretchy=false>[</mo><mi>i</mi><mo separator=true>,</mo><mo>:</mo><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>h_i = P_\theta[i, :]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">h</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>[</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>:</span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mclose>]</span></span></span></span></span>
</li>
<li><strong>Input Sequence Processing</strong>:
For the input sequence <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> and the output sequence <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>y</mi></mrow><annotation encoding=application/x-tex>y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span></span></span></span>, the activations follow the standard calculations of the pre-trained language model, with the prefix influencing the results:<!-- -->
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>=</mo><msub><mtext>LM</mtext><mi>ϕ</mi></msub><mo stretchy=false>(</mo><msub><mi>z</mi><mi>i</mi></msub><mo separator=true>,</mo><msub><mi>h</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>h_i = \text{LM}_\phi(z_i, h_{&lt;i})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">h</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.0361em;vertical-align:-0.2861em></span><span class=mord><span class="mord text"><span class=mord>LM</span></span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.04398em>z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.044em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">h</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1774em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span></span>
<!-- -->where <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>z_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.04398em>z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.044em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> is the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>-th token of the input sequence, and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>h</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub></mrow><annotation encoding=application/x-tex>h_{&lt;i}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8718em;vertical-align:-0.1774em></span><span class=mord><span class="mord mathnormal">h</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1774em><span></span></span></span></span></span></span></span></span></span> contains the activations from the prefix and the previous tokens in the sequence.</li>
</ul>
</li>
</ol>
<p>The objective of training is to <strong>maximize the log-likelihood</strong> of the output sequence <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>y</mi></mrow><annotation encoding=application/x-tex>y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span></span></span></span>:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>θ</mi></munder><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>ϕ</mi></msub><mo stretchy=false>(</mo><mi>y</mi><mi mathvariant=normal>∣</mi><mi>x</mi><mo separator=true>,</mo><msub><mi>P</mi><mi>θ</mi></msub><mo stretchy=false>)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><msub><mi>Y</mi><mtext>idx</mtext></msub></mrow></munder><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>ϕ</mi></msub><mo stretchy=false>(</mo><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant=normal>∣</mi><msub><mi>h</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\max_\theta \log p_\phi(y | x, P_\theta) = \sum_{i \in Y_{\text{idx}}} \log p_\phi(z_i | h_{&lt;i})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.5021em;vertical-align:-0.7521em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.4306em><span style=top:-2.3479em;margin-left:0em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span><span class=mop>max</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.7521em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">p</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=mord>∣</span><span class="mord mathnormal">x</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.4502em;vertical-align:-1.4002em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.05em><span style=top:-1.8557em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.22222em>Y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3448em><span style=top:-2.3488em;margin-left:-0.2222em;margin-right:0.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">idx</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1512em><span></span></span></span></span></span></span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.4002em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">p</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.04398em>z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.044em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>∣</span><span class=mord><span class="mord mathnormal">h</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1774em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span></span>
<p>Here, only the prefix parameters <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>θ</mi></mrow><annotation encoding=application/x-tex>\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.02778em>θ</span></span></span></span> are optimized, while the parameters of the language model <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding=application/x-tex>\phi</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class="mord mathnormal">ϕ</span></span></span></span> remain fixed.</p>
<p>Once training is complete, the optimized high-dimensional prefix matrix <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>θ</mi></msub></mrow><annotation encoding=application/x-tex>P_\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> is retained. Since reparameterization is only needed during training, the MLP used to map the low-dimensional matrix can be discarded after training.</p>
<p>During inference, the optimized prefix <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>θ</mi></msub></mrow><annotation encoding=application/x-tex>P_\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> is concatenated with a new input sequence <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span>. The combined sequence is then fed into the pre-trained language model to generate the output <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>y</mi></mrow><annotation encoding=application/x-tex>y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span></span></span></span>.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=dataset-setup>Dataset Setup<a href=#dataset-setup class=hash-link aria-label="Direct link to Dataset Setup" title="Direct link to Dataset Setup">​</a></h3>
<ol>
<li>
<p><strong>Table-to-Text Generation Task</strong>:</p>
<ul>
<li>
<p>The authors use three datasets, sorted by complexity and size:</p>
<ol>
<li>
<p><strong>E2E (Novikova et al., 2017)</strong>:</p>
<ul>
<li>A single-domain dataset focusing on restaurant reviews, containing around 50K data samples with 8 fields per entry.</li>
<li>Each sample has multiple reference outputs, with an average output length of 22.9 tokens.</li>
<li><strong>Evaluation metrics</strong>: BLEU, NIST, METEOR, ROUGE-L, CIDEr.</li>
</ul>
</li>
<li>
<p><strong>WebNLG (Gardent et al., 2017)</strong>:</p>
<ul>
<li>A dataset containing 22K samples, with each entry represented as a (subject, property, object) triple.</li>
<li>It spans 14 domains, with the test set divided into <strong>“Seen”</strong> and <strong>“Unseen”</strong> categories to assess the model’s generalization capability.</li>
<li>The average output length is 22.5 tokens.</li>
<li><strong>Evaluation metrics</strong>: BLEU, METEOR, TER.</li>
</ul>
</li>
<li>
<p><strong>DART (Radev et al., 2020)</strong>:</p>
<ul>
<li>An open-domain dataset containing 82K samples, with an input format similar to WebNLG.</li>
<li>It is compiled from multiple sources, including WikiSQL, WikiTableQuestions, E2E, and WebNLG.</li>
<li>The average output length is 21.6 tokens.</li>
<li><strong>Evaluation metrics</strong>: BLEU, METEOR, TER, MoverScore, BERTScore, BLEURT.</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
<li>
<p><strong>Summarization Task</strong>:</p>
<ul>
<li><strong>XSUM (Narayan et al., 2018)</strong>:<!-- -->
<ul>
<li>A large dataset with 225K news articles paired with corresponding summaries.</li>
<li>The average article length is 431 tokens, while the average summary length is 23.3 tokens.</li>
<li><strong>Evaluation metrics</strong>: ROUGE-1, ROUGE-2, ROUGE-L.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=discussion>Discussion<a href=#discussion class=hash-link aria-label="Direct link to Discussion" title="Direct link to Discussion">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=performance-on-table-to-text-generation>Performance on Table-to-Text Generation<a href=#performance-on-table-to-text-generation class=hash-link aria-label="Direct link to Performance on Table-to-Text Generation" title="Direct link to Performance on Table-to-Text Generation">​</a></h3>
<p><img decoding=async loading=lazy alt=table-to-text src=/en/assets/images/img3-e30ba6d651c297b9c11e4fad103a87ce.jpg width=1760 height=512 class=img_ev3q></p>
<p>Despite using only <strong>0.1%</strong> of the task-specific parameters, Prefix-Tuning outperforms other lightweight fine-tuning methods:</p>
<ul>
<li><strong>Adapter-Tuning (ADAPTER)</strong>: Although both methods use 0.1% of the parameters, Prefix-Tuning achieves an average <strong>4.1-point increase</strong> in <strong>BLEU</strong> scores.</li>
<li><strong>FT-TOP2</strong>: This approach fine-tunes only the top two layers of the model’s parameters.</li>
</ul>
<p>Prefix-Tuning performs on par with, and in some cases even surpasses, full fine-tuning. Additionally, compared to Adapter-Tuning, which uses 3.0% of the model’s parameters, Prefix-Tuning remains competitive in performance.</p>
<p>The consistent results across all three datasets—<strong>E2E</strong>, <strong>WebNLG</strong>, and <strong>DART</strong>—highlight the versatility of Prefix-Tuning. Its strong performance on the open-domain DART dataset indicates that Prefix-Tuning can adapt to various domains and relational structures, demonstrating its <strong>robust generalization capabilities</strong>.</p>
<p>Experiments with <strong>GPT-2 Medium</strong> and <strong>GPT-2 Large</strong> show that Prefix-Tuning scales well with model size, suggesting its applicability to even larger models, such as GPT-3.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=performance-on-summarization>Performance on Summarization<a href=#performance-on-summarization class=hash-link aria-label="Direct link to Performance on Summarization" title="Direct link to Performance on Summarization">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=summarization src=/en/assets/images/img5-c4c110ad7a24c752fa91ccbba3c61c37.jpg width=1224 height=324 class=img_ev3q></figure></div>
<p>Using <strong>2% of task-specific parameters</strong>, Prefix-Tuning achieves a <strong>ROUGE-L score of 36.05</strong>, only slightly below the full fine-tuning score of <strong>37.25</strong>. However, when the parameter usage is further reduced to <strong>0.1%</strong>, the ROUGE-L score drops to <strong>35.05</strong>, indicating a performance decline with fewer parameters.</p>
<p>Prefix-Tuning’s performance in summarization lags slightly behind full fine-tuning, likely due to the following reasons:</p>
<ol>
<li>
<p><strong>Data Volume</strong>:
The <strong>XSUM</strong> dataset contains <strong>four times</strong> as many samples as the table-to-text datasets, requiring the model to process a larger amount of data.</p>
</li>
<li>
<p><strong>Input Length</strong>:
On average, XSUM articles are <strong>17 times longer</strong> than the tabular inputs, resulting in significantly more complex input sequences.</p>
</li>
<li>
<p><strong>Task Complexity</strong>:
Summarization demands more from the model, requiring it to <strong>comprehend</strong> the content, identify key information, and generate concise summaries.</p>
</li>
</ol>
<p>Although Prefix-Tuning falls short of full fine-tuning in the summarization task, it still demonstrates <strong>strong potential in resource-constrained environments</strong>. Different tasks pose different challenges for models, and Prefix-Tuning’s advantage diminishes when processing long and complex content. Nonetheless, the method delivers performance comparable to full fine-tuning while drastically reducing the number of trainable parameters.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=low-resource-settings>Low-Resource Settings<a href=#low-resource-settings class=hash-link aria-label="Direct link to Low-Resource Settings" title="Direct link to Low-Resource Settings">​</a></h3>
<p><img decoding=async loading=lazy alt=low-resource src=/en/assets/images/img4-f1ebf1511e6766c091167f5cac1b6c2f.jpg width=1816 height=600 class=img_ev3q></p>
<p>In low-resource scenarios, <strong>Prefix-Tuning</strong> outperforms fine-tuning, with an <strong>average improvement of 2.9 BLEU points</strong> while using far fewer parameters. As the size of the dataset increases, the performance gap between Prefix-Tuning and fine-tuning gradually narrows.</p>
<p>To evaluate performance under low-resource conditions, the authors sampled subsets from the complete datasets—<strong>E2E</strong> for table-to-text generation and <strong>XSUM</strong> for summarization. They created smaller datasets containing <strong>500</strong> samples. Each dataset size was tested using <strong>five different random samples</strong>, with <strong>two random seeds</strong> for each sample, resulting in the <strong>average performance across 10 models</strong> per size.</p>
<p>Both Prefix-Tuning and fine-tuning exhibit <strong>undergeneration</strong> issues in low-data settings, meaning some table content is omitted from the output. However, Prefix-Tuning produces outputs that remain more faithful to the input tables, even with only 100 or 200 samples. In contrast, fine-tuning occasionally generates misleading outputs—such as misreporting a customer rating as “low” when it is actually “average.” Prefix-Tuning avoids such inaccuracies, maintaining fidelity to the input data.</p>
<p>In summary, Prefix-Tuning has a clear <strong>advantage in low-resource settings</strong>, producing better results with fewer parameters. This method excels at accurately reflecting the input content, and its performance is <strong>more stable and reliable</strong> than fine-tuning in scenarios with limited data.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=extrapolation-ability>Extrapolation Ability<a href=#extrapolation-ability class=hash-link aria-label="Direct link to Extrapolation Ability" title="Direct link to Extrapolation Ability">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=extrapolation src=/en/assets/images/img6-c69c1867cbd9a5b90dced69c2ddc6510.jpg width=1224 height=300 class=img_ev3q></figure></div>
<p>The authors also explore <strong>Prefix-Tuning’s extrapolation capability</strong>—the model’s ability to handle topics during testing that differ from those seen during training.</p>
<ul>
<li>
<p><strong>Extrapolation Setup</strong>:</p>
<ul>
<li>
<p><strong>Table-to-Text Generation</strong>:</p>
<ul>
<li>The <strong>WebNLG</strong> dataset is used, with the table topics divided into:<!-- -->
<ul>
<li><strong>SEEN</strong>: Nine categories present in both the training and validation sets.</li>
<li><strong>UNSEEN</strong>: Five categories that appear only in the test set.</li>
</ul>
</li>
</ul>
<p>The model is trained on the SEEN categories, and its performance is evaluated on the UNSEEN categories.</p>
</li>
<li>
<p><strong>Summarization</strong>:
Two types of extrapolation scenarios are tested:</p>
<ol>
<li><strong>News-to-Sports Transfer</strong>:
The model is trained on news articles and tested on sports articles.</li>
<li><strong>Intra-News Transfer</strong>:
The model is trained on articles from categories such as <strong>World, UK, and Business</strong> and tested on articles from other news domains, such as <strong>Health and Technology</strong>.</li>
</ol>
</li>
</ul>
</li>
</ul>
<p>Prefix-Tuning outperforms fine-tuning across <strong>all evaluation metrics</strong>, demonstrating <strong>strong extrapolation capabilities</strong> in both table-to-text generation and summarization tasks.</p>
<p>Interestingly, <strong>Adapter-Tuning</strong> performs similarly to Prefix-Tuning in these extrapolation scenarios. Both methods <strong>freeze the pre-trained language model’s parameters</strong>, which helps retain the model’s generalization capabilities across new topics. This suggests that <strong>preserving the original parameters</strong> of the language model, rather than modifying them through extensive fine-tuning, enhances the model’s ability to generalize to unseen domains.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=how-long-should-the-prefix-be>How Long Should the Prefix Be?<a href=#how-long-should-the-prefix-be class=hash-link aria-label="Direct link to How Long Should the Prefix Be?" title="Direct link to How Long Should the Prefix Be?">​</a></h3>
<p><img decoding=async loading=lazy alt=prefix-length src=/en/assets/images/img7-dc35a6780e755e1f0923ebed7ed835b9.jpg width=1224 height=440 class=img_ev3q></p>
<p>Experiments show that <strong>longer prefixes</strong> tend to improve performance, but performance may slightly decline beyond a certain threshold.</p>
<ul>
<li>In the <strong>summarization task</strong>, the optimal prefix length is <strong>200</strong> tokens.</li>
<li>In the <strong>table-to-text generation task</strong>, the best performance is achieved with a prefix length of <strong>10</strong> tokens.</li>
</ul>
<p>The prefix length has <strong>minimal impact on inference speed</strong> because GPUs can <strong>parallelize attention calculations</strong> efficiently.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=initialization-strategies>Initialization Strategies<a href=#initialization-strategies class=hash-link aria-label="Direct link to Initialization Strategies" title="Direct link to Initialization Strategies">​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=initialization src=/en/assets/images/img9-23182c8367bafa5f5c0b83dfccf3ecf4.jpg width=1224 height=692 class=img_ev3q></figure></div>
<p>In <strong>low-data scenarios</strong>, the <strong>initialization strategy</strong> has a significant impact on performance:</p>
<ul>
<li><strong>Random initialization</strong> results in lower performance with high variability.</li>
<li><strong>Activation-based initialization using meaningful words</strong> substantially improves performance.</li>
</ul>
<p>Using words relevant to the task (e.g., "summarization" or "table-to-text") yields better results than using irrelevant words (e.g., "elephant" or "divide"). However, even initializing with irrelevant words performs better than random initialization.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=suitable-use-cases>Suitable Use Cases<a href=#suitable-use-cases class=hash-link aria-label="Direct link to Suitable Use Cases" title="Direct link to Suitable Use Cases">​</a></h3>
<p>Prefix-Tuning is particularly useful in scenarios that require <strong>independent training for a large number of tasks</strong>, such as <strong>personalized models for multiple users</strong>. To protect user privacy, data from different users must remain isolated, and each user requires a separate model. In this setting, each user is treated as a distinct task.</p>
<p>Prefix-Tuning allows for <strong>flexible addition or removal of users</strong> by modifying the prefixes, preventing data contamination across users.</p>
<p>In contrast, <strong>Adapter-Tuning</strong> struggles in these scenarios since the adapters are integrated into the <strong>transformer layers</strong>. This makes it difficult to separate computations and share resources efficiently across multiple models.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=why-does-prefix-tuning-perform-well-on-unseen-topics>Why Does Prefix-Tuning Perform Well on Unseen Topics?<a href=#why-does-prefix-tuning-perform-well-on-unseen-topics class=hash-link aria-label="Direct link to Why Does Prefix-Tuning Perform Well on Unseen Topics?" title="Direct link to Why Does Prefix-Tuning Perform Well on Unseen Topics?">​</a></h3>
<p>The authors dedicate a section to address this question.</p>
<p>First, <strong>pre-trained language models</strong> are trained on <strong>large-scale general corpora</strong>, which helps the model develop broad generalization abilities. <strong>Freezing the parameters</strong> of these pre-trained models during Prefix-Tuning preserves this generalization capability, allowing the model to perform well on <strong>unseen topics</strong>. Both <strong>Prefix-Tuning</strong> and <strong>Adapter-Tuning</strong> follow this principle by leaving the pre-trained parameters untouched and only fine-tuning a small number of parameters. This prevents interference with the model’s original abilities.</p>
<p>In contrast, <strong>full fine-tuning</strong> can lead to <strong>overfitting</strong>, especially when trained on narrow domains or small datasets. Lightweight tuning methods, like Prefix-Tuning and Adapter-Tuning, mitigate overfitting by optimizing only a small subset of the parameters. As a result, the model retains its generalization capability, making it more suitable for handling <strong>new or unseen topics</strong>.</p>
<p>However, the authors acknowledge that while lightweight tuning retains generalization, it might <strong>limit the model’s ability to optimize fully</strong> for new tasks. In <strong>highly complex tasks</strong>—such as those requiring deep understanding or complex reasoning—full fine-tuning may still be necessary, as lightweight tuning might not be sufficient.</p>
<p>The strong extrapolation results of Prefix-Tuning might also depend on <strong>specific datasets or tasks</strong>. On <strong>irregular or highly complex data</strong>, lightweight tuning methods might struggle to maintain stable generalization performance. Additionally, some of the “unseen” topics in the evaluation may overlap with the <strong>pre-training data</strong>, potentially skewing the results positively.</p>
<p>Ultimately, the authors admit that this remains an <strong>open question</strong>, requiring further research to fully understand why Prefix-Tuning excels in unseen-topic scenarios.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>While the authors offer some explanations for Prefix-Tuning’s success with unseen topics, they acknowledge that the <strong>exact reason remains unclear</strong>.</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=conclusion>Conclusion<a href=#conclusion class=hash-link aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>Prefix-Tuning is a <strong>lightweight fine-tuning method</strong> that guides the model to generate task-specific outputs by adding a small set of trainable prefix parameters.</p>
<p>This approach delivers <strong>impressive performance</strong> in both <strong>table-to-text generation</strong> and <strong>summarization</strong> tasks, even when using only a fraction of the parameters. It also performs exceptionally well in <strong>low-resource</strong> and <strong>unseen-topic</strong> scenarios, demonstrating robust <strong>generalization capabilities</strong>.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>One noticeable drawback of this method is that it <strong>consumes part of the input sequence</strong> to store the prefix tokens.<p>For example, experiments suggest that <strong>200 tokens</strong> are required for optimal performance in summarization. With many language models limited to <strong>512 input tokens</strong>, using nearly half the available space for prefixes can feel <strong>inefficient</strong>.</div></div></header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>Last updated<!-- --> on <b><time datetime=2025-02-11T02:49:16.000Z itemprop=dateModified>Feb 11, 2025</time></b> by <b>zephyr-sh</b></span></div></div><section class=ctaSection_iCjC><div class="
        simpleCta_ji_Y
        simple-cta__coffee_YwC8
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>☕ Fuel my writing with a coffee</h3><p class=simple-cta__subtitle_ol86>Your support keeps my AI & full-stack guides coming.<div class=simple-cta__buttonWrapper_jk1Y><img src=/en/img/bmc-logo.svg alt=cta-button class=simple-cta__buttonImg_Q9VV></div></div><div class="ant-row ant-row-stretch cardsSection_wRaP css-7ny38l" style=margin-left:-8px;margin-right:-8px;row-gap:16px><div style=padding-left:8px;padding-right:8px;display:flex class="ant-col ant-col-xs-24 css-7ny38l"><div class="ant-card ant-card-bordered card_gKx9 fadeInUp_n33J hoverTransform_Mozy css-7ny38l" style=flex:1;display:flex;flex-direction:column><div class=ant-card-body><div style=text-align:center;margin-top:1rem><img src=/en/img/icons/all_in.svg alt="AI / Full-Stack / Custom — All In icon" style=width:48px;height:48px></div><span class="ant-tag ant-tag-orange card__tag_PLj3 css-7ny38l">All-in</span><h4 class=card__title_SQBY>AI / Full-Stack / Custom — All In</h4><p class=card__concept_Ak8F>From idea to launch—efficient systems that are future-ready.<div class=card__bulletHeader_b6cf><h5 class=card__bulletTitle_R_wg>All-In Bundle</h5></div><ul class=card__bulletList_SrNN><li class=card__bulletItem_wCRd>Consulting + Dev + Deploy<li class=card__bulletItem_wCRd>Maintenance & upgrades</ul></div></div></div></div><div class="
        simpleCta_ji_Y
        simple-cta__outro_AXbn
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>🚀 Ready for your next project?</h3><p class=simple-cta__subtitle_ol86>Need a tech partner or custom solution? Let’s connect.</div></section><div style=margin-top:3rem> </div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/en/papers/model-tuning/autoprompt/><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>[20.10] AutoPrompt</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/en/papers/model-tuning/soft-prompts/><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>[21.04] Soft Prompts</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#is-it-the-same-or-different class="table-of-contents__link toc-highlight">Is it the Same or Different?</a><li><a href=#defining-the-problem class="table-of-contents__link toc-highlight">Defining the Problem</a><li><a href=#solving-the-problem class="table-of-contents__link toc-highlight">Solving the Problem</a><ul><li><a href=#model-architecture class="table-of-contents__link toc-highlight">Model Architecture</a><li><a href=#implementation-details class="table-of-contents__link toc-highlight">Implementation Details</a><li><a href=#dataset-setup class="table-of-contents__link toc-highlight">Dataset Setup</a></ul><li><a href=#discussion class="table-of-contents__link toc-highlight">Discussion</a><ul><li><a href=#performance-on-table-to-text-generation class="table-of-contents__link toc-highlight">Performance on Table-to-Text Generation</a><li><a href=#performance-on-summarization class="table-of-contents__link toc-highlight">Performance on Summarization</a><li><a href=#low-resource-settings class="table-of-contents__link toc-highlight">Low-Resource Settings</a><li><a href=#extrapolation-ability class="table-of-contents__link toc-highlight">Extrapolation Ability</a><li><a href=#how-long-should-the-prefix-be class="table-of-contents__link toc-highlight">How Long Should the Prefix Be?</a><li><a href=#initialization-strategies class="table-of-contents__link toc-highlight">Initialization Strategies</a><li><a href=#suitable-use-cases class="table-of-contents__link toc-highlight">Suitable Use Cases</a><li><a href=#why-does-prefix-tuning-perform-well-on-unseen-topics class="table-of-contents__link toc-highlight">Why Does Prefix-Tuning Perform Well on Unseen Topics?</a></ul><li><a href=#conclusion class="table-of-contents__link toc-highlight">Conclusion</a></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/en/docs>Projects</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/papers/intro>Papers</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/blog>Blog</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/terms-of-service>TermsOfUse</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/privacy-policy>Privacy Policy</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/become-an-author>Become an author</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/worklog>Worklog</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>