<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-lightweight/mobilenet-v4/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.6.3"><title data-rh=true>[24.04] MobileNet-V4 | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width,initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/en/papers/lightweight/mobilenet-v4/><meta data-rh=true property=og:locale content=en><meta data-rh=true property=og:locale:alternate content=zh_hant><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[24.04] MobileNet-V4 | DOCSAID"><meta data-rh=true name=description content="Five Years of Evolution"><meta data-rh=true property=og:description content="Five Years of Evolution"><link data-rh=true rel=icon href=/en/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/en/papers/lightweight/mobilenet-v4/><link data-rh=true rel=alternate href=https://docsaid.org/papers/lightweight/mobilenet-v4/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/lightweight/mobilenet-v4/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/lightweight/mobilenet-v4/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/lightweight/mobilenet-v4/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin><link rel=alternate type=application/rss+xml href=/en/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/en/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/en/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin><link rel=stylesheet href=/en/assets/css/styles.1cc926cb.css><script src=/en/assets/js/main.4e7b3da5.js defer></script><script src=/en/assets/js/runtime~main.09aa1197.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/en/><div class=navbar__logo><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/en/docs/>Projects</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/en/papers/intro>Papers</a><a class="navbar__item navbar__link" href=/en/blog>Blog</a><a class="navbar__item navbar__link" href=/en/playground/intro>Playground</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>English</a><ul class=dropdown__menu><li><a href=/papers/lightweight/mobilenet-v4/ rel="noopener noreferrer" class=dropdown__link lang=zh-hant>繁體中文</a><li><a href=/en/papers/lightweight/mobilenet-v4/ rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=en>English</a><li><a href=/ja/papers/lightweight/mobilenet-v4/ rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><a href=https://buymeacoffee.com/zephyr_docsaid target=_blank rel="noopener noreferrer" class="navbar__item navbar__link">Support Us<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a><a href=https://github.com/DocsaidLab target=_blank rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type=button disabled title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live=polite aria-pressed=false><svg viewBox="0 0 24 24" width=24 height=24 class=lightToggleIcon_pyhR><path fill=currentColor d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"/></svg><svg viewBox="0 0 24 24" width=24 height=24 class=darkToggleIcon_wfgR><path fill=currentColor d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"/></svg></button></div><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/en/><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>Research Paper Notes</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="Expand sidebar category 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-anti-spoofing-1>Face Anti-Spoofing (1)</a><button aria-label="Expand sidebar category 'Face Anti-Spoofing (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="Expand sidebar category 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/feature-fusion-7>Feature Fusion (7)</a><button aria-label="Expand sidebar category 'Feature Fusion (7)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/en/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="Collapse sidebar category 'Lightweight (10)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/lightweight/mobilenet-v1/>[17.04] MobileNet-V1</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/lightweight/shufflenet/>[17.07] ShuffleNet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/lightweight/senet/>[17.09] SENet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/lightweight/mobilenet-v2/>[18.01] MobileNet-V2</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/lightweight/mobilenet-v3/>[19.05] MobileNet-V3</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/lightweight/ghostnet/>[19.11] GhostNet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/lightweight/mobile-former/>[21.08] Mobile-Former</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/lightweight/pp-lcnet/>[21.09] PP-LCNet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/lightweight/mobilevit/>[21.10] MobileViT</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/en/papers/lightweight/mobilenet-v4/>[24.04] MobileNet-V4</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/mamba-1>Mamba (1)</a><button aria-label="Expand sidebar category 'Mamba (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/model-tuning-7>Model Tuning (7)</a><button aria-label="Expand sidebar category 'Model Tuning (7)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/multimodality-22>Multimodality (22)</a><button aria-label="Expand sidebar category 'Multimodality (22)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/normalization-1>Normalization (1)</a><button aria-label="Expand sidebar category 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/object-detection-8>Object Detection (8)</a><button aria-label="Expand sidebar category 'Object Detection (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/reparameterization-7>Reparameterization (7)</a><button aria-label="Expand sidebar category 'Reparameterization (7)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="Expand sidebar category 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-detection-10>Text Detection (10)</a><button aria-label="Expand sidebar category 'Text Detection (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="Expand sidebar category 'Text Recognition (20)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="Expand sidebar category 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/transformers-15>Transformers (15)</a><button aria-label="Expand sidebar category 'Transformers (15)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/vision-transformers-11>Vision Transformers (11)</a><button aria-label="Expand sidebar category 'Vision Transformers (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>All Notes: 140 entries</a></ul></nav><button type=button title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/en/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/en/papers/category/lightweight-10><span itemprop=name>Lightweight (10)</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>[24.04] MobileNet-V4</span><meta itemprop=position content=2></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>[24.04] MobileNet-V4</h1></header>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=five-years-of-evolution>Five Years of Evolution<a href=#five-years-of-evolution class=hash-link aria-label="Direct link to Five Years of Evolution" title="Direct link to Five Years of Evolution">​</a></h2>
<p><a href=https://arxiv.org/abs/2404.10518 target=_blank rel="noopener noreferrer"><strong>MobileNetV4 - Universal Models for the Mobile Ecosystem</strong></a></p>
<hr>
<p>Five years have passed since the release of MobileNetV3.</p>
<p>During this time, the academic community has made significant progress with new network architectures and the application of multi-head attention mechanisms.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=defining-the-problem>Defining the Problem<a href=#defining-the-problem class=hash-link aria-label="Direct link to Defining the Problem" title="Direct link to Defining the Problem">​</a></h2>
<p>With these new advancements, it's tempting to integrate them into MobileNet for improved performance.</p>
<p>Firstly, recent trends in attention mechanisms have led to two primary approaches:</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=hybrid-attention>Hybrid Attention<a href=#hybrid-attention class=hash-link aria-label="Direct link to Hybrid Attention" title="Direct link to Hybrid Attention">​</a></h3>
<p>This approach focuses on combining the strengths of CNNs and Transformers, making attention mechanisms more suitable for lightweight networks.</p>
<p>Notable works include:</p>
<ul>
<li><a href=https://arxiv.org/abs/2108.05895 target=_blank rel="noopener noreferrer"><strong>[21.08] Mobile-Former: Bridging MobileNet and Transformer</strong></a></li>
<li><a href=https://arxiv.org/abs/2110.02178 target=_blank rel="noopener noreferrer"><strong>[21.10] MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer</strong></a></li>
<li><a href=https://arxiv.org/abs/2303.14189 target=_blank rel="noopener noreferrer"><strong>[23.03] FastViT: A Fast Hybrid Vision Transformer using Structural Reparameterization</strong></a></li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=efficient-attention>Efficient Attention<a href=#efficient-attention class=hash-link aria-label="Direct link to Efficient Attention" title="Direct link to Efficient Attention">​</a></h3>
<p>This approach aims to improve the efficiency of MHSA, reducing the complexity from <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>O</mi><mo stretchy=false>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>O(n^2)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0641em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.02778em>O</span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">n</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8141em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span> to <span class=katex><span class=katex-mathml><math><semantics><mrow><mi>O</mi><mo stretchy=false>(</mo><mi>n</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>O(n)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.02778em>O</span><span class=mopen>(</span><span class="mord mathnormal">n</span><span class=mclose>)</span></span></span></span>.</p>
<p>Key papers include:</p>
<ul>
<li><a href=https://arxiv.org/abs/2107.06263 target=_blank rel="noopener noreferrer"><strong>[21.07] CMT: Convolutional Neural Networks Meet Vision Transformers</strong></a></li>
<li><a href=https://arxiv.org/abs/2205.14756 target=_blank rel="noopener noreferrer"><strong>[22.05] EfficientViT: Multi-Scale Linear Attention for High-Resolution Dense Prediction</strong></a></li>
<li><a href=https://arxiv.org/abs/2206.02680 target=_blank rel="noopener noreferrer"><strong>[22.06] Separable Self-attention for Mobile Vision Transformers</strong></a></li>
<li><a href=https://arxiv.org/abs/2207.05501 target=_blank rel="noopener noreferrer"><strong>[22.07] Next-ViT: Next Generation Vision Transformer for Efficient Deployment in Realistic Industrial Scenarios</strong></a></li>
<li><a href=https://arxiv.org/abs/2212.08059 target=_blank rel="noopener noreferrer"><strong>[22.12] Rethinking Vision Transformers for MobileNet Size and Speed</strong></a></li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=various-convolutional-network-architectures>Various Convolutional Network Architectures<a href=#various-convolutional-network-architectures class=hash-link aria-label="Direct link to Various Convolutional Network Architectures" title="Direct link to Various Convolutional Network Architectures">​</a></h3>
<p>Beyond attention mechanisms, there are other architectural overviews worth considering:</p>
<ul>
<li><a href=/en/papers/classic-cnns/convnext/><strong>[22.01] ConvNeXt: Making Convolutions Great Again</strong></a></li>
</ul>
<p>These serve as valuable references.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=solving-the-problem>Solving the Problem<a href=#solving-the-problem class=hash-link aria-label="Direct link to Solving the Problem" title="Direct link to Solving the Problem">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=network-architecture>Network Architecture<a href=#network-architecture class=hash-link aria-label="Direct link to Network Architecture" title="Direct link to Network Architecture">​</a></h3>
<p><img decoding=async loading=lazy alt="uib block" src=/en/assets/images/img1-3d70aa43813018cb370af597d75d7001.jpg width=1324 height=504 class=img_ev3q></p>
<p>The authors first extended the inverted bottleneck (IB) from MobileNet-V2.</p>
<p>In the diagram, the <code>Inverted Bottleneck</code> is the basic structure of MobileNet-V2, which you are likely familiar with.</p>
<p>The authors added an additional <code>Depthwise Convolution</code> before this structure and allowed the front and middle parts to "combine freely."</p>
<p>This enables four different combinations:</p>
<ol>
<li>Both selected: Extra DW</li>
<li>First DW selected: Conv Next structure</li>
<li>Middle DW selected: Original IB</li>
<li>Neither selected: Simple FFN</li>
</ol>
<p>This flexible module is termed <code>UIB</code> (Universal Inverted Bottleneck) in the paper.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>info</div><div class=admonitionContent_BuS1><p>Besides <code>UIB</code>, the paper introduces another fixed component for subsequent NAS searches called <code>Alternative Fused IB</code>.<p>One search space rule is:<ul>
<li>Fixed initial layer: Start with <code>Conv2D</code> (3x3 kernel, stride=2) in the first stage, followed by <code>FusedIB</code> in the second stage to balance efficiency and accuracy.</li>
</ul></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=mobile-mqa>Mobile MQA<a href=#mobile-mqa class=hash-link aria-label="Direct link to Mobile MQA" title="Direct link to Mobile MQA">​</a></h3>
<p>After designing the convolutional network architecture, the authors introduced a new attention module: Multi-Query Attention (MQA).</p>
<p>This structure originates from:</p>
<ul>
<li><a href=/en/papers/transformers/mqa/><strong>[19.11] MQA: Sharing Key-Value</strong></a></li>
</ul>
<p>If you recall the basic structure of attention mechanisms, they consist of Query, Key, and Value.</p>
<p>In multi-head attention, each head has its own Query, Key, and Value.</p>
<p>The main idea here is that each head has a different Query but shares the same Key and Value.</p>
<p>Previous experiments have shown that this design doesn't reduce model performance, especially when the batch size is relatively small compared to the feature dimensions. This significantly reduces computation.</p>
<p>This is particularly relevant for mobile devices, where inference often uses a batch size of 1.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>The authors claim to be the first to apply MQA in lightweight networks.</div></div>
<p>Unlike text-based attention mechanisms, this one is applied to images.</p>
<p>Thus, the authors also referenced another paper:</p>
<ul>
<li><a href=/en/papers/vision-transformers/pvt/><strong>[21.02] PVT: Spatial-Reduction Attention</strong></a></li>
</ul>
<p>This paper introduced the Spatial-Reduction Attention (SRA) module, which reduces the spatial dimensions of feature maps before applying attention, thus reducing computation.</p>
<p>Combining the two concepts, replacing SRA's attention with MQA and replacing pooling with convolution results in the Mobile MQA proposed in this paper.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>The paper lists almost ten worthwhile papers to read, which we'll compile later... so busy.</div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=cross-device-optimization>Cross-Device Optimization<a href=#cross-device-optimization class=hash-link aria-label="Direct link to Cross-Device Optimization" title="Direct link to Cross-Device Optimization">​</a></h3>
<p>The core goal of this paper is cross-device optimization.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>In previous MobileNet-V3 research, optimization was only done for the Pixel series.</div></div>
<p>During the experiments, the authors gathered several key insights:</p>
<ol>
<li><strong>Multi-path efficiency issues</strong>:<!-- -->
<ul>
<li>Group convolutions and similar multi-path designs, despite having lower FLOPs counts, have lower efficiency due to memory access complexity.</li>
</ul>
</li>
<li><strong>Hardware support is crucial</strong>:<!-- -->
<ul>
<li>Advanced modules like Squeeze and Excite (SE), GELU, and LayerNorm lack good support on mobile devices.</li>
<li>LayerNorm lags behind BatchNorm.</li>
<li>SE is slow on mobile accelerators.</li>
</ul>
</li>
<li><strong>The power of simplicity</strong>:<!-- -->
<ul>
<li>Simple modules like ReLU, Conv2D, DW-Conv2D, and BatchNorm are well-supported on mobile devices.</li>
</ul>
</li>
</ol>
<p>Based on these insights, the NAS search system prioritizes widely supported standard modules, combining them with the aforementioned <code>UIB</code> and <code>MQA</code> modules during the search.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=discussion>Discussion<a href=#discussion class=hash-link aria-label="Direct link to Discussion" title="Direct link to Discussion">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=imagenet-experimental-results>ImageNet Experimental Results<a href=#imagenet-experimental-results class=hash-link aria-label="Direct link to ImageNet Experimental Results" title="Direct link to ImageNet Experimental Results">​</a></h3>
<p><img decoding=async loading=lazy alt=imagenet-result-1 src=/en/assets/images/img5-9722932525e217f3431ea92073bbd641.jpg width=1224 height=708 class=img_ev3q></p>
<p><img decoding=async loading=lazy alt=imagenet-result-2 src=/en/assets/images/img3-43b1f9ea88a03db7c54a037f11d49731.jpg width=1224 height=908 class=img_ev3q></p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>info</div><div class=admonitionContent_BuS1><p>In the table, the MobileNet series (V1, V2, V3) have been retrained with modern training schedules, resulting in higher performance than reported in the original papers.</div></div>
<p>The MNv4 models excel in efficiency and demonstrate compatibility across different hardware platforms, enabling seamless deployment in the mobile ecosystem without platform-specific adjustments.</p>
<ol>
<li><strong>Performance on CPU</strong>: The MNv4 models are twice as fast as MobileNetV3 and significantly outperform other models with similar accuracy.</li>
<li><strong>Performance on EdgeTPU</strong>: MNv4 is twice as fast as MobileNet V3.</li>
<li><strong>Performance on GPU and Apple ANE</strong>: MNv4 shows excellent front-end performance on the S23 GPU and CoreML on the iPhone 13.</li>
<li><strong>Comparison with competing models</strong>:<!-- -->
<ul>
<li><strong>FastViT</strong>: Ranks second on the Apple Neural Engine but has over five times the latency on GPUs compared to MNv4.</li>
<li><strong>EfficientViT</strong>: Performs well on GPUs but has higher latency on the Apple Neural Engine.</li>
<li><strong>MobileNet V3</strong>: Performs well on CPUs but poorly on other hardware platforms.</li>
</ul>
</li>
</ol>
<p>The authors note that MNv4's success is due to the use of UIB blocks, enhanced NAS recipes, and carefully designed search spaces.</p>
<p>This model's universality sets a new standard for mobile models achieving optimal performance across various hardware platforms.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=effectiveness-of-mqa>Effectiveness of MQA<a href=#effectiveness-of-mqa class=hash-link aria-label="Direct link to Effectiveness of MQA" title="Direct link to Effectiveness of MQA">​</a></h3>
<p><img decoding=async loading=lazy alt=mqa src=/en/assets/images/img2-f262bd37b07c5eadc795a2bfb79234b1.jpg width=1224 height=336 class=img_ev3q></p>
<p>Experiments confirmed the advantages of MQA in hybrid models.</p>
<p>As shown in the table, MQA achieves over 39% acceleration on EdgeTPU and Samsung S23 GPU compared to MHSA, with negligible quality loss (-0.03%).</p>
<p>MQA also reduces MAC and model parameters by over 25%.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=mnv4-conv-s>MNv4-Conv-S<a href=#mnv4-conv-s class=hash-link aria-label="Direct link to MNv4-Conv-S" title="Direct link to MNv4-Conv-S">​</a></h3>
<p>The paper proposes four models, with MNv4-Conv-S being the smallest.</p>
<p>For other model architectures, please refer to the paper directly.</p>
<p><img decoding=async loading=lazy alt=MNv4-Conv-S src=/en/assets/images/img4-98882a72392a6f5387725c6adb45133d.jpg width=1224 height=996 class=img_ev3q></p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=conclusion>Conclusion<a href=#conclusion class=hash-link aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>This is a universal and efficient model designed for optimal operation across the entire mobile ecosystem.</p>
<p>MobileNetV4, through a series of innovations and technical optimizations, achieves Pareto-optimal performance on mobile CPUs, GPUs, DSPs, and dedicated accelerators, which is rare in lightweight model research.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>Pareto Optimality is a concept from economics and engineering that describes an optimal state where no party's situation can improve without at least one party's situation worsening. This concept originates from Italian sociologist Vilfredo Pareto.</div></div>
<p>＊</p>
<p>In past development experiences, every new lightweight model required extensive testing on various phones...</p>
<ul>
<li>Not to see which is best, but to see which phones have issues.</li>
</ul>
<p>For example, the <code>FastViT</code> architecture, which gained significant attention in 2023, showed confusingly reduced performance outside of iPhones.</p>
<p>We appreciate Google testing this round for us, allowing us to use it directly.</div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>Last updated<!-- --> on <b><time datetime=2024-09-27T05:38:00.000Z itemprop=dateModified>Sep 27, 2024</time></b> by <b>zephyr-sh</b></span></div></div></footer><div style=margin-top:3rem> </div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/en/papers/lightweight/mobilevit/><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>[21.10] MobileViT</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/en/papers/category/mamba-1><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>Mamba (1)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#five-years-of-evolution class="table-of-contents__link toc-highlight">Five Years of Evolution</a><li><a href=#defining-the-problem class="table-of-contents__link toc-highlight">Defining the Problem</a><ul><li><a href=#hybrid-attention class="table-of-contents__link toc-highlight">Hybrid Attention</a><li><a href=#efficient-attention class="table-of-contents__link toc-highlight">Efficient Attention</a><li><a href=#various-convolutional-network-architectures class="table-of-contents__link toc-highlight">Various Convolutional Network Architectures</a></ul><li><a href=#solving-the-problem class="table-of-contents__link toc-highlight">Solving the Problem</a><ul><li><a href=#network-architecture class="table-of-contents__link toc-highlight">Network Architecture</a><li><a href=#mobile-mqa class="table-of-contents__link toc-highlight">Mobile MQA</a><li><a href=#cross-device-optimization class="table-of-contents__link toc-highlight">Cross-Device Optimization</a></ul><li><a href=#discussion class="table-of-contents__link toc-highlight">Discussion</a><ul><li><a href=#imagenet-experimental-results class="table-of-contents__link toc-highlight">ImageNet Experimental Results</a><li><a href=#effectiveness-of-mqa class="table-of-contents__link toc-highlight">Effectiveness of MQA</a><li><a href=#mnv4-conv-s class="table-of-contents__link toc-highlight">MNv4-Conv-S</a></ul><li><a href=#conclusion class="table-of-contents__link toc-highlight">Conclusion</a></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/en/docs>Projects</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/papers/intro>Papers</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/blog>Blog</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/terms-of-service>TermsOfUse</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/privacy-policy>Privacy Policy</a><span class=footer__link-separator>·</span><a href=https://buymeacoffee.com/zephyr_docsaid target=_blank rel="noopener noreferrer" class=footer__link-item>Support Us<svg width=13.5 height=13.5 aria-hidden=true viewBox="0 0 24 24" class=iconExternalLink_nPIU><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></svg></a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>