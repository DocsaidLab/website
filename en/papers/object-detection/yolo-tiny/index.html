<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-object-detection/yolo-tiny/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.8.1"><title data-rh=true>[24.12] YOLO-Tiny | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/en/papers/object-detection/yolo-tiny/><meta data-rh=true property=og:locale content=en><meta data-rh=true property=og:locale:alternate content=zh_hant><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[24.12] YOLO-Tiny | DOCSAID"><meta data-rh=true name=description content="I Am a Little Bird"><meta data-rh=true property=og:description content="I Am a Little Bird"><link data-rh=true rel=icon href=/en/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/en/papers/object-detection/yolo-tiny/><link data-rh=true rel=alternate href=https://docsaid.org/papers/object-detection/yolo-tiny/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/object-detection/yolo-tiny/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/object-detection/yolo-tiny/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/object-detection/yolo-tiny/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://docsaid.org/en/papers/category/object-detection","name":"Object Detection (19)","position":1},{"@type":"ListItem","item":"https://docsaid.org/en/papers/object-detection/yolo-tiny/","name":"[24.12] YOLO-Tiny","position":2}]}</script><link rel=alternate type=application/rss+xml href=/en/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/en/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/en/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/en/assets/css/styles.ef02043f.css><script src=/en/assets/js/runtime~main.4e3e805b.js defer></script><script src=/en/assets/js/main.00053b7d.js defer></script><body class=navigation-with-keyboard><svg xmlns=http://www.w3.org/2000/svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light",e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/en/><div class=navbar__logo><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/en/docs/>Projects</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/en/papers/intro>Papers</a><a class="navbar__item navbar__link" href=/en/blog>Blog</a><a class="navbar__item navbar__link" href=/en/playground/intro>Playground</a><a class="navbar__item navbar__link" href=/en/services>Services</a><a class="navbar__item navbar__link" href=/en/aboutus>About Us</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>English</a><ul class=dropdown__menu><li><a href=/papers/object-detection/yolo-tiny/ target=_self rel="noopener noreferrer" class=dropdown__link lang=zh-hant>繁體中文</a><li><a href=/en/papers/object-detection/yolo-tiny/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=en>English</a><li><a href=/ja/papers/object-detection/yolo-tiny/ target=_self rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-mc1tut ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/en/><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>Paper Notes</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/classic-cnns>Classic CNNs (11)</a><button aria-label="Expand sidebar category 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/contrastive-learning>Contrastive Learning (14)</a><button aria-label="Expand sidebar category 'Contrastive Learning (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/deepseek>DeepSeek (5)</a><button aria-label="Expand sidebar category 'DeepSeek (5)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-antispoofing>Face Anti-Spoofing (43)</a><button aria-label="Expand sidebar category 'Face Anti-Spoofing (43)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-recognition>Face Recognition (4)</a><button aria-label="Expand sidebar category 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/feature-fusion>Feature Fusion (10)</a><button aria-label="Expand sidebar category 'Feature Fusion (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/image-generation>Image Generation (1)</a><button aria-label="Expand sidebar category 'Image Generation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/lightweight>Lightweight (10)</a><button aria-label="Expand sidebar category 'Lightweight (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/mamba>Mamba (4)</a><button aria-label="Expand sidebar category 'Mamba (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/model-tuning>Model Tuning (8)</a><button aria-label="Expand sidebar category 'Model Tuning (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/multimodality>Multimodality (24)</a><button aria-label="Expand sidebar category 'Multimodality (24)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/normalization>Normalization (1)</a><button aria-label="Expand sidebar category 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/en/papers/category/object-detection>Object Detection (19)</a><button aria-label="Collapse sidebar category 'Object Detection (19)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/yolov1/>[15.06] YOLOv1</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/ssd/>[15.12] SSD</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/yolov2/>[16.12] YOLOv2</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/retinanet/>[17.08] RetinaNet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/yolov3/>[18.04] YOLOv3</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/atss/>[19.12] ATSS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/yolov4/>[20.04] YOLOv4</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/detr/>[20.05] DETR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/gfl/>[20.06] GFL</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/deformable-detr/>[20.10] Deformable DETR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/smca-detr/>[21.01] SMCA DETR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/h-detr/>[22.07] H-DETR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/yolov7/>[22.07] YOLOv7</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/yolov6/>[22.09] YOLOv6</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/yolo-world/>[24.01] YOLO-World</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/yolov9/>[24.02] YOLOv9</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/yolov10/>[24.05] YOLOv10</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/object-detection/yolov11/>[24.10] YOLOv11</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/en/papers/object-detection/yolo-tiny/>[24.12] YOLO-Tiny</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/reparameterization>Reparameterization (8)</a><button aria-label="Expand sidebar category 'Reparameterization (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/retail-product>Retail Product (6)</a><button aria-label="Expand sidebar category 'Retail Product (6)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/segmentation>Segmentation (1)</a><button aria-label="Expand sidebar category 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-detection>Text Detection (14)</a><button aria-label="Expand sidebar category 'Text Detection (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-recognition>Text Recognition (20)</a><button aria-label="Expand sidebar category 'Text Recognition (20)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-spotting>Text Spotting (4)</a><button aria-label="Expand sidebar category 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/transformers>Transformers (17)</a><button aria-label="Expand sidebar category 'Transformers (17)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/vision-transformers>Vision Transformers (13)</a><button aria-label="Expand sidebar category 'Vision Transformers (13)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>All Notes: 238 entries</a></ul></nav><button type=button title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/en/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li class=breadcrumbs__item><a class=breadcrumbs__link href=/en/papers/category/object-detection><span>Object Detection (19)</span></a><li class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>[24.12] YOLO-Tiny</span></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>[24.12] YOLO-Tiny</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt="Z. Yuan" class=docAuthorImg_vlJe><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Z. Yuan</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a href=https://www.linkedin.com/in/ze-yuan-sh7/ target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 448 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=i-am-a-little-bird>I Am a Little Bird<a href=#i-am-a-little-bird class=hash-link aria-label="Direct link to I Am a Little Bird" title="Direct link to I Am a Little Bird">​</a></h2>
<p><a href=https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.13314 target=_blank rel="noopener noreferrer"><strong>YOLO-Tiny: A lightweight small object detection algorithm for UAV aerial imagery</strong></a></p>
<hr>
<p>Drones have quietly flown into every crevice of our lives.</p>
<p>But for object detection algorithms, the challenges brought by these machines are truly troublesome.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=problem-definition>Problem Definition<a href=#problem-definition class=hash-link aria-label="Direct link to Problem Definition" title="Direct link to Problem Definition">​</a></h2>
<p>Drones have penetrated every gap in daily scenarios. From aerial inspection to disaster detection, the vast amount of imagery they generate poses new challenges to object detection algorithms.</p>
<p>For models, the "sky viewpoint" captured by drones comes with unfriendly conditions: targets are extremely small in the frame with varying scales, often disturbed or partially occluded by the background, further compressing the space for effective feature recognition. Meanwhile, deployment scenarios usually have severe resource constraints, making even accurate high-performance models hard to operate in practice.</p>
<p>Although mainstream object detection methods have matured in performance, especially the one-stage algorithms represented by the YOLO series, which have become the preferred choice for real-time applications due to their speed advantage, their original architectures still struggle to directly address the dual demands of high-altitude imaging and small object detection.</p>
<p>Previous improvements tried replacing convolution modules, adding pyramid structures, introducing attention mechanisms, or performing cross-layer fusion to enhance small object recognition; others focused on training stages such as data augmentation, anchor presets, and scale adjustments.</p>
<p>However, most methods still cannot solve a fundamental problem: achieving real-time, accurate, and stable recognition of tiny suspicious targets in the frame on low-computation terminal devices is not just a matter of "compressing the model."</p>
<p>This paper addresses this issue by proposing a lightweight small object detection architecture designed for UAV aerial tasks, based on YOLOv5s.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=solution>Solution<a href=#solution class=hash-link aria-label="Direct link to Solution" title="Direct link to Solution">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=reviewing-yolov5>Reviewing YOLOv5<a href=#reviewing-yolov5 class=hash-link aria-label="Direct link to Reviewing YOLOv5" title="Direct link to Reviewing YOLOv5">​</a></h3>
<p><img decoding=async loading=lazy alt=model_arch src=/en/assets/images/img2-f9087b153f1fa6f2d326beac80aff3f9.jpg width=1422 height=844 class=img_ev3q></p>
<p>In YOLOv5’s backbone, the input image undergoes five downsampling steps, generating five sets of feature maps (P1 to P5) with resolutions of 320, 160, 80, 40, and 20 respectively. This pyramid-style feature map design enables the model to predict objects of different sizes on corresponding layers.</p>
<p>The standard YOLOv5 detection structure performs multi-scale fusion from P3 (80×80) to P5 (20×20), mainly targeting objects larger than 8×8 pixels.</p>
<p>However, for drones, this size threshold is clearly too high.</p>
<p>Statistics from the VisDrone2019 dataset provide key observations:</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=VisDrone2019 src=/en/assets/images/img3-3b318546e2351662c826cfa09fb15e06.jpg width=1120 height=1080 class=img_ev3q></figure></div>
<ul>
<li>Figure (a) shows severe class imbalance in object numbers,</li>
<li>Figure (b) shows most targets fall within extremely small size ranges,</li>
<li>Figure (c) shows bounding box aspect ratios are highly concentrated,</li>
<li>Figure (d) shows dense annotation hotspots in the middle-lower region.</li>
</ul>
<p>In other words, this is a "highly small-object-biased aerial detection task," and YOLOv5’s current design has a structural bias under this condition: its prediction layers focus mainly on P3–P5, which is the least friendly for extremely small targets.</p>
<p>Previous research tried adding a P2 detection head (160×160 feature map) to YOLOv5 to capture finer signals. While detection improved, parameters and computation rose accordingly, making it too costly for resource-limited devices.</p>
<p>Another group of researchers took a different path: removing the P5 layer and focusing on medium and small objects. But this simplification only yielded limited accuracy gains and failed to break through the bottleneck.</p>
<p>In this paper, the authors continue this line of structural adjustment by further <strong>removing the P4 layer</strong>, compressing the original triple detection structure into a dual-layer architecture with only P2 and P3, concentrating firepower on earlier, higher-resolution feature maps.</p>
<p>But this also brings another risk:</p>
<blockquote>
<p><strong>The P4 + P5 layers account for 92.1% of the total parameters in the YOLOv5s model.</strong></p>
</blockquote>
<p>Removing these nearly halves the total parameters, and detection capability may drop accordingly.</p>
<p>To avoid this "over-lightweight" problem, the authors adopt a compensation strategy:</p>
<ul>
<li><strong>While retaining P2 and P3, moderately increase the model’s depth and width</strong></li>
</ul>
<p>to maintain acceptable feature extraction and fusion capacity.</p>
<p>After practical trade-offs, the authors chose a <strong>depth of 0.67 and width of 0.75</strong> configuration as a compromise between parameter count and computational cost. This choice keeps sufficient model expressiveness while controlling GFLOPs within resource limits, laying a foundation for subsequent module lightweighting.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=module-lightweighting>Module Lightweighting<a href=#module-lightweighting class=hash-link aria-label="Direct link to Module Lightweighting" title="Direct link to Module Lightweighting">​</a></h3>
<p>In model design, there is a clear tension among parameter count, computational cost (GFLOPs), and representational capacity. This tension is especially intense for edge devices like drones, where we want strong expressiveness but cannot afford too many parameters.</p>
<p>In the prior structural adjustments, the authors reduced the P4 and P5 detection heads, cutting parameters by <strong>82.05%</strong>, which also shrunk the model’s "expressive space."</p>
<p>To compensate for this loss, the authors moderately increased depth and width, slightly raising parameters and restoring representational power. However, this also caused GFLOPs to increase from <strong>16.0 to 24.2</strong>, a <strong>53.13%</strong> growth. Further expansion would cause exponential rise in computation, clearly unsuitable for resource-constrained environments.</p>
<p>To resolve this contradiction, the authors introduced a highly efficient architectural unit:</p>
<ul>
<li><strong>Dynamic Convolution</strong>.</li>
</ul>
<p>One of the core feature extraction modules in YOLOv5 is the C3 structure, containing many residual paths and stacked convolutions.</p>
<p>The authors replaced all of it with a newly designed <strong>LW_C3</strong>, featuring the key change:</p>
<ul>
<li><strong>LW_C3</strong>: replaces every <strong>3×3 standard convolution</strong> in residual branches with a <strong>3×3 dynamic convolution</strong>, retaining depth but reducing static computational burden.</li>
</ul>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=LW_C3 src=/en/assets/images/img4-f4e28e929dad19b8d70d08e517e86e5f.jpg width=1224 height=456 class=img_ev3q></figure></div>
<ul>
<li><strong>LW_Downsample</strong>: the original module using 1×1 convolution for channel compression and downsampling is fully replaced with stride=2 dynamic convolution, enhancing expressiveness and receptive field control.</li>
</ul>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=LW_Downsample src=/en/assets/images/img5-1e85ed556d650079536f4ac08f1ff9f1.jpg width=1224 height=244 class=img_ev3q></figure></div>
<p>The core idea of dynamic convolution is similar to dynamic perceptrons:</p>
<blockquote>
<p><strong>For each input <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span>, dynamically select the best weighted combination from a set of basis functions.</strong></p>
</blockquote>
<p>Illustrated below:</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt="dynamic convolution" src=/en/assets/images/img7-509f28cae93c0573d090334f48ee4b88.jpg width=904 height=500 class=img_ev3q></figure></div>
<p>Mathematically, it can be written as:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>y</mi><mo>=</mo><mi>g</mi><mo stretchy=false>(</mo><mover accent=true><mi>W</mi><mo>~</mo></mover><mo stretchy=false>(</mo><mi>x</mi><msup><mo stretchy=false>)</mo><mi>T</mi></msup><mi>x</mi><mo>+</mo><mover accent=true><mi>b</mi><mo>~</mo></mover><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>y = g(\tilde{W}(x)^T x + \tilde{b}(x))</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.1702em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=mopen>(</span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.9202em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:0.13889em>W</span></span><span style=top:-3.6023em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.25em><span class=mord>~</span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose><span class=mclose>)</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8913em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span></span></span></span></span><span class="mord mathnormal">x</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.1813em;vertical-align:-0.25em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.9313em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">b</span></span><span style=top:-3.6134em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.25em><span class=mord>~</span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>))</span></span></span></span></span>
<p>where</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mover accent=true><mi>W</mi><mo>~</mo></mover><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mi>π</mi><mi>k</mi></msub><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo><msub><mover accent=true><mi>W</mi><mo>~</mo></mover><mi>k</mi></msub><mo separator=true>,</mo><mspace width=1em /><mover accent=true><mi>b</mi><mo>~</mo></mover><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mi>π</mi><mi>k</mi></msub><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo><msub><mover accent=true><mi>b</mi><mo>~</mo></mover><mi>k</mi></msub></mrow><annotation encoding=application/x-tex>\tilde{W}(x) = \sum_{k=1}^K \pi_k(x) \tilde{W}_k,\quad
\tilde{b}(x) = \sum_{k=1}^K \pi_k(x) \tilde{b}_k</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.1702em;vertical-align:-0.25em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.9202em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:0.13889em>W</span></span><span style=top:-3.6023em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.25em><span class=mord>~</span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:3.1304em;vertical-align:-1.3021em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8479em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.07153em>K</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.3021em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>π</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span><span class=mord><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.9202em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:0.13889em>W</span></span><span style=top:-3.6023em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.25em><span class=mord>~</span></span></span></span></span></span></span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:1em></span><span class=mspace style=margin-right:0.1667em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.9313em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">b</span></span><span style=top:-3.6134em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.25em><span class=mord>~</span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:3.1304em;vertical-align:-1.3021em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8479em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.07153em>K</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.3021em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>π</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span><span class=mord><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.9313em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal">b</span></span><span style=top:-3.6134em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-0.25em><span class=mord>~</span></span></span></span></span></span></span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span></span>
<p>subject to</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mn>0</mn><mo>≤</mo><msub><mi>π</mi><mi>k</mi></msub><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo><mo>≤</mo><mn>1</mn><mo separator=true>,</mo><mspace width=1em /><munder><mo>∑</mo><mi>k</mi></munder><msub><mi>π</mi><mi>k</mi></msub><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>0 \leq \pi_k(x) \leq 1,\quad \sum_k \pi_k(x) = 1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7804em;vertical-align:-0.136em></span><span class=mord>0</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>≤</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>π</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>≤</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.3521em;vertical-align:-1.3021em></span><span class=mord>1</span><span class=mpunct>,</span><span class=mspace style=margin-right:1em></span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.05em><span style=top:-1.8479em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.3021em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>π</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span></span></span></span></span>
<p>Here, <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>π</mi><mi>k</mi></msub><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\pi_k(x)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>π</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span></span></span></span> is the <strong>attention weight</strong> of the input on the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>k</mi></mrow><annotation encoding=application/x-tex>k</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.03148em>k</span></span></span></span>-th convolution kernel.</p>
<p>Essentially, rather than learning a fixed set of weights, the model learns a "selection" mechanism to decide which feature extraction strategy to emphasize based on input content.</p>
<p>To implement this selection mechanism, the authors used a common SE technique to generate attention weights, with the following steps:</p>
<ol>
<li><strong>Global Average Pooling</strong> to compress spatial information,</li>
<li>A fully connected layer + Sigmoid produces a k-dimensional weight vector <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>π</mi><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\pi(x)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.03588em>π</span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span></span></span></span>,</li>
<li>The weights are applied to k predefined convolution kernels, performing weighted dynamic convolution.</li>
</ol>
<p>For input channels <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>C</mi><mtext>in</mtext></msub></mrow><annotation encoding=application/x-tex>C_{\text{in}}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3175em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">in</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>, output channels <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>C</mi><mtext>out</mtext></msub></mrow><annotation encoding=application/x-tex>C_{\text{out}}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>, kernel size <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>D</mi><mi>k</mi></msub><mo>×</mo><msub><mi>D</mi><mi>k</mi></msub></mrow><annotation encoding=application/x-tex>D_k \times D_k</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>, and kernel count <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>k</mi></mrow><annotation encoding=application/x-tex>k</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.03148em>k</span></span></span></span>, the module’s computational complexity is:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>O</mi><mtext>dynamic</mtext></msub><mo>=</mo><mi>k</mi><msub><mi>C</mi><mtext>in</mtext></msub><msub><mi>C</mi><mtext>out</mtext></msub><msubsup><mi>D</mi><mi>k</mi><mn>2</mn></msubsup><mo>+</mo><mi>k</mi><msub><mi>C</mi><mtext>out</mtext></msub></mrow><annotation encoding=application/x-tex>O_{\text{dynamic}} = k C_{\text{in}} C_{\text{out}} D_k^2 + k C_{\text{out}}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9694em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>O</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">dynamic</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.1111em;vertical-align:-0.247em></span><span class="mord mathnormal" style=margin-right:0.03148em>k</span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3175em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">in</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8641em><span style=top:-2.453em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.247em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class="mord mathnormal" style=margin-right:0.03148em>k</span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span></span>
<p>Compared to standard convolution’s</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>O</mi><mtext>static</mtext></msub><mo>=</mo><mi>H</mi><mi>W</mi><msub><mi>C</mi><mtext>in</mtext></msub><msub><mi>C</mi><mtext>out</mtext></msub><msubsup><mi>D</mi><mi>k</mi><mn>2</mn></msubsup></mrow><annotation encoding=application/x-tex>O_{\text{static}} = H W C_{\text{in}} C_{\text{out}} D_k^2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>O</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3175em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">static</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.1111em;vertical-align:-0.247em></span><span class="mord mathnormal" style=margin-right:0.08125em>H</span><span class="mord mathnormal" style=margin-right:0.13889em>W</span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3175em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">in</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8641em><span style=top:-2.453em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.247em><span></span></span></span></span></span></span></span></span></span></span>
<p>the computation is greatly reduced, especially when the image resolution <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow><annotation encoding=application/x-tex>H \times W</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7667em;vertical-align:-0.0833em></span><span class="mord mathnormal" style=margin-right:0.08125em>H</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>W</span></span></span></span> is large.</p>
<p>By introducing dynamic convolution, the model achieves increased parameters while controlling GFLOPs within an acceptable local range.</p>
<p>More importantly, this design allows each feature point’s perception to be <strong>non-uniform</strong> but adaptively tuned based on input context. This gives YOLOv5’s feature extraction module semantic adaptability for the first time, a critical ability for small object detection.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=adaptive-multi-scale-fusion>Adaptive Multi-Scale Fusion<a href=#adaptive-multi-scale-fusion class=hash-link aria-label="Direct link to Adaptive Multi-Scale Fusion" title="Direct link to Adaptive Multi-Scale Fusion">​</a></h3>
<p>In object detection, <strong>multi-scale feature fusion</strong> is a fundamental technique to enhance model recognition capability. Shallow layers excel at preserving texture and positional information, while deeper layers focus on semantic abstraction and object judgment.</p>
<p>In theory, fusing both should combine "seeing clearly" and "understanding." However, this fusion is not trivial: scale differences cause semantic gaps, and simple concatenation or weighting often only "stacks" rather than "integrates."</p>
<p>To address this fusion failure, the authors proposed the <strong>AMSFF (Adaptive Multi-Scale Spatial Feature Fusion) module</strong>.</p>
<p>Refer to the architecture below:</p>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=asmff src=/en/assets/images/img8-b21120d70dd53e2fc85a428e58fc3869.jpg width=1224 height=284 class=img_ev3q></figure></div>
<p>The AMSFF operation logic, taking neck features <strong>L2</strong> (shallower) and <strong>L3</strong> (deeper) as an example:</p>
<ol>
<li><strong>Scale Alignment</strong>: L2 is downsampled to match L3’s spatial resolution.</li>
<li><strong>Channel Adjustment</strong>: a 1×1 convolution aligns L2’s channel number with L3’s for element-wise operations.</li>
<li><strong>Initial Fusion</strong>: concatenation of adjusted L2 and L3 forms the base fusion tensor.</li>
<li><strong>Weight Learning</strong>: a 1×1 convolution computes two spatially adaptive weight maps <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding=application/x-tex>\alpha_{i,j}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7167em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.0037em>α</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0037em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span> and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>β</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding=application/x-tex>\beta_{i,j}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9805em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05278em>β</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0528em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span> for the two feature layers. A Softmax ensures the weights sum to 1 and lie in [0,1].</li>
<li><strong>Weighted Fusion</strong>: weighted summation is computed by</li>
</ol>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msubsup><mi>y</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>j</mi></mrow><mi>l</mi></msubsup><mo>=</mo><msubsup><mi>α</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>j</mi></mrow><mi>l</mi></msubsup><mo>⋅</mo><msubsup><mi>x</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>j</mi></mrow><mrow><mo stretchy=false>(</mo><mn>1</mn><mo>→</mo><mi>l</mi><mo stretchy=false>)</mo></mrow></msubsup><mo>+</mo><msubsup><mi>β</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>j</mi></mrow><mi>l</mi></msubsup><mo>⋅</mo><msubsup><mi>x</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>j</mi></mrow><mrow><mo stretchy=false>(</mo><mn>2</mn><mo>→</mo><mi>l</mi><mo stretchy=false>)</mo></mrow></msubsup></mrow><annotation encoding=application/x-tex>y^l_{i,j} = \alpha^l_{i,j} \cdot x^{(1 \to l)}_{i,j} + \beta^l_{i,j} \cdot x^{(2 \to l)}_{i,j}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.2822em;vertical-align:-0.3831em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8991em><span style=top:-2.453em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3831em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.2822em;vertical-align:-0.3831em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.0037em>α</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8991em><span style=top:-2.453em;margin-left:-0.0037em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3831em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.4578em;vertical-align:-0.413em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mrel mtight">→</span><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.413em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.2822em;vertical-align:-0.3831em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.05278em>β</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8991em><span style=top:-2.453em;margin-left:-0.0528em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3831em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.4578em;vertical-align:-0.413em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mrel mtight">→</span><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.413em><span></span></span></span></span></span></span></span></span></span></span>
<p>where <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi>x</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>j</mi></mrow><mrow><mo stretchy=false>(</mo><mi>n</mi><mo>→</mo><mi>l</mi><mo stretchy=false>)</mo></mrow></msubsup></mrow><annotation encoding=application/x-tex>x^{(n \to l)}_{i,j}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.4578em;vertical-align:-0.413em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mrel mtight">→</span><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.413em><span></span></span></span></span></span></span></span></span></span> denotes the feature vector from layer <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> scaled to layer <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>l</mi></mrow><annotation encoding=application/x-tex>l</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.01968em>l</span></span></span></span> at position <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>(</mo><mi>i</mi><mo separator=true>,</mo><mi>j</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>(i,j)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.05724em>j</span><span class=mclose>)</span></span></span></span>, and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi>y</mi><mrow><mi>i</mi><mo separator=true>,</mo><mi>j</mi></mrow><mi>l</mi></msubsup></mrow><annotation encoding=application/x-tex>y^l_{i,j}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.2439em;vertical-align:-0.3948em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8491em><span style=top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3948em><span></span></span></span></span></span></span></span></span></span> is the fused feature map.</p>
<ol start=6>
<li><strong>Semantic Expansion</strong>: AMSFF applies two 3×3 dynamic convolutions with dilation rates 1 and 2 to enhance scale adaptation under different contexts.</li>
<li><strong>Integrated Output</strong>: a 1×1 CBS layer packages and outputs the fused structure for subsequent detection heads.</li>
</ol>
<p>Compared to previous fusion methods (FPN, PAN, BiFPN), AMSFF differs not only by adding attention but by treating fusion as a form of <strong>dynamic relationship construction</strong>.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=experimental-setup>Experimental Setup<a href=#experimental-setup class=hash-link aria-label="Direct link to Experimental Setup" title="Direct link to Experimental Setup">​</a></h3>
<p>The study uses the <strong>VisDrone2019</strong> dataset, released by Tianjin University’s Machine Learning and Data Mining Lab.</p>
<p>This dataset contains images captured by drones under various weather and lighting conditions, covering diverse scenes such as cities, suburbs, parking lots, and roads, making it ideal for testing small object and complex background recognition.</p>
<p>VisDrone2019 includes ten object categories and a total of <strong>10,209 images</strong>, divided as:</p>
<ul>
<li>Training set: 6,471 images</li>
<li>Validation set: 548 images</li>
<li>Test set: 3,190 images</li>
</ul>
<p>Dataset characteristics:</p>
<ul>
<li><strong>High scene diversity</strong>: includes static poses and motion tracking,</li>
<li><strong>Small object sizes</strong>: majority of bounding boxes are smaller than 32×32 pixels,</li>
<li><strong>Obvious occlusion and lighting changes</strong>: challenging model generalization.</li>
</ul>
<p>Below are sample images and annotations from four different scenes:</p>
<p><img decoding=async loading=lazy alt=dataset src=/en/assets/images/img9-2c6caf7f7f07a17fa346b26139fe1557.jpg width=1224 height=700 class=img_ev3q></p>
<p>The experiments follow the standard YOLO training procedure, with environment settings and hyperparameters listed below:</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=settings src=/en/assets/images/img10-13a732b51dea7254603a92aaf1fdc3c6.jpg width=852 height=696 class=img_ev3q></figure></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=discussion>Discussion<a href=#discussion class=hash-link aria-label="Direct link to Discussion" title="Direct link to Discussion">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=comparative-experiments-on-network-architecture-adjustments>Comparative Experiments on Network Architecture Adjustments<a href=#comparative-experiments-on-network-architecture-adjustments class=hash-link aria-label="Direct link to Comparative Experiments on Network Architecture Adjustments" title="Direct link to Comparative Experiments on Network Architecture Adjustments">​</a></h3>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt=settings src=/en/assets/images/img11-418309bb70cd3f63b630ae56c9d316f0.jpg width=974 height=566 class=img_ev3q></figure></div>
<p>To evaluate the impact of different detection heads on small object recognition, this study designed <strong>six architectural variants</strong> and conducted comparative experiments under identical training conditions. The specific structural changes are shown in the above table, with corresponding performance results below:</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=result src=/en/assets/images/img12-e54e71e76473f9de31d9bce61e874a59.jpg width=932 height=456 class=img_ev3q></figure></div>
<p>Key observations from the experiments include:</p>
<ol>
<li>
<p><strong>Adding the P2 Detection Head</strong></p>
<p>Adding a <strong>P2 layer (resolution 160×160)</strong> to the original YOLOv5s architecture significantly improved performance on the VisDrone2019 dataset:</p>
<ul>
<li><strong>mAP@0.5 improved by +5.5%</strong></li>
<li><strong>mAP@0.5:0.95 improved by +4.1%</strong></li>
</ul>
<p>This indicates that the model gains higher-resolution feature correspondence ability and can attend to tiny targets earlier. Although parameter count and GFLOPs slightly increased, the overall cost remained acceptable.</p>
</li>
<li>
<p><strong>Removing the P5 Detection Head</strong></p>
<p>Another experiment removed the <strong>P5 (20×20) layer</strong> to reduce parameters and computation related to large objects, focusing resources on medium and small-scale recognition:</p>
<ul>
<li>mAP@0.5 slightly increased by <strong>+0.5%</strong></li>
<li>mAP@0.5:0.95 slightly decreased by <strong>−0.1%</strong></li>
</ul>
<p>While this greatly reduced parameter count, it showed that simply removing deep features yields limited improvement and may slightly harm generalization.</p>
</li>
<li>
<p><strong>Simultaneous Removal of P4 and P5 with Model Depth and Width Enlargement</strong></p>
<p>The final version removed both <strong>P5 and P4</strong>, increasing model depth from 0.33 to 0.67 and width from 0.5 to 0.75 to compensate for reduced representational power caused by aggressive pruning.</p>
<p>This version produced the most significant results:</p>
<ul>
<li><strong>mAP@0.5 overall improvement +8.3%</strong></li>
<li><strong>mAP@0.5:0.95 improvement +5.3%</strong></li>
</ul>
<p>This suggests that although P4 and P5 are deep semantic pathways, they contribute little to small object detection. Their high downsampling rates (16×, 32×) cause serious signal loss. Moreover, moderately increasing network capacity (rather than mere compression) preserves semantic abstraction integrity, enabling the model to respond to tiny targets with more suitable "contextual parsing ability."</p>
</li>
</ol>
<p>This comparative experiment illustrates that for aerial small-object detection tasks, the key is not "more paths" or "deeper features," but identifying nodes that truly "see the small things" and allocating enough capacity for them to perform.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=ablation-study>Ablation Study<a href=#ablation-study class=hash-link aria-label="Direct link to Ablation Study" title="Direct link to Ablation Study">​</a></h3>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt=settings src=/en/assets/images/img13-996166154de6cc5278b1a692a67c0a9a.jpg width=1142 height=654 class=img_ev3q></figure></div>
<p>To verify the independent and combined contributions of three optimization strategies, the authors conducted an ablation study on VisDrone2019.</p>
<p>The specific optimization combinations are shown above, and performance results are summarized below:</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=results src=/en/assets/images/img14-f8d8f18d4e28ea8fbdc14c3066f4aa53.jpg width=1138 height=756 class=img_ev3q></figure></div>
<p>These results reveal each module’s contribution:</p>
<ol>
<li>
<p><strong>Structural Optimization</strong></p>
<ul>
<li>mAP@0.5 +8.3%</li>
<li>mAP@0.5:0.95 +5.3%</li>
<li>Parameters reduced by 81.4% compared to original YOLOv5s</li>
<li>GFLOPs increased by 53.1%</li>
</ul>
<p>By removing P4 and P5 layers (which together account for 92.1% of model parameters), the model detects directly from shallow features (P2, P3). Omitting unnecessary deep features shifts the model’s focus from macro semantics to micro details.</p>
<p>To avoid degradation due to insufficient parameters, the authors simultaneously increased network depth (0.33→0.67) and width (0.5→0.75), preserving certain abstraction capability.</p>
</li>
<li>
<p><strong>Module Lightweighting</strong></p>
<ul>
<li>
<p>LW_C3:</p>
<ul>
<li>mAP@0.5 +2.2%</li>
<li>mAP@0.5:0.95 +1.9%</li>
<li>GFLOPs reduced by 48.2%</li>
</ul>
</li>
<li>
<p>LW_Downsample:</p>
<ul>
<li>mAP@0.5 +3.9%</li>
<li>mAP@0.5:0.95 +3.0%</li>
<li>GFLOPs reduced by 11.0%</li>
</ul>
</li>
</ul>
<p>Although both modules increased parameters by about <strong>38.5%</strong>, GFLOPs significantly decreased due to dynamic convolution’s ability to enhance expressiveness while compressing static computation.</p>
</li>
<li>
<p><strong>AMSFF</strong></p>
<ul>
<li>mAP@0.5 +3.4%</li>
<li>mAP@0.5:0.95 +2.6%</li>
</ul>
<p>AMSFF addresses the "dialogue imbalance" problem in multi-scale feature fusion by learning spatial adaptive weights, allowing shallow detail and deep semantic features to be reasonably apportioned. This is especially critical for small object detection where semantic signals are weak and fusion errors amplify prediction mistakes.</p>
</li>
</ol>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=comparison-with-other-yolo-models>Comparison with Other YOLO Models<a href=#comparison-with-other-yolo-models class=hash-link aria-label="Direct link to Comparison with Other YOLO Models" title="Direct link to Comparison with Other YOLO Models">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=results src=/en/assets/images/img15-c61c5f21b7298022b30c57a724de63c5.jpg width=1144 height=796 class=img_ev3q></figure></div>
<p>The YOLO series has long been synonymous with object detection, widely recognized for end-to-end, ultra-fast inference. From YOLOv3’s multi-scale prediction and Darknet-53 backbone to YOLOv8’s introduction of gradient flow into feature branches and YOLOv10’s removal of Non-Maximum Suppression (NMS), each generation pursues accuracy and efficiency improvements.</p>
<p>Here, the authors compare with smaller versions of mainstream YOLO models. The results show YOLO-Tiny delivers impressive accuracy despite dramatically reduced parameters and computation.</p>
<p>For mAP@0.5, it surpasses YOLOv3-Tiny, YOLOv6s, YOLOv8s, and YOLOv10s by 23.7%, 10.8%, 8.3%, and 9.1% respectively; mAP@0.5:0.95 improvements are 14.4%, 5.8%, 4.2%, and 4.9%. Meanwhile, it saves 60% to 80% of parameters and 30% to 70% of GFLOPs.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=visualization>Visualization<a href=#visualization class=hash-link aria-label="Direct link to Visualization" title="Direct link to Visualization">​</a></h3>
<p><img decoding=async loading=lazy alt=vis src=/en/assets/images/img16-8cbd7998bbe7749e9219c6700c8821b7.jpg width=4372 height=2502 class=img_ev3q></p>
<p>From left to right: original image, YOLOv5s result, and YOLO-Tiny result.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=conclusion>Conclusion<a href=#conclusion class=hash-link aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>Facing extremely small targets in UAV aerial imagery under limited terminal computation, YOLO-Tiny’s structural adjustments and module designs offer a practical technical approach.</p>
<p>Previous lightweight architectures often force explicit trade-offs between speed and accuracy. In VisDrone-like scenarios, small object features are easily diluted by multiple downsampling layers, causing detection accuracy stagnation.</p>
<p>This work prunes large-object detection layers P5 and P4, refocusing the network on smaller scales P3 and P2, while employing dynamic convolution and AMSFF modules for signal compression and feature fusion. This aims to improve small object recognition without increasing computational burden.</p>
<p>Experimental results confirm this strategy yields significant mAP gains on VisDrone2019 while maintaining advantages in parameters and GFLOPs, demonstrating targeted design for small object structures.</p>
<p>However, given the recent publication, lack of released training modules, and absence of open real-world deployment and community validation, its practical effectiveness and generalizability remain to be further observed.</header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>Last updated<!-- --> on <b><time datetime=2025-06-20T09:54:33.000Z itemprop=dateModified>Jun 20, 2025</time></b> by <b>zephyr-sh</b></span></div></div><section class=ctaSection_iCjC><div class="
        simpleCta_ji_Y
        simple-cta__coffee_YwC8
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>☕ Fuel my writing with a coffee</h3><p class=simple-cta__subtitle_ol86>Your support keeps my AI & full-stack guides coming.<div class=simple-cta__buttonWrapper_jk1Y><img src=/en/img/bmc-logo.svg alt=cta-button class=simple-cta__buttonImg_Q9VV></div></div><div class="ant-row ant-row-stretch cardsSection_wRaP css-mc1tut" style=margin-left:-8px;margin-right:-8px;row-gap:16px><div style=padding-left:8px;padding-right:8px;display:flex class="ant-col ant-col-xs-24 css-mc1tut"><div class="ant-card ant-card-bordered card_gKx9 fadeInUp_n33J hoverTransform_Mozy css-mc1tut" style=flex:1;display:flex;flex-direction:column><div class=ant-card-body><div style=text-align:center;margin-top:1rem><img src=/en/img/icons/all_in.svg alt="AI / Full-Stack / Custom — All In icon" style=width:48px;height:48px></div><span class="ant-tag ant-tag-orange card__tag_PLj3 css-mc1tut">All-in</span><h4 class=card__title_SQBY>AI / Full-Stack / Custom — All In</h4><p class=card__concept_Ak8F>From idea to launch—efficient systems that are future-ready.<div class=card__bulletHeader_b6cf><h5 class=card__bulletTitle_R_wg>All-In Bundle</h5></div><ul class=card__bulletList_SrNN><li class=card__bulletItem_wCRd>Consulting + Dev + Deploy<li class=card__bulletItem_wCRd>Maintenance & upgrades</ul></div></div></div></div><div class="
        simpleCta_ji_Y
        simple-cta__outro_AXbn
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>🚀 Ready for your next project?</h3><p class=simple-cta__subtitle_ol86>Need a tech partner or custom solution? Let's connect.</div></section><div style=margin-top:3rem> </div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/en/papers/object-detection/yolov11/><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>[24.10] YOLOv11</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/en/papers/category/reparameterization><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>Reparameterization (8)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#i-am-a-little-bird class="table-of-contents__link toc-highlight">I Am a Little Bird</a><li><a href=#problem-definition class="table-of-contents__link toc-highlight">Problem Definition</a><li><a href=#solution class="table-of-contents__link toc-highlight">Solution</a><ul><li><a href=#reviewing-yolov5 class="table-of-contents__link toc-highlight">Reviewing YOLOv5</a><li><a href=#module-lightweighting class="table-of-contents__link toc-highlight">Module Lightweighting</a><li><a href=#adaptive-multi-scale-fusion class="table-of-contents__link toc-highlight">Adaptive Multi-Scale Fusion</a><li><a href=#experimental-setup class="table-of-contents__link toc-highlight">Experimental Setup</a></ul><li><a href=#discussion class="table-of-contents__link toc-highlight">Discussion</a><ul><li><a href=#comparative-experiments-on-network-architecture-adjustments class="table-of-contents__link toc-highlight">Comparative Experiments on Network Architecture Adjustments</a><li><a href=#ablation-study class="table-of-contents__link toc-highlight">Ablation Study</a><li><a href=#comparison-with-other-yolo-models class="table-of-contents__link toc-highlight">Comparison with Other YOLO Models</a><li><a href=#visualization class="table-of-contents__link toc-highlight">Visualization</a></ul><li><a href=#conclusion class="table-of-contents__link toc-highlight">Conclusion</a></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/en/docs>Projects</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/papers/intro>Papers</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/blog>Blog</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/terms-of-service>TermsOfUse</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/privacy-policy>Privacy Policy</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/become-an-author>Become an author</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/worklog>Worklog</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>