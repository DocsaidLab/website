<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-face-recognition/frvt-distinguishing-twins/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.4.0">
<title data-rh="true">[22.09] FRVT-Twins | DOCSAID</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://docsaid.org/en/img/docsaid-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://docsaid.org/en/img/docsaid-social-card.jpg"><meta data-rh="true" property="og:url" content="https://docsaid.org/en/papers/face-recognition/frvt-distinguishing-twins/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_hant"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-papers-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-papers-current"><meta data-rh="true" property="og:title" content="[22.09] FRVT-Twins | DOCSAID"><meta data-rh="true" name="description" content="Report on Twin Identification Accuracy"><meta data-rh="true" property="og:description" content="Report on Twin Identification Accuracy"><link data-rh="true" rel="icon" href="/en/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docsaid.org/en/papers/face-recognition/frvt-distinguishing-twins/"><link data-rh="true" rel="alternate" href="https://docsaid.org/papers/face-recognition/frvt-distinguishing-twins/" hreflang="zh-hant"><link data-rh="true" rel="alternate" href="https://docsaid.org/en/papers/face-recognition/frvt-distinguishing-twins/" hreflang="en"><link data-rh="true" rel="alternate" href="https://docsaid.org/papers/face-recognition/frvt-distinguishing-twins/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://S9NC0RYCHF-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/en/blog/rss.xml" title="DOCSAID RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/en/blog/atom.xml" title="DOCSAID Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script>


<link rel="search" type="application/opensearchdescription+xml" title="DOCSAID" href="/en/opensearch.xml">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/en/assets/css/styles.1fe4c5ae.css">
<script src="/en/assets/js/runtime~main.3828f683.js" defer="defer"></script>
<script src="/en/assets/js/main.deb2ed7a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/en/"><div class="navbar__logo"><img src="/en/img/docsaid_logo.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/docsaid_logo_white.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href="/en/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/en/papers/intro">Papers</a><a class="navbar__item navbar__link" href="/en/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link" href="/en/papers/face-recognition/frvt-distinguishing-twins/"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/papers/face-recognition/frvt-distinguishing-twins/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hant">繁體中文</a></li><li><a href="/en/papers/face-recognition/frvt-distinguishing-twins/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li></ul></div><a href="https://github.com/DocsaidLab" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/en/"><img src="/en/img/docsaid_logo.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/docsaid_logo_white.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/intro">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/alexnet/">[12.09] AlexNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/vgg/">[14.09] VGG</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/batchnorm/">[15.02] BatchNorm</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/resnet/">[15.12] ResNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/densenet/">[16.08] DenseNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/resnext/">[16.11] ResNeXt</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/mobilenet-v1/">[17.04] MobileNet-V1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/nasnet/">[17.07] NASNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/shufflenet/">[17.07] ShuffleNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/senet/">[17.09] SENet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/mobilenet-v2/">[18.01] MobileNet-V2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/efficientnet/">[19.05] EfficientNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/mobilenet-v3/">[19.05] MobileNet-V3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/ghostnet/">[19.11] GhostNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/vit/">[20.10] ViT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/deit/">[20.12] DeiT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/repvgg/">[21.01] RepVGG</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/pvt/">[21.02] PVT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/swin-transformer/">[21.03] Swin Transformer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/efficientnet-v2/">[21.04] EfficientNet-V2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/mlp-mixer/">[21.05] MLP-Mixer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/beit/">[21.06] BEiT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/pp-lcnet/">[21.09] PP-LCNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/poolformer/">[21.11] PoolFormer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/convnext/">[22.01] ConvNeXt</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/replknet/">[22.03] RepLKNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/mobileone/">[22.06] MobileOne</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/caformer/">[22.10] CAFormer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/qarepvgg/">[22.12] QARepVGG</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/fastvit/">[23.03] FastViT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/vanillanet/">[23.05] VanillaNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/repvit/">[23.07] RepViT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/mobilenet-v4/">[24.04] MobileNet-V4</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/en/papers/category/face-recognition">Face Recognition</a><button aria-label="Collapse sidebar category &#x27;Face Recognition&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/papers/face-recognition/cosface/">[18.01] CosFace</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/en/papers/face-recognition/frvt-distinguishing-twins/">[22.09] FRVT-Twins</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/papers/face-recognition/tivc/">[23.09] TIVC</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/papers/category/feature-fusion">Feature Fusion</a><button aria-label="Expand sidebar category &#x27;Feature Fusion&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/papers/category/language-model">Language Model</a><button aria-label="Expand sidebar category &#x27;Language Model&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/papers/category/multimodality">Multimodality</a><button aria-label="Expand sidebar category &#x27;Multimodality&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/papers/category/object-detection">Object Detection</a><button aria-label="Expand sidebar category &#x27;Object Detection&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/en/papers/category/face-recognition"><span itemprop="name">Face Recognition</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">[22.09] FRVT-Twins</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>[22.09] FRVT-Twins</h1>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="report-on-twin-identification-accuracy">Report on Twin Identification Accuracy<a class="hash-link" aria-label="Direct link to Report on Twin Identification Accuracy" title="Direct link to Report on Twin Identification Accuracy" href="/en/papers/face-recognition/frvt-distinguishing-twins/#report-on-twin-identification-accuracy">​</a></h2>
<p><a href="https://nvlpubs.nist.gov/nistpubs/ir/2022/NIST.IR.8439.pdf" target="_blank" rel="noopener noreferrer"><strong>FRVT: Face Recognition Verification Accuracy on Distinguishing Twins (NIST.IR.8439)</strong></a></p>
<hr>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>The following content has been compiled by ChatGPT-4 and has been manually reviewed, edited, and supplemented.</p></div></div>
<hr>
<p>This is not a paper but a technical report.</p>
<p>The NIST conducted research on distinguishing twins within the scope of the FRVT (Face Recognition Vendor Test).</p>
<p>This is an intriguing issue because the high similarity between twins can pose significant challenges for facial recognition systems.</p>
<p>In fact, &quot;distinguishing twins&quot; is an exceedingly challenging task for facial recognition systems.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>For more information about NIST, you can refer to <a href="https://docsaid.org/blog/nist-and-frvt/" target="_blank" rel="noopener noreferrer"><strong>NIST &amp; FRVT</strong></a>.</p></div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="introduction">Introduction<a class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" href="/en/papers/face-recognition/frvt-distinguishing-twins/#introduction">​</a></h2>
<p>Facial recognition technology is increasingly used in both public and private sectors for identity verification, transaction authorization, and access control.</p>
<p>Over the past decade, accuracy in the FRVT evaluations has significantly improved, supporting these applications.</p>
<p>Since the COVID-19 pandemic, some algorithms have even been able to recognize individuals wearing masks.</p>
<p>However, despite these advancements, the identification of twins remains problematic.</p>
<p>This report documents the results of the latest algorithms in this regard.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="datasets">Datasets<a class="hash-link" aria-label="Direct link to Datasets" title="Direct link to Datasets" href="/en/papers/face-recognition/frvt-distinguishing-twins/#datasets">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="twins-day-dataset-2010-2018">Twins Day Dataset 2010-2018<a class="hash-link" aria-label="Direct link to Twins Day Dataset 2010-2018" title="Direct link to Twins Day Dataset 2010-2018" href="/en/papers/face-recognition/frvt-distinguishing-twins/#twins-day-dataset-2010-2018">​</a></h3>
<ul>
<li><a href="https://biic.wvu.edu/data-sets/twins-day-dataset-2010-1015" target="_blank" rel="noopener noreferrer"><strong>Download</strong></a></li>
</ul>
<p>This dataset, from West Virginia University&#x27;s Center for Identification Technology Research, includes images from Twins Days from 2010 to 2018.</p>
<p>These collections were conducted under IRB protocols with informed consent from each participant.</p>
<p>The image sizes vary by year:</p>
<ul>
<li>2010: 2848x4288</li>
<li>2011: 3744x5616</li>
<li>2012 to 2018: 3300x4400 and 2400x3200.</li>
</ul>
<p>The images are high-quality frontal portraits, meeting NIST SAP50 specifications (head and shoulder composition) and SAP51 specifications (head composition).</p>
<ul>
<li>
<p><strong>Sample Image: Different Individuals</strong></p>
<p><img decoding="async" loading="lazy" alt="different" src="/en/assets/images/img1-dfa583b2ef01c9ed77b3e35eb46a84e0.jpg" width="1224" height="404" class="img_ev3q"></p>
</li>
<li>
<p><strong>Sample Image: Same Individual</strong></p>
<p><img decoding="async" loading="lazy" alt="same" src="/en/assets/images/img2-bda0f61a05a0592d5668920b7feaaaae.jpg" width="1224" height="484" class="img_ev3q"></p>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="immigration-related-images">Immigration-related Images<a class="hash-link" aria-label="Direct link to Immigration-related Images" title="Direct link to Immigration-related Images" href="/en/papers/face-recognition/frvt-distinguishing-twins/#immigration-related-images">​</a></h3>
<p>This dataset includes real-time captured images, primarily from webcam images and some visa application images.</p>
<p>Webcam images are taken by operators under time constraints, leading to variations in roll, pitch, and yaw angles, with sometimes overexposed faces due to bright backgrounds. The average inter-pupil distance is 38 pixels, not conforming to ISO/IEC 19794-5 full-frontal image types.</p>
<p>Some subjects also have visa application images captured in interview environments using dedicated equipment and lighting. These images conform to ISO/IEC 19794-5 standards with a capture size of 300x300 and nearly frontal poses.</p>
<ul>
<li>
<p><strong>Example Image</strong></p>
<p><img decoding="async" loading="lazy" alt="img3" src="/en/assets/images/img3-a3286ebe3d17a383b5e6b0513f88aa58.jpg" width="1020" height="402" class="img_ev3q"></p>
</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="dataset-limitations">Dataset Limitations<a class="hash-link" aria-label="Direct link to Dataset Limitations" title="Direct link to Dataset Limitations" href="/en/papers/face-recognition/frvt-distinguishing-twins/#dataset-limitations">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="small-population">Small Population<a class="hash-link" aria-label="Direct link to Small Population" title="Direct link to Small Population" href="/en/papers/face-recognition/frvt-distinguishing-twins/#small-population">​</a></h3>
<ul>
<li>The Twins Days dataset is relatively small compared to other NIST FRVT 1:1 datasets, containing over 5900 images.</li>
<li>Due to inconsistent or missing metadata, many images and twins were excluded, including some incorrect matches (e.g., A and B are twins, but B and C are also recorded as twins).</li>
<li>Most of the immigration-related dataset images were retained, including 152 pairs of twins and 2,478 images.</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="variations-in-identification-codes">Variations in Identification Codes<a class="hash-link" aria-label="Direct link to Variations in Identification Codes" title="Direct link to Variations in Identification Codes" href="/en/papers/face-recognition/frvt-distinguishing-twins/#variations-in-identification-codes">​</a></h3>
<ul>
<li>Twins Days usually assigns the same identification code to the same participants each year, but sometimes a new code is issued.</li>
<li>This results in some high-threshold non-twin comparisons that are actually correct matches being incorrectly marked as errors.</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="incorrectmissing-metadata">Incorrect/Missing Metadata<a class="hash-link" aria-label="Direct link to Incorrect/Missing Metadata" title="Direct link to Incorrect/Missing Metadata" href="/en/papers/face-recognition/frvt-distinguishing-twins/#incorrectmissing-metadata">​</a></h3>
<ul>
<li>Metadata for Twins Days collections from 2011 to 2016 is partially or entirely missing.</li>
<li>Incorrect metadata, such as twin type or birthdate mismatches, led to the exclusion of many images.</li>
<li>The immigration-related image dataset lacks information to distinguish fraternal from identical twins.</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="imbalanced-data">Imbalanced Data<a class="hash-link" aria-label="Direct link to Imbalanced Data" title="Direct link to Imbalanced Data" href="/en/papers/face-recognition/frvt-distinguishing-twins/#imbalanced-data">​</a></h3>
<ul>
<li>Twins Days images have an uneven distribution of twin types: 2.8% fraternal opposite-sex, 6.7% fraternal same-sex, and 90.5% identical twins.</li>
<li>Age group distribution is also uneven, with most images belonging to the 20-39 age range, and very few from the 40-59 and 60+ age groups.</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="racial-imbalance">Racial Imbalance<a class="hash-link" aria-label="Direct link to Racial Imbalance" title="Direct link to Racial Imbalance" href="/en/papers/face-recognition/frvt-distinguishing-twins/#racial-imbalance">​</a></h3>
<ul>
<li>The Twins Days dataset includes racial identity: 85% White, 10% African American, and 5% others.</li>
<li>The number of racial groups is too numerous for meaningful analysis based on race.</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="algorithm-performance-report">Algorithm Performance Report<a class="hash-link" aria-label="Direct link to Algorithm Performance Report" title="Direct link to Algorithm Performance Report" href="/en/papers/face-recognition/frvt-distinguishing-twins/#algorithm-performance-report">​</a></h2>
<p>With FRVT being open to global participation, many algorithms are involved.</p>
<p>This report documents the results of 478 algorithms submitted to the FRVT 1:1 test from 2019 to mid-February 2022.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="evaluation-metrics">Evaluation Metrics<a class="hash-link" aria-label="Direct link to Evaluation Metrics" title="Direct link to Evaluation Metrics" href="/en/papers/face-recognition/frvt-distinguishing-twins/#evaluation-metrics">​</a></h3>
<ul>
<li>
<p><strong>False Match Rate (FMR)</strong></p>
<p>The False Match Rate (FMR) is the proportion of incorrect matches among all attempts, where faces of different people are wrongly recognized as the same person.</p>
<p>This is a crucial performance metric in facial recognition systems, especially in high-security applications like banking or airport security.</p>
<p>Setting FMR = 0.0001 means only one incorrect match in every 10,000 attempts.</p>
</li>
<li>
<p><strong>False Non-Match Rate (FNMR)</strong></p>
<p>The False Non-Match Rate (FNMR) is the proportion of incorrect non-matches among all attempts, where faces of the same person are wrongly recognized as different people.</p>
<p>This is also an important performance metric, particularly in applications concerning user convenience and experience.</p>
</li>
<li>
<p><strong>FNMR @ FMR = 0.0001</strong></p>
<p>When you see &quot;FNMR @ FMR = 0.0001,&quot; it means observing the False Non-Match Rate (FNMR) when the False Match Rate (FMR) is set to 0.0001.</p>
<p>This measures how well the facial recognition system performs under extremely low false match conditions, ensuring effective recognition of the same person under stringent false match settings.</p>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="identical-twins">Identical Twins<a class="hash-link" aria-label="Direct link to Identical Twins" title="Direct link to Identical Twins" href="/en/papers/face-recognition/frvt-distinguishing-twins/#identical-twins">​</a></h3>
<ul>
<li>
<p>For the Twins Days data, the FMR for identical twins usually exceeds 0.99, indicating these twins are almost always incorrectly recognized as each other by algorithms.</p>
</li>
<li>
<p>FMRs below 0.99 generally result from two situations:</p>
<ul>
<li><strong>System Errors</strong>: Algorithms with high Failure to Enroll (FTE) rates failing to extract features from many or all images.</li>
<li><strong>Poor Algorithms</strong>: Systems with high False Non-Match Rates (FNMR), producing low scores, meaning the algorithm sees everything as different people.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="algorithms-capable-of-identifying-identical-twins">Algorithms Capable of Identifying Identical Twins<a class="hash-link" aria-label="Direct link to Algorithms Capable of Identifying Identical Twins" title="Direct link to Algorithms Capable of Identifying Identical Twins" href="/en/papers/face-recognition/frvt-distinguishing-twins/#algorithms-capable-of-identifying-identical-twins">​</a></h3>
<p>Some algorithms show high accuracy in recognizing identical twins, not always mistakenly identifying identical twins as the same person.</p>
<p>These algorithms include:</p>
<ul>
<li><strong>Algorithms</strong>: aigen-001, aigen-002, beyneai-000, glory-004, mobai-000, and iqface-001.</li>
<li><strong>Performance Metrics</strong>:<!-- -->
<ul>
<li><strong>FNMR (False Non-Match Rate)</strong>: ≤ 0.02</li>
<li><strong>FTE (Failure to Enroll Rate)</strong>: ≤ 0.02</li>
<li><strong>FMR (False Match Rate)</strong>: ≤ 0.7</li>
</ul>
</li>
</ul>
<p>Specifically, aigen-002 is noteworthy, with an FMR of 0.475 for identical twins, meaning this algorithm correctly distinguishes twins about half the time. While this FMR is much higher than the ideal standard (FMR = 0.0001), it is significantly lower than the 0.98 and 0.99 FMRs of most other algorithms, indicating better performance in distinguishing identical twins.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="comprehensive-analysis">Comprehensive Analysis<a class="hash-link" aria-label="Direct link to Comprehensive Analysis" title="Direct link to Comprehensive Analysis" href="/en/papers/face-recognition/frvt-distinguishing-twins/#comprehensive-analysis">​</a></h2>
<p><img decoding="async" loading="lazy" alt="result" src="/en/assets/images/img4-1adafa7b621a164d28b0c32ddb10b599.jpg" width="1224" height="628" class="img_ev3q"></p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="score-distributions">Score Distributions<a class="hash-link" aria-label="Direct link to Score Distributions" title="Direct link to Score Distributions" href="/en/papers/face-recognition/frvt-distinguishing-twins/#score-distributions">​</a></h3>
<p>The figure above shows score distributions for two accurate and representative algorithms across different photo types.</p>
<p>The highest scores come from &quot;mated twins,&quot; indicating comparisons between photos of the same individual taken on the same day.</p>
<p>The next highest scores are from &quot;mated mugshot,&quot; ordinary face images used as a control group.</p>
<p>Comparisons between identical twins (labeled &quot;non-mated identical twins&quot;) also receive similarly high scores.</p>
<p>Scores for same-sex fraternal twins (labeled &quot;non-mated fraternal same-sex twins&quot;) are also close to these high scores.</p>
<p>These scores are all above the threshold set in the report, designed to yield a false match rate (FMR=0.0001) for a set of unrelated face pairs.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>Although twin scores are slightly lower than same individual scores, these results are still far above the model threshold, highlighting the challenge of distinguishing twins from non-twins for algorithms.</p><p>Additionally, the report notes that simply raising the threshold to reduce false matches between twins is ineffective, as the issue lies in the fundamental design of the algorithms, not the threshold settings.</p></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="age-effects">Age Effects<a class="hash-link" aria-label="Direct link to Age Effects" title="Direct link to Age Effects" href="/en/papers/face-recognition/frvt-distinguishing-twins/#age-effects">​</a></h3>
<p>Analyzing different age groups of twins, both datasets show a decrease in similarity scores among unrelated twins in older age groups.</p>
<p><strong>Twins Days dataset</strong> categorizes twins into four age groups: 0-19, 20-39, 40-59, and 60+. Analysis shows lower similarity scores in the oldest age group for both fraternal and identical same-sex twins compared to the youngest age group.</p>
<p><strong>Immigration-related dataset</strong> includes all same-sex twins, divided into three age groups: 0-19, 20-39, and 40-59. In this dataset, similarity scores for the 0-19 age group are closer to those of related twins, while scores for the 40-59 age group are significantly lower, diverging more from related twins&#x27; scores.</p>
<p>Despite lower similarity scores in older age groups, these scores still exceed the algorithm thresholds, indicating algorithms still consider unrelated twins as matches. Therefore, algorithms fail to effectively distinguish between fraternal and identical twins.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>The failure to distinguish fraternal twins is particularly surprising, as fraternal twins have different genomes and should exhibit different facial features. This suggests algorithms may also struggle to accurately differentiate siblings with close birth years.</p></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="longitudinal-effects">Longitudinal Effects<a class="hash-link" aria-label="Direct link to Longitudinal Effects" title="Direct link to Longitudinal Effects" href="/en/papers/face-recognition/frvt-distinguishing-twins/#longitudinal-effects">​</a></h3>
<p>Despite improvements in facial recognition algorithm performance, the ability to distinguish same-sex twins has not improved. Algorithms that perform well on general face data do not show improved or decreased performance when comparing same-sex fraternal and identical twins in the Twins Days dataset.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="conclusion">Conclusion<a class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" href="/en/papers/face-recognition/frvt-distinguishing-twins/#conclusion">​</a></h2>
<p>Considering NIST&#x27;s Face Recognition Vendor Test (FRVT) performance and its ability to distinguish between identical and fraternal twins, current facial recognition technology faces significant challenges, particularly in distinguishing genetically similar identical twins.</p>
<p>Despite lower genetic similarity and potential greater facial differences among fraternal twins, algorithms still struggle to differentiate them, which could lead to catastrophic consequences in high-accuracy-required scenarios.</p>
<p>For future improvements, the report suggests one main point: utilizing higher resolution images to enhance facial recognition system performance.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="using-higher-resolution-images">Using Higher Resolution Images<a class="hash-link" aria-label="Direct link to Using Higher Resolution Images" title="Direct link to Using Higher Resolution Images" href="/en/papers/face-recognition/frvt-distinguishing-twins/#using-higher-resolution-images">​</a></h3>
<p>Higher resolution images can provide more detailed facial skin features, such as skin texture and pore patterns, which are unique to individuals and could help distinguish even genetically identical twins.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>The effectiveness of this approach has been demonstrated by a 2004 patented algorithm (US Patent: US7369685B2).</p><p>This algorithm accurately distinguished twins by analyzing skin texture visible in high-resolution images.</p></div></div>
<p>To achieve this, future research and development should focus on improving the quality of image capture, ensuring an inter-pupil distance of at least 120 pixels, and conforming to ISO standard frontal portraits for skin texture-based analysis. Additionally, mainstream neural network models often downsample input images to improve processing speed, but this loses crucial detail information, affecting recognition accuracy (especially in highly similar cases like twins).</p>
<p>These are the directions for future improvements, and we hope to see better performance in recognizing twins in future FRVTs.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2024-08-08T14:04:01.000Z" itemprop="dateModified">Aug 8, 2024</time></b> by <b>zephyr-sh</b></span></div></div></footer><div style="margin-top:3rem"> </div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/en/papers/face-recognition/cosface/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">[18.01] CosFace</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/en/papers/face-recognition/tivc/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">[23.09] TIVC</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#report-on-twin-identification-accuracy">Report on Twin Identification Accuracy</a></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#introduction">Introduction</a></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#datasets">Datasets</a><ul><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#twins-day-dataset-2010-2018">Twins Day Dataset 2010-2018</a></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#immigration-related-images">Immigration-related Images</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#dataset-limitations">Dataset Limitations</a><ul><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#small-population">Small Population</a></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#variations-in-identification-codes">Variations in Identification Codes</a></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#incorrectmissing-metadata">Incorrect/Missing Metadata</a></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#imbalanced-data">Imbalanced Data</a></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#racial-imbalance">Racial Imbalance</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#algorithm-performance-report">Algorithm Performance Report</a><ul><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#evaluation-metrics">Evaluation Metrics</a></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#identical-twins">Identical Twins</a></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#algorithms-capable-of-identifying-identical-twins">Algorithms Capable of Identifying Identical Twins</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#comprehensive-analysis">Comprehensive Analysis</a><ul><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#score-distributions">Score Distributions</a></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#age-effects">Age Effects</a></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#longitudinal-effects">Longitudinal Effects</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#conclusion">Conclusion</a><ul><li><a class="table-of-contents__link toc-highlight" href="/en/papers/face-recognition/frvt-distinguishing-twins/#using-higher-resolution-images">Using Higher Resolution Images</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class="footer__links"><a class="footer__link-item" href="/en/docs">Docs</a><span class="footer__link-separator">·</span><a class="footer__link-item" href="/en/papers/intro">Papers</a><span class="footer__link-separator">·</span><a class="footer__link-item" href="/en/blog">Blog</a><span class="footer__link-separator">·</span><a href="https://github.com/DocsaidLab" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><span class="footer__link-separator">·</span><a href="https://docsaid.org/blog/terms-of-service" target="_blank" rel="noopener noreferrer" class="footer__link-item">TermsOfUse<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><span class="footer__link-separator">·</span><a href="https://docsaid.org/blog/privacy-policy" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy Policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 DOCSAID.</div></div></div></footer></div>
</body>
</html>