<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-text-recognition/dan/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.8.0"><title data-rh=true>[19.12] DAN | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/en/papers/text-recognition/dan/><meta data-rh=true property=og:locale content=en><meta data-rh=true property=og:locale:alternate content=zh_hant><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[19.12] DAN | DOCSAID"><meta data-rh=true name=description content="They Cannot Be Together"><meta data-rh=true property=og:description content="They Cannot Be Together"><link data-rh=true rel=icon href=/en/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/en/papers/text-recognition/dan/><link data-rh=true rel=alternate href=https://docsaid.org/papers/text-recognition/dan/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/text-recognition/dan/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/text-recognition/dan/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/text-recognition/dan/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://docsaid.org/en/papers/category/text-recognition-20","name":"Text Recognition (20)","position":1},{"@type":"ListItem","item":"https://docsaid.org/en/papers/text-recognition/dan/","name":"[19.12] DAN","position":2}]}</script><link rel=alternate type=application/rss+xml href=/en/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/en/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/en/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/en/assets/css/styles.e52f1f88.css><script src=/en/assets/js/runtime~main.72575d1c.js defer></script><script src=/en/assets/js/main.ddf711aa.js defer></script><body class=navigation-with-keyboard><svg xmlns=http://www.w3.org/2000/svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light",e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/en/><div class=navbar__logo><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/en/docs/>Projects</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/en/papers/intro>Papers</a><a class="navbar__item navbar__link" href=/en/blog>Blog</a><a class="navbar__item navbar__link" href=/en/playground/intro>Playground</a><a class="navbar__item navbar__link" href=/en/services>Services</a><a class="navbar__item navbar__link" href=/en/aboutus>About Us</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>English</a><ul class=dropdown__menu><li><a href=/papers/text-recognition/dan/ target=_self rel="noopener noreferrer" class=dropdown__link lang=zh-hant>繁體中文</a><li><a href=/en/papers/text-recognition/dan/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=en>English</a><li><a href=/ja/papers/text-recognition/dan/ target=_self rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-5uvb3z ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/en/><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>Paper Notes</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="Expand sidebar category 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/contrastive-learning-13>Contrastive Learning (13)</a><button aria-label="Expand sidebar category 'Contrastive Learning (13)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/deepseek-5>DeepSeek (5)</a><button aria-label="Expand sidebar category 'DeepSeek (5)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-anti-spoofing-40>Face Anti-Spoofing (40)</a><button aria-label="Expand sidebar category 'Face Anti-Spoofing (40)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="Expand sidebar category 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/feature-fusion-10>Feature Fusion (10)</a><button aria-label="Expand sidebar category 'Feature Fusion (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/image-generation-1>Image Generation (1)</a><button aria-label="Expand sidebar category 'Image Generation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="Expand sidebar category 'Lightweight (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/mamba-4>Mamba (4)</a><button aria-label="Expand sidebar category 'Mamba (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/model-tuning-8>Model Tuning (8)</a><button aria-label="Expand sidebar category 'Model Tuning (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/multimodality-24>Multimodality (24)</a><button aria-label="Expand sidebar category 'Multimodality (24)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/normalization-1>Normalization (1)</a><button aria-label="Expand sidebar category 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/object-detection-8>Object Detection (8)</a><button aria-label="Expand sidebar category 'Object Detection (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/reparameterization-8>Reparameterization (8)</a><button aria-label="Expand sidebar category 'Reparameterization (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="Expand sidebar category 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-detection-14>Text Detection (14)</a><button aria-label="Expand sidebar category 'Text Detection (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/en/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="Collapse sidebar category 'Text Recognition (20)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/crnn/>[15.07] CRNN</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/rare/>[16.03] RARE</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/cafcn/>[18.09] CA-FCN</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/sar/>[18.11] SAR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/wwwstr/>[19.04] WWWSTR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/satrn/>[19.10] SATRN</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/en/papers/text-recognition/dan/>[19.12] DAN</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/seed/>[20.05] SEED</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/abinet/>[21.03] ABINet</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/vitstr/>[21.05] ViTSTR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/yatr/>[21.07] YATR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/trocr/>[21.09] TrOCR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/safl/>[22.01] SAFL</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/siga/>[22.03] SIGA</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/parseq/>[22.07] PARSeq</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/clip4str/>[23.05] CLIP4STR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/diffusionstr/>[23.06] DiffusionSTR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/union14m/>[23.07] Union14M</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/dtrocr/>[23.08] DTrOCR</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/text-recognition/ocr-scaling-law/>[24.01] OCR Scaling Law</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="Expand sidebar category 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/transformers-17>Transformers (17)</a><button aria-label="Expand sidebar category 'Transformers (17)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/vision-transformers-12>Vision Transformers (12)</a><button aria-label="Expand sidebar category 'Vision Transformers (12)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>All Notes: 215 entries</a></ul></nav><button type=button title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/en/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li class=breadcrumbs__item><a class=breadcrumbs__link href=/en/papers/category/text-recognition-20><span>Text Recognition (20)</span></a><li class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>[19.12] DAN</span></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>[19.12] DAN</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt="Z. Yuan" class=docAuthorImg_vlJe><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Z. Yuan</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a href=https://www.linkedin.com/in/ze-yuan-sh7/ target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 448 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=they-cannot-be-together>They Cannot Be Together<a href=#they-cannot-be-together class=hash-link aria-label="Direct link to They Cannot Be Together" title="Direct link to They Cannot Be Together">​</a></h2>
<p><a href=https://arxiv.org/abs/1912.10205 target=_blank rel="noopener noreferrer"><strong>Decoupled Attention Network for Text Recognition</strong></a></p>
<hr>
<p>In earlier research, CTC algorithms were commonly used as decoders for final output, but in recent years, attention-based architectures have become more popular. The reason is simple: they often perform better!</p>
<p>Adding an attention mechanism has now become standard practice in the field of Scene Text Recognition (STR).</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=problem-definition>Problem Definition<a href=#problem-definition class=hash-link aria-label="Direct link to Problem Definition" title="Direct link to Problem Definition">​</a></h2>
<p>But here lies the issue: <strong>attention maps are often inaccurate.</strong></p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=attention-loss>Attention Loss<a href=#attention-loss class=hash-link aria-label="Direct link to Attention Loss" title="Direct link to Attention Loss">​</a></h3>
<p>The authors reviewed past research and observed that the design of attention maps is based on <strong>feature maps</strong> rather than on textual content.</p>
<p>What does that mean? Let's take a look at the image below:</p>
<p><img decoding=async loading=lazy alt=mismatch src=/en/assets/images/img1-3ac08dd65f21b6c66c9a062261f454be.jpg width=1486 height=646 class=img_ev3q></p>
<p>In the image above, the top row shows the original input image, while the bottom row displays the corresponding attention map.</p>
<p>These attention maps are structured with sequential information: the top-left corner corresponds to the first character, and the bottom-right corner corresponds to the last one. A good attention distribution should have a diagonal pattern, indicating that each character is correctly aligned with a specific region.</p>
<p>In the example, however, the distribution deviates from the diagonal and shifts to another region. This suggests that the model fails to focus on the correct textual information at certain time steps.</p>
<p>According to the authors, this problem arises because attention maps are based on feature maps. As shown in the example, the word "ly" might appear visually similar across different sequence points. As a result, the model becomes "confused" and loses alignment.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=coupled-output>Coupled Output<a href=#coupled-output class=hash-link aria-label="Direct link to Coupled Output" title="Direct link to Coupled Output">​</a></h3>
<p>We need attention maps to align text and images effectively. However, if <strong>alignment and decoding operations are coupled</strong>, the alignment will inevitably be influenced by the decoder's output. This coupling introduces <strong>error accumulation and propagation</strong> during training.</p>
<hr>
<p>Thus, the authors argue: <strong>alignment and decoding should not be coupled.</strong></p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=solution>Solution<a href=#solution class=hash-link aria-label="Direct link to Solution" title="Direct link to Solution">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=model-architecture>Model Architecture<a href=#model-architecture class=hash-link aria-label="Direct link to Model Architecture" title="Direct link to Model Architecture">​</a></h3>
<p><img decoding=async loading=lazy alt="model architecture" src=/en/assets/images/img2-da7c2a2318c0fab3ed7312c521c6e8be.jpg width=1478 height=420 class=img_ev3q></p>
<p>To address the coupling issue, the authors propose the <strong>Decoupled Attention Network (DAN)</strong> architecture, as shown above. The key idea is to design a separate branch dedicated solely to learning attention and predicting the character positions.</p>
<p>Let’s break down the architecture step-by-step:</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=feature-extraction>Feature Extraction<a href=#feature-extraction class=hash-link aria-label="Direct link to Feature Extraction" title="Direct link to Feature Extraction">​</a></h3>
<p>The first step involves <strong>a CNN network to extract features</strong> from the input image, which is a common approach.</p>
<p>The authors use a CNN-based feature encoder similar to previous works, instead of a standard ResNet. The configuration is as follows:</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=cnn src=/en/assets/images/img4-d8b0c8dcc2e7f95d9f0d557afc96be71.jpg width=1022 height=492 class=img_ev3q></figure></div>
<p>The input image <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> (of size <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow><annotation encoding=application/x-tex>H \times W</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7667em;vertical-align:-0.0833em></span><span class="mord mathnormal" style=margin-right:0.08125em>H</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>W</span></span></span></span>) is encoded into a feature map <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>F</mi></mrow><annotation encoding=application/x-tex>F</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>F</span></span></span></span>:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>F</mi><mo>=</mo><mi>F</mi><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo><mo separator=true>,</mo><mspace width=1em /><mi>F</mi><mo>∈</mo><msup><mi mathvariant=double-struck>R</mi><mrow><mi>C</mi><mo>×</mo><mi>H</mi><mi mathvariant=normal>/</mi><msub><mi>r</mi><mi>h</mi></msub><mo>×</mo><mi>W</mi><mi mathvariant=normal>/</mi><msub><mi>r</mi><mi>w</mi></msub></mrow></msup></mrow><annotation encoding=application/x-tex>F = F(x), \quad F \in \mathbb{R}^{C \times H/r_h \times W/r_w}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>F</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>F</span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span><span class=mpunct>,</span><span class=mspace style=margin-right:1em></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.13889em>F</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.938em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.938em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.07153em>C</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style=margin-right:0.08125em>H</span><span class="mord mtight">/</span><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>r</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3448em><span style=top:-2.3488em;margin-left:-0.0278em;margin-right:0.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1512em><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style=margin-right:0.13889em>W</span><span class="mord mtight">/</span><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>r</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1645em><span style=top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02691em>w</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.143em><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
<p>where <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>C</mi></mrow><annotation encoding=application/x-tex>C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>C</span></span></span></span> is the number of output channels, and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>r</mi><mi>h</mi></msub></mrow><annotation encoding=application/x-tex>r_h</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>r</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>r</mi><mi>w</mi></msub></mrow><annotation encoding=application/x-tex>r_w</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>r</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02691em>w</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> are down-sampling factors for height and width, respectively.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=alignment-module>Alignment Module<a href=#alignment-module class=hash-link aria-label="Direct link to Alignment Module" title="Direct link to Alignment Module">​</a></h3>
<p><img decoding=async loading=lazy alt=align src=/en/assets/images/img9-6a8ced748af6a562ecb83792f6498b22.jpg width=1478 height=540 class=img_ev3q></p>
<p>The <strong>Convolutional Alignment Module (CAM)</strong> processes the feature maps.</p>
<p>CAM collects <strong>multi-scale visual features</strong> from the feature encoder and processes them through a series of down-sampling convolution layers. Inspired by Fully Convolutional Networks (FCNs), CAM computes attention for each channel, with each channel representing a class-specific heatmap.</p>
<p>CAM contains <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>L</mi></mrow><annotation encoding=application/x-tex>L</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">L</span></span></span></span> layers. During the <strong>upsampling stage</strong> (using transposed convolutions), the output features from each layer are added to the corresponding down-sampled feature map. Finally, <strong>sigmoid activation and per-channel normalization</strong> generate the attention map:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>A</mi><mo>=</mo><mo stretchy=false>{</mo><mi>α</mi><mo>∗</mo><mn>1</mn><mo separator=true>,</mo><msub><mi>α</mi><mn>2</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><mi>α</mi><mo>∗</mo><mtext>maxT</mtext><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>A = \{ \alpha*1, \alpha_2, \dots, \alpha*{\text{maxT}} \}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">A</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class="mord mathnormal" style=margin-right:0.0037em>α</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.8389em;vertical-align:-0.1944em></span><span class=mord>1</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.0037em>α</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.0037em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.0037em>α</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord text"><span class=mord>maxT</span></span></span><span class=mclose>}</span></span></span></span></span>
<p>where <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mtext>maxT</mtext></mrow><annotation encoding=application/x-tex>\text{maxT}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord text"><span class=mord>maxT</span></span></span></span></span> is the maximum sequence length for decoding. Each attention map has the size <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>H</mi><mi mathvariant=normal>/</mi><msub><mi>r</mi><mi>h</mi></msub><mo>×</mo><mi>W</mi><mi mathvariant=normal>/</mi><msub><mi>r</mi><mi>w</mi></msub></mrow><annotation encoding=application/x-tex>H/r_h \times W/r_w</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.08125em>H</span><span class=mord>/</span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>r</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>W</span><span class=mord>/</span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>r</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02691em>w</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>.</p>
<p>At each time step, the decoder receives a feature map aligned with the corresponding textual region in the original image.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>If this step seems confusing, think of it as <strong>Feature Pyramid Networks (FPN)</strong>:<ul>
<li><a href=/en/papers/feature-fusion/fpn/><strong>[16.12] FPN: Pyramid Architecture</strong></a></li>
</ul></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=decoupled-decoder-module>Decoupled Decoder Module<a href=#decoupled-decoder-module class=hash-link aria-label="Direct link to Decoupled Decoder Module" title="Direct link to Decoupled Decoder Module">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=decoder src=/en/assets/images/img3-4b36aa15d958675e8e7410b1baf254c5.jpg width=900 height=912 class=img_ev3q></figure></div>
<p>Unlike conventional attention decoders, which handle both alignment and recognition, DAN’s <strong>decoder only handles recognition</strong>.</p>
<p>Given the encoded feature map and the attention map, the decoder computes the context vector <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>c</mi><mi>t</mi></msub></mrow><annotation encoding=application/x-tex>c_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">c</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> at time step <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>t</mi></mrow><annotation encoding=application/x-tex>t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6151em></span><span class="mord mathnormal">t</span></span></span></span>:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>c</mi><mo>∗</mo><mi>t</mi><mo>=</mo><mo>∑</mo><mo>∗</mo><msup><mrow><mi>x</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>W</mi><mi mathvariant=normal>/</mi><mi>r</mi><mo>∗</mo><mi>w</mi></mrow></msup><mo>∑</mo><mo>∗</mo><msup><mrow><mi>y</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>H</mi><mi mathvariant=normal>/</mi><mi>r</mi><mo>∗</mo><mi>h</mi></mrow></msup><mi>α</mi><mo>∗</mo><mrow><mi>t</mi><mo separator=true>,</mo><mi>x</mi><mo separator=true>,</mo><mi>y</mi></mrow><mi>F</mi><mi mathvariant=normal>_</mi><mrow><mi>x</mi><mo separator=true>,</mo><mi>y</mi></mrow></mrow><annotation encoding=application/x-tex>c*t = \sum*{x=1}^{W/r*w} \sum*{y=1}^{H/r*h} \alpha*{t, x, y} F\_{x, y}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4653em></span><span class="mord mathnormal">c</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6151em></span><span class="mord mathnormal">t</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.6em;vertical-align:-0.55em></span><span class="mop op-symbol large-op" style=position:relative;top:0em>∑</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>∗</span><span class=mord><span class=mord><span class="mord mathnormal">x</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span><span class=mord>1</span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.938em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>W</span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style=margin-right:0.02778em>r</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight" style=margin-right:0.02691em>w</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-symbol large-op" style=position:relative;top:0em>∑</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>∗</span><span class=mord><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span><span class=mord>1</span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.938em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.08125em>H</span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style=margin-right:0.02778em>r</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight">h</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:0.0037em>α</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.9933em;vertical-align:-0.31em></span><span class=mord><span class="mord mathnormal">t</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">x</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span></span><span class="mord mathnormal" style=margin-right:0.13889em>F</span><span class=mord style=margin-right:0.02778em>_</span><span class=mord><span class="mord mathnormal">x</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span></span></span></span></span></span>
<p>The classifier generates the output <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub></mrow><annotation encoding=application/x-tex>y_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> at each time step:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>=</mo><mi>w</mi><msub><mi>h</mi><mi>t</mi></msub><mo>+</mo><mi>b</mi></mrow><annotation encoding=application/x-tex>y_t = w h_t + b</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class="mord mathnormal" style=margin-right:0.02691em>w</span><span class=mord><span class="mord mathnormal">h</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">b</span></span></span></span></span>
<p>where <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding=application/x-tex>h_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">h</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> is the hidden state of a GRU:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>h</mi><mo>∗</mo><mi>t</mi><mo>=</mo><mtext>GRU</mtext><mo stretchy=false>(</mo><mo stretchy=false>(</mo><mi>e</mi><mo>∗</mo><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><mo separator=true>,</mo><mi>c</mi><mo>∗</mo><mi>t</mi><mo stretchy=false>)</mo><mo separator=true>,</mo><mi>h</mi><mo>∗</mo><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>h*t = \text{GRU}((e*{t-1}, c*t), h*{t-1})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">h</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6151em></span><span class="mord mathnormal">t</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>GRU</span></span><span class=mopen>((</span><span class="mord mathnormal">e</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.8389em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal">t</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span><span class=mord>1</span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">c</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">t</span><span class=mclose>)</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">h</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal">t</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span><span class=mord>1</span></span><span class=mclose>)</span></span></span></span></span>
<p><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>e</mi><mi>t</mi></msub></mrow><annotation encoding=application/x-tex>e_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">e</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> is the embedding of the previous output <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub></mrow><annotation encoding=application/x-tex>y_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>.</p>
<p>The loss function for DAN is:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mtext>Loss</mtext><mo>=</mo><mo>−</mo><mo>∑</mo><mi mathvariant=normal>_</mi><msup><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msup><mi>log</mi><mo>⁡</mo><mi>P</mi><mo stretchy=false>(</mo><msub><mi>g</mi><mi>t</mi></msub><mi mathvariant=normal>∣</mi><mi>I</mi><mo separator=true>,</mo><mi>θ</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\text{Loss} = -\sum\_{t=1}^{T} \log P(g_t | I, \theta)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord text"><span class=mord>Loss</span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.6em;vertical-align:-0.55em></span><span class=mord>−</span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-symbol large-op" style=position:relative;top:0em>∑</span><span class=mspace style=margin-right:0.1667em></span><span class=mord style=margin-right:0.02778em>_</span><span class=mord><span class=mord><span class="mord mathnormal">t</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span><span class=mord>1</span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8913em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>∣</span><span class="mord mathnormal" style=margin-right:0.07847em>I</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.02778em>θ</span><span class=mclose>)</span></span></span></span></span>
<p>where <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>θ</mi></mrow><annotation encoding=application/x-tex>\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.02778em>θ</span></span></span></span> represents all trainable parameters, and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding=application/x-tex>g_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.03588em>g</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.2806em><span style=top:-2.55em;margin-left:-0.0359em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> is the ground truth label at step <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>t</mi></mrow><annotation encoding=application/x-tex>t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6151em></span><span class="mord mathnormal">t</span></span></span></span>.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p><strong>Flexibility of CAM in 1D/2D Modes</strong><p>By adjusting the down-sampling factor <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>r</mi><mi>h</mi></msub></mrow><annotation encoding=application/x-tex>r_h</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>r</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> and CAM stride, DAN can switch between <strong>1D</strong> and <strong>2D recognition modes</strong>:<ul>
<li><strong>1D Recognition</strong>: When <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>H</mi><mi mathvariant=normal>/</mi><msub><mi>r</mi><mi>h</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>H/r_h = 1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.08125em>H</span><span class=mord>/</span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>r</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span></span></span></span>, suitable for long, structured text.</li>
<li><strong>2D Recognition</strong>: When <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>H</mi><mi mathvariant=normal>/</mi><msub><mi>r</mi><mi>h</mi></msub><mo>></mo><mn>1</mn></mrow><annotation encoding=application/x-tex>H/r_h > 1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.08125em>H</span><span class=mord>/</span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>r</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>></span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span></span></span></span>, ideal for irregular text.</li>
</ul></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=handwriting-recognition-training-strategy>Handwriting Recognition Training Strategy<a href=#handwriting-recognition-training-strategy class=hash-link aria-label="Direct link to Handwriting Recognition Training Strategy" title="Direct link to Handwriting Recognition Training Strategy">​</a></h3>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=datasets>Datasets<a href=#datasets class=hash-link aria-label="Direct link to Datasets" title="Direct link to Datasets">​</a></h4>
<ol>
<li>
<p><strong>IAM Dataset</strong>:</p>
<ul>
<li>English handwritten text based on the LOB corpus.</li>
<li>Training: 747 documents (6,482 lines).</li>
<li>Validation: 116 documents (976 lines).</li>
<li>Test: 336 documents (2,915 lines).</li>
</ul>
</li>
<li>
<p><strong>RIMES Dataset</strong>:</p>
<ul>
<li>Handwritten French letters.</li>
<li>Training: 1,500 paragraphs (11,333 lines).</li>
<li>Test: 100 paragraphs (778 lines).</li>
</ul>
</li>
</ol>
<p>Training is conducted on <strong>full-line text</strong>, with <strong>data augmentation</strong> applied. The input image height is normalized to 192, with width adjusted proportionally (up to 2048).</p>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mi>T</mi></mrow><annotation encoding=application/x-tex>maxT</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style=margin-right:0.13889em>T</span></span></span></span> is set to 150 to cover the longest text lines.</li>
<li>CAM layers (except the last) have 128 channels.</li>
</ul>
<p>The model uses <strong>Character Error Rate (CER%)</strong> and <strong>Word Error Rate (WER%)</strong> for evaluation:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mtext>CER / WER</mtext><mo>=</mo><mfrac><mtext>Edit Distance</mtext><mtext>Total Characters / Words</mtext></mfrac></mrow><annotation encoding=application/x-tex>\text{CER / WER} = \frac{\text{Edit Distance}}{\text{Total Characters / Words}}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord text"><span class=mord>CER / WER</span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.3074em;vertical-align:-0.936em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3714em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord text"><span class=mord>Total Characters / Words</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class="mord text"><span class=mord>Edit Distance</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.936em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>No language models or dictionaries are used to maintain the purity of the model’s performance.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=scene-text-recognition-training-strategy>Scene Text Recognition Training Strategy<a href=#scene-text-recognition-training-strategy class=hash-link aria-label="Direct link to Scene Text Recognition Training Strategy" title="Direct link to Scene Text Recognition Training Strategy">​</a></h3>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=datasets-1>Datasets<a href=#datasets-1 class=hash-link aria-label="Direct link to Datasets" title="Direct link to Datasets">​</a></h4>
<ol>
<li>
<p><strong>Regular Scene Text</strong>:</p>
<ul>
<li><strong>IIIT5K-Words</strong>: 3,000 cropped word images.</li>
<li><strong>Street View Text (SVT)</strong>: 647 word images.</li>
<li><strong>ICDAR 2003 (IC03)</strong>: 867 word images.</li>
<li><strong>ICDAR 2013 (IC13)</strong>: 1,015 word images.</li>
</ul>
</li>
<li>
<p><strong>Irregular Scene Text</strong>:</p>
<ul>
<li><strong>SVT-Perspective (SVT-P)</strong>: 639 perspective images.</li>
<li><strong>CUTE80</strong>: 288 curved-text images.</li>
<li><strong>ICDAR 2015 (IC15)</strong>: 2,077 blurred and multi-oriented images.</li>
</ul>
</li>
</ol>
<p>Training data includes <strong>SynthText and Synth90k</strong> datasets. Input image size is scaled to height 32, with width adjusted proportionally (up to 128). Other settings include:</p>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mi>T</mi><mo>=</mo><mn>25</mn></mrow><annotation encoding=application/x-tex>maxT = 25</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style=margin-right:0.13889em>T</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>25</span></span></span></span> (maximum sequence length).</li>
<li>CAM depth <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>L</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding=application/x-tex>L = 8</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">L</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>8</span></span></span></span> with 64 channels per layer (except the last).</li>
<li><strong>Bidirectional decoder</strong> used for final predictions.</li>
<li><strong>ADADELTA</strong> optimizer with an initial learning rate of 1.0, reduced to 0.1 after the third epoch.</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=discussion>Discussion<a href=#discussion class=hash-link aria-label="Direct link to Discussion" title="Direct link to Discussion">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=handwritten-text-recognition-performance>Handwritten Text Recognition Performance<a href=#handwritten-text-recognition-performance class=hash-link aria-label="Direct link to Handwritten Text Recognition Performance" title="Direct link to Handwritten Text Recognition Performance">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=performance src=/en/assets/images/img5-2668afca3f5b2e5df995629923d93148.jpg width=1024 height=560 class=img_ev3q></figure></div>
<ul>
<li>
<p><strong>IAM Dataset</strong>:</p>
<ul>
<li><strong>DAN outperforms</strong> previous state-of-the-art (SOTA) models in <strong>CER</strong>, with an improvement of <strong>1.5%</strong>.</li>
<li><strong>WER</strong>: Although Bhunia et al. (2019) perform better in WER, their model requires cropped single-word images, whereas <strong>DAN</strong> can recognize entire lines of text, offering greater flexibility in real-world applications.</li>
</ul>
</li>
<li>
<p><strong>RIMES Dataset</strong>:</p>
<ul>
<li><strong>CER</strong>: DAN lags behind the SOTA by <strong>0.2%</strong>.</li>
<li><strong>WER</strong>: DAN achieves a <strong>3.7% reduction in errors</strong> (a relative error reduction of 29%) compared to the SOTA.</li>
<li>The significant improvement in WER shows that DAN exhibits <strong>stronger semantic learning abilities</strong>, which is particularly helpful for recognizing longer text sequences.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=ablation-study>Ablation Study<a href=#ablation-study class=hash-link aria-label="Direct link to Ablation Study" title="Direct link to Ablation Study">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=ablation src=/en/assets/images/img10-d56e997f37e49227f5df9e1e159b9dc3.jpg width=852 height=268 class=img_ev3q></figure></div>
<p>According to the results, varying the <strong>output length</strong> does not significantly affect performance, and the computational resources required for the additional channels are negligible. As long as the set output length exceeds the actual text length, DAN’s performance remains stable.</p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=ablation src=/en/assets/images/img11-3af74d64799c71d3dc1a2964cb4bffef.jpg width=940 height=452 class=img_ev3q></figure></div>
<p>As the depth <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>L</mi></mrow><annotation encoding=application/x-tex>L</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">L</span></span></span></span> decreases, DAN’s performance <strong>drops significantly</strong>, indicating that CAM requires sufficient depth to achieve good alignment. To correctly align a character, CAM's receptive field must be large enough to cover the character and its neighboring regions.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=alignment-error-analysis>Alignment Error Analysis<a href=#alignment-error-analysis class=hash-link aria-label="Direct link to Alignment Error Analysis" title="Direct link to Alignment Error Analysis">​</a></h3>
<div align=center><figure style=width:85%><p><img decoding=async loading=lazy alt="error analysis" src=/en/assets/images/img12-d7a4b86f297d73e460bef146f27b54f0.jpg width=1064 height=428 class=img_ev3q></figure></div>
<p>The authors track <strong>attention centers</strong>, identifying the region with the highest attention score. If the current attention center shifts left compared to the previous one, it is recorded as a misalignment. The test samples are divided into five groups based on text length: [0, 30), [30, 40), [40, 50), [50, 60), and [60, 70), with each group containing over 100 samples. The total misalignment data is summed for each group, and the <strong>average misalignment per image (MM/img)</strong> is calculated.</p>
<p>Analysis shows that the improvement in CER is almost directly related to the reduction of misalignment, indicating that DAN’s performance improvement is due to <strong>reducing misalignment errors</strong>.</p>
<p>The following image demonstrates how DAN resolves misalignment errors. The top row shows the input image, the middle row shows the alignment results using traditional attention, and the bottom row shows the results using DAN.</p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt="error analysis" src=/en/assets/images/img6-c4fb9048b29bd05532ccbd96d261e29e.jpg width=1344 height=866 class=img_ev3q></figure></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=recognition-error-analysis>Recognition Error Analysis<a href=#recognition-error-analysis class=hash-link aria-label="Direct link to Recognition Error Analysis" title="Direct link to Recognition Error Analysis">​</a></h3>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt="error analysis" src=/en/assets/images/img7-229463cbc7d951e51d44f7be415a3554.jpg width=896 height=1080 class=img_ev3q></figure></div>
<p>The authors present several <strong>error cases</strong> for DAN, as shown above:</p>
<ol>
<li><strong>(a)</strong>: The character “e” is incorrectly recognized as “p” due to the handwriting style, which makes it difficult to distinguish between the two. Even for humans, it is challenging without context.</li>
<li><strong>(b)</strong>: The recognizer skips a space between two words due to their proximity.</li>
<li><strong>(c)</strong>: Some noise in the texture is misinterpreted as text by DAN.</li>
</ol>
<p>Despite these mistakes, DAN demonstrates <strong>stronger robustness</strong> compared to traditional attention mechanisms. In the presence of noise, traditional attention often produces unpredictable errors because alignment is disrupted, whereas DAN maintains stable alignment, even when generating additional output.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=scene-text-recognition-performance>Scene Text Recognition Performance<a href=#scene-text-recognition-performance class=hash-link aria-label="Direct link to Scene Text Recognition Performance" title="Direct link to Scene Text Recognition Performance">​</a></h3>
<p><img decoding=async loading=lazy alt=performance src=/en/assets/images/img8-475eb29ca6445e26632c9c8bca6fde63.jpg width=1224 height=532 class=img_ev3q></p>
<ul>
<li>
<p><strong>Regular Scene Text Recognition</strong>:</p>
<ul>
<li>DAN achieves <strong>new SOTA performance</strong> on <strong>IIIT5K</strong> and <strong>IC03</strong>.</li>
<li>On <strong>SVT</strong> and <strong>IC13</strong>, DAN’s performance is comparable to the SOTA models, with minor differences.</li>
<li><strong>DAN-1D</strong> performs better on IC03 and IC13, as the images in these datasets are relatively <strong>clean and regular</strong>.</li>
</ul>
</li>
<li>
<p><strong>Irregular Scene Text Recognition</strong>:</p>
<ul>
<li><strong>DAN-2D</strong> achieves SOTA performance on <strong>SVT-P</strong> and <strong>CUTE80</strong>, performing best among 2D models.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=robustness-study>Robustness Study<a href=#robustness-study class=hash-link aria-label="Direct link to Robustness Study" title="Direct link to Robustness Study">​</a></h3>
<p><img decoding=async loading=lazy alt=robustness src=/en/assets/images/img13-b078c174087001a9982b97e95c61cd92.jpg width=1880 height=232 class=img_ev3q></p>
<p>The authors conducted perturbation tests on <strong>IIIT5K</strong> and <strong>IC13</strong> datasets, comparing DAN with <strong>CA-FCN</strong>.</p>
<p>The perturbation strategies used are as follows:</p>
<ol>
<li><strong>IIIT-p</strong>: Padding 10% of the image height and width vertically and horizontally.</li>
<li><strong>IIIT-r-p</strong>:<!-- -->
<ul>
<li>Randomly enlarging the four corners of the image (up to 20%).</li>
<li>Padding the edges to create a quadrilateral, then re-aligning it back into a rectangular image.</li>
</ul>
</li>
<li><strong>IC13-ex</strong>: Expanding the text bounding box by 10% before cropping.</li>
<li><strong>IC13-r-ex</strong>: Randomly enlarging the bounding box (up to 20%) and cropping it into a rectangular image.</li>
</ol>
<p>The results show that <strong>DAN is generally more robust</strong> than CA-FCN in most scenarios, proving DAN’s stability.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=conclusion>Conclusion<a href=#conclusion class=hash-link aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>From the outset, the authors clearly identified the limitations of traditional attention mechanisms and proposed a <strong>decoupled solution</strong>.</p>
<p>DAN proves to be highly valuable in text recognition tasks, offering <strong>flexibility, robustness, and strong performance</strong>. Its ability to reduce alignment errors makes it an effective tool. While there is still room for improvement in handling noisy and visually similar text, its simple architecture and dictionary-free design make DAN a strong candidate for various text recognition applications.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>For cases where the decoding length <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mi>T</mi></mrow><annotation encoding=application/x-tex>maxT</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style=margin-right:0.13889em>T</span></span></span></span> is particularly long, decoupled attention maps may consume significant resources, raising concerns about model efficiency. However, in most real-world scenarios, <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mi>T</mi></mrow><annotation encoding=application/x-tex>maxT</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style=margin-right:0.13889em>T</span></span></span></span> tends to be short, so this is not a major issue.</div></div></header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>Last updated<!-- --> on <b><time datetime=2025-02-11T02:49:16.000Z itemprop=dateModified>Feb 11, 2025</time></b> by <b>zephyr-sh</b></span></div></div><section class=ctaSection_iCjC><div class="
        simpleCta_ji_Y
        simple-cta__coffee_YwC8
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>☕ Fuel my writing with a coffee</h3><p class=simple-cta__subtitle_ol86>Your support keeps my AI & full-stack guides coming.<div class=simple-cta__buttonWrapper_jk1Y><img src=/en/img/bmc-logo.svg alt=cta-button class=simple-cta__buttonImg_Q9VV></div></div><div class="ant-row ant-row-stretch cardsSection_wRaP css-5uvb3z" style=margin-left:-8px;margin-right:-8px;row-gap:16px><div style=padding-left:8px;padding-right:8px;display:flex class="ant-col ant-col-xs-24 css-5uvb3z"><div class="ant-card ant-card-bordered card_gKx9 fadeInUp_n33J hoverTransform_Mozy css-5uvb3z" style=flex:1;display:flex;flex-direction:column><div class=ant-card-body><div style=text-align:center;margin-top:1rem><img src=/en/img/icons/all_in.svg alt="AI / Full-Stack / Custom — All In icon" style=width:48px;height:48px></div><span class="ant-tag ant-tag-orange card__tag_PLj3 css-5uvb3z">All-in</span><h4 class=card__title_SQBY>AI / Full-Stack / Custom — All In</h4><p class=card__concept_Ak8F>From idea to launch—efficient systems that are future-ready.<div class=card__bulletHeader_b6cf><h5 class=card__bulletTitle_R_wg>All-In Bundle</h5></div><ul class=card__bulletList_SrNN><li class=card__bulletItem_wCRd>Consulting + Dev + Deploy<li class=card__bulletItem_wCRd>Maintenance & upgrades</ul></div></div></div></div><div class="
        simpleCta_ji_Y
        simple-cta__outro_AXbn
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>🚀 Ready for your next project?</h3><p class=simple-cta__subtitle_ol86>Need a tech partner or custom solution? Let's connect.</div></section><div style=margin-top:3rem> </div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/en/papers/text-recognition/satrn/><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>[19.10] SATRN</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/en/papers/text-recognition/seed/><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>[20.05] SEED</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#they-cannot-be-together class="table-of-contents__link toc-highlight">They Cannot Be Together</a><li><a href=#problem-definition class="table-of-contents__link toc-highlight">Problem Definition</a><ul><li><a href=#attention-loss class="table-of-contents__link toc-highlight">Attention Loss</a><li><a href=#coupled-output class="table-of-contents__link toc-highlight">Coupled Output</a></ul><li><a href=#solution class="table-of-contents__link toc-highlight">Solution</a><ul><li><a href=#model-architecture class="table-of-contents__link toc-highlight">Model Architecture</a><li><a href=#feature-extraction class="table-of-contents__link toc-highlight">Feature Extraction</a><li><a href=#alignment-module class="table-of-contents__link toc-highlight">Alignment Module</a><li><a href=#decoupled-decoder-module class="table-of-contents__link toc-highlight">Decoupled Decoder Module</a><li><a href=#handwriting-recognition-training-strategy class="table-of-contents__link toc-highlight">Handwriting Recognition Training Strategy</a><li><a href=#scene-text-recognition-training-strategy class="table-of-contents__link toc-highlight">Scene Text Recognition Training Strategy</a></ul><li><a href=#discussion class="table-of-contents__link toc-highlight">Discussion</a><ul><li><a href=#handwritten-text-recognition-performance class="table-of-contents__link toc-highlight">Handwritten Text Recognition Performance</a><li><a href=#ablation-study class="table-of-contents__link toc-highlight">Ablation Study</a><li><a href=#alignment-error-analysis class="table-of-contents__link toc-highlight">Alignment Error Analysis</a><li><a href=#recognition-error-analysis class="table-of-contents__link toc-highlight">Recognition Error Analysis</a><li><a href=#scene-text-recognition-performance class="table-of-contents__link toc-highlight">Scene Text Recognition Performance</a><li><a href=#robustness-study class="table-of-contents__link toc-highlight">Robustness Study</a></ul><li><a href=#conclusion class="table-of-contents__link toc-highlight">Conclusion</a></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/en/docs>Projects</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/papers/intro>Papers</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/blog>Blog</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/terms-of-service>TermsOfUse</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/privacy-policy>Privacy Policy</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/become-an-author>Become an author</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/worklog>Worklog</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>