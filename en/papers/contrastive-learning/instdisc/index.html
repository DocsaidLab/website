<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-contrastive-learning/instdisc/index" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.7.0"><title data-rh=true>[18.05] InstDisc | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/en/img/docsaid-social-card.jpg><meta data-rh=true property=og:url content=https://docsaid.org/en/papers/contrastive-learning/instdisc/><meta data-rh=true property=og:locale content=en><meta data-rh=true property=og:locale:alternate content=zh_hant><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-papers-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-papers-current><meta data-rh=true property=og:title content="[18.05] InstDisc | DOCSAID"><meta data-rh=true name=description content="More is better"><meta data-rh=true property=og:description content="More is better"><link data-rh=true rel=icon href=/en/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/en/papers/contrastive-learning/instdisc/><link data-rh=true rel=alternate href=https://docsaid.org/papers/contrastive-learning/instdisc/ hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/papers/contrastive-learning/instdisc/ hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/papers/contrastive-learning/instdisc/ hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/papers/contrastive-learning/instdisc/ hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><link rel=alternate type=application/rss+xml href=/en/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/en/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/en/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/en/assets/css/styles.8b5c2e41.css><script src=/en/assets/js/runtime~main.a356dea4.js defer></script><script src=/en/assets/js/main.d2f6a1f6.js defer></script><body class=navigation-with-keyboard><script>!function(){var t,e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t=null!==e?e:"light",document.documentElement.setAttribute("data-theme",t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><link rel=preload as=image href=/en/img/docsaid_logo.png><link rel=preload as=image href=/en/img/docsaid_logo_white.png><link rel=preload as=image href=https://github.com/zephyr-sh.png><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/en/><div class=navbar__logo><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/en/docs/>Projects</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/en/papers/intro>Papers</a><a class="navbar__item navbar__link" href=/en/blog>Blog</a><a class="navbar__item navbar__link" href=/en/playground/intro>Playground</a><a class="navbar__item navbar__link" href=/en/aboutus>About Us</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>English</a><ul class=dropdown__menu><li><a href=/papers/contrastive-learning/instdisc/ target=_self rel="noopener noreferrer" class=dropdown__link lang=zh-hant>繁體中文</a><li><a href=/en/papers/contrastive-learning/instdisc/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=en>English</a><li><a href=/ja/papers/contrastive-learning/instdisc/ target=_self rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-7ny38l ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex=-1 class=sidebarLogo_isFc href=/en/><img src=/en/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/en/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>Paper Notes</a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/classic-cnns-11>Classic CNNs (11)</a><button aria-label="Expand sidebar category 'Classic CNNs (11)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/en/papers/category/contrastive-learning-13>Contrastive Learning (13)</a><button aria-label="Collapse sidebar category 'Contrastive Learning (13)'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul style=display:block;overflow:visible;height:auto class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/examplar-cnn/>[14.06] Exemplar CNN</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/en/papers/contrastive-learning/instdisc/>[18.05] InstDisc</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/cpc/>[18.07] CPC</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/invaspread/>[19.04] InvaSpread</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/moco-v1/>[19.11] MoCo v1</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/simclr-v1/>[20.02] SimCLR v1</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/moco-v2/>[20.03] MoCo v2</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/byol/>[20.06] BYOL</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/simclr-v2/>[20.06] SimCLR v2</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/swav/>[20.06] SwAV</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/simsiam/>[20.11] SimSiam</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/dino/>[21.04] DINO</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/en/papers/contrastive-learning/moco-v3/>[21.04] MoCo v3</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/deepseek-5>DeepSeek (5)</a><button aria-label="Expand sidebar category 'DeepSeek (5)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-anti-spoofing-1>Face Anti-Spoofing (1)</a><button aria-label="Expand sidebar category 'Face Anti-Spoofing (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/face-recognition-4>Face Recognition (4)</a><button aria-label="Expand sidebar category 'Face Recognition (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/feature-fusion-10>Feature Fusion (10)</a><button aria-label="Expand sidebar category 'Feature Fusion (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/lightweight-10>Lightweight (10)</a><button aria-label="Expand sidebar category 'Lightweight (10)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/mamba-4>Mamba (4)</a><button aria-label="Expand sidebar category 'Mamba (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/model-tuning-8>Model Tuning (8)</a><button aria-label="Expand sidebar category 'Model Tuning (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/multimodality-24>Multimodality (24)</a><button aria-label="Expand sidebar category 'Multimodality (24)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/normalization-1>Normalization (1)</a><button aria-label="Expand sidebar category 'Normalization (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/object-detection-8>Object Detection (8)</a><button aria-label="Expand sidebar category 'Object Detection (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/reparameterization-8>Reparameterization (8)</a><button aria-label="Expand sidebar category 'Reparameterization (8)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/segmentation-1>Segmentation (1)</a><button aria-label="Expand sidebar category 'Segmentation (1)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-detection-14>Text Detection (14)</a><button aria-label="Expand sidebar category 'Text Detection (14)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-recognition-20>Text Recognition (20)</a><button aria-label="Expand sidebar category 'Text Recognition (20)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/text-spotting-4>Text Spotting (4)</a><button aria-label="Expand sidebar category 'Text Spotting (4)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/transformers-17>Transformers (17)</a><button aria-label="Expand sidebar category 'Transformers (17)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/en/papers/category/vision-transformers-12>Vision Transformers (12)</a><button aria-label="Expand sidebar category 'Vision Transformers (12)'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/en/papers/intro>All Notes: 175 entries</a></ul></nav><button type=button title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/en/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><a class=breadcrumbs__link itemprop=item href=/en/papers/category/contrastive-learning-13><span itemprop=name>Contrastive Learning (13)</span></a><meta itemprop=position content=1><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link itemprop=name>[18.05] InstDisc</span><meta itemprop=position content=2></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>[18.05] InstDisc</h1><div class="undefined margin-bottom--md"><div class=docAuthor_y7l7><img src=https://github.com/zephyr-sh.png alt="Z. Yuan" class=docAuthorImg_vlJe><div><div class=docAuthorName_aSh4><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer">Z. Yuan</a></div><div class=docAuthorTitle_Yp5_>Dosaid maintainer, Full-Stack AI Engineer</div><div class=docAuthorSocials_M3ba><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 496 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a href=https://www.linkedin.com/in/ze-yuan-sh7/ target=_blank rel="noopener noreferrer" class=docAuthorSocialLink_trj9><svg stroke=currentColor fill=currentColor stroke-width=0 viewBox="0 0 448 512" height=20 width=20 xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=more-is-better>More is better<a href=#more-is-better class=hash-link aria-label="Direct link to More is better" title="Direct link to More is better">​</a></h2>
<p><a href=https://arxiv.org/abs/1805.01978 target=_blank rel="noopener noreferrer"><strong>Unsupervised Feature Learning via Non-Parametric Instance Discrimination</strong></a></p>
<hr>
<p>Seizing a break in development, I quickly dive into some papers related to contrastive learning.</p>
<p>Although I’ve already listened to the master class before, reading through it myself feels more solid.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>info</div><div class=admonitionContent_BuS1><p>Here’s a recommended master class on contrastive learning: <a href="https://www.youtube.com/watch?v=iIczStGLkss" target=_blank rel="noopener noreferrer"><strong>Contrastive Learning Paper Overview [Paper Reading]</strong></a><p>The duration is about 90 minutes, covering the basic concepts of contrastive learning, its development history, detailed readings of related papers, and analyses. After watching, you'll have improved for the next 10 years. (?)</div></div>
<p>Before the concept of contrastive learning became popular, metric learning had already been widely used in the industry. The most well-known application is face recognition, with no exceptions.</p>
<p>The core of metric learning lies in learning feature representations <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>F</mi></mrow><annotation encoding=application/x-tex>F</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>F</span></span></span></span>, which establish a measure between samples <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>y</mi></mrow><annotation encoding=application/x-tex>y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span></span></span></span>:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>d</mi><mi>F</mi></msub><mo stretchy=false>(</mo><mi>x</mi><mo separator=true>,</mo><mi>y</mi><mo stretchy=false>)</mo><mo>=</mo><mi mathvariant=normal>∥</mi><mi>F</mi><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo><mo>−</mo><mi>F</mi><mo stretchy=false>(</mo><mi>y</mi><mo stretchy=false>)</mo><mi mathvariant=normal>∥</mi></mrow><annotation encoding=application/x-tex>d_F(x, y)=\|F(x)-F(y)\|</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal">d</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>F</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>∥</span><span class="mord mathnormal" style=margin-right:0.13889em>F</span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>F</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.03588em>y</span><span class=mclose>)</span><span class=mord>∥</span></span></span></span></span>
<p>Once the model is trained, it can only make inferences based on the features it has learned, without the use of a linear classifier.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>For classic papers on metric learning, refer to:<ul>
<li><a href=/en/papers/face-recognition/arcface/><strong>[18.01] ArcFace: Additive Angular Margin Loss</strong></a></li>
<li><a href=/en/papers/face-recognition/cosface/><strong>[18.01] CosFace: Large Margin Cosine Loss</strong></a></li>
</ul><p>During the research process, it was found that normalization—projecting feature vectors uniformly onto a hypersphere—is a key step that can improve model performance.</div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=defining-the-problem>Defining the Problem<a href=#defining-the-problem class=hash-link aria-label="Direct link to Defining the Problem" title="Direct link to Defining the Problem">​</a></h2>
<p>However, what metric learning discusses is "class-level" learning, meaning we must know which class each image belongs to in order to perform metric learning.</p>
<p>Metric learning is inherently supervised learning, but in real-world applications, we typically only have large amounts of "unlabeled" data, making it difficult to apply metric learning in such scenarios.</p>
<p>Thus, researchers have come up with various solutions:</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=generative-models>Generative Models<a href=#generative-models class=hash-link aria-label="Direct link to Generative Models" title="Direct link to Generative Models">​</a></h3>
<p>The concept of generative models is also quite appealing. By building an encoder and decoder, it transforms an image into a hidden feature representation and then reconstructs the image from that representation. Common models include Autoencoders, GANs, VAEs, etc.</p>
<p>The advantage is that no labels are required; as long as images are available, training can begin. However, the downside is the high computational cost. As the resolution of the reconstructed image increases, the computational load grows exponentially.</p>
<p>Moreover, generative models rely on the distribution of data, making them less generalizable, and in some cases, they may even experience model collapse.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=self-supervised-structural-learning>Self-Supervised Structural Learning<a href=#self-supervised-structural-learning class=hash-link aria-label="Direct link to Self-Supervised Structural Learning" title="Direct link to Self-Supervised Structural Learning">​</a></h3>
<p>Self-supervised learning leverages the internal structure of the data to create a prediction task and then trains the model.</p>
<p>Let’s look at some interesting examples:</p>
<ul>
<li>
<p><strong>Context Prediction</strong></p>
<ul>
<li>
<p><a href=https://arxiv.org/abs/1505.05192 target=_blank rel="noopener noreferrer"><strong>[15.05] Unsupervised Visual Representation Learning by Context Prediction</strong></a></p>
<div align=center><figure style=width:60%><p><img decoding=async loading=lazy alt=example src=/en/assets/images/img01-dc1570baedf0c65199bceab3cd28f6ab.jpg width=700 height=508 class=img_ev3q></figure></div>
</li>
</ul>
</li>
<li>
<p><strong>Color Restoration of Grayscale Images</strong></p>
<ul>
<li>
<p><a href=https://arxiv.org/abs/1603.08511 target=_blank rel="noopener noreferrer"><strong>[16.03] Colorful Image Colorization</strong></a></p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=example src=/en/assets/images/img02-e0f712970e17b7cdc6fc51f13479d917.jpg width=1224 height=520 class=img_ev3q></figure></div>
</li>
</ul>
</li>
<li>
<p><strong>Jigsaw Puzzle Solving Task</strong></p>
<ul>
<li>
<p><a href=https://arxiv.org/abs/1603.09246 target=_blank rel="noopener noreferrer"><strong>[16.03] Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles</strong></a></p>
<div align=center><figure style=width:80%><p><img decoding=async loading=lazy alt=example src=/en/assets/images/img03-d21f5de1606d0177eb32ef47594cba8e.jpg width=1658 height=550 class=img_ev3q></figure></div>
</li>
</ul>
</li>
<li>
<p><strong>Filling In Missing Parts of an Image</strong></p>
<ul>
<li>
<p><a href=https://arxiv.org/abs/1604.07379 target=_blank rel="noopener noreferrer"><strong>[16.04] Context Encoders: Feature Learning by Inpainting</strong></a></p>
<div align=center><figure style=width:50%><p><img decoding=async loading=lazy alt=example src=/en/assets/images/img04-22cd5d2f470cde5ad7d909b6840b5d63.jpg width=656 height=748 class=img_ev3q></figure></div>
</li>
</ul>
</li>
<li>
<p><strong>Counting Objects</strong></p>
<ul>
<li>
<p><a href=https://arxiv.org/abs/1708.06734 target=_blank rel="noopener noreferrer"><strong>[17.08] Representation Learning by Learning to Count</strong></a></p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=example src=/en/assets/images/img05-9e80185f239afbf9f5face390be244f8.jpg width=964 height=840 class=img_ev3q></figure></div>
</li>
</ul>
</li>
</ul>
<hr>
<p>After seeing so many proxy tasks, they all seem reasonable, but we cannot explain why these tasks help semantic recognition, nor can we determine the best self-supervised task.</p>
<p>Since there’s no consensus, let’s create one. Inspired by metric learning, the authors propose a novel feature learning training method, aiming to work without artificial labels.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=solving-the-problem>Solving the Problem<a href=#solving-the-problem class=hash-link aria-label="Direct link to Solving the Problem" title="Direct link to Solving the Problem">​</a></h2>
<p>To obtain a "good" feature representation, the authors adopt an "instance-level discrimination" strategy: treating each image as an independent "class" and training a classifier to determine whether each image belongs to its own "class."</p>
<p>Let’s take a look at the model architecture.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=model-architecture>Model Architecture<a href=#model-architecture class=hash-link aria-label="Direct link to Model Architecture" title="Direct link to Model Architecture">​</a></h3>
<p><img decoding=async loading=lazy alt=img2 src=/en/assets/images/img2-92503cc3a554614ce700cbaa7e188e6a.jpg width=1224 height=286 class=img_ev3q></p>
<p>As shown in the diagram above, on the left is a deep convolutional neural network labeled "<strong>Backbone CNN</strong>." Its function is to transform the input image <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> (e.g., a 224<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo>×</mo></mrow><annotation encoding=application/x-tex>\times</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6667em;vertical-align:-0.0833em></span><span class=mord>×</span></span></span></span>224 image) into higher-level semantic features. For common CNN networks, this might involve several layers of convolution, batch normalization, pooling, and other operations. The final layer typically outputs a high-dimensional vector, which serves as the "visual feature representation."</p>
<p>The high-level features output from the Backbone CNN are usually still of large dimensionality (e.g., 2048 dimensions). To run efficiently with large datasets, more compressed and abstract feature descriptions are needed, so the authors add a "<strong>Projection Head</strong>" to project the CNN output vector into a <strong>128-dimensional</strong> vector space.</p>
<p>After projection, the 128-dimensional vector is then subjected to <strong>L2 Normalization (<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=normal>∥</mi><mi mathvariant=bold>v</mi><msub><mi mathvariant=normal>∥</mi><mn>2</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>\|\mathbf{v}\|_2 = 1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>∥</span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mord><span class=mord>∥</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span></span></span></span>)</strong>, which means each sample is constrained to unit length. This is especially useful when computing similarity because, at this point, the dot product <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi mathvariant=bold>v</mi><mi>j</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{v}_i^T \mathbf{v}_j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.1274em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-2.4413em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2587em><span></span></span></span></span></span></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span> represents the cosine of the angle between the two vectors on the hypersphere, with values ranging from <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>[</mo><mo>−</mo><mn>1</mn><mo separator=true>,</mo><mn>1</mn><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>[-1, 1]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>[</span><span class=mord>−</span><span class=mord>1</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>1</span><span class=mclose>]</span></span></span></span>. This makes the calculation more intuitive and stable.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=the-problem-with-traditional-classifiers>The Problem with Traditional Classifiers<a href=#the-problem-with-traditional-classifiers class=hash-link aria-label="Direct link to The Problem with Traditional Classifiers" title="Direct link to The Problem with Traditional Classifiers">​</a></h3>
<p>In traditional Softmax classification models, each class <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>j</mi></mrow><annotation encoding=application/x-tex>j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.854em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.05724em>j</span></span></span></span> corresponds to a weight vector <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>w</mi><mi>j</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{w}_j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7305em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>. Suppose we have <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> images (equivalent to <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> "classes"), with corresponding weight vectors <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>w</mi><mn>1</mn></msub><mo separator=true>,</mo><msub><mi mathvariant=bold>w</mi><mn>2</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mi mathvariant=bold>w</mi><mi>n</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{w}_1, \mathbf{w}_2, \dots, \mathbf{w}_n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6389em;vertical-align:-0.1944em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>. For a given image <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span>, the feature vector produced by the neural network is <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=bold>v</mi><mo>=</mo><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\mathbf{v} = f_\theta(x)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4444em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span></span></span></span>. The conditional probability of the image being classified as the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>-th image (i.e., the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>-th "class") can be written as:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>P</mi><mo stretchy=false>(</mo><mi>i</mi><mo>∣</mo><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo><mtext>  </mtext><mo>=</mo><mtext>  </mtext><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy=false>(</mo><msubsup><mi mathvariant=bold>w</mi><mi>i</mi><mi>T</mi></msubsup><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>exp</mi><mo>⁡</mo><mo stretchy=false>(</mo><msubsup><mi mathvariant=bold>w</mi><mi>j</mi><mi>T</mi></msubsup><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo></mrow></mfrac></mrow><annotation encoding=application/x-tex>P(i \mid \mathbf{v}) \;=\; \frac{\exp(\mathbf{w}_i^T \mathbf{v})}{\sum_{j=1}^{n} \exp(\mathbf{w}_j^T \mathbf{v})}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.6673em;vertical-align:-1.1489em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.5183em><span style=top:-2.2869em><span class=pstrut style=height:3em></span><span class=mord><span class=mop><span class="mop op-symbol small-op" style=position:relative;top:0em>∑</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8043em><span style=top:-2.4003em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.2029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.4358em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>exp</span><span class=mopen>(</span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8231em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span><span style=top:-3.0448em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.413em><span></span></span></span></span></span></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mop>exp</span><span class=mopen>(</span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-2.4413em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2587em><span></span></span></span></span></span></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.1489em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>In this equation, <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi mathvariant=bold>w</mi><mi>i</mi><mi>T</mi></msubsup><mi mathvariant=bold>v</mi></mrow><annotation encoding=application/x-tex>\mathbf{w}_i^T \mathbf{v}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.1em;vertical-align:-0.2587em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-2.4413em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2587em><span></span></span></span></span></span></span><span class="mord mathbf" style=margin-right:0.01597em>v</span></span></span></span> is used to measure the alignment between the feature <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=bold>v</mi></mrow><annotation encoding=application/x-tex>\mathbf{v}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4444em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span></span></span></span> and class <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>; the denominator is the sum of the exponentiated values of all class comparisons (from 1 to <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span>), ensuring that the total probability across all classes sums to 1.</p>
<p>In typical classification problems, the number of classes is fixed and not too large, so this parameterized Softmax is commonly used. However, here, since "each image" is treated as a new class, the number of classes can be enormous (tens of thousands, millions, or more). As a result, each class requires an independent weight vector <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>w</mi><mi>j</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{w}_j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7305em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>, which not only requires significant storage space but also results in high computational costs.</p>
<p>Simply put, it becomes too computationally expensive.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=non-parametric-classifier>Non-Parametric Classifier<a href=#non-parametric-classifier class=hash-link aria-label="Direct link to Non-Parametric Classifier" title="Direct link to Non-Parametric Classifier">​</a></h3>
<p>To address the above problem, the authors propose a "non-parametric" approach:</p>
<ul>
<li><strong>Replace the formula's <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>w</mi><mi>j</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{w}_j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7305em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span> with the feature vector <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>v</mi><mi>j</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{v}_j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7305em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span> stored in a memory bank.</strong></li>
</ul>
<p>In other words, the "class weight" for the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>j</mi></mrow><annotation encoding=application/x-tex>j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.854em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.05724em>j</span></span></span></span>-th image is no longer an independent <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>w</mi><mi>j</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{w}_j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7305em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span>, but instead, it directly uses the feature vector <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>v</mi><mi>j</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{v}_j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7305em;vertical-align:-0.2861em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span></span></span></span> of the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>j</mi></mrow><annotation encoding=application/x-tex>j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.854em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.05724em>j</span></span></span></span>-th image itself. Additionally, the authors enforce normalization of these feature vectors to unit vectors (i.e., length 1) for ease of similarity calculation.</p>
<p>Thus, the Softmax formula can be rewritten as:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>P</mi><mo stretchy=false>(</mo><mi>i</mi><mo>∣</mo><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mtext> ⁣</mtext><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>(</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mi>T</mi></msubsup><mi mathvariant=bold>v</mi><mi mathvariant=normal>/</mi><mi>τ</mi><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>exp</mi><mo>⁡</mo><mtext> ⁣</mtext><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>(</mo><msubsup><mi mathvariant=bold>v</mi><mi>j</mi><mi>T</mi></msubsup><mi mathvariant=bold>v</mi><mi mathvariant=normal>/</mi><mi>τ</mi><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>)</mo></mrow></mfrac></mrow><annotation encoding=application/x-tex>P(i \mid \mathbf{v})
= \frac{\exp\!\bigl(\mathbf{v}_i^T \mathbf{v} / \tau\bigr)}{\sum_{j=1}^{n} \exp\!\bigl(\mathbf{v}_j^T \mathbf{v} / \tau\bigr)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.7658em;vertical-align:-1.1758em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.59em><span style=top:-2.26em><span class=pstrut style=height:3em></span><span class=mord><span class=mop><span class="mop op-symbol small-op" style=position:relative;top:0em>∑</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8043em><span style=top:-2.4003em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.2029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.4358em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>exp</span><span class=mspace style=margin-right:-0.1667em></span><span class=mopen><span class="delimsizing size1">(</span></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8231em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span><span style=top:-3.0448em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.413em><span></span></span></span></span></span></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.1132em>τ</span><span class=mclose><span class="delimsizing size1">)</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.74em><span class=pstrut style=height:3em></span><span class=mord><span class=mop>exp</span><span class=mspace style=margin-right:-0.1667em></span><span class=mopen><span class="delimsizing size1">(</span></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-2.4413em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2587em><span></span></span></span></span></span></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.1132em>τ</span><span class=mclose><span class="delimsizing size1">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.1758em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>Here, <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>τ</mi></mrow><annotation encoding=application/x-tex>\tau</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal" style=margin-right:0.1132em>τ</span></span></span></span> is the "temperature parameter," which can adjust the "sharpness" of the Softmax distribution; <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=bold>v</mi></mrow><annotation encoding=application/x-tex>\mathbf{v}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4444em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span></span></span></span> is the feature vector of the current image <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>x</mi></mrow><annotation encoding=application/x-tex>x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">x</span></span></span></span> produced by forward propagation; <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>v</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{v}_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5944em;vertical-align:-0.15em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> is the feature vector of the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>-th image stored in the "memory bank" (also a unit vector), and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mi>T</mi></msubsup><mi mathvariant=bold>v</mi></mrow><annotation encoding=application/x-tex>\mathbf{v}_i^T \mathbf{v}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.1em;vertical-align:-0.2587em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-2.4413em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2587em><span></span></span></span></span></span></span><span class="mord mathbf" style=margin-right:0.01597em>v</span></span></span></span> is the dot product of the two unit vectors, ranging from -1 to 1, which represents their similarity.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>Originally, <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>w</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{w}_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5944em;vertical-align:-0.15em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> is a learnable parameter, serving as the "anchor" for each class. The greater the inner product between the feature and the anchor, the higher the classification probability, making the model more likely to classify the input feature as that class.<p>Here, the authors forgo the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>w</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{w}_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5944em;vertical-align:-0.15em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> and instead directly use the "feature <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>v</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{v}_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5944em;vertical-align:-0.15em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>" of the data itself as the comparison object. This eliminates the need to learn a separate <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>w</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{w}_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5944em;vertical-align:-0.15em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> for each possible image class, helping to reduce computational costs.<p>This leads to the next question: Since the classification anchors are not fixed but rather drift around as training progresses, how can the model ensure their stability?<p>We will discuss this shortly; let’s first continue with the rest of the architecture.</div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=memory-bank>Memory Bank<a href=#memory-bank class=hash-link aria-label="Direct link to Memory Bank" title="Direct link to Memory Bank">​</a></h3>
<p>The training objective for the non-parametric softmax is similar to that of typical classification problems: to maximize the probability of each training image being "correctly identified as itself," or equivalently, to minimize the negative log-likelihood over the entire training set:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>J</mi><mo stretchy=false>(</mo><mi>θ</mi><mo stretchy=false>)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>log</mi><mo>⁡</mo><mi>P</mi><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>(</mo><mi>i</mi><mo>∣</mo><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy=false>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=false>)</mo><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>)</mo></mrow><annotation encoding=application/x-tex>J(\theta)
= - \sum_{i=1}^{n} \log P\bigl(i \mid f_\theta(x_i)\bigr)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.09618em>J</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.02778em>θ</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.9291em;vertical-align:-1.2777em></span><span class=mord>−</span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.6514em><span style=top:-1.8723em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2777em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mopen><span class="delimsizing size1">(</span></span><span class="mord mathnormal">i</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.2em;vertical-align:-0.35em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span><span class=mclose><span class="delimsizing size1">)</span></span></span></span></span></span>
<p>Here, <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy=false>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>f_\theta(x_i)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span> is denoted as <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>f</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{f}_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathbf" style=margin-right:0.10903em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>. When computing <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>P</mi><mo stretchy=false>(</mo><mi>i</mi><mo>∣</mo><msub><mi mathvariant=bold>f</mi><mi>i</mi></msub><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>P(i \mid \mathbf{f}_i)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathbf" style=margin-right:0.10903em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>, theoretically, the features of all images <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>{</mo><msub><mi mathvariant=bold>v</mi><mi>j</mi></msub><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>\{\mathbf{v}_j\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0361em;vertical-align:-0.2861em></span><span class=mopen>{</span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mclose>}</span></span></span></span> are needed. However, if every backpropagation requires passing all images through the neural network, the computational cost would be very high.</p>
<p>Thus, in practice, the authors maintain a "Memory Bank" (<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=bold>V</mi><mo>=</mo><mo stretchy=false>{</mo><msub><mi mathvariant=bold>v</mi><mi>j</mi></msub><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>\mathbf{V} = \{\mathbf{v}_j\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6861em></span><span class="mord mathbf" style=margin-right:0.01597em>V</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.0361em;vertical-align:-0.2861em></span><span class=mopen>{</span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mclose>}</span></span></span></span>) to store the features of all images, and after each training iteration, the corresponding entry for each image in this Memory Bank is updated using the feature <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>f</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{f}_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathbf" style=margin-right:0.10903em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> from the forward pass.</p>
<p>Since each image has a corresponding position in memory, the previous features can be quickly retrieved to reduce computational cost when dealing with large datasets. If the total number of images <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> is large, calculating the denominator <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>exp</mi><mo>⁡</mo><mo stretchy=false>(</mo><msubsup><mi mathvariant=bold>v</mi><mi>j</mi><mi>T</mi></msubsup><mi mathvariant=bold>v</mi><mi mathvariant=normal>/</mi><mi>τ</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\sum_{j=1}^{n} \exp(\mathbf{v}_j^T \mathbf{v} / \tau)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.2771em;vertical-align:-0.4358em></span><span class=mop><span class="mop op-symbol small-op" style=position:relative;top:0em>∑</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8043em><span style=top:-2.4003em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.2029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.4358em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>exp</span><span class=mopen>(</span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-2.4413em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3948em><span></span></span></span></span></span></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.1132em>τ</span><span class=mclose>)</span></span></span></span> would be prohibitively expensive. For every image, this computation would be <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>O</mi><mo stretchy=false>(</mo><mi>n</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>O(n)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.02778em>O</span><span class=mopen>(</span><span class="mord mathnormal">n</span><span class=mclose>)</span></span></span></span>, and when <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> reaches millions or more, it becomes almost unmanageable.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=noise-contrastive-estimation>Noise-Contrastive Estimation<a href=#noise-contrastive-estimation class=hash-link aria-label="Direct link to Noise-Contrastive Estimation" title="Direct link to Noise-Contrastive Estimation">​</a></h3>
<p>The core idea of NCE is:</p>
<ol>
<li><strong>Transform a multi-class classification problem into multiple binary classification problems.</strong></li>
<li>The goal of the binary classification: distinguish between "real data samples" and "noise samples."</li>
</ol>
<p>In the multi-class scenario, each image is treated as a "class." With NCE, for a given image, we only need to distinguish "whether it is this image" versus "not this image (noise)."</p>
<p>The approach is to treat "other images" as noise, or sample negative examples from a noise distribution (<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>n</mi></msub></mrow><annotation encoding=application/x-tex>P_n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>), and let the model learn to differentiate between positive and negative examples.</p>
<p>For example, to calculate the "probability that feature <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=bold>v</mi></mrow><annotation encoding=application/x-tex>\mathbf{v}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4444em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span></span></span></span> comes from the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>-th image," we can write:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>P</mi><mo stretchy=false>(</mo><mi>i</mi><mo>∣</mo><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy=false>(</mo><msup><mi mathvariant=bold>v</mi><mi>T</mi></msup><msub><mi mathvariant=bold>f</mi><mi>i</mi></msub><mi mathvariant=normal>/</mi><mi>τ</mi><mo stretchy=false>)</mo></mrow><msub><mi>Z</mi><mi>i</mi></msub></mfrac></mrow><annotation encoding=application/x-tex>P(i \mid \mathbf{v}) = \frac{\exp(\mathbf{v}^T \mathbf{f}_i/\tau)}{Z_i}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.3543em;vertical-align:-0.836em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.5183em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>Z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mop>exp</span><span class=mopen>(</span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span></span></span></span></span><span class=mord><span class="mord mathbf" style=margin-right:0.10903em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.1132em>τ</span><span class=mclose>)</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.836em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>Where:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>exp</mi><mo>⁡</mo><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>(</mo><msubsup><mi mathvariant=bold>v</mi><mi>j</mi><mi>T</mi></msubsup><msub><mi mathvariant=bold>f</mi><mi>i</mi></msub><mi mathvariant=normal>/</mi><mi>τ</mi><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>)</mo></mrow><annotation encoding=application/x-tex>Z_i = \sum_{j=1}^n \exp\bigl(\mathbf{v}_j^T \mathbf{f}_i/\tau\bigr)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>Z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:3.0652em;vertical-align:-1.4138em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.6514em><span style=top:-1.8723em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.4138em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>exp</span><span class=mopen><span class="delimsizing size1">(</span></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8913em><span style=top:-2.453em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3831em><span></span></span></span></span></span></span><span class=mord><span class="mord mathbf" style=margin-right:0.10903em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.1132em>τ</span><span class=mclose><span class="delimsizing size1">)</span></span></span></span></span></span>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi mathvariant=bold>f</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\mathbf{f}_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8444em;vertical-align:-0.15em></span><span class=mord><span class="mord mathbf" style=margin-right:0.10903em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> is the feature corresponding to the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>-th image (stored in the memory bank), and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=bold>v</mi></mrow><annotation encoding=application/x-tex>\mathbf{v}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4444em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span></span></span></span> is the feature of some other image.</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>Z_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>Z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> is the "normalizing constant" to ensure that the probabilities for all <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span> sum to 1.</li>
<li>If <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> is large, calculating <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>Z_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>Z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> requires traversing all <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo separator=true>,</mo><mn>2</mn><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><mi>n</mi></mrow><annotation encoding=application/x-tex>j = 1, 2, \dots, n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.854em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.05724em>j</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8389em;vertical-align:-0.1944em></span><span class=mord>1</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>2</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">n</span></span></span></span>, which is computationally expensive.</li>
</ul>
<p>The cleverness of NCE is that, in the case of "a large number of possible classes," it does not directly compute the full denominator of the formula. Instead, it separates the "positive sample" corresponding to the "class <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>" and the "negative sample" corresponding to the "noise distribution."</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>In other words: anything that is not like me is a negative sample, so just pick a small batch to compute.</div></div>
<p>Let the noise distribution <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>n</mi></msub></mrow><annotation encoding=application/x-tex>P_n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> be <strong>uniform</strong> (<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>n</mi></msub><mo stretchy=false>(</mo><mi>i</mi><mo stretchy=false>)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac></mrow><annotation encoding=application/x-tex>P_n(i) = \frac{1}{n}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.1901em;vertical-align:-0.345em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8451em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.394em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.345em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>).</p>
<p>The paper introduces a hyperparameter <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi></mrow><annotation encoding=application/x-tex>m</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span></span></span></span>, which represents that "there are <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi></mrow><annotation encoding=application/x-tex>m</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span></span></span></span> times more noise samples than real samples," and then defines a "posterior probability":</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>h</mi><mo stretchy=false>(</mo><mi>i</mi><mo separator=true>,</mo><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo><mo>:</mo><mo>=</mo><mi>P</mi><mo stretchy=false>(</mo><mi>D</mi><mo>=</mo><mn>1</mn><mo>∣</mo><mi>i</mi><mo separator=true>,</mo><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy=false>(</mo><mi>i</mi><mo>∣</mo><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo></mrow><mrow><mi>P</mi><mo stretchy=false>(</mo><mi>i</mi><mo>∣</mo><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo><mo>+</mo><mi>m</mi><msub><mi>P</mi><mi>n</mi></msub><mo stretchy=false>(</mo><mi>i</mi><mo stretchy=false>)</mo></mrow></mfrac></mrow><annotation encoding=application/x-tex>h(i, \mathbf{v}) := P(D=1 \mid i, \mathbf{v})= \frac{P(i \mid \mathbf{v})}{P(i \mid \mathbf{v}) + m P_n(i)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">h</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>:=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.02778em>D</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>1</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.363em;vertical-align:-0.936em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.427em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:0.2778em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span><span class="mord mathnormal">m</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mclose>)</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:0.2778em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.936em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>The meaning of <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>h</mi><mo stretchy=false>(</mo><mo>⋅</mo><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>h(\cdot)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">h</span><span class=mopen>(</span><span class=mord>⋅</span><span class=mclose>)</span></span></span></span> is that, given feature <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=bold>v</mi></mrow><annotation encoding=application/x-tex>\mathbf{v}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4444em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span></span></span></span> and class <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>, it is the probability that "<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=bold>v</mi></mrow><annotation encoding=application/x-tex>\mathbf{v}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4444em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span></span></span></span> comes from the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>-th image (real data), rather than from noise." <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>P</mi><mo stretchy=false>(</mo><mi>i</mi><mo>∣</mo><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>P(i \mid \mathbf{v})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span></span></span></span> is the output of the above formula, and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi><msub><mi>P</mi><mi>n</mi></msub><mo stretchy=false>(</mo><mi>i</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>m P_n(i)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">m</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mclose>)</span></span></span></span> is the relative probability of selecting a noise sample corresponding to class <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>.</p>
<p>The next key point is:</p>
<ol>
<li><strong>Take the negative log-likelihood for positive samples</strong> (positive samples are correctly classified as positive).</li>
<li><strong>Take the negative log-likelihood for negative samples</strong> (negative samples are correctly classified as negative).</li>
</ol>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>It might seem like empty talk, but many people zone out when they see "calculating negative log-likelihood." Actually, it just means: calculate the probabilities for positive and negative samples separately, then add them together.</div></div>
<p>Thus, we have:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>J</mi><mtext>NCE</mtext></msub><mo stretchy=false>(</mo><mi>θ</mi><mo stretchy=false>)</mo><mo>=</mo><mo>−</mo><msub><mi mathvariant=double-struck>E</mi><msub><mi>P</mi><mi>d</mi></msub></msub><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>[</mo><mi>log</mi><mo>⁡</mo><mi>h</mi><mo stretchy=false>(</mo><mi>i</mi><mo separator=true>,</mo><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>]</mo><mtext>  </mtext><mo>−</mo><mtext>  </mtext><mi>m</mi><mtext> </mtext><msub><mi mathvariant=double-struck>E</mi><msub><mi>P</mi><mi>n</mi></msub></msub><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>[</mo><mi>log</mi><mo>⁡</mo><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>(</mo><mn>1</mn><mo>−</mo><mi>h</mi><mo stretchy=false>(</mo><mi>i</mi><mo separator=true>,</mo><msup><mi mathvariant=bold>v</mi><mo mathvariant=normal lspace=0em rspace=0em>′</mo></msup><mo stretchy=false>)</mo><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>)</mo><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>]</mo></mrow><annotation encoding=application/x-tex>J_{\text{NCE}}(\theta)
= - \mathbb{E}_{P_d}\bigl[\log h(i, \mathbf{v})\bigr]
  \;-\; m \,\mathbb{E}_{P_n}\bigl[\log \bigl(1 - h(i, \mathbf{v}')\bigr)\bigr]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.09618em>J</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.0962em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">NCE</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.02778em>θ</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.2em;vertical-align:-0.35em></span><span class=mord>−</span><span class=mord><span class="mord mathbb">E</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3448em><span style=top:-2.3488em;margin-left:-0.1389em;margin-right:0.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1512em><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2559em><span></span></span></span></span></span></span><span class=mopen><span class="delimsizing size1">[</span></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">h</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span><span class=mclose><span class="delimsizing size1">]</span></span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.2em;vertical-align:-0.35em></span><span class="mord mathnormal">m</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathbb">E</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1645em><span style=top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.143em><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2501em><span></span></span></span></span></span></span><span class=mopen><span class="delimsizing size1">[</span></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mopen><span class="delimsizing size1">(</span></span><span class=mord>1</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.2em;vertical-align:-0.35em></span><span class="mord mathnormal">h</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8019em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class=mclose>)</span><span class=mclose><span class="delimsizing size1">)</span></span><span class=mclose><span class="delimsizing size1">]</span></span></span></span></span></span>
<ul>
<li>Where <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>d</mi></msub></mrow><annotation encoding=application/x-tex>P_d</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> represents the "real data distribution," i.e., the actual images (positive examples).</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>P</mi><mi>n</mi></msub></mrow><annotation encoding=application/x-tex>P_n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> represents the "noise distribution," i.e., the noise samples (negative examples).</li>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=bold>v</mi></mrow><annotation encoding=application/x-tex>\mathbf{v}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4444em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span></span></span></span> and <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msup><mi mathvariant=bold>v</mi><mo mathvariant=normal lspace=0em rspace=0em>′</mo></msup></mrow><annotation encoding=application/x-tex>\mathbf{v}'</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7519em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.7519em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> are feature vectors retrieved from the Memory Bank (<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=bold>V</mi></mrow><annotation encoding=application/x-tex>\mathbf{V}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6861em></span><span class="mord mathbf" style=margin-right:0.01597em>V</span></span></span></span>); one corresponds to the "positive sample" (<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>x_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>), and the other is a randomly selected noise sample.</li>
</ul>
<p>Intuitively, a larger <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>h</mi><mo stretchy=false>(</mo><mi>i</mi><mo separator=true>,</mo><mi mathvariant=bold>v</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\log h(i, \mathbf{v})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">h</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=mclose>)</span></span></span></span> means the model is more confident that "<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=bold>v</mi></mrow><annotation encoding=application/x-tex>\mathbf{v}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4444em></span><span class="mord mathbf" style=margin-right:0.01597em>v</span></span></span></span> belongs to the <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>i</mi></mrow><annotation encoding=application/x-tex>i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6595em></span><span class="mord mathnormal">i</span></span></span></span>-th image" (good); whereas a larger <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>log</mi><mo>⁡</mo><mo stretchy=false>(</mo><mn>1</mn><mo>−</mo><mi>h</mi><mo stretchy=false>(</mo><mo>⋅</mo><mo stretchy=false>)</mo><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\log(1 - h(\cdot))</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mopen>(</span><span class=mord>1</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">h</span><span class=mopen>(</span><span class=mord>⋅</span><span class=mclose>))</span></span></span></span> means the model correctly rejects the noise.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=approximation-of-z_i>Approximation of <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>Z_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>Z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span><a href=#approximation-of-z_i class=hash-link aria-label="Direct link to approximation-of-z_i" title="Direct link to approximation-of-z_i">​</a></h3>
<p>Although we have discussed many aspects, the biggest challenge remains unsolved.</p>
<p>We still need to calculate <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>Z_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>Z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>, which involves <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>exp</mi><mo>⁡</mo><mo stretchy=false>(</mo><msubsup><mi mathvariant=bold>v</mi><mi>j</mi><mi>T</mi></msubsup><msub><mi mathvariant=bold>f</mi><mi>i</mi></msub><mi mathvariant=normal>/</mi><mi>τ</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\sum_{j=1}^{n} \exp(\mathbf{v}_j^T \mathbf{f}_i/\tau)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.2771em;vertical-align:-0.4358em></span><span class=mop><span class="mop op-symbol small-op" style=position:relative;top:0em>∑</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8043em><span style=top:-2.4003em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.2029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.4358em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>exp</span><span class=mopen>(</span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-2.4413em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3948em><span></span></span></span></span></span></span><span class=mord><span class="mord mathbf" style=margin-right:0.10903em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.1132em>τ</span><span class=mclose>)</span></span></span></span>, and when <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> is large, this is still a bottleneck.</p>
<p>A common approach in NCE is to treat <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>Z_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>Z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span> as a "constant" for estimation or approximation, and not involve it in gradient updates. In this paper, the authors refer to the following work:</p>
<ul>
<li><a href=https://www.cs.toronto.edu/~amnih/papers/wordreps.pdf target=_blank rel="noopener noreferrer"><strong>Learning word embeddings efficiently with noise-contrastive estimation</strong></a></li>
</ul>
<p>They use Monte Carlo approximation to estimate:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mi>Z</mi><mo>≃</mo><msub><mi>Z</mi><mi>i</mi></msub><mo>≃</mo><mi>n</mi><mtext> </mtext><msub><mi mathvariant=double-struck>E</mi><mrow><mi>j</mi><mo>∈</mo><mtext>subset</mtext></mrow></msub><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>[</mo><mi>exp</mi><mo>⁡</mo><mo stretchy=false>(</mo><msubsup><mi mathvariant=bold>v</mi><mi>j</mi><mi>T</mi></msubsup><msub><mi mathvariant=bold>f</mi><mi>i</mi></msub><mi mathvariant=normal>/</mi><mi>τ</mi><mo stretchy=false>)</mo><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>]</mo><mo>=</mo><mfrac><mi>n</mi><mi>m</mi></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>exp</mi><mo>⁡</mo><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>(</mo><msubsup><mi mathvariant=bold>v</mi><msub><mi>j</mi><mi>k</mi></msub><mi>T</mi></msubsup><msub><mi mathvariant=bold>f</mi><mi>i</mi></msub><mi mathvariant=normal>/</mi><mi>τ</mi><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>)</mo></mrow><annotation encoding=application/x-tex>Z
\simeq Z_i
\simeq n \,\mathbb{E}_{j \in \text{subset}}
\bigl[\exp(\mathbf{v}_j^T \mathbf{f}_i / \tau)\bigr]
= \frac{n}{m} \sum_{k=1}^{m}
\exp\bigl(\mathbf{v}_{j_k}^T \mathbf{f}_i / \tau\bigr)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.07153em>Z</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>≃</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>Z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>≃</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.2744em;vertical-align:-0.3831em></span><span class="mord mathnormal">n</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathbb">E</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span><span class="mrel mtight">∈</span><span class="mord text mtight"><span class="mord mtight">subset</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mopen><span class="delimsizing size1">[</span></span><span class=mop>exp</span><span class=mopen>(</span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8913em><span style=top:-2.453em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3831em><span></span></span></span></span></span></span><span class=mord><span class="mord mathbf" style=margin-right:0.10903em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.1132em>τ</span><span class=mclose>)</span><span class=mclose><span class="delimsizing size1">]</span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.9535em;vertical-align:-1.3021em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.1076em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal">m</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.6514em><span style=top:-1.8479em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.3021em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mop>exp</span><span class=mopen><span class="delimsizing size1">(</span></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8913em><span style=top:-2.453em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3448em><span style=top:-2.3488em;margin-left:-0.0572em;margin-right:0.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1512em><span></span></span></span></span></span></span></span></span></span><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3831em><span></span></span></span></span></span></span><span class=mord><span class="mord mathbf" style=margin-right:0.10903em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.109em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.1132em>τ</span><span class=mclose><span class="delimsizing size1">)</span></span></span></span></span></span>
<p>Here, <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>{</mo><msub><mi>j</mi><mi>k</mi></msub><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>\{j_k\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord><span class="mord mathnormal" style=margin-right:0.05724em>j</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.0572em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>}</span></span></span></span> is a set of randomly selected indices used to approximate the average value of the entire set.</p>
<p>Instead of summing all <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>n</mi></mrow><annotation encoding=application/x-tex>n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">n</span></span></span></span> terms to calculate <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>Z_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8333em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.07153em>Z</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0715em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>, now we only sample <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi></mrow><annotation encoding=application/x-tex>m</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span></span></span></span> negative examples, perform the exponential operation on them, sum them up, and then multiply by the factor <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mfrac><mi>n</mi><mi>m</mi></mfrac></mrow><annotation encoding=application/x-tex>\frac{n}{m}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0404em;vertical-align:-0.345em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.6954em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.394em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.345em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> to approximate the overall mean.</p>
<p>The paper also mentions that experimentally, a good estimate can be obtained with just a few batches early in training, and this estimate can be fixed for the remainder of the training, which works well.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=proximal-regularization>Proximal Regularization<a href=#proximal-regularization class=hash-link aria-label="Direct link to Proximal Regularization" title="Direct link to Proximal Regularization">​</a></h3>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>info</div><div class=admonitionContent_BuS1><p>Reference: <a href=https://web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf target=_blank rel="noopener noreferrer"><strong>Proximal Algorithms</strong></a></div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>Earlier, we asked: If classification anchors are not fixed but shift during training, how can the model ensure their stability?</div></div>
<p>Unlike typical classification problems, here each "class" only has "one training sample." In each training epoch, each class is only sampled once, which can lead to large oscillations in the learning process. For example, if one image happens to be overfitted or shifted by the model, a large gradient update may occur the next time it is encountered, causing significant fluctuations in the overall training objective.</p>
<p>To mitigate this instability caused by random sampling, the authors introduce the concept of <strong>Proximal Regularization</strong>. By adding a <strong>smoothness constraint</strong> to the loss function, they ensure that the feature vector does not differ too much from the previous iteration. This helps stabilize training and accelerate convergence.</p>
<p>Specifically, we assume two variables:</p>
<ul>
<li><strong>Current iteration (iteration <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>t</mi></mrow><annotation encoding=application/x-tex>t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6151em></span><span class="mord mathnormal">t</span></span></span></span>)</strong>: For training data <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>x_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span>, compute the feature vector <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo stretchy=false>)</mo></mrow></msubsup><mo>=</mo><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy=false>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\mathbf{v}_i^{(t)} = f_\theta(x_i)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3361em><span style=top:-2.55em;margin-left:-0.1076em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.02778em>θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>.</li>
<li><strong>Memory Bank</strong>: Stores the feature vector from the previous iteration (iteration <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>t-1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6984em;vertical-align:-0.0833em></span><span class="mord mathnormal">t</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span></span></span></span>), denoted as <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msubsup></mrow><annotation encoding=application/x-tex>\mathbf{v}_i^{(t-1)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span></span></span></span>.</li>
</ul>
<p>In the original NCE loss, an additional term <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>λ</mi><mi mathvariant=normal>∥</mi><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo stretchy=false>)</mo></mrow></msubsup><mo>−</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msubsup><msup><mi mathvariant=normal>∥</mi><mn>2</mn></msup></mrow><annotation encoding=application/x-tex>\lambda \|\mathbf{v}_i^{(t)} - \mathbf{v}_i^{(t-1)}\|^2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class="mord mathnormal">λ</span><span class=mord>∥</span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mord><span class=mord>∥</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8141em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> is added.</p>
<p>Thus, the objective function becomes:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>h</mi><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>(</mo><mi>i</mi><mo separator=true>,</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msubsup><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>)</mo><mtext>  </mtext><mo>+</mo><mtext>  </mtext><mi>λ</mi><mtext> </mtext><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>∥</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo stretchy=false>)</mo></mrow></msubsup><mo>−</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msubsup><msubsup><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>∥</mo><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding=application/x-tex>- \log h\bigl(i, \mathbf{v}_i^{(t-1)}\bigr)
\;+\; \lambda \,\bigl\|\mathbf{v}_i^{(t)} - \mathbf{v}_i^{(t-1)}\bigr\|_2^2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.3948em;vertical-align:-0.35em></span><span class=mord>−</span><span class=mspace style=margin-right:0.1667em></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">h</span><span class=mopen><span class="delimsizing size1">(</span></span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mclose><span class="delimsizing size1">)</span></span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.3948em;vertical-align:-0.35em></span><span class="mord mathnormal">λ</span><span class=mspace style=margin-right:0.1667em></span><span class=mopen><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.85em><span style=top:-2.85em><span class=pstrut style=height:3.2em></span><span style=width:0.556em;height:1.200em><svg xmlns=http://www.w3.org/2000/svg width=0.556em height=1.200em viewBox="0 0 556 1200"><path d="M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z
M367 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v0 v585 h43z"/></svg></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.35em><span></span></span></span></span></span></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.4537em;vertical-align:-0.3997em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mclose><span class=mclose><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.85em><span style=top:-2.85em><span class=pstrut style=height:3.2em></span><span style=width:0.556em;height:1.200em><svg xmlns=http://www.w3.org/2000/svg width=0.556em height=1.200em viewBox="0 0 556 1200"><path d="M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z
M367 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v0 v585 h43z"/></svg></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.35em><span></span></span></span></span></span></span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.054em><span style=top:-2.3003em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style=top:-3.3029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.3997em><span></span></span></span></span></span></span></span></span></span></span>
<ul>
<li>The first term (<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>h</mi><mo stretchy=false>(</mo><mi>i</mi><mo separator=true>,</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msubsup><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>- \log h(i, \mathbf{v}_i^{(t-1)})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class=mord>−</span><span class=mspace style=margin-right:0.1667em></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">h</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>) is the original positive example loss in NCE.</li>
<li>The second term (<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>λ</mi><mi mathvariant=normal>∥</mi><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo stretchy=false>)</mo></mrow></msubsup><mo>−</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msubsup><msup><mi mathvariant=normal>∥</mi><mn>2</mn></msup></mrow><annotation encoding=application/x-tex>\lambda \|\mathbf{v}_i^{(t)} - \mathbf{v}_i^{(t-1)}\|^2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class="mord mathnormal">λ</span><span class=mord>∥</span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mord><span class=mord>∥</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8141em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>) encourages the new feature <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo stretchy=false>)</mo></mrow></msubsup></mrow><annotation encoding=application/x-tex>\mathbf{v}_i^{(t)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span></span></span></span> not to differ too much from the previous iteration's <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msubsup></mrow><annotation encoding=application/x-tex>\mathbf{v}_i^{(t-1)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span></span></span></span>.</li>
</ul>
<p>Through this <strong>proximal term</strong>, if the feature vector changes too drastically during each update, it will be penalized. As training progresses and the model converges, the ideal scenario is <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo stretchy=false>)</mo></mrow></msubsup><mo>≈</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msubsup></mrow><annotation encoding=application/x-tex>\mathbf{v}_i^{(t)} \approx \mathbf{v}_i^{(t-1)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>≈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span></span></span></span>, and the penalty term gradually diminishes, eventually returning to the original objective function.</p>
<p>After incorporating this, the authors present the final objective function with <strong>Proximal Regularization</strong>:</p>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>J</mi><mtext>NCE</mtext></msub><mo stretchy=false>(</mo><mi>θ</mi><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>J_{\text{NCE}}(\theta)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.09618em>J</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.0962em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">NCE</span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.02778em>θ</span><span class=mclose>)</span></span></span></span></span>
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mo>=</mo><mo>−</mo><msub><mi mathvariant=double-struck>E</mi><msub><mi>P</mi><mi>d</mi></msub></msub><mo fence=true stretchy=true minsize=1.8em maxsize=1.8em>[</mo><mi>log</mi><mo>⁡</mo><mi>h</mi><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>(</mo><mi>i</mi><mo separator=true>,</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msubsup><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>)</mo><mtext>  </mtext><mo>−</mo><mtext>  </mtext><mi>λ</mi><mtext> </mtext><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>∥</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo stretchy=false>)</mo></mrow></msubsup><mo>−</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msubsup><msup><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>∥</mo><mn>2</mn></msup><mo fence=true stretchy=true minsize=1.8em maxsize=1.8em>]</mo><mtext>  </mtext><mo>−</mo><mtext>  </mtext><mi>m</mi><mtext> </mtext><msub><mi mathvariant=double-struck>E</mi><msub><mi>P</mi><mi>n</mi></msub></msub><mo fence=true stretchy=true minsize=1.8em maxsize=1.8em>[</mo><mi>log</mi><mo>⁡</mo><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>(</mo><mn>1</mn><mo>−</mo><mi>h</mi><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>(</mo><mi>i</mi><mo separator=true>,</mo><msup><mi mathvariant=bold>v</mi><mrow><mo mathvariant=normal>′</mo><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></mrow></msup><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>)</mo><mo fence=true stretchy=true minsize=1.2em maxsize=1.2em>)</mo><mo fence=true stretchy=true minsize=1.8em maxsize=1.8em>]</mo><mi mathvariant=normal>.</mi></mrow><annotation encoding=application/x-tex>= - \mathbb{E}_{P_d}
  \Bigl[
    \log h\bigl(i, \mathbf{v}_i^{(t-1)}\bigr)
    \;-\; \lambda \,\bigl\|\mathbf{v}_i^{(t)} - \mathbf{v}_i^{(t-1)}\bigr\|^2
  \Bigr]
  \;-\; m \,\mathbb{E}_{P_n}
  \Bigl[
    \log\bigl(1 - h\bigl(i, \mathbf{v}'^{(t-1)}\bigr)\bigr)
  \Bigr].</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.3669em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.8em;vertical-align:-0.65em></span><span class=mord>−</span><span class=mord><span class="mord mathbb">E</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3448em><span style=top:-2.3488em;margin-left:-0.1389em;margin-right:0.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1512em><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2559em><span></span></span></span></span></span></span><span class=mopen><span class="delimsizing size2">[</span></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">h</span><span class=mopen><span class="delimsizing size1">(</span></span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mclose><span class="delimsizing size1">)</span></span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.3948em;vertical-align:-0.35em></span><span class="mord mathnormal">λ</span><span class=mspace style=margin-right:0.1667em></span><span class=mopen><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.85em><span style=top:-2.85em><span class=pstrut style=height:3.2em></span><span style=width:0.556em;height:1.200em><svg xmlns=http://www.w3.org/2000/svg width=0.556em height=1.200em viewBox="0 0 556 1200"><path d="M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z
M367 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v0 v585 h43z"/></svg></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.35em><span></span></span></span></span></span></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.8em;vertical-align:-0.65em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mclose><span class=mclose><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.85em><span style=top:-2.85em><span class=pstrut style=height:3.2em></span><span style=width:0.556em;height:1.200em><svg xmlns=http://www.w3.org/2000/svg width=0.556em height=1.200em viewBox="0 0 556 1200"><path d="M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z
M367 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v0 v585 h43z"/></svg></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.35em><span></span></span></span></span></span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:1.054em><span style=top:-3.3029em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mclose><span class="delimsizing size2">]</span></span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2778em></span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.8em;vertical-align:-0.65em></span><span class="mord mathnormal">m</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathbb">E</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1645em><span style=top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.143em><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2501em><span></span></span></span></span></span></span><span class=mopen><span class="delimsizing size2">[</span></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mopen><span class="delimsizing size1">(</span></span><span class=mord>1</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.8em;vertical-align:-0.65em></span><span class="mord mathnormal">h</span><span class=mopen><span class="delimsizing size1">(</span></span><span class="mord mathnormal">i</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.938em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span><span class=mclose><span class="delimsizing size1">)</span></span><span class=mclose><span class="delimsizing size1">)</span></span><span class=mclose><span class="delimsizing size2">]</span></span><span class=mord>.</span></span></span></span></span>
<p>This version retains the original NCE components for "positive example <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>h</mi><mo stretchy=false>(</mo><mo>⋅</mo><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\log h(\cdot)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">h</span><span class=mopen>(</span><span class=mord>⋅</span><span class=mclose>)</span></span></span></span>" and "negative example <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>log</mi><mo>⁡</mo><mo stretchy=false>(</mo><mn>1</mn><mo>−</mo><mi>h</mi><mo stretchy=false>(</mo><mo>⋅</mo><mo stretchy=false>)</mo><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>\log(1 - h(\cdot))</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mop>lo<span style=margin-right:0.01389em>g</span></span><span class=mopen>(</span><span class=mord>1</span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">h</span><span class=mopen>(</span><span class=mord>⋅</span><span class=mclose>))</span></span></span></span>" while adding the term <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo>−</mo><mi>λ</mi><mi mathvariant=normal>∥</mi><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo stretchy=false>)</mo></mrow></msubsup><mo>−</mo><msubsup><mi mathvariant=bold>v</mi><mi>i</mi><mrow><mo stretchy=false>(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=false>)</mo></mrow></msubsup><msup><mi mathvariant=normal>∥</mi><mn>2</mn></msup></mrow><annotation encoding=application/x-tex>- \lambda \|\mathbf{v}_i^{(t)} - \mathbf{v}_i^{(t-1)}\|^2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class=mord>−</span><span class="mord mathnormal">λ</span><span class=mord>∥</span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:1.3217em;vertical-align:-0.2769em></span><span class=mord><span class="mord mathbf" style=margin-right:0.01597em>v</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4231em;margin-left:-0.016em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.2198em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2769em><span></span></span></span></span></span></span><span class=mord><span class=mord>∥</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8141em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> to suppress drastic changes in feature vectors.</p>
<p>To verify the effectiveness of Proximal Regularization, the authors compare the impact of different <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>λ</mi></mrow><annotation encoding=application/x-tex>\lambda</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">λ</span></span></span></span> values (such as 0, 10, 30, 50) on training:</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=proximal src=/en/assets/images/img3-301d32df662fb6902be49fd46ea893e5.jpg width=724 height=576 class=img_ev3q></figure></div>
<p>As shown in the figure above, when <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=application/x-tex>\lambda = 0</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">λ</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0</span></span></span></span> (i.e., no proximal term), the original objective function oscillates significantly during training and converges more slowly. With an appropriately sized <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>λ</mi></mrow><annotation encoding=application/x-tex>\lambda</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal">λ</span></span></span></span>, the objective function smooths out, converges faster, and ultimately learns better feature representations.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=discussion>Discussion<a href=#discussion class=hash-link aria-label="Direct link to Discussion" title="Direct link to Discussion">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=parametric-vs-non-parametric-softmax>Parametric vs Non-Parametric Softmax<a href=#parametric-vs-non-parametric-softmax class=hash-link aria-label="Direct link to Parametric vs Non-Parametric Softmax" title="Direct link to Parametric vs Non-Parametric Softmax">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=parametric src=/en/assets/images/img4-3df94fff95c4ab1f41136c0bffa842ec.jpg width=1094 height=498 class=img_ev3q></figure></div>
<p>Since the core of this paper is the "non-parametric Softmax," the authors first conducted an experiment on CIFAR-10 to compare the performance of "parametric Softmax" and "non-parametric Softmax."</p>
<p>Since the CIFAR-10 dataset is relatively small, the non-parametric Softmax denominator can be directly computed, allowing a direct comparison of the two approaches. The evaluation methods used were Linear SVM and k-NN classifiers, applied to "parametric" and "non-parametric" features, and their accuracy rates were compared.</p>
<p>The results, shown in the table above, reveal that the parametric Softmax achieved accuracy rates of 60.3% for SVM and 63.0% for k-NN, while the non-parametric Softmax achieved 75.4% and 80.8%, respectively. This demonstrates a significant improvement in performance with the non-parametric Softmax, validating the authors' approach.</p>
<p>Additionally, the authors explored the effects of using NCE approximation in the non-parametric setting, as shown in the table. The hyperparameter <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi></mrow><annotation encoding=application/x-tex>m</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span></span></span></span> in NCE indicates how many negative samples are drawn for each positive sample:</p>
<ul>
<li>When <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>m = 1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>1</span></span></span></span> (only 1 negative sample), the k-NN accuracy dropped drastically to 42.5%, indicating excessive approximation (too few negative examples).</li>
<li>As <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi></mrow><annotation encoding=application/x-tex>m</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span></span></span></span> increases, the accuracy gradually rises. When <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi><mo>=</mo><mn>4</mn><mo separator=true>,</mo><mn>096</mn></mrow><annotation encoding=application/x-tex>m = 4,096</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8389em;vertical-align:-0.1944em></span><span class=mord>4</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>096</span></span></span></span>, the results were close to the "full version" (<span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi><mo>=</mo><mn>49</mn><mo separator=true>,</mo><mn>999</mn></mrow><annotation encoding=application/x-tex>m = 49,999</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8389em;vertical-align:-0.1944em></span><span class=mord>49</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord>999</span></span></span></span>), suggesting that with enough negative samples, NCE can closely approximate the complete non-parametric Softmax.</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=performance-in-image-classification-tasks>Performance in Image Classification Tasks<a href=#performance-in-image-classification-tasks class=hash-link aria-label="Direct link to Performance in Image Classification Tasks" title="Direct link to Performance in Image Classification Tasks">​</a></h3>
<p>The authors then conducted larger-scale experiments on ImageNet to compare the performance of different methods across various network architectures.</p>
<p>The experimental setup was as follows:</p>
<ul>
<li><strong>Dataset</strong>: ImageNet, approximately 1.28 million images, 1,000 categories.</li>
<li><strong>Temperature parameter <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>τ</mi></mrow><annotation encoding=application/x-tex>\tau</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal" style=margin-right:0.1132em>τ</span></span></span></span></strong>: Set to 0.07.</li>
<li><strong>NCE negative samples <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi></mrow><annotation encoding=application/x-tex>m</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span></span></span></span></strong>: 4,096. The authors balanced "computational cost" and "feature quality."</li>
<li><strong>Training</strong>:<!-- -->
<ul>
<li>Trained for 200 epochs using Momentum SGD.</li>
<li>Batch size = 256.</li>
<li>Initial learning rate of 0.03, maintained for the first 120 epochs, then decayed every 40 epochs by a factor of 0.1.</li>
</ul>
</li>
</ul>
<p>The authors listed several representative unsupervised (or self-supervised) learning methods, including:</p>
<ul>
<li><strong>Random initialization</strong> (random initialization, as a lower bound).</li>
<li><strong>Self-supervised</strong></li>
<li><strong>Adversarial learning</strong></li>
<li><strong>Exemplar CNN</strong></li>
<li><strong>Split-brain autoencoder</strong>: One of the recent self-supervised benchmark methods.</li>
</ul>
<p>For fair comparison, the authors used multiple common architectures: AlexNet, VGG16, ResNet-18, and ResNet-50. Since network depth significantly influences results, they specifically compared the differences between "same method, different depth."</p>
<p>The evaluation methods were as follows:</p>
<ol>
<li><strong>Linear SVM (conv1 ~ conv5)</strong>: Trained a linear classifier on the intermediate features from different convolutional layers (such as conv1, conv2, conv3, ...) and tested the classification performance on the ImageNet validation set.</li>
<li><strong>k-NN (final 128-dimensional output)</strong>: Directly applied nearest neighbor classification on the final 128-dimensional feature output.</li>
</ol>
<p>The experimental results are shown in the table below:</p>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=imagenet src=/en/assets/images/img5-433650f7d0fbb52f7af26bae486276de.jpg width=928 height=720 class=img_ev3q></figure></div>
<p>The authors' method achieved a top-1 accuracy of 35.6% in conv1 ~ conv5, outperforming previous methods, including Split-brain.</p>
<p>Next, when attempting deeper networks such as ResNet-50, the accuracy reached 54.0%, while Exemplar CNN, even using the deeper ResNet-101, only achieved 31.5%. This demonstrates that the authors' method achieves significant improvements as the network depth increases.</p>
<p>The k-NN classification results were close to those of the linear classifier (conv5), indicating that the final 128-dimensional features formed a good metric space. Moreover, the deeper the layer (such as conv4, conv5), the better the results, indicating the authors' method excels in extracting high-level features.</p>
<p>Finally, in terms of efficiency, many methods have features with more than 10,000 dimensions at the optimal layer (such as conv3, conv4), which are not friendly for storage and computation. In contrast, the authors' method only requires 128 dimensions for the final output, making it highly compact. Storing all features for the full ImageNet dataset (1.28 million images) takes only about 600 MB, and nearest neighbor retrieval on a Titan X GPU takes less than 20 ms.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=cross-dataset-generalization>Cross-Dataset Generalization<a href=#cross-dataset-generalization class=hash-link aria-label="Direct link to Cross-Dataset Generalization" title="Direct link to Cross-Dataset Generalization">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt=imagenet src=/en/assets/images/img12-d07f888d47aaeeabcc2f6c6c7ffd09c5.jpg width=1036 height=756 class=img_ev3q></figure></div>
<p>The authors then tested the features learned on ImageNet, <strong>directly</strong> applied to another large dataset, Places (2.45 million images, 205 categories), without fine-tuning, only feature extraction, and then trained a linear classifier or performed k-NN on Places.</p>
<p>The experimental results are shown in the table above. The method achieved accuracy rates of 45.5% and 41.6% on linear classification and k-NN for ResNet-50, outperforming other methods (such as Exemplar CNN, Split-brain, etc.).</p>
<p>These results demonstrate that the features learned on ImageNet can maintain good performance even in different domains (scene classification), showing the method's <strong>cross-domain generalization ability</strong>.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=ablation-experiment---feature-dimension>Ablation Experiment - Feature Dimension<a href=#ablation-experiment---feature-dimension class=hash-link aria-label="Direct link to Ablation Experiment - Feature Dimension" title="Direct link to Ablation Experiment - Feature Dimension">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt="emb dim" src=/en/assets/images/img8-072eaf882646377bc2d6f65b8400df09.jpg width=764 height=138 class=img_ev3q></figure></div>
<p>After confirming that the model architecture is effective, the authors conducted some ablation experiments.</p>
<p>The first explores the impact of feature dimension. The authors compared feature dimensions of 32, 64, 128, and 256, with results shown in the table above.</p>
<p>The experiments show that performance significantly improves when the dimension increases from 32 to 128. However, the improvement from 128 to 256 saturates, meaning that 128 dimensions already provide sufficient representation power. While increasing the dimension further may bring slight benefits, it is not as significant as the earlier increase.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=ablation-experiment---training-set-size>Ablation Experiment - Training Set Size<a href=#ablation-experiment---training-set-size class=hash-link aria-label="Direct link to Ablation Experiment - Training Set Size" title="Direct link to Ablation Experiment - Training Set Size">​</a></h3>
<div align=center><figure style=width:70%><p><img decoding=async loading=lazy alt="train size" src=/en/assets/images/img9-b1d30f8d9446f815df628130d1edd8a1.jpg width=900 height=144 class=img_ev3q></figure></div>
<p>Next, the authors explored the impact of "training set size" on model performance. The experimental setup was as follows:</p>
<ul>
<li><strong>ImageNet training set</strong>: Used 10%, 50%, and 100% of the images as the training set.</li>
<li><strong>Validation set</strong>: The complete ImageNet validation set was used for testing the model.</li>
</ul>
<p>The experimental results are shown in the table above. As the training set size increases, the model performance continues to improve. This shows that the method effectively utilizes more unlabeled data to improve feature quality, and performs better with larger training sets.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>This result is very appealing because it means that as long as we keep extracting more unlabeled data, this method can continually benefit and learn stronger features.</div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=visualization-analysis>Visualization Analysis<a href=#visualization-analysis class=hash-link aria-label="Direct link to Visualization Analysis" title="Direct link to Visualization Analysis">​</a></h3>
<div align=center><figure style=width:90%><p><img decoding=async loading=lazy alt=vis src=/en/assets/images/img7-9c047a1543b7d8098c8f48e6f626403a.jpg width=1430 height=998 class=img_ev3q></figure></div>
<p>Finally, the authors presented some feature visualization results, which demonstrate the "image search by image" functionality. By comparing image features, the model finds the closest images to the "query."</p>
<p>The experimental results are shown in the figure above:</p>
<ul>
<li><strong>Best case (top four rows)</strong>: The top 10 retrieved images are all from the same category as the query image (indicating that the model's metric space is extremely precise).</li>
<li><strong>Worst case (bottom four rows)</strong>: The top 10 images are not from the same "real class," but are visually or shape-wise very similar. For example, although they belong to different species or categories, they look similar (e.g., having the same black-and-white stripes or similar shapes and backgrounds).</li>
</ul>
<p>The authors point out that even in "failure cases," visually similar images can still be retrieved, which proves that the "instance-level" embedding space truly captures visual features, rather than just random correspondences.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=conclusion>Conclusion<a href=#conclusion class=hash-link aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>The paper also includes experiments applied to "semi-supervised classification" and "object detection," but we won't go into detail here. Interested readers can refer to the original paper.</p>
<p>Overall, these experiments thoroughly validate the versatility and scalability of the authors' approach: it is effective not only for classification and retrieval but also demonstrates good generalization across different network architectures, data scales, and downstream tasks (semi-supervised classification, detection).</p>
<p>After the paper's release, the unsupervised learning framework based on NCE loss quickly achieved impressive results on large-scale datasets and demonstrated strong performance in practical applications.</p>
<p>There are still several classic papers to follow up on, so let’s continue reading.</header></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col></div><div class="col lastUpdated_JAkA"><span class=theme-last-updated>Last updated<!-- --> on <b><time datetime=2025-02-11T02:49:16.000Z itemprop=dateModified>Feb 11, 2025</time></b> by <b>zephyr-sh</b></span></div></div><div style=margin-top:3rem> </div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/en/papers/contrastive-learning/examplar-cnn/><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>[14.06] Exemplar CNN</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/en/papers/contrastive-learning/cpc/><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>[18.07] CPC</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#more-is-better class="table-of-contents__link toc-highlight">More is better</a><li><a href=#defining-the-problem class="table-of-contents__link toc-highlight">Defining the Problem</a><ul><li><a href=#generative-models class="table-of-contents__link toc-highlight">Generative Models</a><li><a href=#self-supervised-structural-learning class="table-of-contents__link toc-highlight">Self-Supervised Structural Learning</a></ul><li><a href=#solving-the-problem class="table-of-contents__link toc-highlight">Solving the Problem</a><ul><li><a href=#model-architecture class="table-of-contents__link toc-highlight">Model Architecture</a><li><a href=#the-problem-with-traditional-classifiers class="table-of-contents__link toc-highlight">The Problem with Traditional Classifiers</a><li><a href=#non-parametric-classifier class="table-of-contents__link toc-highlight">Non-Parametric Classifier</a><li><a href=#memory-bank class="table-of-contents__link toc-highlight">Memory Bank</a><li><a href=#noise-contrastive-estimation class="table-of-contents__link toc-highlight">Noise-Contrastive Estimation</a><li><a href=#approximation-of-z_i class="table-of-contents__link toc-highlight">Approximation of Z_i</a><li><a href=#proximal-regularization class="table-of-contents__link toc-highlight">Proximal Regularization</a></ul><li><a href=#discussion class="table-of-contents__link toc-highlight">Discussion</a><ul><li><a href=#parametric-vs-non-parametric-softmax class="table-of-contents__link toc-highlight">Parametric vs Non-Parametric Softmax</a><li><a href=#performance-in-image-classification-tasks class="table-of-contents__link toc-highlight">Performance in Image Classification Tasks</a><li><a href=#cross-dataset-generalization class="table-of-contents__link toc-highlight">Cross-Dataset Generalization</a><li><a href=#ablation-experiment---feature-dimension class="table-of-contents__link toc-highlight">Ablation Experiment - Feature Dimension</a><li><a href=#ablation-experiment---training-set-size class="table-of-contents__link toc-highlight">Ablation Experiment - Training Set Size</a><li><a href=#visualization-analysis class="table-of-contents__link toc-highlight">Visualization Analysis</a></ul><li><a href=#conclusion class="table-of-contents__link toc-highlight">Conclusion</a></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/en/docs>Projects</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/papers/intro>Papers</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/blog>Blog</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/terms-of-service>TermsOfUse</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/privacy-policy>Privacy Policy</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/become-an-author>Become an author</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/en/worklog>Worklog</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2024 DOCSAID.</div></div></div></footer></div>