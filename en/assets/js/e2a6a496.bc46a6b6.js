"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[7145],{26641:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>l});var t=n(74848),s=n(28453);const r={},o="[23.09] TIVC",a={id:"face-recognition/tivc/index",title:"[23.09] TIVC",description:"Perspective on Twin Identification",source:"@site/i18n/en/docusaurus-plugin-content-docs-papers/current/face-recognition/2309-tivc/index.md",sourceDirName:"face-recognition/2309-tivc",slug:"/face-recognition/tivc/",permalink:"/en/papers/face-recognition/tivc/",draft:!1,unlisted:!1,tags:[],version:"current",lastUpdatedBy:"zephyr-sh",lastUpdatedAt:1724052268e3,frontMatter:{},sidebar:"papersSidebar",previous:{title:"[22.09] FRVT-Twins",permalink:"/en/papers/face-recognition/frvt-distinguishing-twins/"},next:{title:"Feature Fusion",permalink:"/en/papers/category/feature-fusion"}},c={},l=[{value:"Perspective on Twin Identification",id:"perspective-on-twin-identification",level:2},{value:"Review from Another Paper",id:"review-from-another-paper",level:2},{value:"Pre-DCNN Algorithms",id:"pre-dcnn-algorithms",level:3},{value:"Deep Learning Approaches",id:"deep-learning-approaches",level:3},{value:"Defining the Problem",id:"defining-the-problem",level:2},{value:"Solving the Problem",id:"solving-the-problem",level:2},{value:"Experiment 1: Human Identification of Monozygotic Twins",id:"experiment-1-human-identification-of-monozygotic-twins",level:3},{value:"Experiment 2: DCNN Identification of Monozygotic Twins",id:"experiment-2-dcnn-identification-of-monozygotic-twins",level:3},{value:"Discussion",id:"discussion",level:2},{value:"Experimental Results",id:"experimental-results",level:3},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const i={a:"a",h1:"h1",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.h1,{id:"2309-tivc",children:"[23.09] TIVC"}),"\n",(0,t.jsx)(i.h2,{id:"perspective-on-twin-identification",children:"Perspective on Twin Identification"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.a,{href:"https://dl.acm.org/doi/pdf/10.1145/3609224",children:(0,t.jsx)(i.strong,{children:"Twin Identification over Viewpoint Change: A Deep Convolutional Neural Network Surpasses Humans"})})}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.p,{children:"Identifying twins has always been a challenge in computer vision research."}),"\n",(0,t.jsx)(i.p,{children:"This paper aims to compare the accuracy of human and Deep Convolutional Neural Networks (DCNN) in the identification of monozygotic twins, especially under varying viewpoints. Specifically, researchers aim to understand the differences in how these two systems distinguish highly similar faces and evaluate their reliability in real-world applications."}),"\n",(0,t.jsx)(i.h2,{id:"review-from-another-paper",children:"Review from Another Paper"}),"\n",(0,t.jsx)(i.p,{children:"Initially, we intended to review the following paper:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"https://www.sciencedirect.com/science/article/abs/pii/S0262885621002365",children:(0,t.jsx)(i.strong,{children:"[21.12] Monozygotic twin face recognition: An in-depth analysis and plausible improvements"})})}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"However, the PDF of this paper requires a paid download. We later found that subsequent papers cited this work extensively. Conveniently, we can now explore its content together!"}),"\n",(0,t.jsx)(i.h3,{id:"pre-dcnn-algorithms",children:"Pre-DCNN Algorithms"}),"\n",(0,t.jsx)(i.p,{children:"From 2011 to 2014, numerous studies tested commercial face recognition algorithms on the task of distinguishing monozygotic twins. The consensus was that facial recognition technology of that era could not effectively distinguish identical twins. These early systems typically employed Principal Component Analysis (PCA) or manually selected features to process facial images, using a logarithmic likelihood function to reduce error rates. These studies predominantly relied on the Notre Dame Twins dataset (ND-TWINS-2009-2010)."}),"\n",(0,t.jsx)(i.p,{children:"In these early studies, for some twins, images could be acquired from both 2009 and 2010, supporting delayed recognition tests. The availability and quality of these datasets spurred multiple studies on twin face recognition. For example, in one study, participants completed an identity verification task, viewing pairs of monozygotic twins (different identity trials) and the same number of same identity image pairs, all taken under identical lighting conditions. The results showed that humans performed significantly better when given more time to make decisions, indicating the importance of time in recognizing identical twins."}),"\n",(0,t.jsx)(i.p,{children:"Among the tested computer algorithms, only one commercial algorithm (Cognitec) approached but did not surpass human performance. Additionally, as image conditions varied, these early algorithms exhibited increased false positive rates when distinguishing identical twins."}),"\n",(0,t.jsx)(i.h3,{id:"deep-learning-approaches",children:"Deep Learning Approaches"}),"\n",(0,t.jsx)(i.p,{children:"Deep learning, particularly DCNNs, has significantly advanced automatic face recognition technology. These networks' key strength lies in their ability to generalize across variations in images and appearances. Attempts to apply DCNNs to twin differentiation, though few, have yielded some initial success."}),"\n",(0,t.jsx)(i.p,{children:'For instance, one study found that combining PCA, Histogram of Oriented Gradients (HOG), and Local Binary Patterns (LBP) outperformed object-trained CNNs on the ND-TWINS-2009 dataset. Another study created a baseline measure of facial similarity to assess the impact of "similar" identities without familial ties, revealing a significant number of potential look-alikes in large datasets.'}),"\n",(0,t.jsx)(i.p,{children:"Recent research also suggests that optimizing deep networks for twin identification is feasible. For example, some studies used large datasets for preliminary training, followed by optimization to distinguish monozygotic twins, achieving good results. However, a major limitation of these studies is the non-public availability of datasets, making it difficult to replicate and verify results."}),"\n",(0,t.jsx)(i.p,{children:"The National Institute of Standards and Technology (NIST) conducted the Face Recognition Vendor Test (FRVT) to examine the problem of differentiating monozygotic twins. The study showed that all algorithms submitted to FRVT failed to detect twin impostors at a threshold producing a false positive rate of one in ten thousand. While these results provide valuable insights, the conclusions drawn are limited due to various factors."}),"\n",(0,t.jsx)(i.p,{children:"In this study, researchers selected a high-accuracy DCNN and tested whether there was a relationship between human perception of highly similar images and DCNN by correlating their similarity ratings. This not only provides human benchmark tests using the same facial stimuli and viewpoint conditions as algorithm tests but also helps understand the reliability of face recognition systems for highly similar faces, including twins."}),"\n",(0,t.jsx)(i.h2,{id:"defining-the-problem",children:"Defining the Problem"}),"\n",(0,t.jsx)(i.p,{children:"Returning to the original paper, given the challenge of identifying monozygotic twins for both humans and machine vision systems, the objective is straightforward:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.strong,{children:"Compare the performance of humans and machines in distinguishing monozygotic twins."})}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Researchers aim to find ways to optimize machine vision systems by understanding the differences between human and computer vision in recognizing identical twins."}),"\n",(0,t.jsx)(i.h2,{id:"solving-the-problem",children:"Solving the Problem"}),"\n",(0,t.jsx)(i.h3,{id:"experiment-1-human-identification-of-monozygotic-twins",children:"Experiment 1: Human Identification of Monozygotic Twins"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"Experiment 1",src:n(56212).A+"",width:"1224",height:"476"})}),"\n",(0,t.jsx)(i.p,{children:"In Experiment 1, researchers measured the performance of human participants in identifying twins using the ND-TWINS-2009-2010 dataset."}),"\n",(0,t.jsx)(i.p,{children:"Eighty-seven student participants from the University of Texas at Dallas (UTD) were recruited and compensated with course credits."}),"\n",(0,t.jsx)(i.p,{children:"Twenty-nine participants were assigned to each viewpoint condition (frontal to frontal, frontal to 45 degrees, and frontal to 90 degrees). Participants had to be at least 18 years old and have normal or corrected-to-normal vision."}),"\n",(0,t.jsx)(i.p,{children:"Eligibility was determined through a Qualtrics survey. All experimental procedures were approved by the UTD Institutional Review Board."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Experimental Design"})}),"\n",(0,t.jsx)(i.p,{children:"Researchers tested facial identity matching (identity verification) based on the type of stimuli. The image pairs were either of the same identity (same identity pairs) or different identities. Different identity pairs were further divided into twin impostor pairs and general impostor pairs. Same identity pairs consisted of two different images of the same person. Twin impostor pairs consisted of monozygotic twins, while general impostor pairs consisted of images of two different, unrelated individuals. Each type of image pair was tested under three viewpoint conditions."}),"\n",(0,t.jsx)(i.p,{children:"Identity matching accuracy was measured by calculating the AUC for two conditions: (a) same identity pairs vs. twin impostor pairs, and (b) same identity pairs vs. general impostor pairs."}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Procedure"})}),"\n",(0,t.jsx)(i.p,{children:"Participants first completed a screening questionnaire to determine eligibility, confirming they were at least 18 years old and had normal or corrected-to-normal vision. Eligible participants were directed to an online informed consent form. Upon completion, they received a code to schedule their study session. Participants met with a research assistant via a participant-specific Microsoft Teams link at the scheduled time."}),"\n",(0,t.jsx)(i.p,{children:"The researcher briefly described the task, explaining that participants would see a series of face image pairs and rate the certainty of whether the pairs showed the same person or two different people. Participants were informed that the experiment might include identical twins."}),"\n",(0,t.jsx)(i.p,{children:"During each trial, a pair of face images appeared side-by-side on the screen. Participants rated whether the image pair showed the same person or two different people using a 5-point scale. Response options included: (1) Definitely different people, (2) Probably different people, (3) Not sure, (4) Probably the same person, (5) Definitely the same person."}),"\n",(0,t.jsx)(i.p,{children:"Participants selected their rating with a mouse, and the images and scale remained on screen until a response was made. The experiment was programmed in PsychoPy. The order of trials was randomized for each participant."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"experiment-2-dcnn-identification-of-monozygotic-twins",children:"Experiment 2: DCNN Identification of Monozygotic Twins"}),"\n",(0,t.jsx)(i.p,{children:"In the algorithmic test, a DCNN based on the ResNet-101 architecture was used. The network was trained on the Universe dataset, a web-crawled dataset containing 5,714,444 images of 58,020 unique identities. The dataset features significant variability in attributes like pose, lighting, resolution, and age. The demographic composition of the Universe dataset is unknown."}),"\n",(0,t.jsx)(i.p,{children:"The network comprises 101 layers, using skip connections to maintain the error signal amplitude during training. Crystal loss with an alpha parameter set to 50 was applied to ensure the L2 norm remained constant during learning."}),"\n",(0,t.jsx)(i.p,{children:"As a preprocessing step for network training, facial images were cropped to include only the internal face and aligned to a size of 128 \xd7 128 before inputting into the network. This procedure was uniformly applied across all image poses. Once fully trained, the output of the penultimate fully connected layer was used to generate identity representation features for each image."}),"\n",(0,t.jsx)(i.h2,{id:"discussion",children:"Discussion"}),"\n",(0,t.jsx)(i.h3,{id:"experimental-results",children:"Experimental Results"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"Experimental Results",src:n(2275).A+"",width:"1224",height:"588"})}),"\n",(0,t.jsx)(i.p,{children:"In the above image, the red dots represent the computer vision system's results, while the other dots represent human participants' results."}),"\n",(0,t.jsx)(i.p,{children:"Under all conditions, identity matching accuracy was significantly higher for general impostor conditions than for twin impostor conditions."}),"\n",(0,t.jsx)(i.p,{children:"As the viewpoint difference between images increased, accuracy decreased, with the decline being more pronounced for the twin impostor condition compared to the general impostor condition."}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"AUC Measurement Method"})}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["For each participant, the AUC was calculated under each viewpoint condition for two scenarios:","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Image pairs under the general impostor condition."}),"\n",(0,t.jsx)(i.li,{children:"Image pairs under the twin impostor condition."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Basis for AUC Calculation"})}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"In both conditions, correct identity verification responses were generated from same-identity image pairs."}),"\n",(0,t.jsx)(i.li,{children:"False positives in the general impostor condition came from image pairs showing two different, unrelated identities."}),"\n",(0,t.jsx)(i.li,{children:"False positives in the twin impostor condition came from image pairs showing monozygotic twins."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Human Experiment Results"})}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"General impostor condition, frontal to frontal: 0.969"}),"\n",(0,t.jsx)(i.li,{children:"Twin impostor condition, frontal to frontal: 0.874"}),"\n",(0,t.jsx)(i.li,{children:"General impostor condition, frontal to 45 degrees: 0.933"}),"\n",(0,t.jsx)(i.li,{children:"Twin impostor condition, frontal to 45 degrees: 0.691"}),"\n",(0,t.jsx)(i.li,{children:"General impostor condition, frontal to 90 degrees: 0.869"}),"\n",(0,t.jsx)(i.li,{children:"Twin impostor condition, frontal to 90 degrees: 0.652"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"DCNN Experiment Results"})}),"\n",(0,t.jsx)(i.p,{children:"For each image pair viewed in the human data collection experiment, the DCNN generated similarity scores. The accuracy of the DCNN in distinguishing identities was measured by calculating the AUC assigned to same-identity and different-identity image pairs. Correct responses came from image pairs showing the same identity, while false positives came from image pairs showing different identities. The performance of the DCNN is shown in the above figure, represented by red circles, overlaid on the individual human performance data."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"For the general impostor condition, the DCNN achieved perfect identity matching performance (AUC = 1.0)."}),"\n",(0,t.jsx)(i.li,{children:"For the twin impostor condition, the DCNN's identity matching performance remained high (AUC = 0.96)."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,t.jsx)(i.p,{children:"This study emphasizes the importance of epigenetic biometric features in distinguishing monozygotic twins. Although fingerprints and iris textures are considered the most reliable methods, facial recognition technology also shows promise."}),"\n",(0,t.jsx)(i.p,{children:"Compared to earlier face recognition algorithms, DCNNs maintain high accuracy under different viewpoints and lighting conditions, demonstrating significant improvements."}),"\n",(0,t.jsx)(i.p,{children:"The experimental results indicate that DCNNs surpass most human participants in all tested conditions, particularly in the challenging task of twin identification. This contrasts with the findings of the NIST, highlighting the importance of considering DCNN performance in different problem contexts. Human participants showed considerable individual variability, while the DCNN consistently maintained high performance without individual differences. Future research should consider incorporating more identification information, including external features, and further explore the nature of facial representations generated by DCNNs to enhance the combined performance of humans and machines in twin identification tasks, which is especially important for challenging image matching tasks such as forensic applications."}),"\n",(0,t.jsx)(i.p,{children:"\uff0a"}),"\n",(0,t.jsx)(i.p,{children:"Having reviewed this paper, we believe the most important conclusion is:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.strong,{children:"The performance of computer vision systems and humans is consistent, so exploring the mechanisms by which human experts identify twins can help improve computer vision systems."})}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Although we hoped the paper would provide solutions or architectures for solving the twin identification problem, it did not. However, since we've gone through it, we might as well record it here."})]})}function h(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},56212:(e,i,n)=>{n.d(i,{A:()=>t});const t=n.p+"assets/images/img1-2539c562754578afedae808db3ed3698.jpg"},2275:(e,i,n)=>{n.d(i,{A:()=>t});const t=n.p+"assets/images/img2-d0e8b0f3f66cb64f37013c8ee8b42ebb.jpg"},28453:(e,i,n)=>{n.d(i,{R:()=>o,x:()=>a});var t=n(96540);const s={},r=t.createContext(s);function o(e){const i=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(r.Provider,{value:i},e.children)}}}]);