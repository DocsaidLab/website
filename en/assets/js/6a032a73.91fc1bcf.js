"use strict";(self.webpackChunkdocsaid_website=self.webpackChunkdocsaid_website||[]).push([["73126"],{90834:function(e,n,r){r.r(n),r.d(n,{default:()=>p,frontMatter:()=>o,metadata:()=>i,assets:()=>a,toc:()=>d,contentTitle:()=>c});var i=JSON.parse('{"id":"mrzscanner/advance","title":"Advanced","description":"When invoking the MRZScanner model, you can make advanced configurations by passing parameters.","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/mrzscanner/advance.md","sourceDirName":"mrzscanner","slug":"/mrzscanner/advance","permalink":"/en/docs/mrzscanner/advance","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedBy":"zephyr-sh","lastUpdatedAt":1735811993000,"sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Quick Start","permalink":"/en/docs/mrzscanner/quickstart"},"next":{"title":"Model Design","permalink":"/en/docs/mrzscanner/model_arch"}}'),t=r("85893"),s=r("50065");let o={sidebar_position:4},c="Advanced",a={},d=[{value:"Initialization",id:"initialization",level:2},{value:"1. Backend",id:"1-backend",level:3},{value:"2. ModelType",id:"2-modeltype",level:3},{value:"3. ModelCfg",id:"3-modelcfg",level:3},{value:"Inference",id:"inference",level:2},{value:"Center Cropping",id:"center-cropping",level:3},{value:"Post-Processing",id:"post-processing",level:3}];function l(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"advanced",children:"Advanced"})}),"\n",(0,t.jsxs)(n.p,{children:["When invoking the ",(0,t.jsx)(n.code,{children:"MRZScanner"})," model, you can make advanced configurations by passing parameters."]}),"\n",(0,t.jsx)(n.h2,{id:"initialization",children:"Initialization"}),"\n",(0,t.jsx)(n.p,{children:"The following are advanced configuration options during the initialization phase:"}),"\n",(0,t.jsx)(n.h3,{id:"1-backend",children:"1. Backend"}),"\n",(0,t.jsxs)(n.p,{children:["The Backend is an enumeration type used to specify the computation backend for ",(0,t.jsx)(n.code,{children:"MRZScanner"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"It includes the following options:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"cpu"}),": Use CPU for computation."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"cuda"}),": Use GPU for computation (requires appropriate hardware support)."]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from capybara import Backend\n\nmodel = MRZScanner(backend=Backend.cuda) # Use CUDA backend\n#\n# Or\n#\nmodel = MRZScanner(backend=Backend.cpu) # Use CPU backend\n"})}),"\n",(0,t.jsx)(n.p,{children:"We use ONNXRuntime as the inference engine for the model. Although ONNXRuntime supports various backends (including CPU, CUDA, OpenCL, DirectX, TensorRT, etc.), due to the environments typically in use, we have encapsulated it slightly and currently only provide CPU and CUDA backends. Additionally, to use CUDA computation, you need appropriate hardware support and must install the corresponding CUDA drivers and toolkit."}),"\n",(0,t.jsx)(n.p,{children:"If CUDA is not installed on your system or the version is incorrect, the CUDA computation backend will not be available."}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["If you have other requirements, refer to the ",(0,t.jsx)(n.a,{href:"https://onnxruntime.ai/docs/execution-providers/index.html",children:(0,t.jsx)(n.strong,{children:"ONNXRuntime official documentation"})})," for custom configurations."]}),"\n",(0,t.jsxs)(n.li,{children:["For installation-related issues, refer to the ",(0,t.jsx)(n.a,{href:"https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements",children:(0,t.jsx)(n.strong,{children:"ONNXRuntime Release Notes"})})]}),"\n"]})}),"\n",(0,t.jsx)(n.h3,{id:"2-modeltype",children:"2. ModelType"}),"\n",(0,t.jsxs)(n.p,{children:["ModelType is an enumeration type used to specify the type of model used by ",(0,t.jsx)(n.code,{children:"MRZScanner"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"It includes the following option:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"spotting"}),": Use an end-to-end model architecture."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["You can specify the model to use via the ",(0,t.jsx)(n.code,{children:"model_type"})," parameter."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from mrzscanner import MRZScanner\n\nmodel = MRZScanner(model_type=MRZScanner.spotting)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"3-modelcfg",children:"3. ModelCfg"}),"\n",(0,t.jsxs)(n.p,{children:["You can use ",(0,t.jsx)(n.code,{children:"list_models"})," to see all available models."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from mrzscanner import MRZScanner\n\nprint(MRZScanner().list_models())\n# >>> ['20240919']\n"})}),"\n",(0,t.jsxs)(n.p,{children:["You can specify the model configuration using the ",(0,t.jsx)(n.code,{children:"model_cfg"})," parameter."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"model = MRZScanner(model_cfg='20240919') # Use '20240919' configuration\n"})}),"\n",(0,t.jsx)(n.h2,{id:"inference",children:"Inference"}),"\n",(0,t.jsx)(n.p,{children:"The following are advanced configuration options during the inference phase:"}),"\n",(0,t.jsx)(n.h3,{id:"center-cropping",children:"Center Cropping"}),"\n",(0,t.jsx)(n.p,{children:"During the inference phase, setting appropriate advanced options can significantly affect the model's performance and results."}),"\n",(0,t.jsxs)(n.p,{children:["One critical parameter is ",(0,t.jsx)(n.code,{children:"do_center_crop"}),", which determines whether to perform center cropping during inference."]}),"\n",(0,t.jsx)(n.p,{children:"This setting is particularly important because images encountered in real-world applications are often not in standard square dimensions."}),"\n",(0,t.jsx)(n.p,{children:"In fact, image sizes and ratios vary, for example:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Photos taken with a smartphone commonly use a 9:16 aspect ratio;"}),"\n",(0,t.jsx)(n.li,{children:"Scanned documents usually follow the A4 paper ratio;"}),"\n",(0,t.jsx)(n.li,{children:"Webpage screenshots are typically 16:9;"}),"\n",(0,t.jsx)(n.li,{children:"Images taken via webcam are often 4:3."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"These non-square images, when directly used for inference without appropriate processing, often contain irrelevant areas or blank spaces, which negatively affect the model's inference performance. Center cropping helps effectively reduce these irrelevant areas by focusing on the central region of the image, thus improving inference accuracy and efficiency."}),"\n",(0,t.jsx)(n.p,{children:"Usage:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import capybara as cb\nfrom mrzscanner import MRZScanner\n\nmodel = MRZScanner()\n\nimg = cb.imread('path/to/image.jpg')\nresult = model(img, do_center_crop=True) # Use center cropping\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"When to Use"}),": Use center cropping when the image aspect ratio is not square and does not crop the MRZ region."]})}),"\n",(0,t.jsx)(n.h3,{id:"post-processing",children:"Post-Processing"}),"\n",(0,t.jsxs)(n.p,{children:["In addition to center cropping, we provide a post-processing option to further improve model accuracy. We offer a post-processing parameter, which is set to ",(0,t.jsx)(n.code,{children:"do_postprocess=True"})," by default."]}),"\n",(0,t.jsxs)(n.p,{children:["This is because the MRZ block has certain rules, such as country codes being uppercase letters, and gender being either ",(0,t.jsx)(n.code,{children:"M"})," or ",(0,t.jsx)(n.code,{children:"F"}),", etc. These rules can be used to standardize the MRZ block."]}),"\n",(0,t.jsx)(n.p,{children:"Thus, we perform manual corrections for blocks that can be standardized. For example, the following code snippet replaces possible misinterpreted digits with the correct characters in fields where numbers should not appear:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import re\n\ndef replace_digits(text: str):\n    text = re.sub('0', 'O', text)\n    text = re.sub('1', 'I', text)\n    text = re.sub('2', 'Z', text)\n    text = re.sub('4', 'A', text)\n    text = re.sub('5', 'S', text)\n    text = re.sub('8', 'B', text)\n    return text\n\nif doc_type == 3:  # TD1\n    if len(results[0]) != 30 or len(results[1]) != 30 or len(results[2]) != 30:\n        return [''], ErrorCodes.POSTPROCESS_FAILED_TD1_LENGTH\n    # Line1\n    doc = results[0][0:2]\n    country = replace_digits(results[0][2:5])\n"})}),"\n",(0,t.jsx)(n.p,{children:"While this post-processing step hasn't significantly improved accuracy in our cases, retaining this feature can still help correct erroneous recognition results in certain situations."}),"\n",(0,t.jsxs)(n.p,{children:["You can set ",(0,t.jsx)(n.code,{children:"do_postprocess"})," to ",(0,t.jsx)(n.code,{children:"False"})," during inference to get the raw recognition results."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"result, msg = model(img, do_postprocess=False)\n"})})]})}function p(e={}){let{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},50065:function(e,n,r){r.d(n,{Z:function(){return c},a:function(){return o}});var i=r(67294);let t={},s=i.createContext(t);function o(e){let n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);