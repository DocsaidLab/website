"use strict";(self.webpackChunkdocsaid_website=self.webpackChunkdocsaid_website||[]).push([["85806"],{4563:function(e,n,t){t.r(n),t.d(n,{assets:function(){return s},contentTitle:function(){return a},default:function(){return p},frontMatter:function(){return r},metadata:function(){return i},toc:function(){return u}});var i=t(95668),o=t(85893),l=t(50065);let r={slug:"file-crawler-python-implementation",title:"Python Implementation of a Web File Downloader",authors:"Z. Yuan",image:"/en/img/2024/0923.webp",tags:["Python","File Crawler"],description:"Implement a simple web file downloader."},a=void 0,s={authorsImageUrls:[void 0]},u=[];function c(e){let n={p:"p",...(0,l.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.p,{children:"We came across a webpage containing hundreds of PDF file links."}),"\n",(0,o.jsx)(n.p,{children:"As engineers, if we were to download them manually, it would be highly inefficient, right?"}),"\n",(0,o.jsx)(n.p,{children:"So, what we need here is a small script that will help us download all the files."})]})}function p(e={}){let{wrapper:n}={...(0,l.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},50065:function(e,n,t){t.d(n,{Z:function(){return a},a:function(){return r}});var i=t(67294);let o={},l=i.createContext(o);function r(e){let n=i.useContext(l);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(l.Provider,{value:n},e.children)}},95668:function(e){e.exports=JSON.parse('{"permalink":"/en/blog/file-crawler-python-implementation","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/09-23-file-crawler/index.md","title":"Python Implementation of a Web File Downloader","description":"Implement a simple web file downloader.","date":"2024-09-23T00:00:00.000Z","tags":[{"inline":true,"label":"Python","permalink":"/en/blog/tags/python"},{"inline":true,"label":"File Crawler","permalink":"/en/blog/tags/file-crawler"}],"readingTime":1.705,"hasTruncateMarker":true,"authors":[{"name":"Z. Yuan","title":"Dosaid maintainer, Full-Stack AI Engineer","url":"https://github.com/zephyr-sh","socials":{"github":"https://github.com/zephyr-sh","linkedin":"https://www.linkedin.com/in/ze-yuan-sh7/"},"imageURL":"https://github.com/zephyr-sh.png","key":"Z. Yuan","page":null}],"frontMatter":{"slug":"file-crawler-python-implementation","title":"Python Implementation of a Web File Downloader","authors":"Z. Yuan","image":"/en/img/2024/0923.webp","tags":["Python","File Crawler"],"description":"Implement a simple web file downloader."},"unlisted":false,"prevItem":{"title":"Update Docusaurus to 3.6.0","permalink":"/en/blog/update-docusaurus-to-3-6-0"},"nextItem":{"title":"Automatically Count Articles in Docusaurus Sidebar","permalink":"/en/blog/customized-docusaurus-sidebars-auto-count"}}')}}]);