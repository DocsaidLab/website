"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[95486],{54125:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>p,frontMatter:()=>c,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"mrzscanner/advance","title":"Advanced","description":"When invoking the MRZScanner model, you can adjust advanced settings by passing specific parameters.","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/mrzscanner/advance.md","sourceDirName":"mrzscanner","slug":"/mrzscanner/advance","permalink":"/en/docs/mrzscanner/advance","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedBy":"zephyr-sh","lastUpdatedAt":1726709795000,"sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"QuickStart","permalink":"/en/docs/mrzscanner/quickstart"},"next":{"title":"Model Design","permalink":"/en/docs/mrzscanner/model_arch"}}');var t=r(74848),s=r(28453);const c={sidebar_position:4},o="Advanced",a={},d=[{value:"Initialization",id:"initialization",level:2},{value:"1. Backend",id:"1-backend",level:3},{value:"2. ModelType",id:"2-modeltype",level:3},{value:"3. ModelCfg",id:"3-modelcfg",level:3},{value:"Inference",id:"inference",level:2},{value:"Center Cropping",id:"center-cropping",level:3},{value:"Post-Processing",id:"post-processing",level:3}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"advanced",children:"Advanced"})}),"\n",(0,t.jsxs)(n.p,{children:["When invoking the ",(0,t.jsx)(n.code,{children:"MRZScanner"})," model, you can adjust advanced settings by passing specific parameters."]}),"\n",(0,t.jsx)(n.h2,{id:"initialization",children:"Initialization"}),"\n",(0,t.jsx)(n.p,{children:"Here are the advanced settings options available during the initialization phase:"}),"\n",(0,t.jsx)(n.h3,{id:"1-backend",children:"1. Backend"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"Backend"})," is an enumerated type used to specify the computation backend for ",(0,t.jsx)(n.code,{children:"MRZScanner"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"It includes the following options:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"cpu"}),": Uses the CPU for computation."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"cuda"}),": Uses the GPU for computation (requires appropriate hardware support)."]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from docsaidkit import Backend\n\nmodel = MRZScanner(backend=Backend.cuda)  # Use CUDA backend\n#\n# or\n#\nmodel = MRZScanner(backend=Backend.cpu)  # Use CPU backend\n"})}),"\n",(0,t.jsx)(n.p,{children:"We use ONNXRuntime as the inference engine for the model. Although ONNXRuntime supports multiple backends (including CPU, CUDA, OpenCL, DirectX, TensorRT, and more), we\u2019ve streamlined the implementation for regular use environments, currently only offering CPU and CUDA backends. In addition to the necessary hardware support, using the CUDA backend also requires installing the corresponding CUDA drivers and toolkit."}),"\n",(0,t.jsx)(n.p,{children:"If CUDA is not installed on your system or if the version is incorrect, the CUDA backend will not function."}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["For other backend options, refer to the ",(0,t.jsx)(n.a,{href:"https://onnxruntime.ai/docs/execution-providers/index.html",children:(0,t.jsx)(n.strong,{children:"ONNXRuntime official documentation"})}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["For dependency installation details, check the ",(0,t.jsx)(n.a,{href:"https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements",children:(0,t.jsx)(n.strong,{children:"ONNXRuntime Release Notes"})}),"."]}),"\n"]})}),"\n",(0,t.jsx)(n.h3,{id:"2-modeltype",children:"2. ModelType"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"ModelType"})," is an enumerated type used to specify the type of model used by ",(0,t.jsx)(n.code,{children:"MRZScanner"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"It includes the following option:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"spotting"}),": Uses an end-to-end model architecture."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["You can specify the model using the ",(0,t.jsx)(n.code,{children:"model_type"})," parameter."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from mrzscanner import MRZScanner\n\nmodel = MRZScanner(model_type=MRZScanner.spotting)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"3-modelcfg",children:"3. ModelCfg"}),"\n",(0,t.jsxs)(n.p,{children:["You can view all available models using the ",(0,t.jsx)(n.code,{children:"list_models"})," function."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from mrzscanner import MRZScanner\n\nprint(MRZScanner().list_models())\n# >>> ['20240919']\n"})}),"\n",(0,t.jsxs)(n.p,{children:["You can specify the model configuration using the ",(0,t.jsx)(n.code,{children:"model_cfg"})," parameter."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"model = MRZScanner(model_cfg='20240919')  # Use the '20240919' configuration\n"})}),"\n",(0,t.jsx)(n.h2,{id:"inference",children:"Inference"}),"\n",(0,t.jsx)(n.p,{children:"Below are the advanced settings options available during the inference phase:"}),"\n",(0,t.jsx)(n.h3,{id:"center-cropping",children:"Center Cropping"}),"\n",(0,t.jsx)(n.p,{children:"During inference, adjusting certain advanced options can significantly impact the model\u2019s performance and accuracy."}),"\n",(0,t.jsxs)(n.p,{children:["One key parameter is ",(0,t.jsx)(n.code,{children:"do_center_crop"}),", which determines whether to apply center cropping during inference."]}),"\n",(0,t.jsx)(n.p,{children:"This setting is particularly important because real-world images are often not in a standard square format."}),"\n",(0,t.jsx)(n.p,{children:"In practice, images come in various sizes and aspect ratios, such as:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Photos taken with a smartphone, typically in a 9:16 aspect ratio."}),"\n",(0,t.jsx)(n.li,{children:"Scanned documents often in an A4 paper ratio."}),"\n",(0,t.jsx)(n.li,{children:"Webpage screenshots commonly in a 16:9 aspect ratio."}),"\n",(0,t.jsx)(n.li,{children:"Images taken with a webcam, usually in a 4:3 ratio."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"When these non-square images are directly fed into the model without appropriate preprocessing, irrelevant areas or blank spaces can negatively impact the model\u2019s inference performance. Applying center cropping can effectively reduce these irrelevant areas, allowing the model to focus on the central part of the image, thereby improving both accuracy and efficiency."}),"\n",(0,t.jsx)(n.p,{children:"Here\u2019s how to use it:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import docsaidkit as D\nfrom mrzscanner import MRZScanner\n\nmodel = MRZScanner()\n\nimg = D.imread('path/to/image.jpg')\nresult = model(img, do_center_crop=True)  # Apply center cropping\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"When to use"}),": Use center cropping when the image is not square and will not cut off the MRZ area."]})}),"\n",(0,t.jsx)(n.h3,{id:"post-processing",children:"Post-Processing"}),"\n",(0,t.jsxs)(n.p,{children:["In addition to center cropping, we offer a post-processing option to further improve model accuracy. By default, this parameter is set to ",(0,t.jsx)(n.code,{children:"do_postprocess=True"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["This is because MRZ blocks follow certain rules, such as country codes being restricted to uppercase letters, and gender being limited to ",(0,t.jsx)(n.code,{children:"M"})," and ",(0,t.jsx)(n.code,{children:"F"}),". These rules can be used to standardize MRZ blocks."]}),"\n",(0,t.jsx)(n.p,{children:"We perform manual corrections for the fields that can be standardized. For instance, in the following code snippet, we replace characters that were mistakenly recognized as digits in fields where only letters should appear:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import re\n\ndef replace_digits(text: str):\n    text = re.sub('0', 'O', text)\n    text = re.sub('1', 'I', text)\n    text = re.sub('2', 'Z', text)\n    text = re.sub('4', 'A', text)\n    text = re.sub('5', 'S', text)\n    text = re.sub('8', 'B', text)\n    return text\n\nif doc_type == 3:  # TD1\n    if len(results[0]) != 30 or len(results[1]) != 30 or len(results[2]) != 30:\n        return [''], ErrorCodes.POSTPROCESS_FAILED_TD1_LENGTH\n    # Line1\n    doc = results[0][0:2]\n    country = replace_digits(results[0][2:5])\n"})}),"\n",(0,t.jsx)(n.p,{children:"While in our case, this post-processing step did not significantly improve overall accuracy, it can help correct recognition errors in certain scenarios."}),"\n",(0,t.jsxs)(n.p,{children:["If you want to receive raw recognition results, you can set ",(0,t.jsx)(n.code,{children:"do_postprocess"})," to ",(0,t.jsx)(n.code,{children:"False"})," during inference:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"result, msg = model(img, do_postprocess=False)\n"})})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>c,x:()=>o});var i=r(96540);const t={},s=i.createContext(t);function c(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:c(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);