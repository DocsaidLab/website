"use strict";(self.webpackChunkdocsaid_website=self.webpackChunkdocsaid_website||[]).push([["87954"],{91873:function(s,e,a){a.r(e),a.d(e,{frontMatter:()=>r,default:()=>d,contentTitle:()=>t,assets:()=>m,toc:()=>c,metadata:()=>n});var n=JSON.parse('{"id":"transformers/albert/index","title":"[19.09] ALBERT","description":"A Compact Version of BERT","source":"@site/i18n/en/docusaurus-plugin-content-docs-papers/current/transformers/1909-albert/index.md","sourceDirName":"transformers/1909-albert","slug":"/transformers/albert/","permalink":"/en/papers/transformers/albert/","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedBy":"zephyr-sh","lastUpdatedAt":1739242156000,"frontMatter":{"title":"[19.09] ALBERT","authors":"Z. Yuan"},"sidebar":"papersSidebar","previous":{"title":"[19.07] RoBERTa","permalink":"/en/papers/transformers/roberta/"},"next":{"title":"[19.11] MQA","permalink":"/en/papers/transformers/mqa/"}}'),i=a(85893),l=a(50065);let r={title:"[19.09] ALBERT",authors:"Z. Yuan"},t=void 0,m={},c=[{value:"A Compact Version of BERT",id:"a-compact-version-of-bert",level:2},{value:"The Problem",id:"the-problem",level:2},{value:"The Solution",id:"the-solution",level:2},{value:"Factorized Embedding Parameterization",id:"factorized-embedding-parameterization",level:3},{value:"Cross-layer Parameter Sharing",id:"cross-layer-parameter-sharing",level:3},{value:"Sentence-Order Prediction Loss (SOP)",id:"sentence-order-prediction-loss-sop",level:3},{value:"Discussion",id:"discussion",level:2},{value:"BERT vs. ALBERT: Overall Comparison",id:"bert-vs-albert-overall-comparison",level:3},{value:"Embedding Parameter Factorization",id:"embedding-parameter-factorization",level:3},{value:"Cross-layer Parameter Sharing",id:"cross-layer-parameter-sharing-1",level:3},{value:"The Effectiveness of Sentence-Order Prediction",id:"the-effectiveness-of-sentence-order-prediction",level:3},{value:"State-of-the-art Results on NLU Tasks",id:"state-of-the-art-results-on-nlu-tasks",level:3},{value:"Conclusion",id:"conclusion",level:2}];function h(s){let e={a:"a",admonition:"admonition",annotation:"annotation",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",math:"math",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,l.a)(),...s.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h2,{id:"a-compact-version-of-bert",children:"A Compact Version of BERT"}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.a,{href:"https://arxiv.org/abs/1909.11942",children:(0,i.jsx)(e.strong,{children:"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"})})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.p,{children:"After BERT, there's still more BERT."}),"\n",(0,i.jsx)(e.h2,{id:"the-problem",children:"The Problem"}),"\n",(0,i.jsx)(e.p,{children:"BERT, with its massive 340M parameters, is computationally expensive to train. While BERT serves as a baseline, subsequent research models have increasingly grown in size, with models reaching billions of parameters."}),"\n",(0,i.jsx)(e.p,{children:"0.1B \u2794 0.3B \u2794 0.5B \u2794 1.0B \u2794 1.5B \u2794 \uFF1F\uFF1F\uFF1F"}),"\n",(0,i.jsx)(e.p,{children:"The authors of this paper argue that models cannot simply keep growing in size. The resources required for training such models are becoming prohibitive."}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.strong,{children:"We need a smaller BERT!"})}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"the-solution",children:"The Solution"}),"\n",(0,i.jsx)(e.p,{children:"ALBERT shares the same architecture as BERT but introduces several innovations to reduce model size and improve efficiency:"}),"\n",(0,i.jsx)(e.h3,{id:"factorized-embedding-parameterization",children:"Factorized Embedding Parameterization"}),"\n",(0,i.jsxs)(e.p,{children:["In BERT and its successors (such as XLNet and RoBERTa), the size of the WordPiece embeddings ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsx)(e.mrow,{children:(0,i.jsx)(e.mi,{children:"E"})}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E"})]})})}),(0,i.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"})]})})]})," and the hidden layers ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsx)(e.mrow,{children:(0,i.jsx)(e.mi,{children:"H"})}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"H"})]})})}),(0,i.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"})]})})]})," are tied together, with ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"\u2261"}),(0,i.jsx)(e.mi,{children:"H"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E \u2261 H"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"\u2261"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"})]})]})]}),"."]}),"\n",(0,i.jsx)(e.p,{children:"This has two main drawbacks:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"From a modeling perspective"}),": WordPiece embeddings primarily learn context-independent representations, whereas hidden layer embeddings focus on context-sensitive representations. By decoupling ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsx)(e.mrow,{children:(0,i.jsx)(e.mi,{children:"E"})}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E"})]})})}),(0,i.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"})]})})]})," and ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsx)(e.mrow,{children:(0,i.jsx)(e.mi,{children:"H"})}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"H"})]})})}),(0,i.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"})]})})]}),", the model can allocate parameters more effectively. Hidden layers should have larger capacity (",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"H"}),(0,i.jsx)(e.mo,{children:">"}),(0,i.jsx)(e.mi,{children:"E"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"H > E"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.7224em",verticalAlign:"-0.0391em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:">"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"})]})]})]}),")."]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"From a practical perspective"}),": In natural language processing, the vocabulary size ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsx)(e.mrow,{children:(0,i.jsx)(e.mi,{children:"V"})}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"V"})]})})}),(0,i.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.22222em"},children:"V"})]})})]})," is usually very large. If ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"\u2261"}),(0,i.jsx)(e.mi,{children:"H"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E \u2261 H"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"\u2261"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"})]})]})]}),", increasing ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsx)(e.mrow,{children:(0,i.jsx)(e.mi,{children:"H"})}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"H"})]})})}),(0,i.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"})]})})]})," significantly increases the size of the embedding matrix, which is of size ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"V"}),(0,i.jsx)(e.mo,{children:"\xd7"}),(0,i.jsx)(e.mi,{children:"E"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"V \\times E"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.7667em",verticalAlign:"-0.0833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.22222em"},children:"V"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"\xd7"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"})]})]})]}),". This can lead to models with billions of parameters, many of which are sparsely updated during training."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"ALBERT addresses this by factorizing the embedding parameters into two smaller matrices:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:["The one-hot vectors are first projected into a lower-dimensional embedding space of size ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsx)(e.mrow,{children:(0,i.jsx)(e.mi,{children:"E"})}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E"})]})})}),(0,i.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"})]})})]}),"."]}),"\n",(0,i.jsx)(e.li,{children:"They are then projected into the hidden layer space."}),"\n"]}),"\n",(0,i.jsxs)(e.p,{children:["This factorization reduces the number of embedding parameters from ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"O"}),(0,i.jsx)(e.mo,{stretchy:"false",children:"("}),(0,i.jsx)(e.mi,{children:"V"}),(0,i.jsx)(e.mo,{children:"\xd7"}),(0,i.jsx)(e.mi,{children:"H"}),(0,i.jsx)(e.mo,{stretchy:"false",children:")"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"O(V \\times H)"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"O"}),(0,i.jsx)(e.span,{className:"mopen",children:"("}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.22222em"},children:"V"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"\xd7"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"}),(0,i.jsx)(e.span,{className:"mclose",children:")"})]})]})]})," to ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"O"}),(0,i.jsx)(e.mo,{stretchy:"false",children:"("}),(0,i.jsx)(e.mi,{children:"V"}),(0,i.jsx)(e.mo,{children:"\xd7"}),(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"+"}),(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"\xd7"}),(0,i.jsx)(e.mi,{children:"H"}),(0,i.jsx)(e.mo,{stretchy:"false",children:")"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"O(V \\times E + E \\times H)"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"O"}),(0,i.jsx)(e.span,{className:"mopen",children:"("}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.22222em"},children:"V"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"\xd7"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.7667em",verticalAlign:"-0.0833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"+"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.7667em",verticalAlign:"-0.0833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"\xd7"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"}),(0,i.jsx)(e.span,{className:"mclose",children:")"})]})]})]}),"."]}),"\n",(0,i.jsxs)(e.p,{children:["When ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"H"}),(0,i.jsx)(e.mo,{children:">"}),(0,i.jsx)(e.mi,{children:"E"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"H > E"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.7224em",verticalAlign:"-0.0391em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:">"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"})]})]})]}),", the parameter count is significantly reduced!"]}),"\n",(0,i.jsxs)(e.admonition,{type:"tip",children:[(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Let\u2019s look at an example."})}),(0,i.jsxs)(e.p,{children:["Suppose the vocabulary size ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsx)(e.mrow,{children:(0,i.jsx)(e.mi,{children:"V"})}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"V"})]})})}),(0,i.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.22222em"},children:"V"})]})})]})," is 30,000 and the hidden layer size ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsx)(e.mrow,{children:(0,i.jsx)(e.mi,{children:"H"})}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"H"})]})})}),(0,i.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"})]})})]})," is 1,024. In BERT, where ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"\u2261"}),(0,i.jsx)(e.mi,{children:"H"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E \u2261 H"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"\u2261"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"})]})]})]}),", the embedding matrix has ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"V"}),(0,i.jsx)(e.mo,{children:"\xd7"}),(0,i.jsx)(e.mi,{children:"H"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"30"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"000"}),(0,i.jsx)(e.mo,{children:"\xd7"}),(0,i.jsx)(e.mn,{children:"1"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"024"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"30"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"720"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"000"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"V \\times H = 30,000 \\times 1,024 = 30,720,000"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.7667em",verticalAlign:"-0.0833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.22222em"},children:"V"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"\xd7"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(e.span,{className:"mord",children:"30"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"000"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"\xd7"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(e.span,{className:"mord",children:"1"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"024"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(e.span,{className:"mord",children:"30"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"720"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"000"})]})]})]})," parameters."]}),(0,i.jsxs)(e.p,{children:["In ALBERT, if we set the embedding size ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsx)(e.mrow,{children:(0,i.jsx)(e.mi,{children:"E"})}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E"})]})})}),(0,i.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"})]})})]})," to a smaller value like 128, the embedding matrix is factorized into two parts:"]}),(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:["The first part has ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"V"}),(0,i.jsx)(e.mo,{children:"\xd7"}),(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"30"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"000"}),(0,i.jsx)(e.mo,{children:"\xd7"}),(0,i.jsx)(e.mn,{children:"128"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"3"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"840"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"000"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"V \\times E = 30,000 \\times 128 = 3,840,000"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.7667em",verticalAlign:"-0.0833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.22222em"},children:"V"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"\xd7"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(e.span,{className:"mord",children:"30"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"000"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"\xd7"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,i.jsx)(e.span,{className:"mord",children:"128"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(e.span,{className:"mord",children:"3"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"840"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"000"})]})]})]})," parameters."]}),"\n",(0,i.jsxs)(e.li,{children:["The second part has ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"\xd7"}),(0,i.jsx)(e.mi,{children:"H"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"128"}),(0,i.jsx)(e.mo,{children:"\xd7"}),(0,i.jsx)(e.mn,{children:"1"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"024"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"131"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"072"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E \\times H = 128 \\times 1,024 = 131,072"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.7667em",verticalAlign:"-0.0833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"\xd7"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,i.jsx)(e.span,{className:"mord",children:"128"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"\xd7"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(e.span,{className:"mord",children:"1"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"024"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(e.span,{className:"mord",children:"131"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"072"})]})]})]})," parameters."]}),"\n"]}),(0,i.jsxs)(e.p,{children:["So, ALBERT\u2019s total embedding parameter count is ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mn,{children:"3"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"840"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"000"}),(0,i.jsx)(e.mo,{children:"+"}),(0,i.jsx)(e.mn,{children:"131"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"072"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"3"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"971"}),(0,i.jsx)(e.mo,{separator:"true",children:","}),(0,i.jsx)(e.mn,{children:"072"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"3,840,000 + 131,072 = 3,971,072"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(e.span,{className:"mord",children:"3"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"840"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"000"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(e.span,{className:"mbin",children:"+"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(e.span,{className:"mord",children:"131"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"072"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(e.span,{className:"mord",children:"3"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"971"}),(0,i.jsx)(e.span,{className:"mpunct",children:","}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(e.span,{className:"mord",children:"072"})]})]})]}),", a significant reduction from BERT\u2019s 30,720,000 parameters."]}),(0,i.jsx)(e.p,{children:"This not only reduces memory requirements but also improves computational efficiency."})]}),"\n",(0,i.jsx)(e.h3,{id:"cross-layer-parameter-sharing",children:"Cross-layer Parameter Sharing"}),"\n",(0,i.jsx)(e.p,{children:"Several prior works have focused on improving model parameter efficiency:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Dehghani et al. (2018) with Universal Transformer (UT)"}),":"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"https://arxiv.org/abs/1807.03819",children:(0,i.jsx)(e.strong,{children:"[18.07] Universal transformers"})})}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"They proposed a Universal Transformer and found it outperformed standard Transformers. Universal Transformer shares parameters across layers, a similar approach to ALBERT, enhancing the model\u2019s learning capabilities, particularly with respect to time-stepping between different layers."}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Bai et al. (2019) with Deep Equilibrium Models (DQE)"}),":"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"https://arxiv.org/abs/1909.01377",children:(0,i.jsx)(e.strong,{children:"[19.09] Deep equilibrium models"})})}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:'Their research showed that Deep Equilibrium Models (DQE) reach an "equilibrium" where the input and output embeddings for a layer become identical. This means that the model\'s representational power stabilizes at this equilibrium point, with no significant changes in the output.'}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(e.p,{children:["ALBERT takes inspiration from these approaches, implementing ",(0,i.jsx)(e.strong,{children:"cross-layer parameter sharing"})," in several ways:"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Sharing only the parameters of the feed-forward network (FFN) across layers."}),"\n",(0,i.jsx)(e.li,{children:"Sharing only the attention mechanism parameters."}),"\n"]}),"\n",(0,i.jsxs)(e.p,{children:["By default, ALBERT shares ",(0,i.jsx)(e.strong,{children:"all parameters across all layers"}),", unless otherwise specified. Through measuring L2 distance and cosine similarity, the authors analyzed the embedding behavior, showing that ALBERT\u2019s embeddings exhibit ",(0,i.jsx)(e.strong,{children:"oscillating dynamics"}),", unlike the DQE model that converges."]}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{alt:"albert cross-layer parameter sharing",src:a(57525).Z+"",width:"1438",height:"484"})}),"\n",(0,i.jsx)(e.p,{children:"ALBERT\u2019s embeddings don\u2019t reach a stable equilibrium like DQE, but rather maintain dynamic changes. These oscillations could offer unique advantages for ALBERT\u2019s design and performance."}),"\n",(0,i.jsx)(e.h3,{id:"sentence-order-prediction-loss-sop",children:"Sentence-Order Prediction Loss (SOP)"}),"\n",(0,i.jsx)(e.p,{children:"In addition to the MLM loss, BERT also used an additional NSP (Next Sentence Prediction) loss. However, subsequent studies found that NSP was ineffective and removed it."}),"\n",(0,i.jsx)(e.p,{children:"The authors hypothesize that NSP\u2019s inefficacy comes from the task being too simple compared to MLM. NSP combines topic prediction and coherence prediction, with topic prediction being easier to learn and overlapping with MLM learning."}),"\n",(0,i.jsxs)(e.p,{children:["The authors emphasize that modeling sentence-level coherence is important for language understanding and propose the ",(0,i.jsx)(e.strong,{children:"Sentence-Order Prediction (SOP)"})," loss:"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Positive examples are the same as BERT, two consecutive segments from the same document."}),"\n",(0,i.jsx)(e.li,{children:"Negative examples are also two consecutive segments from the same document, but with their order swapped."}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"The model must predict which segment comes first, forcing it to learn more fine-grained distinctions in coherence."}),"\n",(0,i.jsx)(e.h2,{id:"discussion",children:"Discussion"}),"\n",(0,i.jsx)(e.h3,{id:"bert-vs-albert-overall-comparison",children:"BERT vs. ALBERT: Overall Comparison"}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{alt:"albert comparison",src:a(81318).Z+"",width:"1722",height:"350"})}),"\n",(0,i.jsx)(e.p,{children:"ALBERT\u2019s design choices primarily focus on improving parameter efficiency."}),"\n",(0,i.jsx)(e.p,{children:"As shown above, ALBERT-xxlarge uses only about 70% of BERT-large's parameters, yet it outperforms BERT in multiple downstream tasks, including SQuAD v1.1 (+1.9%), SQuAD v2.0 (+3.1%), MNLI (+1.4%), SST-2 (+2.2%), and RACE (+8.4%)."}),"\n",(0,i.jsx)(e.p,{children:"Additionally, ALBERT\u2019s training throughput surpasses BERT\u2019s. On the same TPU setup, ALBERT-large processes data 1.7 times faster than BERT-large, though ALBERT-xxlarge is slower, taking roughly three times as long as BERT-large due to its larger size."}),"\n",(0,i.jsx)(e.h3,{id:"embedding-parameter-factorization",children:"Embedding Parameter Factorization"}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{alt:"albert embedding size",src:a(72337).Z+"",width:"1668",height:"446"})}),"\n",(0,i.jsxs)(e.p,{children:["The table above shows the impact of varying the embedding size ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsx)(e.mrow,{children:(0,i.jsx)(e.mi,{children:"E"})}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E"})]})})}),(0,i.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"})]})})]})," on ALBERT-base."]}),"\n",(0,i.jsxs)(e.p,{children:["For non-shared parameters (BERT-style), a larger embedding size yields slight performance improvements. However, in the fully parameter-shared (ALBERT-style) setup, ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"128"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E = 128"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,i.jsx)(e.span,{className:"mord",children:"128"})]})]})]})," performs best."]}),"\n",(0,i.jsxs)(e.p,{children:["Based on these results, the authors decided to use an embedding size of ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"128"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E = 128"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,i.jsx)(e.span,{className:"mord",children:"128"})]})]})]})," in future model expansions."]}),"\n",(0,i.jsx)(e.h3,{id:"cross-layer-parameter-sharing-1",children:"Cross-layer Parameter Sharing"}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{alt:"albert cross-layer parameter sharing",src:a(1190).Z+"",width:"1612",height:"388"})}),"\n",(0,i.jsx)(e.p,{children:"The table above presents the results of experiments with different cross-layer parameter sharing strategies:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:["Using ALBERT-base configuration (",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"768"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E = 768"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,i.jsx)(e.span,{className:"mord",children:"768"})]})]})]})," and ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"128"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E = 128"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,i.jsx)(e.span,{className:"mord",children:"128"})]})]})]}),")."]}),"\n"]}),"\n",(0,i.jsxs)(e.p,{children:["Fully sharing parameters impacts performance slightly in both settings, but with ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"128"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E = 128"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,i.jsx)(e.span,{className:"mord",children:"128"})]})]})]}),", the drop is minimal (-1.5). With ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"768"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E = 768"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,i.jsx)(e.span,{className:"mord",children:"768"})]})]})]}),", the drop is more significant (-2.5)."]}),"\n",(0,i.jsxs)(e.p,{children:["Most of the performance drop comes from sharing FFN parameters. Sharing attention parameters has almost no impact on performance with ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"128"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E = 128"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,i.jsx)(e.span,{className:"mord",children:"128"})]})]})]})," (+0.1) but has a small negative impact with ",(0,i.jsxs)(e.span,{className:"katex",children:[(0,i.jsx)(e.span,{className:"katex-mathml",children:(0,i.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(e.semantics,{children:[(0,i.jsxs)(e.mrow,{children:[(0,i.jsx)(e.mi,{children:"E"}),(0,i.jsx)(e.mo,{children:"="}),(0,i.jsx)(e.mn,{children:"768"})]}),(0,i.jsx)(e.annotation,{encoding:"application/x-tex",children:"E = 768"})]})})}),(0,i.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(e.span,{className:"mrel",children:"="}),(0,i.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(e.span,{className:"base",children:[(0,i.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,i.jsx)(e.span,{className:"mord",children:"768"})]})]})]})," (-0.7)."]}),"\n",(0,i.jsx)(e.p,{children:"While dividing layers into groups and sharing parameters within each group could be considered, the experiments show that the smaller the group, the better the performance, but the more parameters are required."}),"\n",(0,i.jsx)(e.p,{children:"Therefore, the authors ultimately chose the full parameter-sharing strategy as the default."}),"\n",(0,i.jsx)(e.h3,{id:"the-effectiveness-of-sentence-order-prediction",children:"The Effectiveness of Sentence-Order Prediction"}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{alt:"albert sentence order prediction",src:a(42097).Z+"",width:"1864",height:"298"})}),"\n",(0,i.jsx)(e.p,{children:"The authors compared three types of cross-sentence loss conditions:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"None (XLNet and RoBERTa style)."}),"\n",(0,i.jsx)(e.li,{children:"NSP (BERT style)."}),"\n",(0,i.jsx)(e.li,{children:"SOP (ALBERT style)."}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"Results show that NSP has no discriminative power for SOP tasks (accuracy of 52.0%, close to random), suggesting NSP mainly learns topic shifts. SOP performs well on the NSP task (78.9% accuracy) and even better on SOP tasks (86.5%)."}),"\n",(0,i.jsx)(e.p,{children:"Moreover, SOP significantly improves downstream performance on multi-sentence encoding tasks: SQuAD1.1 increases by 1%, SQuAD2.0 by 2%, and RACE by 1.7%."}),"\n",(0,i.jsx)(e.h3,{id:"state-of-the-art-results-on-nlu-tasks",children:"State-of-the-art Results on NLU Tasks"}),"\n",(0,i.jsx)("figure",{children:(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.img,{alt:"albert nlu",src:a(76921).Z+"",width:"1426",height:"522"}),"\n",(0,i.jsx)("figcaption",{children:"ALBERT's performance on the GLUE benchmark"})]})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)("figure",{children:(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.img,{alt:"albert nlu",src:a(37718).Z+"",width:"1496",height:"622"}),"\n",(0,i.jsx)("figcaption",{children:"ALBERT's performance on SQuAD and RACE benchmarks"})]})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsxs)(e.p,{children:["Finally, the authors present state-of-the-art results in two fine-tuning settings: ",(0,i.jsx)(e.strong,{children:"Single-model"})," and ",(0,i.jsx)(e.strong,{children:"Ensemble"})," models:"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Single-model"}),":","\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Median results of five runs are reported on the development set."}),"\n",(0,i.jsx)(e.li,{children:"ALBERT uses the best configuration: ALBERT-xxlarge with both MLM and SOP loss functions and no dropout."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Ensemble models"}),":","\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Checkpoints are selected based on development set performance, ranging from 6 to 17 depending on the task."}),"\n",(0,i.jsx)(e.li,{children:'On GLUE and RACE benchmarks, the predictions of multiple models are averaged, while in SQuAD, the prediction scores for multiple spans and the "unanswerable" decisions are averaged.'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"Both single and ensemble models demonstrate significant improvements over the previous state-of-the-art on three benchmarks:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"GLUE"}),": ALBERT achieves a score of 89.4."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"SQuAD 2.0"}),": F1 score reaches 92.2."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"RACE"}),": Accuracy reaches 89.4."]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"ALBERT's performance on RACE is particularly impressive, with large gains over other models:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"+17.4% over BERT."}),"\n",(0,i.jsx)(e.li,{children:"+7.6% over XLNet."}),"\n",(0,i.jsx)(e.li,{children:"+6.2% over RoBERTa."}),"\n",(0,i.jsx)(e.li,{children:"+5.3% over DCMI+."}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsx)(e.p,{children:"ALBERT introduces innovative ways to improve parameter efficiency and introduces a more targeted loss function that enhances cross-sentence understanding. Its design has a profound impact on future large language models."}),"\n",(0,i.jsx)(e.p,{children:"For those developing language models with limited resources, ALBERT is an excellent option!"})]})}function d(s={}){let{wrapper:e}={...(0,l.a)(),...s.components};return e?(0,i.jsx)(e,{...s,children:(0,i.jsx)(h,{...s})}):h(s)}},57525:function(s,e,a){a.d(e,{Z:()=>n});let n=a.p+"assets/images/img1-686d86f52340b4f89d2b2b345f131484.jpg"},76921:function(s,e,a){a.d(e,{Z:()=>n});let n=a.p+"assets/images/img10-64a76be7cb3f2964977fe9fa0c4e01a6.jpg"},37718:function(s,e,a){a.d(e,{Z:()=>n});let n=a.p+"assets/images/img11-0f582f0cb077fc0593372bd5a7a8f780.jpg"},81318:function(s,e,a){a.d(e,{Z:()=>n});let n=a.p+"assets/images/img2-5334c010a4648b4e4668f456d79fd1b9.jpg"},72337:function(s,e,a){a.d(e,{Z:()=>n});let n=a.p+"assets/images/img3-7ea5a08de8f5d2eb05aecd6994145ca8.jpg"},1190:function(s,e,a){a.d(e,{Z:()=>n});let n=a.p+"assets/images/img4-f2f86eaaf7bfa6e42c2c96c99eacd71c.jpg"},42097:function(s,e,a){a.d(e,{Z:()=>n});let n=a.p+"assets/images/img5-b6b86bde188999fe8745a83f0472c5cf.jpg"},50065:function(s,e,a){a.d(e,{Z:()=>t,a:()=>r});var n=a(67294);let i={},l=n.createContext(i);function r(s){let e=n.useContext(l);return n.useMemo(function(){return"function"==typeof s?s(e):{...e,...s}},[e,s])}function t(s){let e;return e=s.disableParentContext?"function"==typeof s.components?s.components(i):s.components||i:r(s.components),n.createElement(l.Provider,{value:e},s.children)}}}]);