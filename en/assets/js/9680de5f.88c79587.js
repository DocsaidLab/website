"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[6490],{33194:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>h,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var a=n(74848),t=n(28453);const i={},r="[16.08] DenseNet",l={id:"densenet/index",title:"[16.08] DenseNet",description:"Connecting Everything",source:"@site/i18n/en/docusaurus-plugin-content-docs-papers/current/1608-densenet/index.md",sourceDirName:"1608-densenet",slug:"/densenet/",permalink:"/en/papers/densenet/",draft:!1,unlisted:!1,tags:[],version:"current",lastUpdatedBy:"zephyr-sh",lastUpdatedAt:1722471113e3,frontMatter:{},sidebar:"papersSidebar",previous:{title:"[14.09] VGG",permalink:"/en/papers/vgg/"},next:{title:"[16.11] ResNeXt",permalink:"/en/papers/resnext/"}},h={},c=[{value:"Connecting Everything",id:"connecting-everything",level:2},{value:"Defining the Problem",id:"defining-the-problem",level:2},{value:"Solving the Problem",id:"solving-the-problem",level:2},{value:"Network Architecture",id:"network-architecture",level:3},{value:"Average Pooling",id:"average-pooling",level:3},{value:"Growth Rate",id:"growth-rate",level:3},{value:"Bottleneck Layers",id:"bottleneck-layers",level:3},{value:"Compression",id:"compression",level:3},{value:"Implementation Details",id:"implementation-details",level:3},{value:"Discussion",id:"discussion",level:2},{value:"Experimental Results",id:"experimental-results",level:3},{value:"Compact Models",id:"compact-models",level:3},{value:"Feature Reuse",id:"feature-reuse",level:3},{value:"Conclusion",id:"conclusion",level:2}];function o(e){const s={a:"a",admonition:"admonition",annotation:"annotation",h1:"h1",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",math:"math",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",msub:"msub",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(s.h1,{id:"1608-densenet",children:"[16.08] DenseNet"}),"\n",(0,a.jsx)(s.h2,{id:"connecting-everything",children:"Connecting Everything"}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/1608.06993",children:(0,a.jsx)(s.strong,{children:"Densely Connected Convolutional Networks"})})}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.admonition,{type:"info",children:(0,a.jsx)(s.p,{children:"The following content has been compiled by ChatGPT-4 and manually proofread, edited, and supplemented."})}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.p,{children:"As CNNs have become deeper, gradient information from input images often vanishes, making training difficult."}),"\n",(0,a.jsx)(s.p,{children:"Various studies began exploring how to improve the flow of information through deep networks, one of the most significant being ResNet."}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/1512.03385",children:(0,a.jsx)(s.strong,{children:"Deep Residual Learning for Image Recognition"})})}),"\n"]}),"\n",(0,a.jsx)(s.h2,{id:"defining-the-problem",children:"Defining the Problem"}),"\n",(0,a.jsx)(s.p,{children:"ResNet uses additive identity mappings to ensure information preservation, but many layers contribute very little:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/1603.09382",children:(0,a.jsx)(s.strong,{children:"Deep networks with stochastic depth"})})}),"\n"]}),"\n",(0,a.jsxs)(s.admonition,{type:"tip",children:[(0,a.jsx)(s.p,{children:"This issue will be revisited in MobileNetV2. We\u2019ll discuss it in detail when we read that paper."}),(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:(0,a.jsx)(s.a,{href:"/en/papers/mobilenet-v2/",children:(0,a.jsx)(s.strong,{children:"Mobilenet-V2: Bottleneck Inside the Refinement"})})}),"\n"]})]}),"\n",(0,a.jsx)(s.p,{children:"Besides ResNet, another famous method is Highway Networks:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/1505.00387",children:(0,a.jsx)(s.strong,{children:"Highway Networks"})})}),"\n"]}),"\n",(0,a.jsx)(s.p,{children:"This paper doesn\u2019t aim to refute the above research but proposes a new connection method to make information flow more efficiently through the network."}),"\n",(0,a.jsx)(s.h2,{id:"solving-the-problem",children:"Solving the Problem"}),"\n",(0,a.jsx)(s.h3,{id:"network-architecture",children:"Network Architecture"}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"DenseNet",src:n(8373).A+"",width:"1184",height:"828"})}),"\n",(0,a.jsx)(s.p,{children:"This diagram is very intuitive but can be misleading:"}),"\n",(0,a.jsx)(s.p,{children:"This is not the entire network architecture; it describes the structure of a Dense Block."}),"\n",(0,a.jsx)(s.p,{children:"In this structure, each layer\u2019s input is the concatenation of all previous layers' outputs, and there is no downsampling."}),"\n",(0,a.jsx)(s.p,{children:"The authors proposed this connection method to address the issue of minimal contributions from the final layers in ResNet:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"If the information can't flow to the end, let\u2019s connect every layer together!"}),"\n"]}),"\n",(0,a.jsx)(s.h3,{id:"average-pooling",children:"Average Pooling"}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"Pooling Layers",src:n(67882).A+"",width:"1648",height:"266"})}),"\n",(0,a.jsx)(s.p,{children:"As shown above."}),"\n",(0,a.jsx)(s.p,{children:"In Convolutional Neural Networks (CNNs), downsampling layers (such as pooling layers) are essential for changing the feature map size."}),"\n",(0,a.jsx)(s.p,{children:"To effectively downsample, the authors divided the network into multiple densely connected Dense Blocks."}),"\n",(0,a.jsx)(s.p,{children:"Between each Dense Block, there are transition layers that perform convolution and pooling operations."}),"\n",(0,a.jsx)(s.p,{children:"The entire transition layer consists of Batch Normalization and a 1\xd71 convolutional layer, followed by a 2\xd72 average pooling layer."}),"\n",(0,a.jsx)(s.h3,{id:"growth-rate",children:"Growth Rate"}),"\n",(0,a.jsx)(s.p,{children:"An important feature of DenseNet is the growth rate."}),"\n",(0,a.jsxs)(s.p,{children:["In DenseNet, if each function ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"H"}),(0,a.jsx)(s.mi,{children:"l"})]})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"H_l"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8333em",verticalAlign:"-0.15em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.08125em"},children:"H"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0813em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]})]})})]})," produces k feature maps, then the ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"l"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"l"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.01968em"},children:"l"})]})})]}),"-th layer has ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"k"}),(0,a.jsx)(s.mn,{children:"0"})]}),(0,a.jsx)(s.mo,{children:"+"}),(0,a.jsx)(s.mi,{children:"k"}),(0,a.jsx)(s.mo,{children:"\xd7"}),(0,a.jsx)(s.mo,{stretchy:"false",children:"("}),(0,a.jsx)(s.mi,{children:"l"}),(0,a.jsx)(s.mo,{children:"\u2212"}),(0,a.jsx)(s.mn,{children:"1"}),(0,a.jsx)(s.mo,{stretchy:"false",children:")"})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"k_0 + k \\times (l - 1)"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8444em",verticalAlign:"-0.15em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.03148em"},children:"k"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3011em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0315em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"0"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,a.jsx)(s.span,{className:"mbin",children:"+"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.7778em",verticalAlign:"-0.0833em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.03148em"},children:"k"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,a.jsx)(s.span,{className:"mbin",children:"\xd7"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,a.jsx)(s.span,{className:"mopen",children:"("}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.01968em"},children:"l"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,a.jsx)(s.span,{className:"mbin",children:"\u2212"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,a.jsx)(s.span,{className:"mord",children:"1"}),(0,a.jsx)(s.span,{className:"mclose",children:")"})]})]})]})," input feature maps, where ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"k"}),(0,a.jsx)(s.mn,{children:"0"})]})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"k_0"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8444em",verticalAlign:"-0.15em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.03148em"},children:"k"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3011em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0315em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"0"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]})]})})]})," is the number of channels in the input layer."]}),"\n",(0,a.jsx)(s.p,{children:"A significant difference between DenseNet and other network architectures is that it can have very narrow layers, such as k = 12. This hyperparameter k is known as the network\u2019s growth rate."}),"\n",(0,a.jsx)(s.p,{children:'Research shows that relatively small growth rates can achieve state-of-the-art results on the tested datasets. This is because each layer can access all previous feature maps within its block, leveraging the network\'s "collective knowledge." The growth rate controls the amount of new information each layer contributes to the global state, which can be accessed from any position in the network without duplicating it layer by layer.'}),"\n",(0,a.jsx)(s.h3,{id:"bottleneck-layers",children:"Bottleneck Layers"}),"\n",(0,a.jsx)(s.p,{children:"Although each layer only produces k output feature maps, it typically has more inputs."}),"\n",(0,a.jsx)(s.p,{children:"Research suggests introducing a 1\xd71 convolution before each 3\xd73 convolution as a bottleneck layer to reduce the number of input feature maps, thereby improving computational efficiency."}),"\n",(0,a.jsx)(s.p,{children:"This design is particularly effective for DenseNet, leading the authors to refer to such a network as DenseNet-B."}),"\n",(0,a.jsx)(s.p,{children:"The bottleneck layer structure is: BN-ReLU-Conv(1\xd71)-BN-ReLU-Conv(3\xd73). In experiments, each 1\xd71 convolution produces 4k feature maps."}),"\n",(0,a.jsx)(s.h3,{id:"compression",children:"Compression"}),"\n",(0,a.jsx)(s.p,{children:"To further enhance model compactness, the authors designed a method to reduce the number of feature maps in the transition layers."}),"\n",(0,a.jsxs)(s.p,{children:["If a Dense Block contains m feature maps, the subsequent transition layer will produce ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"b"}),(0,a.jsx)(s.mi,{children:"\u03b8"}),(0,a.jsx)(s.mi,{children:"m"}),(0,a.jsx)(s.mi,{children:"c"})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"b\u03b8mc"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"b"}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"\u03b8"}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"m"}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"c"})]})})]})," output feature maps, where ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mn,{children:"0"}),(0,a.jsx)(s.mo,{children:"<"}),(0,a.jsx)(s.mi,{children:"\u03b8"}),(0,a.jsx)(s.mo,{children:"\u2264"}),(0,a.jsx)(s.mn,{children:"1"})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"0 < \u03b8 \u2264 1"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6835em",verticalAlign:"-0.0391em"}}),(0,a.jsx)(s.span,{className:"mord",children:"0"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"<"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8304em",verticalAlign:"-0.136em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"\u03b8"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"\u2264"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,a.jsx)(s.span,{className:"mord",children:"1"})]})]})]})," is called the compression factor. When ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"\u03b8"}),(0,a.jsx)(s.mo,{children:"="}),(0,a.jsx)(s.mn,{children:"1"})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\u03b8 = 1"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"\u03b8"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"="}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,a.jsx)(s.span,{className:"mord",children:"1"})]})]})]}),", the number of feature maps in the transition layer remains unchanged."]}),"\n",(0,a.jsxs)(s.p,{children:["The authors referred to DenseNets with ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"\u03b8"}),(0,a.jsx)(s.mo,{children:"<"}),(0,a.jsx)(s.mn,{children:"1"})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\u03b8 < 1"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.7335em",verticalAlign:"-0.0391em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"\u03b8"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"<"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,a.jsx)(s.span,{className:"mord",children:"1"})]})]})]})," as DenseNet-C and set ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"\u03b8"}),(0,a.jsx)(s.mo,{children:"="}),(0,a.jsx)(s.mn,{children:"0.5"})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\u03b8 = 0.5"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"\u03b8"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"="}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,a.jsx)(s.span,{className:"mord",children:"0.5"})]})]})]})," in their experiments. When using both bottleneck layers and transition layers with ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"\u03b8"}),(0,a.jsx)(s.mo,{children:"<"}),(0,a.jsx)(s.mn,{children:"1"})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\u03b8 < 1"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.7335em",verticalAlign:"-0.0391em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"\u03b8"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"<"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,a.jsx)(s.span,{className:"mord",children:"1"})]})]})]}),", the model is called DenseNet-BC."]}),"\n",(0,a.jsx)(s.h3,{id:"implementation-details",children:"Implementation Details"}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"DenseNet Architecture",src:n(80039).A+"",width:"1498",height:"724"})}),"\n",(0,a.jsx)(s.p,{children:"For all datasets except ImageNet, the authors experimented with DenseNets having three Dense Blocks."}),"\n",(0,a.jsx)(s.p,{children:"Each Dense Block contained the same number of layers. Before entering the first Dense Block, the input image underwent a convolution with 16 (or twice the growth rate for DenseNet-BC) output channels. For convolutions with kernel size 3\xd73, each side of the input was zero-padded to maintain the feature map size."}),"\n",(0,a.jsx)(s.p,{children:"Between two consecutive Dense Blocks, the authors used a 1\xd71 convolution followed by a 2\xd72 average pooling as the transition layer. At the end of the last Dense Block, global average pooling was performed, followed by a softmax classifier. The feature map sizes in the three Dense Blocks were 32\xd732, 16\xd716, and 8\xd78, respectively."}),"\n",(0,a.jsx)(s.p,{children:"The authors used the following basic DenseNet configurations in their experiments:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"L = 40, k = 12"}),"\n",(0,a.jsx)(s.li,{children:"L = 100, k = 12"}),"\n",(0,a.jsx)(s.li,{children:"L = 100, k = 24"}),"\n"]}),"\n",(0,a.jsx)(s.p,{children:"For DenseNet-BC, the configurations were:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"L = 100, k = 12"}),"\n",(0,a.jsx)(s.li,{children:"L = 250, k = 24"}),"\n",(0,a.jsx)(s.li,{children:"L = 190, k = 40"}),"\n"]}),"\n",(0,a.jsx)(s.p,{children:"In experiments on the ImageNet dataset, the authors used a DenseNet-BC structure with four Dense Blocks, experimenting with 224\xd7224 input images."}),"\n",(0,a.jsx)(s.p,{children:"The initial convolution layer had 2k convolutions of size 7\xd77 with a stride of 2."}),"\n",(0,a.jsx)(s.p,{children:"The number of feature maps in all other layers also depended on the setting of k."}),"\n",(0,a.jsx)(s.h2,{id:"discussion",children:"Discussion"}),"\n",(0,a.jsx)(s.h3,{id:"experimental-results",children:"Experimental Results"}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"DenseNet Results",src:n(25628).A+"",width:"1348",height:"502"})}),"\n",(0,a.jsx)(s.p,{children:"The above image plots the single-crop top-1 validation errors of DenseNets and ResNets as functions of the number of parameters and FLOPs, showing the differences in performance and computational resource usage."}),"\n",(0,a.jsx)(s.p,{children:"In the left plot, we see the relationship between validation error and the number of parameters for DenseNet and ResNet. DenseNet-201, with around 20M parameters, has a validation error similar to ResNet-101, which has over 40M parameters. This indicates that DenseNet can achieve similar performance to ResNet with fewer parameters."}),"\n",(0,a.jsx)(s.p,{children:"The right plot shows the relationship between validation error and the number of FLOPs. In this plot, we see that a DenseNet with the same computational load as ResNet-50 performs comparably to ResNet-101, which requires twice the computational load. This further demonstrates DenseNet\u2019s computational efficiency, achieving high performance with relatively fewer computational resources."}),"\n",(0,a.jsx)(s.h3,{id:"compact-models",children:"Compact Models"}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"Compactness",src:n(69977).A+"",width:"1226",height:"490"})}),"\n",(0,a.jsx)(s.p,{children:"Any feature map learned by a DenseNet layer can be accessed by all subsequent layers, a direct result of input concatenation."}),"\n",(0,a.jsx)(s.p,{children:"This encourages feature reuse throughout the network, leading to a more compact model."}),"\n",(0,a.jsx)(s.p,{children:"The two charts on the left show an experiment comparing the parameter efficiency of all DenseNet variants (left) and similar ResNet architectures (right). The authors trained several small networks of different depths on C10+ and plotted their test accuracy as a function of network parameters. Results show that DenseNet-BC is the most parameter-efficient among all DenseNet variants."}),"\n",(0,a.jsx)(s.p,{children:"Moreover, DenseNet-BC requires only about one-third the parameters of ResNet to achieve the same accuracy."}),"\n",(0,a.jsx)(s.p,{children:"A DenseNet-BC with only 0.8M trainable parameters can achieve accuracy comparable to a 1001-layer ResNet (10.2M parameters)."}),"\n",(0,a.jsx)(s.h3,{id:"feature-reuse",children:"Feature Reuse"}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"Feature Reuse",src:n(54958).A+"",width:"1224",height:"528"})}),"\n",(0,a.jsx)(s.p,{children:"The DenseNet design allows layers to access feature maps from all preceding layers (through transition layers)."}),"\n",(0,a.jsx)(s.p,{children:"The authors conducted an experiment to investigate whether the trained network utilized this feature. They trained a DenseNet (L=40, k=12) and calculated the weights assigned by each convolutional layer within the block to other layers."}),"\n",(0,a.jsx)(s.p,{children:"The image above shows heatmaps for all three Dense Blocks. The way to read this is: the horizontal axis represents the Target layer, the vertical axis represents the Source layer, and the color indicates the weight size, with darker colors indicating larger weights."}),"\n",(0,a.jsx)(s.p,{children:"Several features can be observed from the image:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"All layers distribute their weights across multiple inputs within the same block, indicating that features extracted by earlier layers are directly used by deeper layers."}),"\n",(0,a.jsx)(s.li,{children:"Transition layers distribute their weights across all layers in the previous Dense Block, with information flowing through a few indirect paths from the first layer to the last."}),"\n",(0,a.jsx)(s.li,{children:"Layers within the second and third Dense Blocks consistently assign minimal weights to the outputs of transition layers (the top row of the triangle), suggesting that transition layers output many redundant features."}),"\n",(0,a.jsx)(s.li,{children:"The final classification layer predominantly uses the final feature map, indicating that the network generates some higher-level features in the later stages."}),"\n"]}),"\n",(0,a.jsxs)(s.admonition,{type:"tip",children:[(0,a.jsx)(s.p,{children:"After reading this, we were left puzzled:"}),(0,a.jsx)(s.p,{children:(0,a.jsx)(s.strong,{children:'Why do "layers within the second and third Dense Blocks consistently assign minimal weights to the outputs of transition layers"?'})}),(0,a.jsx)(s.p,{children:"The top row of Block2 and Block3 looks entirely zero, which doesn't make sense."}),(0,a.jsx)(s.p,{children:"Since different Dense Blocks rely on transition layers to convey information, if these weights are zero, no information would be transmitted. A closer look at the next layer after the transition layer, the second row, shows more reasonable weights, although not very large, but at least with some variance."}),(0,a.jsx)(s.p,{children:"The second layer should just be the first layer plus a convolution, then concatenated, and shouldn't have such a stark difference (completely zero)."}),(0,a.jsx)(s.p,{children:"So, one guess is that there might be an error in the visualization code."}),(0,a.jsx)(s.p,{children:"If you know the real reason, feel free to let us know!"})]}),"\n",(0,a.jsx)(s.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,a.jsx)(s.p,{children:"DenseNet combines identity mappings, deep supervision, and diversified depth features, allowing feature reuse throughout the network, resulting in a more compact and accurate model. Due to its compact internal representation and reduced feature redundancy, DenseNet has shown its potential as a robust feature extractor for various computer vision tasks based on convolutional features."}),"\n",(0,a.jsx)(s.p,{children:"Future work will explore DenseNet\u2019s application in feature transfer, further expanding its utility in the field of computer vision."})]})}function m(e={}){const{wrapper:s}={...(0,t.R)(),...e.components};return s?(0,a.jsx)(s,{...e,children:(0,a.jsx)(o,{...e})}):o(e)}},8373:(e,s,n)=>{n.d(s,{A:()=>a});const a=n.p+"assets/images/img1-8894d2efaf544bddcf1ad3887d1348f3.jpg"},67882:(e,s,n)=>{n.d(s,{A:()=>a});const a=n.p+"assets/images/img2-0f25ed2e69e84860655a5bf92b708adf.jpg"},80039:(e,s,n)=>{n.d(s,{A:()=>a});const a=n.p+"assets/images/img3-1708cee76cc88f579e2fcb70cedd3723.jpg"},25628:(e,s,n)=>{n.d(s,{A:()=>a});const a=n.p+"assets/images/img4-ba0241055ab701a1a5313cf34c48a9ef.jpg"},69977:(e,s,n)=>{n.d(s,{A:()=>a});const a=n.p+"assets/images/img5-b528820b88ac7ac8b29e5be9c1cd72a4.jpg"},54958:(e,s,n)=>{n.d(s,{A:()=>a});const a=n.p+"assets/images/img6-d65d7d9895b3014fcd0189ef78e0abf9.jpg"},28453:(e,s,n)=>{n.d(s,{R:()=>r,x:()=>l});var a=n(96540);const t={},i=a.createContext(t);function r(e){const s=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function l(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),a.createElement(i.Provider,{value:s},e.children)}}}]);