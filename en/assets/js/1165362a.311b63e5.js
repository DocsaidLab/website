"use strict";(self.webpackChunkdocsaid_website=self.webpackChunkdocsaid_website||[]).push([["75758"],{5055:function(e,t,i){i.r(t),i.d(t,{frontMatter:()=>l,default:()=>h,contentTitle:()=>a,assets:()=>d,toc:()=>o,metadata:()=>n});var n=JSON.parse('{"id":"docclassifier/quickstart","title":"Quick Start","description":"We provide a simple model inference interface, including preprocessing and postprocessing logic.","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/docclassifier/quickstart.md","sourceDirName":"docclassifier","slug":"/docclassifier/quickstart","permalink":"/en/docs/docclassifier/quickstart","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedBy":"zephyr-sh","lastUpdatedAt":1735811993000,"sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Installation","permalink":"/en/docs/docclassifier/installation"},"next":{"title":"Advanced","permalink":"/en/docs/docclassifier/advance"}}'),s=i(85893),r=i(50065);let l={sidebar_position:3},a="Quick Start",d={},o=[{value:"Registering Data",id:"registering-data",level:2},{value:"Duplicate Registration",id:"duplicate-registration",level:2},{value:"Model Inference",id:"model-inference",level:2},{value:"Threshold Settings",id:"threshold-settings",level:2}];function c(e){let t={a:"a",admonition:"admonition",code:"code",del:"del",h1:"h1",h2:"h2",header:"header",hr:"hr",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"quick-start",children:"Quick Start"})}),"\n",(0,s.jsx)(t.p,{children:"We provide a simple model inference interface, including preprocessing and postprocessing logic."}),"\n",(0,s.jsxs)(t.p,{children:["First, you need to import the required dependencies and create the ",(0,s.jsx)(t.code,{children:"DocClassifier"})," class."]}),"\n",(0,s.jsx)(t.h2,{id:"registering-data",children:"Registering Data"}),"\n",(0,s.jsx)(t.p,{children:"Before we talk about the model, let's first discuss registering data."}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:["In the inference data folder, there is a ",(0,s.jsx)(t.code,{children:"register"})," folder that contains all the registered data. You can place your registration data here, and ",(0,s.jsx)(t.code,{children:"DocClassifier"})," will automatically read all the data in the folder during inference. If you want to use your own dataset, specify the ",(0,s.jsx)(t.code,{children:"register_root"})," parameter when creating the ",(0,s.jsx)(t.code,{children:"DocClassifier"}),", and set it to the root directory of your dataset."]}),"\n",(0,s.jsx)(t.p,{children:"We have preloaded several image registration files within the module. You can refer to these files and expand them as needed. We strongly recommend using your own dataset to ensure the model can adapt to your application scenario."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"register",src:i(30898).Z+"",width:"2387",height:"1562"})}),"\n",(0,s.jsx)(t.admonition,{type:"tip",children:(0,s.jsx)(t.p,{children:"We recommend using full-page images with minimal background interference to improve the stability of the model."})}),"\n",(0,s.jsx)(t.admonition,{type:"danger",children:(0,s.jsxs)(t.p,{children:["Many of the images preloaded in the folder are collected from the internet, and their resolution is low. They are only for demonstration purposes and are not suitable for deployment. Please use the ",(0,s.jsx)(t.code,{children:"register_root"})," parameter with your own dataset to ensure the model adapts to your use case."]})}),"\n",(0,s.jsx)(t.h2,{id:"duplicate-registration",children:"Duplicate Registration"}),"\n",(0,s.jsx)(t.p,{children:"This issue is divided into two situations:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Situation 1: Duplicate file names"})}),"\n",(0,s.jsx)(t.p,{children:"In our implementation, the file names in the registration folder serve as the query index for the data."}),"\n",(0,s.jsx)(t.p,{children:"Therefore, when file names are duplicated, the latter files will overwrite the former ones."}),"\n",(0,s.jsx)(t.p,{children:"This issue is not serious, as the overwritten files won't be used, and it won't affect the model's inference."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Situation 2: Duplicate file contents"})}),"\n",(0,s.jsx)(t.p,{children:"The same file is registered more than once."}),"\n",(0,s.jsx)(t.p,{children:"Suppose the user registers three identical images with different labels. During inference, the scores will be the same in the similarity ranking process, but one will always appear first. In this case, the model cannot guarantee that the same label will be returned each time."}),"\n",(0,s.jsxs)(t.p,{children:["This issue is also not severe, but it introduces uncertainty, and you may not understand why this happens. (",(0,s.jsx)(t.del,{children:"Hey!"}),")"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.admonition,{type:"tip",children:(0,s.jsx)(t.p,{children:"In summary, please take registering data seriously."})}),"\n",(0,s.jsx)(t.h2,{id:"model-inference",children:"Model Inference"}),"\n",(0,s.jsx)(t.admonition,{type:"info",children:(0,s.jsx)(t.p,{children:"We have designed an automatic model download feature. When the program detects that you are missing a model, it will automatically connect to our server to download it."})}),"\n",(0,s.jsx)(t.p,{children:"Once the registration data is ready, you can start model inference."}),"\n",(0,s.jsx)(t.p,{children:"Here is a simple example, starting with the model:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"import cv2\nfrom skimage import io\nfrom docclassifier import DocClassifier\n\nimg = io.imread('https://github.com/DocsaidLab/DocClassifier/blob/main/docs/test_driver.jpg?raw=true')\nimg = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n\nmodel = DocClassifier()\n\nmost_similar, max_score = model(img)\nprint(f'most_similar: {most_similar}, max_score: {max_score:.4f}')\n# >>> most_similar: None, max_score: 0.0000\n"})}),"\n",(0,s.jsxs)(t.admonition,{type:"tip",children:[(0,s.jsxs)(t.p,{children:["For the above example, refer to the image download link: ",(0,s.jsx)(t.a,{href:"https://github.com/DocsaidLab/DocClassifier/blob/main/docs/test_driver.jpg",children:(0,s.jsx)(t.strong,{children:"test_driver.jpg"})})]}),(0,s.jsx)("div",{align:"center",children:(0,s.jsx)("figure",{style:{width:"50%"},children:(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"test_card",src:i(76428).Z+"",width:"600",height:"431"})})})})]}),"\n",(0,s.jsxs)(t.p,{children:["By default, this example returns ",(0,s.jsx)(t.code,{children:"None"})," and ",(0,s.jsx)(t.code,{children:"0.0000"})," because the difference between our default registration data and the input image is significant. Therefore, the model finds the similarity between the image and the registration data to be very low."]}),"\n",(0,s.jsx)(t.admonition,{type:"tip",children:(0,s.jsx)(t.p,{children:"The pre-registered driver's license data is of a deer; the input recognition image is a blank driver's license. (Quite a difference!)"})}),"\n",(0,s.jsxs)(t.p,{children:["In this case, you may consider lowering the ",(0,s.jsx)(t.code,{children:"threshold"})," parameter:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"model = DocClassifier(\n    threshold=0.6\n)\n\n# Re-run the inference\nmost_similar, max_score = model(img)\nprint(f'most_similar: {most_similar}, max_score: {max_score:.4f}')\n# >>> most_similar: Taiwan driver's license front, max_score: 0.6116\n"})}),"\n",(0,s.jsxs)(t.p,{children:["This time, you will get a label name and a score: ",(0,s.jsx)(t.code,{children:"Taiwan driver's license front"})," and ",(0,s.jsx)(t.code,{children:"0.6116"}),". This score represents the similarity between the input image and the registration data."]}),"\n",(0,s.jsx)(t.admonition,{type:"tip",children:(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.code,{children:"DocClassifier"})," is wrapped with ",(0,s.jsx)(t.code,{children:"__call__"}),", so you can directly call the instance for inference."]})}),"\n",(0,s.jsx)(t.h2,{id:"threshold-settings",children:"Threshold Settings"}),"\n",(0,s.jsx)(t.p,{children:"We use the TPR@FPR=1e-4 standard to evaluate the model's capability, but this standard is relatively strict and may lead to a suboptimal user experience during deployment."}),"\n",(0,s.jsx)(t.p,{children:"Therefore, we recommend using a TPR@FPR=1e-1 or TPR@FPR=1e-2 threshold setting during deployment."}),"\n",(0,s.jsxs)(t.p,{children:["Currently, our default threshold uses the ",(0,s.jsx)(t.code,{children:"TPR@FPR=1e-2"})," standard, which we have determined through testing and evaluation to be a more suitable threshold. The detailed threshold settings are shown in the table below:"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"lcnet050_cosface_f256_r128_squeeze_imagenet_clip_20240326 results"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:(0,s.jsxs)(t.strong,{children:["Setting ",(0,s.jsx)(t.code,{children:"model_cfg"}),' to "20240326"']})}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"TPR@FPR=1e-4: 0.912"})}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"FPR"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"1e-05"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"1e-04"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"1e-03"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"1e-02"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"1e-01"}),(0,s.jsx)(t.th,{style:{textAlign:"center"},children:"1"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"TPR"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"0.856"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"0.912"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"0.953"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"0.980"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"0.996"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"1.0"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"Threshold"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"0.705"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"0.682"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"0.657"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"0.626"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"0.581"}),(0,s.jsx)(t.td,{style:{textAlign:"center"},children:"0.359"})]})]})]}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){let{wrapper:t}={...(0,r.a)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},30898:function(e,t,i){i.d(t,{Z:()=>n});let n=i.p+"assets/images/register_demo-1c3139c67a91705bc4305f20e5787b9a.jpg"},76428:function(e,t,i){i.d(t,{Z:()=>n});let n=i.p+"assets/images/test_driver-a09fac15b8077060fed16d5a4ce9c273.jpg"},50065:function(e,t,i){i.d(t,{Z:()=>a,a:()=>l});var n=i(67294);let s={},r=n.createContext(s);function l(e){let t=n.useContext(r);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),n.createElement(r.Provider,{value:t},e.children)}}}]);