"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[1475],{72560:e=>{e.exports=JSON.parse('{"version":{"pluginId":"papers","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"papersSidebar":[{"type":"link","label":"Research Paper Notes","href":"/en/papers/intro","docId":"intro","unlisted":false},{"type":"category","label":"Classic CNNs","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[12.09] AlexNet","href":"/en/papers/classic-cnns/alexnet/","docId":"classic-cnns/alexnet/index","unlisted":false},{"type":"link","label":"[14.09] VGG","href":"/en/papers/classic-cnns/vgg/","docId":"classic-cnns/vgg/index","unlisted":false},{"type":"link","label":"[15.12] ResNet","href":"/en/papers/classic-cnns/resnet/","docId":"classic-cnns/resnet/index","unlisted":false},{"type":"link","label":"[16.08] DenseNet","href":"/en/papers/classic-cnns/densenet/","docId":"classic-cnns/densenet/index","unlisted":false},{"type":"link","label":"[16.11] ResNeXt","href":"/en/papers/classic-cnns/resnext/","docId":"classic-cnns/resnext/index","unlisted":false},{"type":"link","label":"[17.07] NASNet","href":"/en/papers/classic-cnns/nasnet/","docId":"classic-cnns/nasnet/index","unlisted":false},{"type":"link","label":"[19.05] EfficientNet","href":"/en/papers/classic-cnns/efficientnet/","docId":"classic-cnns/efficientnet/index","unlisted":false},{"type":"link","label":"[21.04] EfficientNet-V2","href":"/en/papers/classic-cnns/efficientnet-v2/","docId":"classic-cnns/efficientnet-v2/index","unlisted":false}],"href":"/en/papers/category/classic-cnns"},{"type":"category","label":"Face Anti-Spoofing","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[24.03] CFPL-FAS","href":"/en/papers/face-antispoofing/cfpl-fas/","docId":"face-antispoofing/cfpl-fas/index","unlisted":false}],"href":"/en/papers/category/face-anti-spoofing"},{"type":"category","label":"Face Recognition","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[18.01] ArcFace","href":"/en/papers/face-recognition/arcface/","docId":"face-recognition/arcface/index","unlisted":false},{"type":"link","label":"[18.01] CosFace","href":"/en/papers/face-recognition/cosface/","docId":"face-recognition/cosface/index","unlisted":false},{"type":"link","label":"[22.09] FRVT-Twins","href":"/en/papers/face-recognition/frvt-distinguishing-twins/","docId":"face-recognition/frvt-distinguishing-twins/index","unlisted":false},{"type":"link","label":"[23.09] TIVC","href":"/en/papers/face-recognition/tivc/","docId":"face-recognition/tivc/index","unlisted":false}],"href":"/en/papers/category/face-recognition"},{"type":"category","label":"Feature Fusion","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[15.05] U-Net","href":"/en/papers/feature-fusion/unet/","docId":"feature-fusion/unet/index","unlisted":false},{"type":"link","label":"[16.03] Hourglass","href":"/en/papers/feature-fusion/hourglass/","docId":"feature-fusion/hourglass/index","unlisted":false},{"type":"link","label":"[16.12] FPN","href":"/en/papers/feature-fusion/fpn/","docId":"feature-fusion/fpn/index","unlisted":false},{"type":"link","label":"[18.03] PANet","href":"/en/papers/feature-fusion/panet/","docId":"feature-fusion/panet/index","unlisted":false},{"type":"link","label":"[19.04] NAS-FPN","href":"/en/papers/feature-fusion/nasfpn/","docId":"feature-fusion/nasfpn/index","unlisted":false},{"type":"link","label":"[19.11] EfficientDet","href":"/en/papers/feature-fusion/bifpn/","docId":"feature-fusion/bifpn/index","unlisted":false},{"type":"link","label":"[19.12] UNet++","href":"/en/papers/feature-fusion/unetpp/","docId":"feature-fusion/unetpp/index","unlisted":false}],"href":"/en/papers/category/feature-fusion"},{"type":"category","label":"Lightweight","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[17.04] MobileNet-V1","href":"/en/papers/lightweight/mobilenet-v1/","docId":"lightweight/mobilenet-v1/index","unlisted":false},{"type":"link","label":"[17.07] ShuffleNet","href":"/en/papers/lightweight/shufflenet/","docId":"lightweight/shufflenet/index","unlisted":false},{"type":"link","label":"[17.09] SENet","href":"/en/papers/lightweight/senet/","docId":"lightweight/senet/index","unlisted":false},{"type":"link","label":"[18.01] MobileNet-V2","href":"/en/papers/lightweight/mobilenet-v2/","docId":"lightweight/mobilenet-v2/index","unlisted":false},{"type":"link","label":"[19.05] MobileNet-V3","href":"/en/papers/lightweight/mobilenet-v3/","docId":"lightweight/mobilenet-v3/index","unlisted":false},{"type":"link","label":"[19.11] GhostNet","href":"/en/papers/lightweight/ghostnet/","docId":"lightweight/ghostnet/index","unlisted":false},{"type":"link","label":"[21.08] Mobile-Former","href":"/en/papers/lightweight/mobile-former/","docId":"lightweight/mobile-former/index","unlisted":false},{"type":"link","label":"[21.09] PP-LCNet","href":"/en/papers/lightweight/pp-lcnet/","docId":"lightweight/pp-lcnet/index","unlisted":false},{"type":"link","label":"[21.10] MobileViT","href":"/en/papers/lightweight/mobilevit/","docId":"lightweight/mobilevit/index","unlisted":false},{"type":"link","label":"[24.04] MobileNet-V4","href":"/en/papers/lightweight/mobilenet-v4/","docId":"lightweight/mobilenet-v4/index","unlisted":false}],"href":"/en/papers/category/lightweight"},{"type":"category","label":"Multimodality","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[19.08] LXMERT","href":"/en/papers/multimodality/lxmert/","docId":"multimodality/lxmert/index","unlisted":false},{"type":"link","label":"[19.08] ViLBERT","href":"/en/papers/multimodality/vilbert/","docId":"multimodality/vilbert/index","unlisted":false},{"type":"link","label":"[19.08] VisualBERT","href":"/en/papers/multimodality/visualbert/","docId":"multimodality/visualbert/index","unlisted":false},{"type":"link","label":"[19.08] VL-BERT","href":"/en/papers/multimodality/vlbert/","docId":"multimodality/vlbert/index","unlisted":false},{"type":"link","label":"[19.09] UNITER","href":"/en/papers/multimodality/uniter/","docId":"multimodality/uniter/index","unlisted":false},{"type":"link","label":"[20.04] Oscar","href":"/en/papers/multimodality/oscar/","docId":"multimodality/oscar/index","unlisted":false},{"type":"link","label":"[20.04] Pixel-BERT","href":"/en/papers/multimodality/pixelbert/","docId":"multimodality/pixelbert/index","unlisted":false},{"type":"link","label":"[20.06] ERNIE-ViL","href":"/en/papers/multimodality/ernie-vil/","docId":"multimodality/ernie-vil/index","unlisted":false},{"type":"link","label":"[20.06] VILLA","href":"/en/papers/multimodality/villa/","docId":"multimodality/villa/index","unlisted":false},{"type":"link","label":"[20.12] UNIMO","href":"/en/papers/multimodality/unimo/","docId":"multimodality/unimo/index","unlisted":false},{"type":"link","label":"[21.01] VinVL","href":"/en/papers/multimodality/vinvl/","docId":"multimodality/vinvl/index","unlisted":false},{"type":"link","label":"[21.02] ViLT","href":"/en/papers/multimodality/vilt/","docId":"multimodality/vilt/index","unlisted":false},{"type":"link","label":"[21.02] VL-T5","href":"/en/papers/multimodality/vlt5/","docId":"multimodality/vlt5/index","unlisted":false},{"type":"link","label":"[21.03] CLIP","href":"/en/papers/multimodality/clip/","docId":"multimodality/clip/index","unlisted":false},{"type":"link","label":"[21.04] MDETR","href":"/en/papers/multimodality/mdetr/","docId":"multimodality/mdetr/index","unlisted":false},{"type":"link","label":"[21.07] ALBEF","href":"/en/papers/multimodality/albef/","docId":"multimodality/albef/index","unlisted":false},{"type":"link","label":"[21.08] SimVLM","href":"/en/papers/multimodality/simvlm/","docId":"multimodality/simvlm/index","unlisted":false},{"type":"link","label":"[21.11] METER","href":"/en/papers/multimodality/meter/","docId":"multimodality/meter/index","unlisted":false}],"href":"/en/papers/category/multimodality"},{"type":"category","label":"Normalization","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[15.02] BatchNorm","href":"/en/papers/normalization/batchnorm/","docId":"normalization/batchnorm/index","unlisted":false}],"href":"/en/papers/category/normalization"},{"type":"category","label":"Object Detection","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[15.06] YOLO-V1","href":"/en/papers/object-detection/yolov1/","docId":"object-detection/yolov1/index","unlisted":false},{"type":"link","label":"[16.12] YOLO-V2","href":"/en/papers/object-detection/yolov2/","docId":"object-detection/yolov2/index","unlisted":false},{"type":"link","label":"[17.08] RetinaNet","href":"/en/papers/object-detection/retinanet/","docId":"object-detection/retinanet/index","unlisted":false},{"type":"link","label":"[18.04] YOLO-V3","href":"/en/papers/object-detection/yolov3/","docId":"object-detection/yolov3/index","unlisted":false},{"type":"link","label":"[20.05] DETR","href":"/en/papers/object-detection/detr/","docId":"object-detection/detr/index","unlisted":false}],"href":"/en/papers/category/object-detection"},{"type":"category","label":"Reparameterization","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[21.01] RepVGG","href":"/en/papers/reparameterization/repvgg/","docId":"reparameterization/repvgg/index","unlisted":false},{"type":"link","label":"[22.03] RepLKNet","href":"/en/papers/reparameterization/replknet/","docId":"reparameterization/replknet/index","unlisted":false},{"type":"link","label":"[22.06] MobileOne","href":"/en/papers/reparameterization/mobileone/","docId":"reparameterization/mobileone/index","unlisted":false},{"type":"link","label":"[22.12] QARepVGG","href":"/en/papers/reparameterization/qarepvgg/","docId":"reparameterization/qarepvgg/index","unlisted":false},{"type":"link","label":"[23.03] FastViT","href":"/en/papers/reparameterization/fastvit/","docId":"reparameterization/fastvit/index","unlisted":false},{"type":"link","label":"[23.05] VanillaNet","href":"/en/papers/reparameterization/vanillanet/","docId":"reparameterization/vanillanet/index","unlisted":false},{"type":"link","label":"[23.07] RepViT","href":"/en/papers/reparameterization/repvit/","docId":"reparameterization/repvit/index","unlisted":false}],"href":"/en/papers/category/reparameterization"},{"type":"category","label":"Segmentation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[14.11] FCN","href":"/en/papers/segmentation/fcn/","docId":"segmentation/fcn/index","unlisted":false}],"href":"/en/papers/category/segmentation"},{"type":"category","label":"Text Detection","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[17.04] EAST","href":"/en/papers/text-detection/east/","docId":"text-detection/east/index","unlisted":false},{"type":"link","label":"[18.07] TextSnake","href":"/en/papers/text-detection/textsnake/","docId":"text-detection/textsnake/index","unlisted":false},{"type":"link","label":"[19.03] PSENet","href":"/en/papers/text-detection/psenet/","docId":"text-detection/psenet/index","unlisted":false},{"type":"link","label":"[19.08] PAN","href":"/en/papers/text-detection/pan/","docId":"text-detection/pan/index","unlisted":false},{"type":"link","label":"[19.11] DBNet","href":"/en/papers/text-detection/dbnet/","docId":"text-detection/dbnet/index","unlisted":false}],"href":"/en/papers/category/text-detection"},{"type":"category","label":"Transformers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[17.06] Transformer","href":"/en/papers/transformers/transformer/","docId":"transformers/transformer/index","unlisted":false},{"type":"link","label":"[18.06] GPT-1","href":"/en/papers/transformers/gpt_1/","docId":"transformers/gpt_1/index","unlisted":false},{"type":"link","label":"[18.10] BERT","href":"/en/papers/transformers/bert/","docId":"transformers/bert/index","unlisted":false},{"type":"link","label":"[19.01] Transformer-XL","href":"/en/papers/transformers/transformer-xl/","docId":"transformers/transformer-xl/index","unlisted":false},{"type":"link","label":"[19.02] Adapter","href":"/en/papers/transformers/adapter/","docId":"transformers/adapter/index","unlisted":false},{"type":"link","label":"[19.02] GPT-2","href":"/en/papers/transformers/gpt_2/","docId":"transformers/gpt_2/index","unlisted":false},{"type":"link","label":"[19.04] Sparse Transformer","href":"/en/papers/transformers/sparse-transformer/","docId":"transformers/sparse-transformer/index","unlisted":false},{"type":"link","label":"[20.01] Scaling Laws","href":"/en/papers/transformers/scaling_laws/","docId":"transformers/scaling_laws/index","unlisted":false},{"type":"link","label":"[20.04] Longformer","href":"/en/papers/transformers/longformer/","docId":"transformers/longformer/index","unlisted":false},{"type":"link","label":"[20.05] GPT-3","href":"/en/papers/transformers/gpt_3/","docId":"transformers/gpt_3/index","unlisted":false},{"type":"link","label":"[20.07] BigBird","href":"/en/papers/transformers/bigbird/","docId":"transformers/bigbird/index","unlisted":false},{"type":"link","label":"[20.10] AutoPrompt","href":"/en/papers/transformers/autoprompt/","docId":"transformers/autoprompt/index","unlisted":false},{"type":"link","label":"[21.04] RoFormer","href":"/en/papers/transformers/roformer/","docId":"transformers/roformer/index","unlisted":false}],"href":"/en/papers/category/transformers"},{"type":"category","label":"Vision Transformers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"[20.10] ViT","href":"/en/papers/vision-transformers/vit/","docId":"vision-transformers/vit/index","unlisted":false},{"type":"link","label":"[20.12] DeiT","href":"/en/papers/vision-transformers/deit/","docId":"vision-transformers/deit/index","unlisted":false},{"type":"link","label":"[21.02] PVT","href":"/en/papers/vision-transformers/pvt/","docId":"vision-transformers/pvt/index","unlisted":false},{"type":"link","label":"[21.03] Swin Transformer","href":"/en/papers/vision-transformers/swin-transformer/","docId":"vision-transformers/swin-transformer/index","unlisted":false},{"type":"link","label":"[21.05] MLP-Mixer","href":"/en/papers/vision-transformers/mlp-mixer/","docId":"vision-transformers/mlp-mixer/index","unlisted":false},{"type":"link","label":"[21.06] BEiT","href":"/en/papers/vision-transformers/beit/","docId":"vision-transformers/beit/index","unlisted":false},{"type":"link","label":"[21.11] MAE","href":"/en/papers/vision-transformers/mae/","docId":"vision-transformers/mae/index","unlisted":false},{"type":"link","label":"[21.11] PoolFormer","href":"/en/papers/vision-transformers/poolformer/","docId":"vision-transformers/poolformer/index","unlisted":false},{"type":"link","label":"[22.01] ConvMixer","href":"/en/papers/vision-transformers/convmixer/","docId":"vision-transformers/convmixer/index","unlisted":false},{"type":"link","label":"[22.01] ConvNeXt","href":"/en/papers/vision-transformers/convnext/","docId":"vision-transformers/convnext/index","unlisted":false},{"type":"link","label":"[22.10] CAFormer","href":"/en/papers/vision-transformers/caformer/","docId":"vision-transformers/caformer/index","unlisted":false}],"href":"/en/papers/category/vision-transformers"}]},"docs":{"classic-cnns/alexnet/index":{"id":"classic-cnns/alexnet/index","title":"[12.09] AlexNet","description":"The Rise of Convolutional Networks","sidebar":"papersSidebar"},"classic-cnns/densenet/index":{"id":"classic-cnns/densenet/index","title":"[16.08] DenseNet","description":"Connecting Everything","sidebar":"papersSidebar"},"classic-cnns/efficientnet-v2/index":{"id":"classic-cnns/efficientnet-v2/index","title":"[21.04] EfficientNet-V2","description":"Deep convolutional creep","sidebar":"papersSidebar"},"classic-cnns/efficientnet/index":{"id":"classic-cnns/efficientnet/index","title":"[19.05] EfficientNet","description":"Compound Scaling","sidebar":"papersSidebar"},"classic-cnns/nasnet/index":{"id":"classic-cnns/nasnet/index","title":"[17.07] NASNet","description":"Searching for Network Architectures","sidebar":"papersSidebar"},"classic-cnns/resnet/index":{"id":"classic-cnns/resnet/index","title":"[15.12] ResNet","description":"Convolutional with 100 Layers","sidebar":"papersSidebar"},"classic-cnns/resnext/index":{"id":"classic-cnns/resnext/index","title":"[16.11] ResNeXt","description":"Exploring the Next Dimension","sidebar":"papersSidebar"},"classic-cnns/vgg/index":{"id":"classic-cnns/vgg/index","title":"[14.09] VGG","description":"Deep and More Deep","sidebar":"papersSidebar"},"face-antispoofing/cfpl-fas/index":{"id":"face-antispoofing/cfpl-fas/index","title":"[24.03] CFPL-FAS","description":"Class-Free Prompt Learning","sidebar":"papersSidebar"},"face-recognition/arcface/index":{"id":"face-recognition/arcface/index","title":"[18.01] ArcFace","description":"Additive Angular Margin Loss","sidebar":"papersSidebar"},"face-recognition/cosface/index":{"id":"face-recognition/cosface/index","title":"[18.01] CosFace","description":"Large Margin Cosine Loss","sidebar":"papersSidebar"},"face-recognition/frvt-distinguishing-twins/index":{"id":"face-recognition/frvt-distinguishing-twins/index","title":"[22.09] FRVT-Twins","description":"Report on Twin Identification Accuracy","sidebar":"papersSidebar"},"face-recognition/tivc/index":{"id":"face-recognition/tivc/index","title":"[23.09] TIVC","description":"Perspective on Twin Identification","sidebar":"papersSidebar"},"feature-fusion/bifpn/index":{"id":"feature-fusion/bifpn/index","title":"[19.11] EfficientDet","description":"The Power of BiFPN","sidebar":"papersSidebar"},"feature-fusion/fpn/index":{"id":"feature-fusion/fpn/index","title":"[16.12] FPN","description":"The Pyramid Structure","sidebar":"papersSidebar"},"feature-fusion/hourglass/index":{"id":"feature-fusion/hourglass/index","title":"[16.03] Hourglass","description":"The Forgotten Elder","sidebar":"papersSidebar"},"feature-fusion/nasfpn/index":{"id":"feature-fusion/nasfpn/index","title":"[19.04] NAS-FPN","description":"Money Talks","sidebar":"papersSidebar"},"feature-fusion/panet/index":{"id":"feature-fusion/panet/index","title":"[18.03] PANet","description":"Give Me a Shortcut","sidebar":"papersSidebar"},"feature-fusion/unet/index":{"id":"feature-fusion/unet/index","title":"[15.05] U-Net","description":"The Dawn of Integration","sidebar":"papersSidebar"},"feature-fusion/unetpp/index":{"id":"feature-fusion/unetpp/index","title":"[19.12] UNet++","description":"The Subtle Weaver","sidebar":"papersSidebar"},"intro":{"id":"intro","title":"Research Paper Notes","description":"Daily Life","sidebar":"papersSidebar"},"lightweight/ghostnet/index":{"id":"lightweight/ghostnet/index","title":"[19.11] GhostNet","description":"Ghost in Feature Maps","sidebar":"papersSidebar"},"lightweight/mobile-former/index":{"id":"lightweight/mobile-former/index","title":"[21.08] Mobile-Former","description":"Bidirectional Bridge","sidebar":"papersSidebar"},"lightweight/mobilenet-v1/index":{"id":"lightweight/mobilenet-v1/index","title":"[17.04] MobileNet-V1","description":"Pioneers of Depthwise Separable Convolutions","sidebar":"papersSidebar"},"lightweight/mobilenet-v2/index":{"id":"lightweight/mobilenet-v2/index","title":"[18.01] MobileNet-V2","description":"Refining the Bottleneck","sidebar":"papersSidebar"},"lightweight/mobilenet-v3/index":{"id":"lightweight/mobilenet-v3/index","title":"[19.05] MobileNet-V3","description":"Custom Architecture Search","sidebar":"papersSidebar"},"lightweight/mobilenet-v4/index":{"id":"lightweight/mobilenet-v4/index","title":"[24.04] MobileNet-V4","description":"Five Years of Evolution","sidebar":"papersSidebar"},"lightweight/mobilevit/index":{"id":"lightweight/mobilevit/index","title":"[21.10] MobileViT","description":"Changing the Design of Convolution Kernels","sidebar":"papersSidebar"},"lightweight/pp-lcnet/index":{"id":"lightweight/pp-lcnet/index","title":"[21.09] PP-LCNet","description":"Exploring the Boundaries of Speed","sidebar":"papersSidebar"},"lightweight/senet/index":{"id":"lightweight/senet/index","title":"[17.09] SENet","description":"Squeeze and Excitation Network","sidebar":"papersSidebar"},"lightweight/shufflenet/index":{"id":"lightweight/shufflenet/index","title":"[17.07] ShuffleNet","description":"Channel Shuffling Network","sidebar":"papersSidebar"},"multimodality/albef/index":{"id":"multimodality/albef/index","title":"[21.07] ALBEF","description":"Pursuing the Pure Path","sidebar":"papersSidebar"},"multimodality/clip/index":{"id":"multimodality/clip/index","title":"[21.03] CLIP","description":"Breaking the Dimensional Barrier","sidebar":"papersSidebar"},"multimodality/ernie-vil/index":{"id":"multimodality/ernie-vil/index","title":"[20.06] ERNIE-ViL","description":"The Double-Edged Sword of Knowledge","sidebar":"papersSidebar"},"multimodality/lxmert/index":{"id":"multimodality/lxmert/index","title":"[19.08] LXMERT","description":"More Pre-training","sidebar":"papersSidebar"},"multimodality/mdetr/index":{"id":"multimodality/mdetr/index","title":"[21.04] MDETR","description":"The Art of Continuity","sidebar":"papersSidebar"},"multimodality/meter/index":{"id":"multimodality/meter/index","title":"[21.11] METER","description":"A Colorful Dashboard","sidebar":"papersSidebar"},"multimodality/oscar/index":{"id":"multimodality/oscar/index","title":"[20.04] Oscar","description":"The Anchors of Oscar","sidebar":"papersSidebar"},"multimodality/pixelbert/index":{"id":"multimodality/pixelbert/index","title":"[20.04] Pixel-BERT","description":"The Language of Pixels","sidebar":"papersSidebar"},"multimodality/simvlm/index":{"id":"multimodality/simvlm/index","title":"[21.08] SimVLM","description":"Simplifying Things","sidebar":"papersSidebar"},"multimodality/unimo/index":{"id":"multimodality/unimo/index","title":"[20.12] UNIMO","description":"Intertwined Clues","sidebar":"papersSidebar"},"multimodality/uniter/index":{"id":"multimodality/uniter/index","title":"[19.09] UNITER","description":"The Song of the Unifiers","sidebar":"papersSidebar"},"multimodality/vilbert/index":{"id":"multimodality/vilbert/index","title":"[19.08] ViLBERT","description":"Interweaving in the Prologue","sidebar":"papersSidebar"},"multimodality/villa/index":{"id":"multimodality/villa/index","title":"[20.06] VILLA","description":"The Phantom in the Villa","sidebar":"papersSidebar"},"multimodality/vilt/index":{"id":"multimodality/vilt/index","title":"[21.02] ViLT","description":"Enter the Scene","sidebar":"papersSidebar"},"multimodality/vinvl/index":{"id":"multimodality/vinvl/index","title":"[21.01] VinVL","description":"Revisiting Oscar","sidebar":"papersSidebar"},"multimodality/visualbert/index":{"id":"multimodality/visualbert/index","title":"[19.08] VisualBERT","description":"Gaze at the Prelude","sidebar":"papersSidebar"},"multimodality/vlbert/index":{"id":"multimodality/vlbert/index","title":"[19.08] VL-BERT","description":"Watching from the Prelude","sidebar":"papersSidebar"},"multimodality/vlt5/index":{"id":"multimodality/vlt5/index","title":"[21.02] VL-T5","description":"Consistent Output","sidebar":"papersSidebar"},"normalization/batchnorm/index":{"id":"normalization/batchnorm/index","title":"[15.02] BatchNorm","description":"Batch Normalization","sidebar":"papersSidebar"},"object-detection/detr/index":{"id":"object-detection/detr/index","title":"[20.05] DETR","description":"A Foundation Across Domains","sidebar":"papersSidebar"},"object-detection/retinanet/index":{"id":"object-detection/retinanet/index","title":"[17.08] RetinaNet","description":"Focal Loss is the Key","sidebar":"papersSidebar"},"object-detection/yolov1/index":{"id":"object-detection/yolov1/index","title":"[15.06] YOLO-V1","description":"You Only Look Once","sidebar":"papersSidebar"},"object-detection/yolov2/index":{"id":"object-detection/yolov2/index","title":"[16.12] YOLO-V2","description":"Expanding a Large Number of Categories","sidebar":"papersSidebar"},"object-detection/yolov3/index":{"id":"object-detection/yolov3/index","title":"[18.04] YOLO-V3","description":"Introducing Multi-Scale Detection","sidebar":"papersSidebar"},"reparameterization/fastvit/index":{"id":"reparameterization/fastvit/index","title":"[23.03] FastViT","description":"Reparameterized ViT Experiments","sidebar":"papersSidebar"},"reparameterization/mobileone/index":{"id":"reparameterization/mobileone/index","title":"[22.06] MobileOne","description":"One Millisecond Optimization","sidebar":"papersSidebar"},"reparameterization/qarepvgg/index":{"id":"reparameterization/qarepvgg/index","title":"[22.12] QARepVGG","description":"Making RepVGG Great Again","sidebar":"papersSidebar"},"reparameterization/replknet/index":{"id":"reparameterization/replknet/index","title":"[22.03] RepLKNet","description":"Giant Convolutional Kernels","sidebar":"papersSidebar"},"reparameterization/repvgg/index":{"id":"reparameterization/repvgg/index","title":"[21.01] RepVGG","description":"Making VGG Great Again","sidebar":"papersSidebar"},"reparameterization/repvit/index":{"id":"reparameterization/repvit/index","title":"[23.07] RepViT","description":"Revisiting Mobile CNN from the ViT Perspective","sidebar":"papersSidebar"},"reparameterization/vanillanet/index":{"id":"reparameterization/vanillanet/index","title":"[23.05] VanillaNet","description":"Vanilla Minimalism","sidebar":"papersSidebar"},"segmentation/fcn/index":{"id":"segmentation/fcn/index","title":"[14.11] FCN","description":"Fully Convolutional Networks","sidebar":"papersSidebar"},"text-detection/dbnet/index":{"id":"text-detection/dbnet/index","title":"[19.11] DBNet","description":"Differentiable Binarization Function","sidebar":"papersSidebar"},"text-detection/east/index":{"id":"text-detection/east/index","title":"[17.04] EAST","description":"Simplifying Text Detection","sidebar":"papersSidebar"},"text-detection/pan/index":{"id":"text-detection/pan/index","title":"[19.08] PAN","description":"Pixel Aggregation Strategy","sidebar":"papersSidebar"},"text-detection/psenet/index":{"id":"text-detection/psenet/index","title":"[19.03] PSENet","description":"Progressive Scale Expansion Strategy","sidebar":"papersSidebar"},"text-detection/textsnake/index":{"id":"text-detection/textsnake/index","title":"[18.07] TextSnake","description":"A snake of text","sidebar":"papersSidebar"},"transformers/adapter/index":{"id":"transformers/adapter/index","title":"[19.02] Adapter","description":"Saving 96% of Parameters","sidebar":"papersSidebar"},"transformers/autoprompt/index":{"id":"transformers/autoprompt/index","title":"[20.10] AutoPrompt","description":"Model Language","sidebar":"papersSidebar"},"transformers/bert/index":{"id":"transformers/bert/index","title":"[18.10] BERT","description":"Twelve Layers of Encoders","sidebar":"papersSidebar"},"transformers/bigbird/index":{"id":"transformers/bigbird/index","title":"[20.07] BigBird","description":"BigBird Attention Mechanism","sidebar":"papersSidebar"},"transformers/gpt_1/index":{"id":"transformers/gpt_1/index","title":"[18.06] GPT-1","description":"Twelve-Layer Decoder","sidebar":"papersSidebar"},"transformers/gpt_2/index":{"id":"transformers/gpt_2/index","title":"[19.02] GPT-2","description":"Forty-Eight Layers of Decoders","sidebar":"papersSidebar"},"transformers/gpt_3/index":{"id":"transformers/gpt_3/index","title":"[20.05] GPT-3","description":"Ninety-Six Layer Decoder","sidebar":"papersSidebar"},"transformers/longformer/index":{"id":"transformers/longformer/index","title":"[20.04] Longformer","description":"Long Attention Mechanism","sidebar":"papersSidebar"},"transformers/roformer/index":{"id":"transformers/roformer/index","title":"[21.04] RoFormer","description":"Rotary Position Embedding","sidebar":"papersSidebar"},"transformers/scaling_laws/index":{"id":"transformers/scaling_laws/index","title":"[20.01] Scaling Laws","description":"Scaling Laws for Neural Language Models","sidebar":"papersSidebar"},"transformers/sparse-transformer/index":{"id":"transformers/sparse-transformer/index","title":"[19.04] Sparse Transformer","description":"Sparse Attention Mechanism","sidebar":"papersSidebar"},"transformers/transformer-xl/index":{"id":"transformers/transformer-xl/index","title":"[19.01] Transformer-XL","description":"Longer Contexts","sidebar":"papersSidebar"},"transformers/transformer/index":{"id":"transformers/transformer/index","title":"[17.06] Transformer","description":"The Dawn of a New Era","sidebar":"papersSidebar"},"vision-transformers/beit/index":{"id":"vision-transformers/beit/index","title":"[21.06] BEiT","description":"Discrete Encoding Pre-Training","sidebar":"papersSidebar"},"vision-transformers/caformer/index":{"id":"vision-transformers/caformer/index","title":"[22.10] CAFormer","description":"MetaFormer User Manual","sidebar":"papersSidebar"},"vision-transformers/convmixer/index":{"id":"vision-transformers/convmixer/index","title":"[22.01] ConvMixer","description":"Convolutional Mixer","sidebar":"papersSidebar"},"vision-transformers/convnext/index":{"id":"vision-transformers/convnext/index","title":"[22.01] ConvNeXt","description":"Making Convolutions Great Again","sidebar":"papersSidebar"},"vision-transformers/deit/index":{"id":"vision-transformers/deit/index","title":"[20.12] DeiT","description":"Distillation ViT","sidebar":"papersSidebar"},"vision-transformers/mae/index":{"id":"vision-transformers/mae/index","title":"[21.11] MAE","description":"A Quarter of the Clue","sidebar":"papersSidebar"},"vision-transformers/mlp-mixer/index":{"id":"vision-transformers/mlp-mixer/index","title":"[21.05] MLP-Mixer","description":"Less Loss is Gain","sidebar":"papersSidebar"},"vision-transformers/poolformer/index":{"id":"vision-transformers/poolformer/index","title":"[21.11] PoolFormer","description":"You Need a Meta!","sidebar":"papersSidebar"},"vision-transformers/pvt/index":{"id":"vision-transformers/pvt/index","title":"[21.02] PVT","description":"Spatial Reduction Attention Mechanism","sidebar":"papersSidebar"},"vision-transformers/swin-transformer/index":{"id":"vision-transformers/swin-transformer/index","title":"[21.03] Swin Transformer","description":"The Dance Begins","sidebar":"papersSidebar"},"vision-transformers/vit/index":{"id":"vision-transformers/vit/index","title":"[20.10] ViT","description":"Pioneering a New World","sidebar":"papersSidebar"}}}}')}}]);