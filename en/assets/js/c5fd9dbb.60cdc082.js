"use strict";(self.webpackChunkdocsaid_website=self.webpackChunkdocsaid_website||[]).push([["78709"],{41979:function(e){e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"mount-disk-on-ubuntu","metadata":{"permalink":"/en/blog/mount-disk-on-ubuntu","source":"@site/i18n/en/docusaurus-plugin-content-blog/2025/01-25-mount-disk-on-ubuntu/index.md","title":"Mounting a USB Drive on Ubuntu","description":"A guide to mounting a disk on Ubuntu","date":"2025-01-25T00:00:00.000Z","tags":[{"inline":true,"label":"ubuntu","permalink":"/en/blog/tags/ubuntu"},{"inline":true,"label":"mount","permalink":"/en/blog/tags/mount"}],"readingTime":4.07,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"mount-disk-on-ubuntu","title":"Mounting a USB Drive on Ubuntu","authors":"Zephyr","image":"/en/img/2025/0125.webp","tags":["ubuntu","mount"],"description":"A guide to mounting a disk on Ubuntu"},"unlisted":false,"nextItem":{"title":"Useful GitHub Markdown Syntax","permalink":"/en/blog/github-markdown-advanced-syntax"}},"content":"After inserting the USB drive into an Ubuntu system, one may unintentionally start staring blankly at the screen.\\n\\nThen it hits you that Ubuntu is an operating system that requires you to \\"mount\\" disks manually.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Check Where the Disk Is\\n\\nBefore mounting the disk, you first need to confirm whether the system has detected it.\\n\\n1. Open the terminal and run the following command:\\n\\n   ```bash\\n   sudo fdisk -l\\n   ```\\n\\n   This command will list all the available disks and partitions in the system.\\n\\n   Locate the disk you want to mount, usually named something like `/dev/sdb` or `/dev/sdc`, with partition names such as `/dev/sda1` or `/dev/sdc1`.\\n\\n   :::tip\\n   You can also use the `lsblk` command, depending on your personal preference.\\n   :::\\n\\n2. Check the file system type of the disk:\\n\\n   Assuming the disk found is `/dev/sda1`, you can check its file system type with the following command:\\n\\n   ```bash\\n   sudo blkid /dev/sda1 | grep TYPE\\n   ```\\n\\n   This command will display the file system type of the partition, such as `ext4`, `ntfs`, or `exfat`, helping you decide the appropriate mounting method.\\n\\n## Create a Mount Directory\\n\\nBefore mounting the disk, you need a directory to serve as the mount point.\\n\\nHere, we\'ll assume the path is `/mnt/mydisk` and run the following command:\\n\\n```bash\\nsudo mkdir -p /mnt/mydisk\\n```\\n\\n:::tip\\nYou can choose any directory name you like, as long as the directory exists and is empty.\\n:::\\n\\n## Mount the Disk\\n\\nChoose the appropriate mount method based on the disk\'s file system type.\\n\\n### ext4\\n\\nRun the following command to mount the disk to the target directory:\\n\\n```bash\\nsudo mount /dev/sda1 /mnt/mydisk\\n```\\n\\nCheck if the mount was successful:\\n\\n```bash\\ndf -h\\n```\\n\\nIf successful, you should see `/mnt/mydisk` in the output.\\n\\n### NTFS or exFAT\\n\\nIf the disk uses NTFS or exFAT file systems, you may need to install the necessary tools.\\n\\n1. Install the required tools:\\n\\n   ```bash\\n   sudo apt update\\n   sudo apt install ntfs-3g exfat-fuse exfat-utils\\n   ```\\n\\n2. Mount the NTFS or exFAT partition (using exFAT as an example):\\n\\n   ```bash\\n   sudo mount -t exfat /dev/sda1 /mnt/mydisk\\n   ```\\n\\n## Common Issues\\n\\n1. **Insufficient Permissions After Mounting**:\\n\\n   Some file systems (like NTFS or exFAT) do not support native Linux permission modification commands (such as `chmod` or `chown`). If you encounter this issue, you can specify the appropriate permissions when mounting.\\n\\n   Unmount first:\\n\\n   ```bash\\n   sudo umount /mnt/mydisk\\n   ```\\n\\n   Remount and specify permissions:\\n\\n   ```bash\\n   sudo mount -t exfat -o uid=1000,gid=1000,fmask=0022,dmask=0022 /dev/sda1 /mnt/mydisk\\n   ```\\n\\n   The meaning of each parameter is as follows:\\n\\n   - `-t exfat`: Specifies the file system type.\\n   - `uid=1000`: Specifies the UID of the file owner.\\n   - `gid=1000`: Specifies the GID of the file group.\\n   - `fmask=0022` and `dmask=0022`: Set the default permissions for files and directories.\\n\\n   Verify if the permissions are correct after mounting:\\n\\n   ```bash\\n   ls -l /mnt/mydisk\\n   ```\\n\\n   :::tip\\n   The `0022` is an octal number, corresponding to `755` permissions.\\n   :::\\n\\n---\\n\\n2. **Mount Directory Not Created**:\\n\\n   If the mount directory does not exist, the mount command will fail. Make sure the directory is created:\\n\\n   ```bash\\n   sudo mkdir -p /mnt/mydisk\\n   ```\\n\\n---\\n\\n3. **Don\'t Know the UID and GID**:\\n\\n   You can use the following command to find the UID and GID of the current user:\\n\\n   ```bash\\n   id\\n   ```\\n\\n   Example output:\\n\\n   ```\\n   uid=1000(username) gid=1000(username)\\n   ```\\n\\n   Here, `uid` is the user ID, and `gid` is the group ID.\\n\\n---\\n\\n4. **Automatically Mount the Disk**:\\n\\n   To automatically mount the disk on every boot, you can configure it in the `/etc/fstab` file.\\n\\n   Open the `/etc/fstab` file with a text editor:\\n\\n   ```bash\\n   sudo vim /etc/fstab\\n   ```\\n\\n   Add the following line at the end of the file (modify it according to the actual disk information):\\n\\n   ```bash\\n   /dev/sda1 /mnt/mydisk ntfs-3g defaults,uid=1000,gid=1000 0 0\\n   ```\\n\\n   After saving and exiting, verify the configuration with:\\n\\n   ```bash\\n   sudo mount -a\\n   ```\\n\\n   If no error message appears, the configuration is successful.\\n\\n---\\n\\n5. **Unmount the Disk**:\\n\\n   To unmount the disk, use the following command:\\n\\n   ```bash\\n   sudo umount /mnt/mydisk\\n   ```\\n\\n   If the disk is in use, you may encounter an error. In this case, use the `-l` option to force the unmount:\\n\\n   ```bash\\n   sudo umount -l /mnt/mydisk\\n   ```\\n\\n   After unmounting, you can confirm with the following command:\\n\\n   ```bash\\n   df -h\\n   ```\\n\\n---\\n\\n6. **Disk Not Formatted**:\\n\\n   A new disk may need to be formatted before use. Use the `mkfs` command to format the disk:\\n\\n   ```bash\\n   sudo mkfs -t ext4 /dev/sda1\\n   ```\\n\\n   This command will format `/dev/sda1` as the ext4 file system. To use a different file system, change the `-t` option.\\n\\n   :::warning\\n   Formatting the disk will erase all data, so make sure to back up important files in advance.\\n   :::\\n\\n## Conclusion\\n\\nIn summary, mounting a disk on Ubuntu is not complicated. Once you master the basic commands and keep the necessary precautions in mind, you can easily complete the process.\\n\\nThis is a simple record of the disk mounting process, and we hope it helps you."},{"id":"github-markdown-advanced-syntax","metadata":{"permalink":"/en/blog/github-markdown-advanced-syntax","source":"@site/i18n/en/docusaurus-plugin-content-blog/2025/01-13-github-markdown-advanced-syntax/index.md","title":"Useful GitHub Markdown Syntax","description":"Introducing uncommon yet practical syntax.","date":"2025-01-13T00:00:00.000Z","tags":[{"inline":true,"label":"GitHub","permalink":"/en/blog/tags/git-hub"},{"inline":true,"label":"Markdown","permalink":"/en/blog/tags/markdown"}],"readingTime":4.13,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"github-markdown-advanced-syntax","title":"Useful GitHub Markdown Syntax","authors":"Zephyr","image":"/en/img/2025/0113.webp","tags":["GitHub","Markdown"],"description":"Introducing uncommon yet practical syntax."},"unlisted":false,"prevItem":{"title":"Mounting a USB Drive on Ubuntu","permalink":"/en/blog/mount-disk-on-ubuntu"},"nextItem":{"title":"Extract Font File Information","permalink":"/en/blog/extract-font-info-by-python"}},"content":"Writing README files on GitHub is likely a familiar task, but most of the time, we only use basic syntax.\\n\\nThere are many appealing and practical features you shouldn\'t miss out on!\\n\\n\x3c!-- truncate --\x3e\\n\\n## Basic Syntax\\n\\nLet\'s take 10 seconds to quickly review some commonly used basic syntax:\\n\\n| Function            | Syntax                                         | Example                                        |\\n| ------------------- | ---------------------------------------------- | ---------------------------------------------- |\\n| **Heading**         | `# Heading 1`, `## Heading 2`, `### Heading 3` | `# Heading 1`, `## Heading 2`, `### Heading 3` |\\n| **Bold**            | `**text**` or `__text__`                       | `**bold text**`                                |\\n| **Italic**          | `*text*` or `_text_`                           | `*italic text*`                                |\\n| **Strikethrough**   | `~~text~~`                                     | `~~strikethrough text~~`                       |\\n| **Blockquote**      | `> blockquote`                                 | `> This is a quote`                            |\\n| **Inline Code**     | `` `code` ``                                   | `` `print(\\"Hello, World!\\")` ``                 |\\n| **Code Block**      | ```                                            | `print(\\"Code block\\")`                          |\\n| **Unordered List**  | `- item` or `* item`                           | `- unordered 1` or `* unordered 2`             |\\n| **Ordered List**    | `1. item`                                      | `1. ordered 1` <br /> `2. ordered 2`           |\\n| **Hyperlink**       | `[link text](URL)`                             | `[GitHub](https://github.com)`                 |\\n| **Horizontal Rule** | `---` or `***`                                 | `---` or `***`                                 |\\n| **Emoji**           | `:emoji_code:`                                 | `:smile:`, `:thumbsup:`                        |\\n\\nEasy! Everyone knows these basics.\\n\\nBesides these, Markdown offers numerous advanced features that can make your documents more organized.\\n\\nHere are a few syntax examples:\\n\\n## 1. Task Lists\\n\\nTask lists display plans, development progress, or to-dos in a checkbox format.\\n\\nIn collaborative projects, they clearly show completed and pending tasks, simplifying tracking and delegation.\\n\\n### Writing Example\\n\\n```\\n- [x] Complete initial project setup\\n- [ ] Write user requirements document\\n- [ ] Integrate front-end and back-end code\\n```\\n\\nIn the example above, `[x]` represents completed tasks, while `[ ]` represents pending tasks.\\n\\nIn GitHub\'s Issues, Pull Requests, or Discussions, tasks are updated in real-time once someone checks off an item.\\n\\n### Visual Output\\n\\n- [x] Complete initial project setup\\n- [ ] Write user requirements document\\n- [ ] Integrate front-end and back-end code\\n\\n---\\n\\n## 2. Alerts\\n\\nAlerts provide highlighted frames and icons in documents to display critical information.\\n\\nThis feature isn\'t native to Markdown but is an extension provided by GitHub.\\n\\n:::tip\\nSince this is an extension, it might not render correctly on other Markdown editors or platforms.\\n\\nAdditionally, it differs significantly from Docusaurus syntax, so be cautious when converting content.\\n:::\\n\\n### Writing Example\\n\\nGitHub offers five types of alerts: `NOTE`, `TIP`, `IMPORTANT`, `WARNING`, and `CAUTION`.\\n\\n```markdown\\n> [!NOTE]\\n> Useful information for skimming users.\\n\\n> [!TIP]\\n> Tips for better or easier implementation.\\n\\n> [!IMPORTANT]\\n> Essential details for achieving a goal.\\n\\n> [!WARNING]\\n> Critical info requiring immediate attention.\\n\\n> [!CAUTION]\\n> Warnings about risks or negative outcomes.\\n```\\n\\nFor multi-line content, add `>` at the start of each line:\\n\\n```markdown\\n> [!TIP]\\n> This is a tip.\\n>\\n> Here is another tip.\\n```\\n\\n### Visual Output\\n\\nDue to limitations here, refer to a GitHub screenshot for results:\\n\\n![GitHub Alert Example](./img/img1.jpg)\\n\\n## 3. Footnotes\\n\\nFor long-form documents or academic-style texts, footnotes allow for referencing sources or adding supplementary information.\\n\\nGitHub Markdown supports footnotes, linking supplementary details to the text while keeping it clean.\\n\\n:::info\\nThis section demonstrates custom anchors.\\n\\nIf you\'re not reading this for that purpose, feel free to ignore it.\\n\\n[**Click here for the custom anchor section**](#my-custom-anchor)\\n:::\\n\\n### Writing Example\\n\\n```markdown\\nIn this step, we use a special feature[^1].\\n\\n[^1]: Detailed notes or external links can be added here.\\n```\\n\\nRendered, it places a superscript number in the text that links to detailed notes at the bottom.\\n\\n### Visual Output\\n\\nIn this step, we use a special feature[^1]. (\uD83D\uDC48 Click on the superscript to check it out.)\\n\\n[^1]: This is a footnote for demonstration.\\n\\n## 4. Escaping Characters\\n\\nSometimes, you want certain symbols like asterisks (\\\\*) or backticks (`) displayed as-is, rather than interpreted as Markdown syntax. In such cases, use escaping.\\n\\n### Writing Example\\n\\n```markdown\\nTo display a `*` symbol, add a backslash: \\\\*\\n\\nLet\'s rename \\\\*our-new-project\\\\* to \\\\*our-old-project\\\\*.\\n```\\n\\n### Visual Output\\n\\nTo display a `*` symbol, add a backslash: \\\\*\\n\\nLet\'s rename \\\\*our-new-project\\\\* to \\\\*our-old-project\\\\*.\\n\\n## 5. Custom Anchors\\n\\nWhile headings automatically generate anchors for navigation, sometimes you need to link non-heading content. You can manually insert HTML anchor tags.\\n\\n### Writing Example\\n\\n1. Link to a heading:\\n\\n   ```markdown\\n   [Link to the \\"Footnotes\\" section](#3-footnotes)\\n   ```\\n\\n2. Link to a custom paragraph:\\n\\n   ```markdown\\n   <a name=\\"my-custom-anchor\\"></a>\\n   This is a special paragraph for internal linking.\\n\\n   [Link to this paragraph](#my-custom-anchor)\\n   ```\\n\\n### Visual Output\\n\\n[**Click here to link to the \\"Footnotes\\" section**](#3-footnotes)\\n\\n---\\n\\n<a name=\\"my-custom-anchor\\"></a>\\n**This is a special paragraph for internal linking.**\\n\\n## Conclusion\\n\\nThese features provide more flexibility in document writing and offer richer presentation options.\\n\\nWe hope this article helps you better understand advanced GitHub Markdown syntax and enhances your document writing experience.\\n\\n## References\\n\\n- [**Basic writing and formatting syntax**](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)"},{"id":"extract-font-info-by-python","metadata":{"permalink":"/en/blog/extract-font-info-by-python","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/12-26-extract-font-info-by-python/index.md","title":"Extract Font File Information","description":"Retrieve font file information using Python.","date":"2024-12-26T00:00:00.000Z","tags":[{"inline":true,"label":"font-tools","permalink":"/en/blog/tags/font-tools"},{"inline":true,"label":"Python","permalink":"/en/blog/tags/python"}],"readingTime":14.645,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"extract-font-info-by-python","title":"Extract Font File Information","authors":"Zephyr","image":"/en/img/2024/1226.webp","tags":["font-tools","Python"],"description":"Retrieve font file information using Python."},"unlisted":false,"prevItem":{"title":"Useful GitHub Markdown Syntax","permalink":"/en/blog/github-markdown-advanced-syntax"},"nextItem":{"title":"Batch Video Conversion","permalink":"/en/blog/flexible-video-conversion-by-python"}},"content":"Although we frequently use various fonts, we often get stuck when it comes to retrieving font parameters.\\n\\nWe forget after using them, and then look them up again next time?\\n\\nThis makes us seem unprofessional, so we need to write a program to solve the problem.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Install `fontTools`\\n\\nWe use `fontTools` to retrieve font-related information. It is a widely praised Python package for handling font files, allowing us to manipulate and parse various TTF and OTF files.\\n\\nFirst, install `fontTools` using the following command:\\n\\n```bash\\npip install fonttools\\n```\\n\\n:::info\\nIf you\'re interested in `fontTools`, you can refer to their project on GitHub: [**fontTools-github**](https://github.com/fonttools/fonttools)\\n:::\\n\\nOnce installed, you can start running the program.\\n\\n## Key Implementation Points\\n\\nBefore we start using the code, let\u2019s review the key implementation points:\\n\\n1. **Remove Control Characters (`remove_control_characters`)**\\n\\n   This function is used to clean up control or invisible characters from a string, as these characters may interfere with subsequent processing. We need to remove them first. Additionally, some characters are made up of multiple Unicode combinations. We use the `unicodedata` module to normalize the string, converting these composite characters into a single character to ensure consistency.\\n\\n   :::tip\\n   If you don\u2019t need this functionality, you can set `normalize` to `False`.\\n   :::\\n\\n2. **Extract Font Information (`extract_font_info`)**\\n\\n   This function extracts various pieces of information from a font and organizes them into a structured, easy-to-read dictionary. It includes a variety of keys, described as follows:\\n\\n   - `fileName`: The path of the font file on the system.\\n   - `tables`: Lists all available tables in the font file.\\n   - `nameTable`: The raw name table indexed by `nameID`.\\n   - `nameTableReadable`: Maps common `nameID` values (e.g., font family, version) to more readable keys.\\n   - `cmapTable`: A mapping of various encodings (platformID, platEncID) to glyph names.\\n   - `headTable`: Basic font parameter information such as `unitsPerEm`, `xMin`, `yMin`, etc.\\n   - `hheaTable`: Horizontal layout information, including ascent, descent, and line gap.\\n   - `OS2Table`: Information about weight (usWeightClass), width (usWidthClass), and embedding restrictions (fsType).\\n   - `postTable`: PostScript-related information, such as whether the font is monospaced (isFixedPitch) and the italic angle (italicAngle).\\n   - `layoutMetrics`: Typography metrics derived from multiple tables, including bounding box, unitsPerEm, line spacing, etc.\\n   - `summary`: A quick overview of the font, including font family, subfamily, version, weight class, and whether it is italic.\\n\\n---\\n\\nOne of the most important parts is the `cmapTable`, which maps various encodings to corresponding characters. In our implementation, we further process this table to convert encodings into readable platform names and encoding names:\\n\\n1. **Platform Name (`platform_name`)**\\n\\n   `platformID` represents the platform supported by the font. Common platform codes include:\\n\\n   - `0`: Unicode (general font standard)\\n   - `1`: Macintosh (Mac system-specific fonts)\\n   - `3`: Windows (Windows system-specific fonts)\\n\\n   In the code, these codes are converted to their corresponding descriptions via a dictionary:\\n\\n   ```python\\n   platform_name = {\\n       0: \'Unicode\',\\n       1: \'Macintosh\',\\n       3: \'Windows\'\\n   }.get(cmap.platformID, f\\"Platform {cmap.platformID}\\")\\n   ```\\n\\n   This code first checks if the `platformID` exists in the dictionary. If a corresponding value is found, it returns the name (e.g., `\'Unicode\'`). If not, it returns `Platform {cmap.platformID}` to handle custom platform codes not in the dictionary.\\n\\n2. **Encoding Name (`encoding_name`)**\\n\\n   The encoding method in the font is determined by both `platformID` and `platEncID`. Common combinations and their meanings are as follows:\\n\\n   - `(0, 0)`: Unicode 1.0\\n   - `(0, 3)`: Unicode 2.0+\\n   - `(0, 4)`: Unicode 2.0+ with BMP (Basic Multilingual Plane)\\n   - `(1, 0)`: Mac Roman (Macintosh Roman alphabet encoding)\\n   - `(3, 1)`: Windows Unicode BMP (Windows Basic Multilingual Plane encoding)\\n   - `(3, 10)`: Windows Unicode Full (Windows Full Unicode encoding)\\n\\n   In the code, these combinations are stored in a nested dictionary and looked up using the tuple `(platformID, platEncID)`:\\n\\n   ```python\\n   encoding_name = {\\n       (0, 0): \'Unicode 1.0\',\\n       (0, 3): \'Unicode 2.0+\',\\n       (0, 4): \'Unicode 2.0+ with BMP\',\\n       (1, 0): \'Mac Roman\',\\n       (3, 1): \'Windows Unicode BMP\',\\n       (3, 10): \'Windows Unicode Full\'\\n   }.get((cmap.platformID, cmap.platEncID), f\\"Encoding {cmap.platEncID}\\")\\n   ```\\n\\n   If a matching combination is found, the program returns the corresponding description. If no match is found, it defaults to `Encoding {cmap.platEncID}`, used to handle unknown encodings.\\n\\n## Code\\n\\nHere is the complete code. You can export the output information as JSON for further analysis or tracking.\\n\\n```python\\nimport re\\nimport unicodedata\\nfrom pathlib import Path\\nfrom typing import List, Union\\n\\nfrom fontTools.ttLib import TTFont\\n\\n\\ndef load_ttfont(font_path: Union[str, Path], **kwargs) -> TTFont:\\n    \\"\\"\\"Load a TrueType font file.\\"\\"\\"\\n    if isinstance(font_path, Path):\\n        font_path = str(font_path)\\n    return TTFont(font_path, **kwargs)\\n\\n\\ndef remove_control_characters(text: str, normalize: bool = True) -> str:\\n    \\"\\"\\"\\n    Remove control characters and invisible formatting characters from a string.\\n\\n    Args:\\n        text (str): The input string.\\n        normalize (bool): Whether to normalize the text to remove inconsistencies.\\n\\n    Returns:\\n        str: The sanitized string with control and invisible characters removed.\\n    \\"\\"\\"\\n    # Remove basic control characters (C0 and C1 control codes)\\n    sanitized = re.sub(r\'[\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]\', \'\', text)\\n\\n    # Remove specific Unicode control and invisible formatting characters\\n    sanitized = re.sub(\\n        r\'[\\\\u200B-\\\\u200F\\\\u2028-\\\\u202F\\\\u2060-\\\\u206F]\', \'\', sanitized)\\n\\n    # Remove directional formatting characters (optional, adjust if needed)\\n    sanitized = re.sub(r\'[\\\\u202A-\\\\u202E]\', \'\', sanitized)\\n\\n    # Optionally, normalize the text to remove any leftover inconsistencies\\n    if normalize:\\n        sanitized = unicodedata.normalize(\'NFKC\', sanitized)\\n\\n    return sanitized\\n\\n\\ndef extract_font_info(\\n    font_path: Union[str, Path],\\n    normalize: bool = True\\n) -> dict:\\n    \\"\\"\\"Extract detailed metadata and structural information from a font file.\\n\\n    Args:\\n        font_path (Union[str, Path]): Path to the font file.\\n\\n    Returns:\\n        dict: A dictionary containing font metadata and tables, including:\\n\\n            - fileName (str): Path to the font file.\\n            - tables (list): List of available tables in the font.\\n            - nameTable (dict): Raw name table values, keyed by nameID.\\n            - nameTableReadable (dict): Readable name table with keys:\\n                * copyright (str): Copyright information.\\n                * fontFamily (str): Font family name.\\n                * fontSubfamily (str): Font subfamily name.\\n                * uniqueID (str): Unique identifier for the font.\\n                * fullName (str): Full font name.\\n                * version (str): Font version string.\\n                * postScriptName (str): PostScript name.\\n            - cmapTable (dict): Character-to-glyph mappings, keyed by encoding.\\n            - cmapTableIndex (list): List of encoding descriptions.\\n            - headTable (dict): Font header table with keys:\\n                * unitsPerEm (int): Units per em.\\n                * xMin (int): Minimum x-coordinate of the glyph bounding box.\\n                * yMin (int): Minimum y-coordinate of the glyph bounding box.\\n                * xMax (int): Maximum x-coordinate of the glyph bounding box.\\n                * yMax (int): Maximum y-coordinate of the glyph bounding box.\\n            - hheaTable (dict): Horizontal header table with keys:\\n                * ascent (int): Typographic ascent.\\n                * descent (int): Typographic descent.\\n                * lineGap (int): Line gap.\\n            - OS2Table (dict): OS/2 table with keys:\\n                * usWeightClass (int): Weight class.\\n                * usWidthClass (int): Width class.\\n                * fsType (int): Embedding restrictions.\\n            - postTable (dict): PostScript table with keys:\\n                * isFixedPitch (bool): Whether the font is monospaced.\\n                * italicAngle (float): Italic angle of the font.\\n            - layoutMetrics (dict): Font layout metrics with keys:\\n                * unitsPerEm (int): Units per em.\\n                * boundingBox (dict): Bounding box coordinates:\\n                    - xMin (int): Minimum x-coordinate.\\n                    - yMin (int): Minimum y-coordinate.\\n                    - xMax (int): Maximum x-coordinate.\\n                    - yMax (int): Maximum y-coordinate.\\n                * ascent (int): Typographic ascent.\\n                * descent (int): Typographic descent.\\n                * lineGap (int): Line gap.\\n            - summary (dict): High-level font summary with keys:\\n                * fontFamily (str): Font family name.\\n                * fontSubfamily (str): Font subfamily name.\\n                * version (str): Font version.\\n                * weightClass (int): Weight class.\\n                * isItalic (bool): Whether the font is italic.\\n    \\"\\"\\"\\n\\n    if isinstance(font_path, Path):\\n        font_path = str(font_path)\\n\\n    font = TTFont(font_path)\\n    font_info = {}\\n\\n    # File name and available tables\\n    font_info[\'fileName\'] = font_path\\n    font_info[\'tables\'] = list(font.keys())\\n\\n    # Parse name table\\n    name_table = {}\\n    for record in font[\'name\'].names:\\n        try:\\n            raw_string = record.string.decode(\'utf-16-be\').strip()\\n            clean_string = remove_control_characters(raw_string, normalize)\\n            name_table[record.nameID] = clean_string\\n        except UnicodeDecodeError:\\n            name_table[record.nameID] = remove_control_characters(\\n                record.string.decode(errors=\'ignore\'), normalize)\\n    font_info[\'nameTable\'] = name_table\\n\\n    # Readable name table for common nameIDs\\n    name_table_readable = {\\n        \'copyright\': name_table.get(0, \'\'),\\n        \'fontFamily\': name_table.get(1, \'\'),\\n        \'fontSubfamily\': name_table.get(2, \'\'),\\n        \'uniqueID\': name_table.get(3, \'\'),\\n        \'fullName\': name_table.get(4, \'\'),\\n        \'version\': name_table.get(5, \'\'),\\n        \'postScriptName\': name_table.get(6, \'\'),\\n    }\\n    font_info[\'nameTableReadable\'] = {\\n        k: remove_control_characters(v, normalize)\\n        for k, v in name_table_readable.items()\\n    }\\n\\n    # Parse cmap table\\n    cmap_table = {}\\n    cmap_table_index = []\\n\\n    for cmap in font[\'cmap\'].tables:\\n        platform_name = {\\n            0: \'Unicode\',\\n            1: \'Macintosh\',\\n            3: \'Windows\'\\n        }.get(cmap.platformID, f\\"Platform {cmap.platformID}\\")\\n\\n        encoding_name = {\\n            (0, 0): \'Unicode 1.0\',\\n            (0, 3): \'Unicode 2.0+\',\\n            (0, 4): \'Unicode 2.0+ with BMP\',\\n            (1, 0): \'Mac Roman\',\\n            (3, 1): \'Windows Unicode BMP\',\\n            (3, 10): \'Windows Unicode Full\'\\n        }.get((cmap.platformID, cmap.platEncID), f\\"Encoding {cmap.platEncID}\\")\\n\\n        cmap_entries = {}\\n        for codepoint, glyph_name in cmap.cmap.items():\\n            char = chr(codepoint)\\n            cmap_entries[remove_control_characters(char, normalize)] = \\\\\\n                remove_control_characters(glyph_name, normalize)\\n\\n        key = f\\"{platform_name}, {encoding_name}\\"\\n        cmap_table[key] = cmap_entries\\n        cmap_table_index.append(key)\\n\\n    font_info[\'cmapTable\'] = cmap_table\\n    font_info[\'cmapTableIndex\'] = cmap_table_index\\n\\n    # Parse head table\\n    head = font[\'head\']\\n    head_table = {\\n        \'unitsPerEm\': head.unitsPerEm,\\n        \'xMin\': head.xMin,\\n        \'yMin\': head.yMin,\\n        \'xMax\': head.xMax,\\n        \'yMax\': head.yMax,\\n    }\\n    font_info[\'headTable\'] = head_table\\n\\n    # Parse hhea table\\n    hhea = font[\'hhea\']\\n    hhea_table = {\\n        \'ascent\': hhea.ascent,\\n        \'descent\': hhea.descent,\\n        \'lineGap\': hhea.lineGap,\\n    }\\n    font_info[\'hheaTable\'] = hhea_table\\n\\n    # Parse OS/2 table\\n    os2 = font[\'OS/2\']\\n    os2_table = {\\n        \'usWeightClass\': os2.usWeightClass,\\n        \'usWidthClass\': os2.usWidthClass,\\n        \'fsType\': os2.fsType,\\n    }\\n    font_info[\'OS2Table\'] = os2_table\\n\\n    # Parse post table\\n    post = font[\'post\']\\n    post_table = {\\n        \'isFixedPitch\': post.isFixedPitch,\\n        \'italicAngle\': post.italicAngle,\\n    }\\n    font_info[\'postTable\'] = post_table\\n\\n    # Combine layout-related metrics\\n    font_info[\'layoutMetrics\'] = {\\n        \'unitsPerEm\': head_table[\'unitsPerEm\'],\\n        \'boundingBox\': {\\n            \'xMin\': head_table[\'xMin\'],\\n            \'yMin\': head_table[\'yMin\'],\\n            \'xMax\': head_table[\'xMax\'],\\n            \'yMax\': head_table[\'yMax\']\\n        },\\n        \'ascent\': hhea_table[\'ascent\'],\\n        \'descent\': hhea_table[\'descent\'],\\n        \'lineGap\': hhea_table[\'lineGap\']\\n    }\\n\\n    # Font summary\\n    font_info[\'summary\'] = {\\n        \'fontFamily\': name_table_readable[\'fontFamily\'],\\n        \'fontSubfamily\': name_table_readable[\'fontSubfamily\'],\\n        \'version\': name_table_readable[\'version\'],\\n        \'weightClass\': os2.usWeightClass,\\n        \'isItalic\': post_table[\'italicAngle\'] != 0\\n    }\\n\\n    return font_info\\n```\\n\\n## Example Output\\n\\nLet\u2019s take the font file `OcrB-Regular.ttf` as an example. We will call the function and then export the results to a JSON file:\\n\\n```python\\nimport json\\n\\nfont_infos = extract_font_info(\'OcrB-Regular.ttf\')\\njson.dump(font_infos, open(\'OcrB-Regular-Info.json\', \'w\'),\\n          indent=2, ensure_ascii=False)\\n```\\n\\nThe output will be as follows:\\n\\n```json\\n{\\n  \\"fileName\\": \\"/path/to/your/folder/OcrB-Regular.ttf\\",\\n  \\"tables\\": [\\n    \\"GlyphOrder\\",\\n    \\"head\\",\\n    \\"hhea\\",\\n    \\"maxp\\",\\n    \\"OS/2\\",\\n    \\"hmtx\\",\\n    \\"hdmx\\",\\n    \\"cmap\\",\\n    \\"fpgm\\",\\n    \\"prep\\",\\n    \\"cvt \\",\\n    \\"loca\\",\\n    \\"glyf\\",\\n    \\"name\\",\\n    \\"post\\"\\n  ],\\n  \\"nameTable\\": {\\n    \\"0\\": \\"This is a copyrighted typeface program\\",\\n    \\"1\\": \\"OcrB\\",\\n    \\"2\\": \\"Regular\\",\\n    \\"3\\": \\"Altsys Fontographer 3.5  OcrB Regular\\",\\n    \\"4\\": \\"OcrB Regular\\",\\n    \\"5\\": \\"Altsys Fontographer 3.5  4/15/93\\",\\n    \\"6\\": \\"OcrB Regular\\"\\n  },\\n  \\"nameTableReadable\\": {\\n    \\"copyright\\": \\"This is a copyrighted typeface program\\",\\n    \\"fontFamily\\": \\"OcrB\\",\\n    \\"fontSubfamily\\": \\"Regular\\",\\n    \\"uniqueID\\": \\"Altsys Fontographer 3.5  OcrB Regular\\",\\n    \\"fullName\\": \\"OcrB Regular\\",\\n    \\"version\\": \\"Altsys Fontographer 3.5  4/15/93\\",\\n    \\"postScriptName\\": \\"OcrB Regular\\"\\n  },\\n  \\"cmapTable\\": {\\n    \\"Unicode, Unicode 1.0\\": {\\n      \\" \\": \\"nonbreakingspace\\",\\n      \\"!\\": \\"exclam\\",\\n      \\"\\\\\\"\\": \\"quotedbl\\",\\n      \\"#\\": \\"numbersign\\",\\n      \\"$\\": \\"dollar\\",\\n      \\"%\\": \\"percent\\",\\n      \\"&\\": \\"ampersand\\",\\n      \\"\'\\": \\"quotesingle\\",\\n      \\"(\\": \\"parenleft\\",\\n      \\")\\": \\"parenright\\",\\n      \\"*\\": \\"asterisk\\",\\n      \\"+\\": \\"plus\\",\\n      \\",\\": \\"comma\\",\\n      \\"-\\": \\"hyphen\\",\\n      \\".\\": \\"period\\",\\n      \\"/\\": \\"slash\\",\\n      \\"0\\": \\"zero\\",\\n      \\"1\\": \\"one\\",\\n      \\"2\\": \\"two\\",\\n      \\"3\\": \\"three\\",\\n      \\"4\\": \\"four\\",\\n      \\"5\\": \\"five\\",\\n      \\"6\\": \\"six\\",\\n      \\"7\\": \\"seven\\",\\n      \\"8\\": \\"eight\\",\\n      \\"9\\": \\"nine\\",\\n      \\":\\": \\"colon\\",\\n      \\";\\": \\"semicolon\\",\\n      \\"<\\": \\"less\\",\\n      \\"=\\": \\"equal\\",\\n      \\">\\": \\"greater\\",\\n      \\"?\\": \\"question\\",\\n      \\"@\\": \\"at\\",\\n      \\"A\\": \\"A\\",\\n      \\"B\\": \\"B\\",\\n      \\"C\\": \\"C\\",\\n      \\"D\\": \\"D\\",\\n      \\"E\\": \\"E\\",\\n      \\"F\\": \\"F\\",\\n      \\"G\\": \\"G\\",\\n      \\"H\\": \\"H\\",\\n      \\"I\\": \\"I\\",\\n      \\"J\\": \\"J\\",\\n      \\"K\\": \\"K\\",\\n      \\"L\\": \\"L\\",\\n      \\"M\\": \\"M\\",\\n      \\"N\\": \\"N\\",\\n      \\"O\\": \\"O\\",\\n      \\"P\\": \\"P\\",\\n      \\"Q\\": \\"Q\\",\\n      \\"R\\": \\"R\\",\\n      \\"S\\": \\"S\\",\\n      \\"T\\": \\"T\\",\\n      \\"U\\": \\"U\\",\\n      \\"V\\": \\"V\\",\\n      \\"W\\": \\"W\\",\\n      \\"X\\": \\"X\\",\\n      \\"Y\\": \\"Y\\",\\n      \\"Z\\": \\"Z\\",\\n      \\"[\\": \\"bracketleft\\",\\n      \\"\\\\\\\\\\": \\"backslash\\",\\n      \\"]\\": \\"bracketright\\",\\n      \\"^\\": \\"asciicircum\\",\\n      \\"_\\": \\"underscore\\",\\n      \\"`\\": \\"grave\\",\\n      \\"a\\": \\"a\\",\\n      \\"b\\": \\"b\\",\\n      \\"c\\": \\"c\\",\\n      \\"d\\": \\"d\\",\\n      \\"e\\": \\"e\\",\\n      \\"f\\": \\"f\\",\\n      \\"g\\": \\"g\\",\\n      \\"h\\": \\"h\\",\\n      \\"i\\": \\"i\\",\\n      \\"j\\": \\"j\\",\\n      \\"k\\": \\"k\\",\\n      \\"l\\": \\"l\\",\\n      \\"m\\": \\"m\\",\\n      \\"n\\": \\"n\\",\\n      \\"o\\": \\"o\\",\\n      \\"p\\": \\"p\\",\\n      \\"q\\": \\"q\\",\\n      \\"r\\": \\"r\\",\\n      \\"s\\": \\"zcaron\\",\\n      \\"t\\": \\"t\\",\\n      \\"u\\": \\"u\\",\\n      \\"v\\": \\"v\\",\\n      \\"w\\": \\"w\\",\\n      \\"x\\": \\"x\\",\\n      \\"y\\": \\"y\\",\\n      \\"z\\": \\"z\\",\\n      \\"{\\": \\"braceleft\\",\\n      \\"|\\": \\"bar\\",\\n      \\"}\\": \\"braceright\\",\\n      \\"\xa1\\": \\"exclamdown\\",\\n      \\"\xa2\\": \\"cent\\",\\n      \\"\xa3\\": \\"sterling\\",\\n      \\"\xa4\\": \\"currency\\",\\n      \\"\xa5\\": \\"yen\\",\\n      \\"\xa7\\": \\"section\\",\\n      \\" \u0308\\": \\"dieresis\\",\\n      \\"\xab\\": \\"guillemotleft\\",\\n      \\"\xad\\": \\"hyphen\\",\\n      \\" \u0304\\": \\"macron\\",\\n      \\" \u0301\\": \\"acute\\",\\n      \\"\xb7\\": \\"periodcentered\\",\\n      \\" \u0327\\": \\"cedilla\\",\\n      \\"\xbb\\": \\"guillemotright\\",\\n      \\"\xbf\\": \\"questiondown\\",\\n      \\"\xc0\\": \\"Agrave\\",\\n      \\"\xc1\\": \\"Aacute\\",\\n      \\"\xc2\\": \\"Acircumflex\\",\\n      \\"\xc3\\": \\"Atilde\\",\\n      \\"\xc4\\": \\"Adieresis\\",\\n      \\"\xc5\\": \\"Aring\\",\\n      \\"\xc6\\": \\"AE\\",\\n      \\"\xc7\\": \\"Ccedilla\\",\\n      \\"\xc8\\": \\"Egrave\\",\\n      \\"\xc9\\": \\"Eacute\\",\\n      \\"\xca\\": \\"Ecircumflex\\",\\n      \\"\xcb\\": \\"Edieresis\\",\\n      \\"\xcc\\": \\"Igrave\\",\\n      \\"\xcd\\": \\"Iacute\\",\\n      \\"\xce\\": \\"Icircumflex\\",\\n      \\"\xcf\\": \\"Idieresis\\",\\n      \\"\xd0\\": \\"Eth\\",\\n      \\"\xd1\\": \\"Ntilde\\",\\n      \\"\xd2\\": \\"Ograve\\",\\n      \\"\xd3\\": \\"Oacute\\",\\n      \\"\xd4\\": \\"Ocircumflex\\",\\n      \\"\xd5\\": \\"Otilde\\",\\n      \\"\xd6\\": \\"Odieresis\\",\\n      \\"\xd7\\": \\".null\\",\\n      \\"\xd8\\": \\"Oslash\\",\\n      \\"\xd9\\": \\"Ugrave\\",\\n      \\"\xda\\": \\"Uacute\\",\\n      \\"\xdb\\": \\"Ucircumflex\\",\\n      \\"\xdc\\": \\"Udieresis\\",\\n      \\"\xdd\\": \\"Yacute#1\\",\\n      \\"\xde\\": \\"Thorn\\",\\n      \\"\xdf\\": \\"germandbls\\",\\n      \\"\xe0\\": \\"agrave\\",\\n      \\"\xe1\\": \\"aacute\\",\\n      \\"\xe2\\": \\"acircumflex\\",\\n      \\"\xe3\\": \\"atilde\\",\\n      \\"\xe4\\": \\"adieresis\\",\\n      \\"\xe5\\": \\"aring\\",\\n      \\"\xe6\\": \\"ae\\",\\n      \\"\xe7\\": \\"ccedilla\\",\\n      \\"\xe8\\": \\"egrave\\",\\n      \\"\xe9\\": \\"eacute\\",\\n      \\"\xea\\": \\"ecircumflex\\",\\n      \\"\xeb\\": \\"edieresis\\",\\n      \\"\xec\\": \\"igrave\\",\\n      \\"\xed\\": \\"iacute\\",\\n      \\"\xee\\": \\"icircumflex\\",\\n      \\"\xef\\": \\"idieresis\\",\\n      \\"\xf0\\": \\"Yacute\\",\\n      \\"\xf1\\": \\"ntilde\\",\\n      \\"\xf2\\": \\"ograve\\",\\n      \\"\xf3\\": \\"oacute\\",\\n      \\"\xf4\\": \\"ocircumflex\\",\\n      \\"\xf5\\": \\"otilde\\",\\n      \\"\xf6\\": \\"odieresis\\",\\n      \\"\xf8\\": \\"oslash\\",\\n      \\"\xf9\\": \\"ugrave\\",\\n      \\"\xfa\\": \\"uacute\\",\\n      \\"\xfb\\": \\"ucircumflex\\",\\n      \\"\xfc\\": \\"udieresis\\",\\n      \\"\xfd\\": \\"yacute\\",\\n      \\"\xfe\\": \\"thorn\\",\\n      \\"\xff\\": \\"ydieresis\\",\\n      \\"\u0131\\": \\"dotlessi\\",\\n      \\"\u0141\\": \\"Lslash\\",\\n      \\"\u0142\\": \\"lslash\\",\\n      \\"\u0152\\": \\"OE\\",\\n      \\"\u0153\\": \\"oe\\",\\n      \\"\u0160\\": \\"Scaron\\",\\n      \\"\u0161\\": \\"scaron\\",\\n      \\"\u0178\\": \\"Ydieresis\\",\\n      \\"\u017D\\": \\"Zcaron\\",\\n      \\"\u02BA\\": \\"hungarumlaut\\",\\n      \\"\u02C6\\": \\"circumflex\\",\\n      \\"\u02C7\\": \\"caron\\",\\n      \\"\u02C9\\": \\"macron\\",\\n      \\" \u0306\\": \\"breve\\",\\n      \\" \u0307\\": \\"dotaccent\\",\\n      \\" \u030A\\": \\"ring\\",\\n      \\" \u0328\\": \\"ogonek\\",\\n      \\" \u0303\\": \\"tilde\\",\\n      \\"\u2013\\": \\"endash\\",\\n      \\"\u2014\\": \\"emdash\\",\\n      \\"\u2018\\": \\"quoteleft\\",\\n      \\"\u201A\\": \\"quotesinglbase\\",\\n      \\"\u201C\\": \\"quotedblleft\\",\\n      \\"\u201D\\": \\"quotedblright\\",\\n      \\"\u201E\\": \\"quotedblbase\\",\\n      \\"\u2020\\": \\"dagger\\",\\n      \\"\u2021\\": \\"daggerdbl\\",\\n      \\"...\\": \\"ellipsis\\",\\n      \\"\u2039\\": \\"guilsinglleft\\",\\n      \\"\u203A\\": \\"guilsinglright\\",\\n      \\"\u2212\\": \\"minus\\",\\n      \\"\u2219\\": \\"periodcentered\\"\\n    },\\n    \\"Macintosh, Mac Roman\\": {\\n      \\"\\": \\"udieresis\\",\\n      \\" \\": \\"dagger\\",\\n      \\"!\\": \\"exclam\\",\\n      \\"\\\\\\"\\": \\"quotedbl\\",\\n      \\"#\\": \\"numbersign\\",\\n      \\"$\\": \\"dollar\\",\\n      \\"%\\": \\"percent\\",\\n      \\"&\\": \\"ampersand\\",\\n      \\"\'\\": \\"quotesingle\\",\\n      \\"(\\": \\"parenleft\\",\\n      \\")\\": \\"parenright\\",\\n      \\"*\\": \\"asterisk\\",\\n      \\"+\\": \\"plus\\",\\n      \\",\\": \\"comma\\",\\n      \\"-\\": \\"hyphen\\",\\n      \\".\\": \\"period\\",\\n      \\"/\\": \\"slash\\",\\n      \\"0\\": \\"zero\\",\\n      \\"1\\": \\"one\\",\\n      \\"2\\": \\"two\\",\\n      \\"3\\": \\"three\\",\\n      \\"4\\": \\"four\\",\\n      \\"5\\": \\"five\\",\\n      \\"6\\": \\"six\\",\\n      \\"7\\": \\"seven\\",\\n      \\"8\\": \\"eight\\",\\n      \\"9\\": \\"nine\\",\\n      \\":\\": \\"colon\\",\\n      \\";\\": \\"semicolon\\",\\n      \\"<\\": \\"less\\",\\n      \\"=\\": \\"equal\\",\\n      \\">\\": \\"greater\\",\\n      \\"?\\": \\"question\\",\\n      \\"@\\": \\"at\\",\\n      \\"A\\": \\"A\\",\\n      \\"B\\": \\"B\\",\\n      \\"C\\": \\"C\\",\\n      \\"D\\": \\"D\\",\\n      \\"E\\": \\"E\\",\\n      \\"F\\": \\"F\\",\\n      \\"G\\": \\"G\\",\\n      \\"H\\": \\"H\\",\\n      \\"I\\": \\"I\\",\\n      \\"J\\": \\"J\\",\\n      \\"K\\": \\"K\\",\\n      \\"L\\": \\"L\\",\\n      \\"M\\": \\"M\\",\\n      \\"N\\": \\"N\\",\\n      \\"O\\": \\"O\\",\\n      \\"P\\": \\"P\\",\\n      \\"Q\\": \\"Q\\",\\n      \\"R\\": \\"R\\",\\n      \\"S\\": \\"S\\",\\n      \\"T\\": \\"T\\",\\n      \\"U\\": \\"U\\",\\n      \\"V\\": \\"V\\",\\n      \\"W\\": \\"W\\",\\n      \\"X\\": \\"X\\",\\n      \\"Y\\": \\"Y\\",\\n      \\"Z\\": \\"Z\\",\\n      \\"[\\": \\"bracketleft\\",\\n      \\"\\\\\\\\\\": \\"backslash\\",\\n      \\"]\\": \\"bracketright\\",\\n      \\"^\\": \\"asciicircum\\",\\n      \\"_\\": \\"underscore\\",\\n      \\"`\\": \\"grave\\",\\n      \\"a\\": \\"a\\",\\n      \\"b\\": \\"b\\",\\n      \\"c\\": \\"c\\",\\n      \\"d\\": \\"d\\",\\n      \\"e\\": \\"e\\",\\n      \\"f\\": \\"f\\",\\n      \\"g\\": \\"g\\",\\n      \\"h\\": \\"h\\",\\n      \\"i\\": \\"i\\",\\n      \\"j\\": \\"j\\",\\n      \\"k\\": \\"k\\",\\n      \\"l\\": \\"l\\",\\n      \\"m\\": \\"m\\",\\n      \\"n\\": \\"n\\",\\n      \\"o\\": \\"o\\",\\n      \\"p\\": \\"p\\",\\n      \\"q\\": \\"q\\",\\n      \\"r\\": \\"r\\",\\n      \\"s\\": \\"s\\",\\n      \\"t\\": \\"t\\",\\n      \\"u\\": \\"u\\",\\n      \\"v\\": \\"v\\",\\n      \\"w\\": \\"w\\",\\n      \\"x\\": \\"x\\",\\n      \\"y\\": \\"y\\",\\n      \\"z\\": \\"z\\",\\n      \\"{\\": \\"braceleft\\",\\n      \\"|\\": \\"bar\\",\\n      \\"}\\": \\"braceright\\",\\n      \\"\xa2\\": \\"cent\\",\\n      \\"\xa3\\": \\"sterling\\",\\n      \\"\xa4\\": \\"section\\",\\n      \\"\xa7\\": \\"germandbls\\",\\n      \\"\xab\\": \\"acute\\",\\n      \\"\xac\\": \\"dieresis\\",\\n      \\"\xae\\": \\"AE\\",\\n      \\" \u0304\\": \\"Oslash\\",\\n      \\" \u0301\\": \\"yen\\",\\n      \\"3\u20444\\": \\"ae\\",\\n      \\"\xbf\\": \\"oslash\\",\\n      \\"\xc0\\": \\"questiondown\\",\\n      \\"\xc1\\": \\"exclamdown\\",\\n      \\"\xc7\\": \\"guillemotleft\\",\\n      \\"\xc8\\": \\"guillemotright\\",\\n      \\"\xc9\\": \\"ellipsis\\",\\n      \\"\xca\\": \\"nonbreakingspace\\",\\n      \\"\xcb\\": \\"Agrave\\",\\n      \\"\xcc\\": \\"Atilde\\",\\n      \\"\xcd\\": \\"Otilde\\",\\n      \\"\xce\\": \\"OE\\",\\n      \\"\xcf\\": \\"oe\\",\\n      \\"\xd0\\": \\"endash\\",\\n      \\"\xd1\\": \\"emdash\\",\\n      \\"\xd2\\": \\"quotedblleft\\",\\n      \\"\xd3\\": \\"quotedblright\\",\\n      \\"\xd4\\": \\"quoteleft\\",\\n      \\"\xd8\\": \\"ydieresis\\",\\n      \\"\xd9\\": \\"Ydieresis\\",\\n      \\"\xdb\\": \\"currency\\",\\n      \\"\xdc\\": \\"guilsinglleft\\",\\n      \\"\xdd\\": \\"guilsinglright\\",\\n      \\"\xe0\\": \\"daggerdbl\\",\\n      \\"\xe1\\": \\"periodcentered\\",\\n      \\"\xe2\\": \\"quotesinglbase\\",\\n      \\"\xe3\\": \\"quotedblbase\\",\\n      \\"\xe5\\": \\"Acircumflex\\",\\n      \\"\xe6\\": \\"Ecircumflex\\",\\n      \\"\xe7\\": \\"Aacute\\",\\n      \\"\xe8\\": \\"Edieresis\\",\\n      \\"\xe9\\": \\"Egrave\\",\\n      \\"\xea\\": \\"Iacute\\",\\n      \\"\xeb\\": \\"Icircumflex\\",\\n      \\"\xec\\": \\"Idieresis\\",\\n      \\"\xed\\": \\"Igrave\\",\\n      \\"\xee\\": \\"Oacute\\",\\n      \\"\xef\\": \\"Ocircumflex\\",\\n      \\"\xf1\\": \\"Ograve\\",\\n      \\"\xf2\\": \\"Uacute\\",\\n      \\"\xf3\\": \\"Ucircumflex\\",\\n      \\"\xf4\\": \\"Ugrave\\",\\n      \\"\xf5\\": \\"dotlessi\\",\\n      \\"\xf6\\": \\"circumflex\\",\\n      \\"\xf7\\": \\"tilde\\",\\n      \\"\xf8\\": \\"macron\\",\\n      \\"\xf9\\": \\"breve\\",\\n      \\"\xfa\\": \\"dotaccent\\",\\n      \\"\xfb\\": \\"ring\\",\\n      \\"\xfc\\": \\"cedilla\\",\\n      \\"\xfd\\": \\"hungarumlaut\\",\\n      \\"\xfe\\": \\"ogonek\\",\\n      \\"\xff\\": \\"caron\\"\\n    },\\n    \\"Windows, Windows Unicode BMP\\": {\\n      \\" \\": \\"nonbreakingspace\\",\\n      \\"!\\": \\"exclam\\",\\n      \\"\\\\\\"\\": \\"quotedbl\\",\\n      \\"#\\": \\"numbersign\\",\\n      \\"$\\": \\"dollar\\",\\n      \\"%\\": \\"percent\\",\\n      \\"&\\": \\"ampersand\\",\\n      \\"\'\\": \\"quotesingle\\",\\n      \\"(\\": \\"parenleft\\",\\n      \\")\\": \\"parenright\\",\\n      \\"*\\": \\"asterisk\\",\\n      \\"+\\": \\"plus\\",\\n      \\",\\": \\"comma\\",\\n      \\"-\\": \\"hyphen\\",\\n      \\".\\": \\"period\\",\\n      \\"/\\": \\"slash\\",\\n      \\"0\\": \\"zero\\",\\n      \\"1\\": \\"one\\",\\n      \\"2\\": \\"two\\",\\n      \\"3\\": \\"three\\",\\n      \\"4\\": \\"four\\",\\n      \\"5\\": \\"five\\",\\n      \\"6\\": \\"six\\",\\n      \\"7\\": \\"seven\\",\\n      \\"8\\": \\"eight\\",\\n      \\"9\\": \\"nine\\",\\n      \\":\\": \\"colon\\",\\n      \\";\\": \\"semicolon\\",\\n      \\"<\\": \\"less\\",\\n      \\"=\\": \\"equal\\",\\n      \\">\\": \\"greater\\",\\n      \\"?\\": \\"question\\",\\n      \\"@\\": \\"at\\",\\n      \\"A\\": \\"A\\",\\n      \\"B\\": \\"B\\",\\n      \\"C\\": \\"C\\",\\n      \\"D\\": \\"D\\",\\n      \\"E\\": \\"E\\",\\n      \\"F\\": \\"F\\",\\n      \\"G\\": \\"G\\",\\n      \\"H\\": \\"H\\",\\n      \\"I\\": \\"I\\",\\n      \\"J\\": \\"J\\",\\n      \\"K\\": \\"K\\",\\n      \\"L\\": \\"L\\",\\n      \\"M\\": \\"M\\",\\n      \\"N\\": \\"N\\",\\n      \\"O\\": \\"O\\",\\n      \\"P\\": \\"P\\",\\n      \\"Q\\": \\"Q\\",\\n      \\"R\\": \\"R\\",\\n      \\"S\\": \\"S\\",\\n      \\"T\\": \\"T\\",\\n      \\"U\\": \\"U\\",\\n      \\"V\\": \\"V\\",\\n      \\"W\\": \\"W\\",\\n      \\"X\\": \\"X\\",\\n      \\"Y\\": \\"Y\\",\\n      \\"Z\\": \\"Z\\",\\n      \\"[\\": \\"bracketleft\\",\\n      \\"\\\\\\\\\\": \\"backslash\\",\\n      \\"]\\": \\"bracketright\\",\\n      \\"^\\": \\"asciicircum\\",\\n      \\"_\\": \\"underscore\\",\\n      \\"`\\": \\"grave\\",\\n      \\"a\\": \\"a\\",\\n      \\"b\\": \\"b\\",\\n      \\"c\\": \\"c\\",\\n      \\"d\\": \\"d\\",\\n      \\"e\\": \\"e\\",\\n      \\"f\\": \\"f\\",\\n      \\"g\\": \\"g\\",\\n      \\"h\\": \\"h\\",\\n      \\"i\\": \\"i\\",\\n      \\"j\\": \\"j\\",\\n      \\"k\\": \\"k\\",\\n      \\"l\\": \\"l\\",\\n      \\"m\\": \\"m\\",\\n      \\"n\\": \\"n\\",\\n      \\"o\\": \\"o\\",\\n      \\"p\\": \\"p\\",\\n      \\"q\\": \\"q\\",\\n      \\"r\\": \\"r\\",\\n      \\"s\\": \\"zcaron\\",\\n      \\"t\\": \\"t\\",\\n      \\"u\\": \\"u\\",\\n      \\"v\\": \\"v\\",\\n      \\"w\\": \\"w\\",\\n      \\"x\\": \\"x\\",\\n      \\"y\\": \\"y\\",\\n      \\"z\\": \\"z\\",\\n      \\"{\\": \\"braceleft\\",\\n      \\"|\\": \\"bar\\",\\n      \\"}\\": \\"braceright\\",\\n      \\"\xa1\\": \\"exclamdown\\",\\n      \\"\xa2\\": \\"cent\\",\\n      \\"\xa3\\": \\"sterling\\",\\n      \\"\xa4\\": \\"currency\\",\\n      \\"\xa5\\": \\"yen\\",\\n      \\"\xa7\\": \\"section\\",\\n      \\" \u0308\\": \\"dieresis\\",\\n      \\"\xab\\": \\"guillemotleft\\",\\n      \\"\xad\\": \\"hyphen\\",\\n      \\" \u0304\\": \\"macron\\",\\n      \\" \u0301\\": \\"acute\\",\\n      \\"\xb7\\": \\"periodcentered\\",\\n      \\" \u0327\\": \\"cedilla\\",\\n      \\"\xbb\\": \\"guillemotright\\",\\n      \\"\xbf\\": \\"questiondown\\",\\n      \\"\xc0\\": \\"Agrave\\",\\n      \\"\xc1\\": \\"Aacute\\",\\n      \\"\xc2\\": \\"Acircumflex\\",\\n      \\"\xc3\\": \\"Atilde\\",\\n      \\"\xc4\\": \\"Adieresis\\",\\n      \\"\xc5\\": \\"Aring\\",\\n      \\"\xc6\\": \\"AE\\",\\n      \\"\xc7\\": \\"Ccedilla\\",\\n      \\"\xc8\\": \\"Egrave\\",\\n      \\"\xc9\\": \\"Eacute\\",\\n      \\"\xca\\": \\"Ecircumflex\\",\\n      \\"\xcb\\": \\"Edieresis\\",\\n      \\"\xcc\\": \\"Igrave\\",\\n      \\"\xcd\\": \\"Iacute\\",\\n      \\"\xce\\": \\"Icircumflex\\",\\n      \\"\xcf\\": \\"Idieresis\\",\\n      \\"\xd0\\": \\"Eth\\",\\n      \\"\xd1\\": \\"Ntilde\\",\\n      \\"\xd2\\": \\"Ograve\\",\\n      \\"\xd3\\": \\"Oacute\\",\\n      \\"\xd4\\": \\"Ocircumflex\\",\\n      \\"\xd5\\": \\"Otilde\\",\\n      \\"\xd6\\": \\"Odieresis\\",\\n      \\"\xd7\\": \\".null\\",\\n      \\"\xd8\\": \\"Oslash\\",\\n      \\"\xd9\\": \\"Ugrave\\",\\n      \\"\xda\\": \\"Uacute\\",\\n      \\"\xdb\\": \\"Ucircumflex\\",\\n      \\"\xdc\\": \\"Udieresis\\",\\n      \\"\xdd\\": \\"Yacute#1\\",\\n      \\"\xde\\": \\"Thorn\\",\\n      \\"\xdf\\": \\"germandbls\\",\\n      \\"\xe0\\": \\"agrave\\",\\n      \\"\xe1\\": \\"aacute\\",\\n      \\"\xe2\\": \\"acircumflex\\",\\n      \\"\xe3\\": \\"atilde\\",\\n      \\"\xe4\\": \\"adieresis\\",\\n      \\"\xe5\\": \\"aring\\",\\n      \\"\xe6\\": \\"ae\\",\\n      \\"\xe7\\": \\"ccedilla\\",\\n      \\"\xe8\\": \\"egrave\\",\\n      \\"\xe9\\": \\"eacute\\",\\n      \\"\xea\\": \\"ecircumflex\\",\\n      \\"\xeb\\": \\"edieresis\\",\\n      \\"\xec\\": \\"igrave\\",\\n      \\"\xed\\": \\"iacute\\",\\n      \\"\xee\\": \\"icircumflex\\",\\n      \\"\xef\\": \\"idieresis\\",\\n      \\"\xf0\\": \\"Yacute\\",\\n      \\"\xf1\\": \\"ntilde\\",\\n      \\"\xf2\\": \\"ograve\\",\\n      \\"\xf3\\": \\"oacute\\",\\n      \\"\xf4\\": \\"ocircumflex\\",\\n      \\"\xf5\\": \\"otilde\\",\\n      \\"\xf6\\": \\"odieresis\\",\\n      \\"\xf8\\": \\"oslash\\",\\n      \\"\xf9\\": \\"ugrave\\",\\n      \\"\xfa\\": \\"uacute\\",\\n      \\"\xfb\\": \\"ucircumflex\\",\\n      \\"\xfc\\": \\"udieresis\\",\\n      \\"\xfd\\": \\"yacute\\",\\n      \\"\xfe\\": \\"thorn\\",\\n      \\"\xff\\": \\"ydieresis\\",\\n      \\"\u0131\\": \\"dotlessi\\",\\n      \\"\u0141\\": \\"Lslash\\",\\n      \\"\u0142\\": \\"lslash\\",\\n      \\"\u0152\\": \\"OE\\",\\n      \\"\u0153\\": \\"oe\\",\\n      \\"\u0160\\": \\"Scaron\\",\\n      \\"\u0161\\": \\"scaron\\",\\n      \\"\u0178\\": \\"Ydieresis\\",\\n      \\"\u017D\\": \\"Zcaron\\",\\n      \\"\u02BA\\": \\"hungarumlaut\\",\\n      \\"\u02C6\\": \\"circumflex\\",\\n      \\"\u02C7\\": \\"caron\\",\\n      \\"\u02C9\\": \\"macron\\",\\n      \\" \u0306\\": \\"breve\\",\\n      \\" \u0307\\": \\"dotaccent\\",\\n      \\" \u030A\\": \\"ring\\",\\n      \\" \u0328\\": \\"ogonek\\",\\n      \\" \u0303\\": \\"tilde\\",\\n      \\"\u2013\\": \\"endash\\",\\n      \\"\u2014\\": \\"emdash\\",\\n      \\"\u2018\\": \\"quoteleft\\",\\n      \\"\u201A\\": \\"quotesinglbase\\",\\n      \\"\u201C\\": \\"quotedblleft\\",\\n      \\"\u201D\\": \\"quotedblright\\",\\n      \\"\u201E\\": \\"quotedblbase\\",\\n      \\"\u2020\\": \\"dagger\\",\\n      \\"\u2021\\": \\"daggerdbl\\",\\n      \\"...\\": \\"ellipsis\\",\\n      \\"\u2039\\": \\"guilsinglleft\\",\\n      \\"\u203A\\": \\"guilsinglright\\",\\n      \\"\u2212\\": \\"minus\\",\\n      \\"\u2219\\": \\"periodcentered\\"\\n    }\\n  },\\n  \\"cmapTableIndex\\": [\\n    \\"Unicode, Unicode 1.0\\",\\n    \\"Macintosh, Mac Roman\\",\\n    \\"Windows, Windows Unicode BMP\\"\\n  ],\\n  \\"headTable\\": {\\n    \\"unitsPerEm\\": 1000,\\n    \\"xMin\\": -89,\\n    \\"yMin\\": -337,\\n    \\"xMax\\": 691,\\n    \\"yMax\\": 744\\n  },\\n  \\"hheaTable\\": {\\n    \\"ascent\\": 744,\\n    \\"descent\\": -337,\\n    \\"lineGap\\": 0\\n  },\\n  \\"OS2Table\\": {\\n    \\"usWeightClass\\": 400,\\n    \\"usWidthClass\\": 5,\\n    \\"fsType\\": 2\\n  },\\n  \\"postTable\\": {\\n    \\"isFixedPitch\\": 0,\\n    \\"italicAngle\\": 0.0\\n  },\\n  \\"layoutMetrics\\": {\\n    \\"unitsPerEm\\": 1000,\\n    \\"boundingBox\\": {\\n      \\"xMin\\": -89,\\n      \\"yMin\\": -337,\\n      \\"xMax\\": 691,\\n      \\"yMax\\": 744\\n    },\\n    \\"ascent\\": 744,\\n    \\"descent\\": -337,\\n    \\"lineGap\\": 0\\n  },\\n  \\"summary\\": {\\n    \\"fontFamily\\": \\"OcrB\\",\\n    \\"fontSubfamily\\": \\"Regular\\",\\n    \\"version\\": \\"Altsys Fontographer 3.5  4/15/93\\",\\n    \\"weightClass\\": 400,\\n    \\"isItalic\\": false\\n  }\\n}\\n```\\n\\n## References\\n\\n- [**Character to Glyph Mapping Table**](https://developer.apple.com/fonts/TrueType-Reference-Manual/RM06/Chap6cmap.html?utm_source=chatgpt.com)\\n- [**cmap \u2014 Character to Glyph Index Mapping Table**](https://learn.microsoft.com/en-us/typography/opentype/spec/cmap?utm_source=chatgpt.com)"},{"id":"flexible-video-conversion-by-python","metadata":{"permalink":"/en/blog/flexible-video-conversion-by-python","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/12-17-flexible-video-conversion-by-python/index.md","title":"Batch Video Conversion","description":"Build a batch conversion process with Python and ffmpeg to convert to a specified format.","date":"2024-12-17T00:00:00.000Z","tags":[{"inline":true,"label":"Media-Processing","permalink":"/en/blog/tags/media-processing"},{"inline":true,"label":"Python","permalink":"/en/blog/tags/python"},{"inline":true,"label":"ffmpeg","permalink":"/en/blog/tags/ffmpeg"}],"readingTime":3.965,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"flexible-video-conversion-by-python","title":"Batch Video Conversion","authors":"Zephyr","image":"/en/img/2024/1217.webp","tags":["Media-Processing","Python","ffmpeg"],"description":"Build a batch conversion process with Python and ffmpeg to convert to a specified format."},"unlisted":false,"prevItem":{"title":"Extract Font File Information","permalink":"/en/blog/extract-font-info-by-python"},"nextItem":{"title":"Automating Ubuntu System Status Checks with ChatGPT","permalink":"/en/blog/system-status-checking-by-chatgpt"}},"content":"A batch of MOV video files were received, but the system does not support reading them. They need to be converted to MP4 for compatibility.\\n\\nI had to write some code myself.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Design Draft\\n\\nThe go-to tool for video conversion is undoubtedly ffmpeg. This open-source tool supports almost all audio and video formats and allows you to control the conversion process through command-line parameters.\\n\\nInitially, we wanted to implement this functionality directly in the frontend, so others could convert files however they wanted...\\n\\nHowever, we encountered difficulties when calling it from the browser and spent an hour trying to resolve the issue without success. So, we decided to handle the conversion locally.\\n\\nConverting locally is much easier. At first, we considered writing a Bash script, but then we realized Python might be easier to maintain, so we chose to use Python together with ffmpeg to accomplish the task.\\n\\n## What is FFMPEG?\\n\\n[ffmpeg](https://ffmpeg.org/) is an extremely powerful open-source multimedia processing tool, widely used for tasks like format conversion, streaming, editing, and merging multimedia files.\\n\\nIt supports a wide range of common and uncommon audio and video formats and includes a large number of codecs. With simple command-line operations, ffmpeg allows you to quickly perform tasks like conversion, cutting, embedding subtitles, resampling, compression, and cross-platform streaming.\\n\\nSince ffmpeg is an open-source project and can be easily installed and run on various operating systems (Linux, macOS, Windows), it has become an indispensable tool in media workflows.\\n\\nIn general, we can accomplish common conversion tasks with simple commands, such as converting a MOV file to MP4:\\n\\n```bash\\nffmpeg -i input.mov -c copy output.mp4\\n```\\n\\nHere, `-i` specifies the input file path, and `-c copy` means copying the video and audio streams directly (without re-encoding), which significantly reduces processing time and maintains the original quality. If you want to adjust quality, encoding parameters, output resolution, bitrate, or channels, ffmpeg provides highly flexible command-line parameters for customization.\\n\\nIn short, it\'s an excellent tool that you should learn to use!\\n\\n## Environment Setup\\n\\nWe are developing on an Ubuntu system, and similar Linux systems can be used as well.\\n\\n1. **Python Environment**: Ensure that Python 3.x is installed:\\n\\n   ```bash\\n   python3 --version\\n   ```\\n\\n2. **Install ffmpeg**: On Ubuntu, you can install ffmpeg with the following commands:\\n\\n   ```bash\\n   sudo apt update\\n   sudo apt install ffmpeg\\n   ```\\n\\n   After installation, check the version:\\n\\n   ```bash\\n   ffmpeg -version\\n   ```\\n\\n3. **Code Structure**: Create a `convert.py` file in your project folder (you can name it differently), and paste the following code into it.\\n\\n## Example Code\\n\\n```python\\nimport subprocess\\nimport sys\\nfrom pathlib import Path\\n\\ndef convert_videos(input_dir: Path, src_format: str, dest_format: str):\\n    # Check if the target directory exists\\n    if not input_dir.is_dir():\\n        print(f\\"Error: The target directory \'{input_dir}\' does not exist.\\")\\n        sys.exit(1)\\n\\n    # Automatically create an output directory\\n    output_dir = input_dir / \\"output\\"\\n    output_dir.mkdir(parents=True, exist_ok=True)\\n\\n    # Ensure format strings start with a period\\n    if not src_format.startswith(\\".\\"):\\n        src_format = f\\".{src_format}\\"\\n    if not dest_format.startswith(\\".\\"):\\n        dest_format = f\\".{dest_format}\\"\\n\\n    # Iterate over all files with the source format (case insensitive)\\n    video_files = [f for f in input_dir.rglob(\\"*\\") if f.suffix.casefold() == src_format.casefold()]\\n\\n    if not video_files:\\n        print(f\\"No {src_format} files found.\\")\\n        sys.exit(0)\\n\\n    for file in video_files:\\n        output_file = output_dir / f\\"{file.stem}{dest_format}\\"\\n        print(f\\"Converting: \'{file}\' -> \'{output_file}\'\\")\\n\\n        # Use ffmpeg to convert the file\\n        try:\\n            subprocess.run(\\n                [\\n                    \\"ffmpeg\\", \\"-i\\", str(file),\\n                    \\"-c\\", \\"copy\\",\\n                    str(output_file)\\n                ],\\n                check=True,\\n                stdout=subprocess.PIPE,\\n                stderr=subprocess.PIPE\\n            )\\n            print(f\\"Conversion successful: \'{output_file}\'\\")\\n        except subprocess.CalledProcessError as e:\\n            print(f\\"Conversion failed: \'{file}\'\\")\\n            print(e.stderr.decode())\\n\\n    print(f\\"All files processed. Output directory: \'{output_dir}\'\\")\\n\\n\\nif __name__ == \\"__main__\\":\\n    # Check if the user has provided parameters\\n    if len(sys.argv) != 4:\\n        print(f\\"Usage: python {sys.argv[0]} <input directory> <source format> <destination format>\\")\\n        print(f\\"Example: python {sys.argv[0]} \'videos\' \'MOV\' \'mp4\'\\")\\n        sys.exit(1)\\n\\n    input_dir = Path(sys.argv[1]).resolve()\\n    src_format = sys.argv[2]\\n    dest_format = sys.argv[3]\\n\\n    convert_videos(input_dir, src_format, dest_format)\\n```\\n\\n## How to Use\\n\\n1. **Prepare Source Files**: Place the files to be converted (e.g., MOV, AVI, MKV) into the specified directory (e.g., `videos`).\\n\\n2. **Run the Conversion**: Navigate to the directory containing the script and run the following command:\\n\\n   ```bash\\n   python3 convert.py videos MOV mp4\\n   ```\\n\\n   If you want to convert AVI files to MKV, use:\\n\\n   ```bash\\n   python3 convert.py videos avi mkv\\n   ```\\n\\n   After running the command, the program will generate the converted files in the `videos/output` folder.\\n\\n3. **Check the Results**: Ensure that the `output` folder contains the correctly converted files in the desired format.\\n\\n## Advanced Use\\n\\nIf you want to compress and adjust the quality of the files, you can add specific parameters to the ffmpeg command, such as:\\n\\n```bash\\nffmpeg -i input.avi -c:v libx264 -crf 20 output.mp4\\n```\\n\\nYou can modify the script to adjust how ffmpeg is called for this purpose.\\n\\n## Conclusion\\n\\nThat\'s it! We wrote a simple script during development, and I hope it\'s helpful to you.\\n\\nYou can now start converting your files!"},{"id":"system-status-checking-by-chatgpt","metadata":{"permalink":"/en/blog/system-status-checking-by-chatgpt","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/12-12-system-status-checking-by-chatgpt/index.md","title":"Automating Ubuntu System Status Checks with ChatGPT","description":"Automate system status checks with ChatGPT.","date":"2024-12-12T00:00:00.000Z","tags":[{"inline":true,"label":"System-Monitoring","permalink":"/en/blog/tags/system-monitoring"},{"inline":true,"label":"Automation","permalink":"/en/blog/tags/automation"},{"inline":true,"label":"OpenAI-Integration","permalink":"/en/blog/tags/open-ai-integration"}],"readingTime":12.82,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"system-status-checking-by-chatgpt","title":"Automating Ubuntu System Status Checks with ChatGPT","authors":"Zephyr","image":"/en/img/2024/1212.webp","tags":["System-Monitoring","Automation","OpenAI-Integration"],"description":"Automate system status checks with ChatGPT."},"unlisted":false,"prevItem":{"title":"Batch Video Conversion","permalink":"/en/blog/flexible-video-conversion-by-python"},"nextItem":{"title":"Add Author Info to Docusaurus Docs","permalink":"/en/blog/customized-docusaurus-author-to-plugin-content-docs"}},"content":"To analyze issues, we need to check the system\'s status, but we may not be proficient in reading system logs.\\n\\nIn such cases, we can use ChatGPT to automate basic system status checks.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Key Features\\n\\nFirst, we collect system status and performance metrics using built-in Linux commands such as `uptime`, `top`, `free`, `df`, `systemctl`, `sensors`, `smartctl`, `dmesg`, `journalctl`, `ss`, `ip`, `docker`, etc.\\n\\nNext, we divide the raw report into several sections, and use the GPT model (specified as `gpt-4o`) backed by the OpenAI API to automatically generate summaries and compile the information.\\n\\nFinally, we combine multiple summaries into one, generating a system status report in Markdown format, which includes:\\n\\n- System status description\\n- Problem analysis\\n- Improvement and recommendation proposals\\n\\n:::warning\\nThe code in this article may require adjustments as the OpenAI API is updated. Please ensure that the API usage aligns with the code.\\n:::\\n\\n## Prerequisites\\n\\n1. **Required Packages and Commands**:\\n\\n   - `curl`: Used for HTTP communication with the API\\n   - `jq`: Used to parse JSON formatted API responses\\n   - `smartctl`: Used to check disk SMART information\\n   - `systemctl`: Used to check service status and failures\\n   - `docker`: Used to check Docker container status (ignore errors if Docker is not in use)\\n   - `sensors`: Used to retrieve system temperature information (if unavailable, the program will display a Warning)\\n\\n   Ensure that these commands are correctly installed and can run properly on the system.\\n\\n2. **OpenAI API Key**:\\n\\n   This program will use the OpenAI API to generate system report summaries and final analysis.\\n\\n   Ensure you have a valid OpenAI API key and store it in the specified path:\\n\\n   - Default path: `/home/your_user_name/.openai_api_key`\\n\\n   ```bash\\n   echo \\"YOUR_OPENAI_API_KEY\\" > /home/your_user_name/.openai_api_key\\n   chmod 600 /home/your_user_name/.openai_api_key\\n   ```\\n\\n   Make sure to replace `YOUR_OPENAI_API_KEY` with your actual API Key.\\n\\n3. **Working Directory and Disk Space**:\\n\\n   The default working directory is `/var/log/system_checking_by_chatgpt`. The program will create the following files and folders here:\\n\\n   - `raw_report_YYYY-MM-DD.txt`: Raw data collection report\\n   - `chunks_YYYY-MM-DD/`: Files after being chunked\\n   - `summary_YYYY-MM-DD/`: Files containing GPT summaries of each chunk\\n   - `combined_summary_YYYY-MM-DD.txt`: Final summary file combining all chunk summaries\\n   - `final_report_YYYY-MM-DD.md`: Final analysis report in Markdown format\\n   - `debug_YYYY-MM-DD.log`: Debug log file\\n\\n   Ensure there is enough space in this directory (at least 100MB). The program will exit automatically if space is insufficient.\\n\\n4. **Execution Permissions**:\\n\\n   Ensure the program has executable permissions:\\n\\n   ```bash\\n   chmod +x system_checking_by_chatgpt.sh\\n   ```\\n\\n## Execution Method\\n\\nRun the program in the terminal to start generating the report.\\n\\nThe expected execution flow is as follows:\\n\\n1. **Initialization and Checks**: The program will check for the presence of all necessary external commands and confirm that the `OPENAI_API_KEY` is not empty. If there are any issues, it will immediately interrupt and display an error.\\n2. **System Information Collection**: The program will collect system information using various commands and consolidate the output into `raw_report_YYYY-MM-DD.txt`.\\n3. **Chunking and Summarization**: The program will divide `raw_report_YYYY-MM-DD.txt` into several subfiles of approximately 200 lines (`chunk_*`), and each subfile will be processed by the OpenAI API to generate summary files (`summary_chunk_*`), highlighting the key points and issues from that chunk.\\n4. **Merging All Summaries and Final Analysis**: The program will merge all summaries into a single file `combined_summary_YYYY-MM-DD.txt`, and then call the OpenAI API to generate the \\"final report.\\"\\n5. **Generating Final Report**: The final report will be saved as `final_report_YYYY-MM-DD.md`, which will include:\\n   - System status description\\n   - Problem and anomaly analysis\\n   - Suggested solutions and diagnostic recommendations (which may include tables and command examples)\\n\\n## Notes\\n\\n1. **API Key Security**: Please keep the `OPENAI_API_KEY` secure. It should not be exposed, and it is recommended to restrict file read permissions (e.g., set to 600).\\n2. **Smart Adjustment of the Collection Scope**: If you wish to expand or reduce the system information collected, you can add or remove commands in the `collect_system_info()` function.\\n3. **OpenAI API Model and Token Limits**: By default, the model `MODEL=\\"gpt-4o\\"` is used. Ensure this model is available within your API permissions. If the summaries or final report are too long and cause the API to fail or time out, consider adjusting the `CHUNK_SIZE` or reducing the output content.\\n4. **Timezone and Date Format**: The program uses `date +\\"%Y-%m-%d\\"` to format the date, which can be modified as needed.\\n\\n## Example Flow\\n\\nBelow is a complete example of the running process:\\n\\n1. **Verify Environment and API Key**:\\n\\n   ```bash\\n   echo \\"sk-abc123xxx...\\" > /home/your_user_name/.openai_api_key\\n   chmod 600 /home/your_user_name/.openai_api_key\\n   ```\\n\\n2. **Run the Program**:\\n\\n   ```bash\\n   sudo bash system_checking_by_chatgpt.sh\\n   ```\\n\\n   The program will display:\\n\\n   ```\\n   [INFO] Starting program...\\n   [INFO] API key successfully loaded.\\n   [INFO] Starting system information collection...\\n   [INFO] System information collection complete, saved at /var/log/system_checking_by_chatgpt/raw_report_2024-12-12.txt\\n   [INFO] Requesting summary for /var/log/system_checking_by_chatgpt/chunks_2024-12-12/chunk_aa...\\n   ...\\n   [INFO] Final report generated: /var/log/system_checking_by_chatgpt/final_report_2024-12-12.md\\n   [INFO] Program execution complete.\\n   ```\\n\\n3. **View the Report**:\\n\\n   ```bash\\n   less /var/log/system_checking_by_chatgpt/final_report_2024-12-12.md\\n   ```\\n\\n4. **Review the Debug Log (if needed)**:\\n   ```bash\\n   less /var/log/system_checking_by_chatgpt/debug_2024-12-12.log\\n   ```\\n\\n## Code\\n\\n```shell title=\\"system_checking_by_chatgpt.sh\\"\\n#!/usr/bin/env bash\\n\\nset -euo pipefail\\n# set -x  # Enable for debugging if needed\\n\\n########################################\\n# Basic Setup and Checks\\n########################################\\n\\nDATE=$(date +\\"%Y-%m-%d\\")\\nWORK_DIR=\\"/var/log/system_checking_by_chatgpt\\"\\nRAW_REPORT=\\"$WORK_DIR/raw_report_$DATE.txt\\"\\nCHUNKS_DIR=\\"$WORK_DIR/chunks_$DATE\\"\\nSUMMARY_DIR=\\"$WORK_DIR/summary_$DATE\\"\\nFINAL_REPORT=\\"$WORK_DIR/final_report_$DATE.md\\"  # Using Markdown format\\nDEBUG_LOG=\\"$WORK_DIR/debug_$DATE.log\\"\\n\\nmkdir -p \\"$WORK_DIR\\"\\nmkdir -p \\"$CHUNKS_DIR\\"\\nmkdir -p \\"$SUMMARY_DIR\\"\\n\\n# Check required commands\\nREQUIRED_COMMANDS=(\\"curl\\" \\"jq\\" \\"smartctl\\" \\"systemctl\\" \\"docker\\" \\"sensors\\")\\nfor cmd in \\"${REQUIRED_COMMANDS[@]}\\"; do\\n    if ! command -v \\"$cmd\\" &>/dev/null; then\\n        echo \\"[ERROR] Required command $cmd is not installed.\\" | tee -a \\"$DEBUG_LOG\\"\\n        exit 1\\n    fi\\ndone\\n\\n# Check available disk space\\nAVAILABLE_SPACE=$(df \\"$WORK_DIR\\" | tail -1 | awk \'{print $4}\')\\nif [ \\"$AVAILABLE_SPACE\\" -lt 102400 ]; then # less than 100MB\\n    echo \\"[ERROR] Insufficient disk space in $WORK_DIR.\\" | tee -a \\"$DEBUG_LOG\\"\\n    exit 1\\nfi\\n\\n# Logging function: output to stderr to avoid interfering with function returns\\nlog() {\\n    local LEVEL=$1\\n    shift\\n    local MESSAGE=\\"$@\\"\\n    {\\n        echo \\"[$LEVEL] $MESSAGE\\" | tee -a \\"$DEBUG_LOG\\" >&2\\n        logger -t \\"system_checking_by_chatgpt\\" \\"[$LEVEL] $MESSAGE\\"\\n    }\\n}\\n\\nlog \\"INFO\\" \\"Script execution started...\\"\\n\\n########################################\\n# Load API Key\\n########################################\\n\\nOPENAI_KEY_FILE=\\"/home/your_user_name/.openai_api_key\\"\\nif [ ! -f \\"$OPENAI_KEY_FILE\\" ]; then\\n    log \\"ERROR\\" \\"$OPENAI_KEY_FILE does not exist.\\"\\n    exit 1\\nfi\\n\\nOPENAI_API_KEY=$(cat \\"$OPENAI_KEY_FILE\\")\\nif [ -z \\"$OPENAI_API_KEY\\" ]; then\\n    log \\"ERROR\\" \\"OPENAI_API_KEY is empty.\\"\\n    exit 1\\nfi\\nexport OPENAI_API_KEY\\n\\nlog \\"INFO\\" \\"API key successfully loaded.\\"\\n\\nAPI_URL=\\"https://api.openai.com/v1/chat/completions\\"\\nMODEL=\\"gpt-4o\\"\\n\\n########################################\\n# Function Definitions\\n########################################\\n\\ncollect_system_info() {\\n    {\\n        echo \\"=== System Uptime ===\\"\\n        uptime\\n        echo \\"\\"\\n\\n        echo \\"=== Date & Time ===\\"\\n        date\\n        echo \\"\\"\\n\\n        echo \\"=== CPU & Memory Usage ===\\"\\n        top -b -n1 | head -n 20\\n        echo \\"\\"\\n\\n        echo \\"=== Memory Usage (free) ===\\"\\n        free -h\\n        echo \\"\\"\\n\\n        echo \\"=== Disk Usage (df) ===\\"\\n        df -h\\n        echo \\"\\"\\n\\n        echo \\"=== Failed Services ===\\"\\n        systemctl list-units --state=failed\\n        echo \\"\\"\\n\\n        echo \\"=== Temperature Sensors ===\\"\\n        sensors 2>/dev/null || echo \\"[WARNING] Could not retrieve temperature information.\\"\\n        echo \\"\\"\\n\\n        echo \\"=== NVMe / SMART Status ===\\"\\n        sudo smartctl -a /dev/nvme0n1 2>/dev/null || echo \\"[WARNING] Could not check /dev/nvme0n1\\"\\n        echo \\"\\"\\n        sudo smartctl -a /dev/nvme1n1 2>/dev/null || echo \\"[WARNING] Could not check /dev/nvme1n1\\"\\n        echo \\"\\"\\n\\n        echo \\"=== Recent dmesg Entries (Last 100 lines) ===\\"\\n        dmesg | tail -n 100\\n        echo \\"\\"\\n\\n        echo \\"=== System Journal (Last 300 lines, errors only) ===\\"\\n        journalctl -p err -n 300\\n        echo \\"\\"\\n\\n        echo \\"=== Network Status (ss -tulpn) ===\\"\\n        ss -tulpn 2>/dev/null || echo \\"[WARNING] Could not retrieve network status.\\"\\n        echo \\"\\"\\n\\n        echo \\"=== Network Interface Statistics (ip -s link) ===\\"\\n        ip -s link\\n        echo \\"\\"\\n\\n        echo \\"=== Docker Containers (if any) ===\\"\\n        docker ps -a 2>/dev/null || echo \\"[INFO] Docker is not running or not installed.\\"\\n        echo \\"\\"\\n\\n    } > \\"$RAW_REPORT\\"\\n}\\n\\ngenerate_chunk_summaries() {\\n    # Split RAW_REPORT into chunks\\n    CHUNK_SIZE=200\\n    split -l $CHUNK_SIZE \\"$RAW_REPORT\\" \\"$CHUNKS_DIR/chunk_\\"\\n\\n    CHUNKS=(\\"$CHUNKS_DIR\\"/chunk_*)\\n\\n    if [ ${#CHUNKS[@]} -eq 0 ]; then\\n        log \\"ERROR\\" \\"No chunks generated!\\"\\n        exit 1\\n    fi\\n\\n    # Prompt for chunk summaries\\n    CHUNK_SYSTEM_PROMPT=\\"You are a professional system administration consultant. The following is a portion of the system information. Please extract and summarize: (1) Important system status info (e.g., CPU/memory usage, disk usage, network status, service states, error messages), and (2) any abnormalities, errors, or issues requiring attention. Be as detailed as possible, while remaining clear and organized.\\"\\n\\n    summaries=()\\n\\n    for chunk_file in \\"${CHUNKS[@]}\\"; do\\n        CHUNK_CONTENT=$(cat \\"$chunk_file\\")\\n\\n        CHUNK_API_PAYLOAD=$(jq -n \\\\\\n            --arg system_prompt \\"$CHUNK_SYSTEM_PROMPT\\" \\\\\\n            --arg user_prompt \\"$CHUNK_CONTENT\\" \\\\\\n            --arg model \\"$MODEL\\" \\\\\\n            \'{\\n                \\"model\\": $model,\\n                \\"messages\\": [\\n                    {\\"role\\": \\"system\\", \\"content\\": $system_prompt},\\n                    {\\"role\\": \\"user\\", \\"content\\": $user_prompt}\\n                ]\\n            }\')\\n\\n        log \\"INFO\\" \\"Requesting summary for $chunk_file ...\\"\\n        START_TIME=$(date +%s)\\n        RESPONSE=$(curl -sS -X POST \\"$API_URL\\" \\\\\\n          -H \\"Authorization: Bearer $OPENAI_API_KEY\\" \\\\\\n          -H \\"Content-Type: application/json\\" \\\\\\n          -d \\"$CHUNK_API_PAYLOAD\\")\\n\\n        if [ $? -ne 0 ]; then\\n            log \\"ERROR\\" \\"Failed to communicate with ChatGPT API during summary phase: $chunk_file\\"\\n            exit 1\\n        fi\\n        END_TIME=$(date +%s)\\n        log \\"INFO\\" \\"API request took $((END_TIME - START_TIME)) seconds.\\"\\n\\n        SUMMARY=$(echo \\"$RESPONSE\\" | jq -r \'.choices[0].message.content\' 2>>\\"$DEBUG_LOG\\" || echo \\"\\")\\n\\n        if [ -z \\"$SUMMARY\\" ] || [ \\"$SUMMARY\\" = \\"null\\" ]; then\\n            log \\"ERROR\\" \\"No summary returned for chunk: $chunk_file\\"\\n            echo \\"Raw Response: $RESPONSE\\" >> \\"$DEBUG_LOG\\"\\n            exit 1\\n        fi\\n\\n        SUMMARY_FILE=\\"$SUMMARY_DIR/summary_$(basename \\"$chunk_file\\").txt\\"\\n        echo \\"$SUMMARY\\" > \\"$SUMMARY_FILE\\"\\n        summaries+=(\\"$SUMMARY_FILE\\")\\n    done\\n\\n    # Print summary file paths to stdout only\\n    for s in \\"${summaries[@]}\\"; do\\n        echo \\"$s\\"\\n    done\\n}\\n\\ncombine_summaries() {\\n    local summaries=(\\"$@\\")\\n    COMBINED_SUMMARY=\\"$WORK_DIR/combined_summary_$DATE.txt\\"\\n    rm -f \\"$COMBINED_SUMMARY\\"\\n    touch \\"$COMBINED_SUMMARY\\"\\n\\n    log \\"INFO\\" \\"Combining all chunk summaries...\\"\\n    {\\n        echo \\"Below are the combined summaries from multiple chunks:\\"\\n        echo \\"------------------------------------\\"\\n        for sfile in \\"${summaries[@]}\\"; do\\n            echo \\"=== Chunk Summary ===\\"\\n            cat \\"$sfile\\"\\n            echo \\"\\"\\n        done\\n    } > \\"$COMBINED_SUMMARY\\"\\n\\n    echo \\"$COMBINED_SUMMARY\\"\\n}\\n\\ngenerate_final_report() {\\n    local COMBINED_SUMMARY=\\"$1\\"\\n\\n    # Use a HEREDOC for the final prompt to avoid quote issues\\n    FINAL_SYSTEM_PROMPT=$(cat <<EOF\\nYou are a professional system administration consultant. Below is a combined set of summaries from multiple chunks of system information. Please produce a **very detailed final report** in **Markdown format** that includes the following three main sections with clear markdown headings:\\n\\n**1. Current System Status**:\\nDescribe the current resource usage (CPU, memory, disk), service states, network status, critical logs, error messages, and any abnormal events.\\n\\n**2. System Status Analysis**:\\nAnalyze the above information, highlight potential issues, explain possible causes for anomalies, identify performance bottlenecks, unusual conditions, or risks.\\n\\n**3. Recommended Solutions**:\\nBased on your analysis, provide feasible and specific improvement suggestions, diagnostic steps, performance optimizations, error remediation steps, and advice to enhance system stability.\\n\\nMaintain clarity, logical structure, and abundant detail.\\nEOF\\n)\\n\\n    FINAL_INPUT=$(cat \\"$COMBINED_SUMMARY\\")\\n\\n    FINAL_API_PAYLOAD=$(jq -n \\\\\\n        --arg system_prompt \\"$FINAL_SYSTEM_PROMPT\\" \\\\\\n        --arg user_prompt \\"$FINAL_INPUT\\" \\\\\\n        --arg model \\"$MODEL\\" \\\\\\n        \'{\\n            \\"model\\": $model,\\n            \\"messages\\": [\\n                {\\"role\\": \\"system\\", \\"content\\": $system_prompt},\\n                {\\"role\\": \\"user\\", \\"content\\": $user_prompt}\\n            ]\\n        }\')\\n\\n    log \\"INFO\\" \\"Starting final analysis...\\"\\n    log \\"DEBUG\\" \\"Final analysis payload: $FINAL_API_PAYLOAD\\"\\n\\n    START_TIME=$(date +%s)\\n    RESPONSE=$(curl -sS -X POST \\"$API_URL\\" \\\\\\n      -H \\"Authorization: Bearer $OPENAI_API_KEY\\" \\\\\\n      -H \\"Content-Type: application/json\\" \\\\\\n      -d \\"$FINAL_API_PAYLOAD\\")\\n\\n    if [ $? -ne 0 ]; then\\n        log \\"ERROR\\" \\"Failed to communicate with ChatGPT API during final analysis.\\"\\n        exit 1\\n    fi\\n    END_TIME=$(date +%s)\\n    log \\"INFO\\" \\"API request took $((END_TIME - START_TIME)) seconds.\\"\\n\\n    log \\"DEBUG\\" \\"Final analysis response: $RESPONSE\\"\\n\\n    FINAL_ANALYSIS=$(echo \\"$RESPONSE\\" | jq -r \'.choices[0].message.content\' 2>>\\"$DEBUG_LOG\\" || echo \\"\\")\\n\\n    if [ -z \\"$FINAL_ANALYSIS\\" ] || [ \\"$FINAL_ANALYSIS\\" = \\"null\\" ]; then\\n        log \\"ERROR\\" \\"Failed to retrieve the final analysis.\\"\\n        echo \\"Raw Response: $RESPONSE\\" >> \\"$DEBUG_LOG\\"\\n        exit 1\\n    fi\\n\\n    {\\n        echo \\"# Daily System Check Report - $DATE\\"\\n        echo \\"\\"\\n        echo \\"$FINAL_ANALYSIS\\"\\n    } > \\"$FINAL_REPORT\\"\\n\\n    log \\"INFO\\" \\"Final report generated: $FINAL_REPORT\\"\\n}\\n\\n########################################\\n# Main Flow\\n########################################\\n\\nlog \\"INFO\\" \\"Collecting system information...\\"\\ncollect_system_info\\nlog \\"INFO\\" \\"System information collected and saved in $RAW_REPORT\\"\\n\\nmapfile -t summaries < <(generate_chunk_summaries)\\nCOMBINED_SUMMARY_FILE=$(combine_summaries \\"${summaries[@]}\\")\\ngenerate_final_report \\"$COMBINED_SUMMARY_FILE\\"\\n\\nlog \\"INFO\\" \\"Script execution completed.\\"\\n```\\n\\n## Report Example\\n\\n```markdown\\n# Daily System Check Report - 2024-12-12\\n\\n# Detailed System Status Report\\n\\n## 1. Current System Status\\n\\n### Resource Usage\\n\\n- **Uptime and Load Average**: The system has been operating for 3 hours and 44 minutes, with a high load average of 7.06, 7.05, 7.09, which may indicate CPU strain if there are fewer cores than these values suggest.\\n- **CPU Usage**: The overall CPU utilization is 15.5% for user processes, 7.0% for system processes, and 77.5% idle. However, there are four processes utilizing over 100% CPU each, indicating potential multi-threaded applications engaging multiple cores.\\n- **Memory Usage**: The system has a total memory of 125 GiB, with 10 GiB free and 48 GiB actively used. The buffer/cache accounts for 76 GiB, indicating adequate available memory. Swap usage is negligible at 0 out of 2 GiB, suggesting effective memory management.\\n- **Disk Usage**: The root partition is 70% full with 1.2 TB used of 1.8 TB. The /data partition is at 51% usage with 881 GB used.\\n\\n### Thermal and Smart Monitoring\\n\\n- **CPU Temperatures**: Multiple CPU cores (e.g., Core 20, Package id 0, Core 28, Core 12) are running critically hot at 96\xb0C, 85\xb0C, and 84\xb0C, indicating potential overheating issues.\\n- **NVMe Health**: Despite passing the health assessment, 85 \\"Invalid Field in Command\\" errors exist in the error log. The NVMe operates at 53\xb0C, which is safe.\\n\\n### Service States\\n\\n- No failed services are reported besides consistent issues with `snap.firmware-updater.firmware-notifier.service` and a `fwupd-refresh.service` failure. Multiple failures are also noted for `NetworkManager-dispatcher.service`.\\n\\n### Network Status\\n\\n- **Network Interface**: `enp5s0` has multiple `NETDEV WATCHDOG` timeouts, indicating network communication issues. The system has firewall blocks affecting multicast traffic.\\n- **Listening Services**: Active services include Nginx (ports 80 and 443), Docker proxies (ports 8000 and 18080), and SSHD on a high port (20712).\\n- **Traffic**: Interfaces `veth321800f` and `vethc3fefc25` have normal TX/RX operations, while `veth814eefd` shows no RX data, suggesting possible configuration issues.\\n\\n### Critical Logs and Errors\\n\\n- **Out of Memory Events**: Several OOM events resulted in killing critical processes which may impact system stability.\\n- **Other Errors**: An SSH error involving a \\"Connection reset by peer\\" and 85 occurrences of \\"Invalid Field in Command\\" in SMART logs.\\n\\n## 2. System Status Analysis\\n\\n### Potential Issues\\n\\n1. **High CPU Load**: The system load average is high, suggesting significant processing activities, possibly nearing core limits.\\n2. **Overheating**: CPU temperatures exceeding high thresholds pose a risk of thermal throttling or hardware damage.\\n3. **Disk Errors**: SMART errors could indicate misconfigurations or impending hardware issues needing investigation.\\n4. **Network Interruptions**: The recurring `NETDEV WATCHDOG` timeouts and blocked multicast traffic can degrade network performance.\\n5. **Memory Constraints**: Consistent OOM events denote memory overutilization or leaks, necessitating review of processes like `pipewire`, `xdg-permission-`, and more.\\n\\n### Unusual Conditions or Risks\\n\\n- **Failed Service Starts**: Persistent service failures around the firmware updater and NetworkManager services reveal potential system configuration or dependency issues.\\n- **Network Driver**: `r8169` driver might have compatibility problems with hardware leading to frequent timeouts and errors.\\n- **Security Alerts**: AppArmor and firewall logs indicate possible misconfigurations or unneeded traffic blocks that might impact network performance.\\n\\n## 3. Recommended Solutions\\n\\n### Immediate Actions:\\n\\n- **Address CPU Overheating**: Evaluate cooling solutions, including checking fans, conducting thermal paste reapplications, or employing better case ventilation.\\n- **Investigate NVMe Errors**: Review firmware compatibility and update NVMe driver/firmware. Verify command syntaxes used by SMART tools.\\n- **Resolve OOM Events**: Analyze high-memory processes for inefficiencies or leaks, scale up physical memory, or fine-tune swapping parameters.\\n\\n### Network Solutions:\\n\\n- **Optimize NIC Configuration**: Update or reinstall the `r8169` driver, inspect physical network connectivity, and monitor for more accurate diagnostics on `enp5s0`.\\n- **Adjust Firewall Rules**: Review and possibly amend UFW rules to correctly handle multicast traffic without unnecessary blocks.\\n\\n### Enhancing System Stability:\\n\\n- **Review Service and Kernel Configurations**: Correct `snap.firmware-updater.firmware-notifier.service` and `NetworkManager-dispatcher.service` by checking service dependencies and configuration errors.\\n- **Implement Effective Monitoring**: Employ an extensive monitoring setup for regular checks on temperature, network performance, and memory.\\n- **System and Network Upgrades**: Should persistent high load and overheating be non-resolvable through tuning, consider hardware scaling, particularly for CPU and memory enhancements.\\n```"},{"id":"customized-docusaurus-author-to-plugin-content-docs","metadata":{"permalink":"/en/blog/customized-docusaurus-author-to-plugin-content-docs","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/12-10-add-author-to-plugin-content-docs/index.md","title":"Add Author Info to Docusaurus Docs","description":"The official version doesn\u2019t support it, so we had to do it ourselves.","date":"2024-12-10T00:00:00.000Z","tags":[{"inline":true,"label":"Docusaurus","permalink":"/en/blog/tags/docusaurus"},{"inline":true,"label":"Author","permalink":"/en/blog/tags/author"}],"readingTime":6.965,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"customized-docusaurus-author-to-plugin-content-docs","title":"Add Author Info to Docusaurus Docs","authors":"Zephyr","image":"/en/img/2024/1210.webp","tags":["Docusaurus","Author"],"description":"The official version doesn\u2019t support it, so we had to do it ourselves."},"unlisted":false,"prevItem":{"title":"Automating Ubuntu System Status Checks with ChatGPT","permalink":"/en/blog/system-status-checking-by-chatgpt"},"nextItem":{"title":"A Brief Introduction to Graph Convolutional Networks","permalink":"/en/blog/graph-convolutional-networks"}},"content":"If you\'re also using Docusaurus to write a website, then you must be aware that Docusaurus has two main content types:\\n\\n- The plugin used for blogs is: `@docusaurus/plugin-content-blog`\\n- The part for technical documentation is: `@docusaurus/plugin-content-docs`\\n\\nAmong them, only `blog` has author info functionality, while `docs` does not.\\n\\nOh no, what a shock!\\n\\n\x3c!-- truncate --\x3e\\n\\n## First, Ask the Official Team\\n\\nWe first went to the Docusaurus GitHub to ask about this feature and see if the official team supports it.\\n\\n- [**How to add author info to docs? #10701**](https://github.com/facebook/docusaurus/discussions/10701)\\n\\n    <div align=\\"center\\">\\n    <figure style={{\\"width\\": \\"90%\\"}}>\\n    ![ask-docusaurus](./img/img1.jpg)\\n    </figure>\\n    </div>\\n\\nMaybe the Docusaurus authors would show some mercy and help us add this feature.\\n\\nBut after waiting for a while, we got a reply from the official team:\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"90%\\"}}>\\n![docusaurus-reply](./img/img2.jpg)\\n</figure>\\n</div>\\n\\nIn short, they tell you to figure it out yourself; the official team doesn\u2019t support it.\\n\\nIt looks like it\'s better to rely on ourselves, so we had no choice but to forge ahead.\\n\\n## Add Author Info\\n\\nIn the original design, the author info is placed in the `blog/authors.yml` file, and the content looks something like this:\\n\\n```yml\\nZephyr:\\n  name: Zephyr\\n  title: Dosaid maintainer, Full-Stack AI Engineer\\n  url: https://github.com/zephyr-sh\\n  image_url: https://github.com/zephyr-sh.png\\n  socials:\\n    github: \\"zephyr-sh\\"\\n```\\n\\nWe first create a new file `blog/authors.json` in the same path and rewrite the same content into JSON format:\\n\\n```json\\n{\\n  \\"Zephyr\\": {\\n    \\"name\\": \\"Zephyr\\",\\n    \\"title\\": \\"Dosaid maintainer, Full-Stack AI Engineer\\",\\n    \\"url\\": \\"https://github.com/zephyr-sh\\",\\n    \\"image_url\\": \\"https://github.com/zephyr-sh.png\\",\\n    \\"socials\\": {\\n      \\"github\\": \\"zephyr-sh\\"\\n    }\\n  }\\n}\\n```\\n\\n:::info\\nDuring development, we found that parsing YML files was cumbersome, and after some testing, we decided that using JSON format is the easiest.\\n:::\\n\\n:::tip\\nAlthough this file is meant for `docs`, we still place it in the `blog` folder so that we remember to update it when making changes.\\n:::\\n\\n## Extract DocItem/Content\\n\\n:::warning\\nFrom this step onward, we need to modify the Docusaurus source code.\\n\\nIf there are future breaking updates to Docusaurus, this modification may cause the website to malfunction. Make sure you have the ability to maintain the website before proceeding.\\n:::\\n\\nFirst, we extract the `DocItemContent` code. Please run the following command:\\n\\n```shell\\nnpx docusaurus swizzle @docusaurus/theme-classic DocItem/Content\\n```\\n\\nAfter running the command, you will encounter a few questions:\\n\\n1. **Which language do you want to use?**\\n\\n   We select `JavaScript`.\\n\\n2. **Which swizzle action do you want to do?**\\n\\n   We select `Eject`.\\n\\n3. **Do you really want to swizzle this unsafe internal component?**\\n\\n   We select `YES: I know what I am doing!`.\\n\\n---\\n\\nNow, you can find a path: `src/theme/DocItem/Content`, where there is an `index.js` file. This is where we need to make changes.\\n\\n- The original code for this program is here: [**docusaurus-theme-classic/src/theme/DocItem/Content**](https://github.com/facebook/docusaurus/blob/main/packages/docusaurus-theme-classic/src/theme/DocItem/Content)\\n\\nThe modified code is as follows:\\n\\n```jsx\\nimport { useDoc } from \\"@docusaurus/plugin-content-docs/client\\";\\nimport { ThemeClassNames } from \\"@docusaurus/theme-common\\";\\nimport DocItemAuthors from \\"@theme/DocItem/Authors\\";\\nimport Heading from \\"@theme/Heading\\";\\nimport MDXContent from \\"@theme/MDXContent\\";\\nimport clsx from \\"clsx\\";\\nimport React from \\"react\\";\\n\\nfunction useSyntheticTitle() {\\n  const { metadata, frontMatter, contentTitle } = useDoc();\\n  const shouldRender =\\n    !frontMatter.hide_title && typeof contentTitle === \\"undefined\\";\\n  if (!shouldRender) {\\n    return null;\\n  }\\n  return metadata.title;\\n}\\n\\nexport default function DocItemContent({ children }) {\\n  const syntheticTitle = useSyntheticTitle();\\n\\n  return (\\n    <div className={clsx(ThemeClassNames.docs.docMarkdown, \\"markdown\\")}>\\n      {syntheticTitle ? (\\n        <header>\\n          <Heading as=\\"h1\\">{syntheticTitle}</Heading>\\n          <DocItemAuthors />\\n          <MDXContent>{children}</MDXContent>\\n        </header>\\n      ) : (\\n        <>\\n          <DocItemAuthors />\\n          <MDXContent>{children}</MDXContent>\\n        </>\\n      )}\\n    </div>\\n  );\\n}\\n```\\n\\nThe key addition is a new module:\\n\\n- `import DocItemAuthors from \\"@theme/DocItem/Authors\\";`\\n\\nThis part will be implemented later.\\n\\n## Implement DocItem/Authors\\n\\nNow, let\'s implement the `Authors` component. Please run the following commands:\\n\\n```shell\\nmkdir -p src/theme/DocItem/Authors\\ntouch src/theme/DocItem/Authors/index.js\\ntouch src/theme/DocItem/Authors/styles.module.css\\n```\\n\\nFor this part, we refer to the `Authors` component in `Blog` and replicate it.\\n\\n- [**docusaurus-theme-classic/src/theme/Blog/Components/Author**](https://github.com/facebook/docusaurus/tree/main/packages/docusaurus-theme-classic/src/theme/Blog/Components/Author)\\n\\nThe code for `DocItem/Authors/index.js` is as follows:\\n\\n```jsx\\nimport { useDoc } from \\"@docusaurus/plugin-content-docs/client\\";\\nimport authorsData from \\"@site/blog/authors.json\\";\\nimport React from \\"react\\";\\nimport {\\n  FaEnvelope,\\n  FaGithub,\\n  FaLinkedin,\\n  FaRss,\\n  FaStackOverflow,\\n  FaTwitter,\\n} from \\"react-icons/fa\\";\\nimport styles from \\"./index.module.css\\";\\n\\nfunction normalizeSocialLink(platform, handleOrUrl) {\\n  const isAbsoluteUrl =\\n    handleOrUrl.startsWith(\\"http://\\") || handleOrUrl.startsWith(\\"https://\\");\\n  if (isAbsoluteUrl) {\\n    return handleOrUrl;\\n  }\\n  switch (platform) {\\n    case \\"x\\":\\n      return `https://x.com/${handleOrUrl}`;\\n    case \\"github\\":\\n      return `https://github.com/${handleOrUrl}`;\\n    case \\"linkedin\\":\\n      return `https://www.linkedin.com/in/${handleOrUrl}/`;\\n    case \\"stackoverflow\\":\\n      return `https://stackoverflow.com/users/${handleOrUrl}`;\\n    case \\"newsletter\\":\\n      return handleOrUrl;\\n    case \\"email\\":\\n      return `mailto:${handleOrUrl}`;\\n    default:\\n      return handleOrUrl;\\n  }\\n}\\n\\nconst socialIconMap = {\\n  x: FaTwitter,\\n  github: FaGithub,\\n  linkedin: FaLinkedin,\\n  stackoverflow: FaStackOverflow,\\n  email: FaEnvelope,\\n  newsletter: FaRss,\\n};\\n\\nexport default function DocItemAuthors() {\\n  const { frontMatter } = useDoc();\\n  let { authors } = frontMatter;\\n\\n  if (!authors) {\\n    return null;\\n  }\\n\\n  if (typeof authors === \\"string\\") {\\n    authors = [authors];\\n  }\\n\\n  const resolvedAuthors = authors\\n    .map((authorKeyOrObj) => {\\n      if (typeof authorKeyOrObj === \\"string\\") {\\n        const authorInfo = authorsData[authorKeyOrObj];\\n        if (!authorInfo) {\\n          console.warn(\\n            `No author data found for key \'${authorKeyOrObj}\' in authors.json`\\n          );\\n          return null;\\n        }\\n        return {\\n          name: authorInfo.name,\\n          title: authorInfo.title,\\n          url: authorInfo.url,\\n          imageURL: authorInfo.image_url,\\n          socials: authorInfo.socials,\\n          description: authorInfo.description,\\n        };\\n      } else {\\n        const { name, title, url, image_url, imageURL, socials, description } =\\n          authorKeyOrObj;\\n        return {\\n          name,\\n          title,\\n          url,\\n          imageURL: imageURL || image_url,\\n          socials,\\n          description,\\n        };\\n      }\\n    })\\n    .filter(Boolean);\\n\\n  if (resolvedAuthors.length === 0) {\\n    return null;\\n  }\\n\\n  return (\\n    <div className={`${styles.docAuthors} margin-bottom--md`}>\\n      {resolvedAuthors.map((author, index) => {\\n        const { name, title, url, imageURL, socials, description } = author;\\n        return (\\n          <div key={index} className={styles.docAuthor}>\\n            {imageURL && (\\n              <img src={imageURL} alt={name} className={styles.docAuthorImg} />\\n            )}\\n            <div>\\n              <div className={styles.docAuthorName}>\\n                {url ? (\\n                  <a href={url} target=\\"_blank\\" rel=\\"noopener noreferrer\\">\\n                    {name}\\n                  </a>\\n                ) : (\\n                  name\\n                )}\\n              </div>\\n              {title && <div className={styles.docAuthorTitle}>{title}</div>}\\n              {description && (\\n                <div className={styles.docAuthorDesc}>{description}</div>\\n              )}\\n\\n              {socials && (\\n                <div className={styles.docAuthorSocials}>\\n                  {Object.entries(socials).map(([platform, handleOrUrl]) => {\\n                    const SocialIcon = socialIconMap[platform] || FaEnvelope;\\n                    const normalizedUrl = normalizeSocialLink(\\n                      platform,\\n                      handleOrUrl\\n                    );\\n                    return (\\n                      <a\\n                        key={platform}\\n                        href={normalizedUrl}\\n                        target=\\"_blank\\"\\n                        rel=\\"noopener noreferrer\\"\\n                        className={styles.docAuthorSocialLink}\\n                      >\\n                        <SocialIcon size={20} />\\n                      </a>\\n                    );\\n                  })}\\n                </div>\\n              )}\\n            </div>\\n          </div>\\n        );\\n      })}\\n    </div>\\n  );\\n}\\n```\\n\\nHere, we\'re using `react-icons`. If you haven\'t installed it yet, please run the following command:\\n\\n```shell\\nyarn add react-icons\\n```\\n\\nPlease note that some parts are hardcoded here, for example:\\n\\n```jsx\\nfunction normalizeSocialLink(platform, handleOrUrl) {\\n  const isAbsoluteUrl =\\n    handleOrUrl.startsWith(\\"http://\\") || handleOrUrl.startsWith(\\"https://\\");\\n  if (isAbsoluteUrl) {\\n    return handleOrUrl;\\n  }\\n  switch (platform) {\\n    case \\"x\\":\\n      return `https://x.com/${handleOrUrl}`;\\n    case \\"github\\":\\n      return `https://github.com/${handleOrUrl}`;\\n    case \\"linkedin\\":\\n      return `https://www.linkedin.com/in/${handleOrUrl}/`;\\n    case \\"stackoverflow\\":\\n      return `https://stackoverflow.com/users/${handleOrUrl}`;\\n    case \\"newsletter\\":\\n      return handleOrUrl;\\n    case \\"email\\":\\n      return `mailto:${handleOrUrl}`;\\n    default:\\n      return handleOrUrl;\\n  }\\n}\\n\\nconst socialIconMap = {\\n  x: FaTwitter,\\n  github: FaGithub,\\n  linkedin: FaLinkedin,\\n  stackoverflow: FaStackOverflow,\\n  email: FaEnvelope,\\n  newsletter: FaRss,\\n};\\n```\\n\\nIf the URLs change, you may need to modify these areas.\\n\\nFinally, here is the code for `DocItem/Authors/styles.module.css`:\\n\\n```css\\n.docAuthor {\\n  display: flex;\\n  align-items: center;\\n  margin-bottom: 2rem;\\n}\\n\\n.docAuthorImg {\\n  width: 60px;\\n  height: 60px;\\n  border-radius: 50%;\\n  margin-right: 0.75rem;\\n  object-fit: cover;\\n}\\n\\n.docAuthorName {\\n  font-weight: 600;\\n  font-size: 1rem;\\n  margin-bottom: 0.25rem;\\n  color: #111;\\n}\\n\\n.docAuthorName a {\\n  text-decoration: none;\\n  color: inherit;\\n}\\n\\n.docAuthorName a:hover {\\n  text-decoration: underline;\\n}\\n\\n.docAuthorTitle {\\n  font-size: 0.85rem;\\n  color: #555;\\n  margin-bottom: 0.25rem;\\n  line-height: 1.2;\\n}\\n\\n.docAuthorDesc {\\n  font-size: 0.85rem;\\n  color: #333;\\n  margin-bottom: 0.4rem;\\n  line-height: 1.4;\\n}\\n\\n.docAuthorSocials {\\n  display: flex;\\n  gap: 0.5rem;\\n  flex-wrap: wrap;\\n  align-items: center;\\n}\\n\\n.docAuthorSocialLink {\\n  display: inline-flex;\\n  align-items: center;\\n  text-decoration: none;\\n  color: inherit;\\n  line-height: 1;\\n}\\n\\n.docAuthorSocialLink:hover {\\n  color: var(--ifm-color-primary);\\n}\\n```\\n\\nThe implementation approach here depends on personal style. After testing several times, this design looks quite good.\\n\\nYou can modify these styles according to your own needs.\\n\\n## Adjust the FrontMatter of the Document\\n\\nFinally, in order to display the author info in the `docs` files, we need to add the author\'s information to the `FrontMatter` of the document.\\n\\nFor example, in our website article: [**[20.08] HiPPO: Hippo\'s Memory**](https://docsaid.org/en/papers/mamba/hippo)\\n\\nThe original article looked like this:\\n\\n```mdx\\n# [20.08] HiPPO\\n\\n## Hippo\'s Memory\\n\\n[**HiPPO: Recurrent Memory with Optimal Polynomial Projections**](https://arxiv.org/abs/2008.07669)\\n```\\n\\nNow, in order to include author information, we **cannot** use `#` for the title; instead, we need to define the title using `FrontMatter`.\\n\\nSo we modify it to:\\n\\n```mdx\\n---\\ntitle: \\"[20.08] HiPPO\\"\\nauthors: Zephyr\\n---\\n\\n## Hippo\'s Memory\\n\\n[**HiPPO: Recurrent Memory with Optimal Polynomial Projections**](https://arxiv.org/abs/2008.07669)\\n```\\n\\nIn the `authors` field, specify the author\'s name so that the author information will be displayed.\\n\\n:::tip\\nMake sure that the name in `authors` matches the name in `authors.json`, otherwise, the author information will not be shown.\\n:::\\n\\n## Implementation Complete\\n\\nFinally, let\'s take a look at the effect on the website:\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"60%\\"}}>\\n![docusaurus-author](./img/img3.jpg)\\n</figure>\\n</div>\\n\\nAs shown in the image above, we have successfully added author information to the `docs` files. Cheers!\\n\\nThis concludes our implementation process. We hope it is helpful to you."},{"id":"graph-convolutional-networks","metadata":{"permalink":"/en/blog/graph-convolutional-networks","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/12-05-graph-convolutional-networks/index.md","title":"A Brief Introduction to Graph Convolutional Networks","description":"A simple introduction to GCN","date":"2024-12-05T00:00:00.000Z","tags":[{"inline":true,"label":"graph-convolutional-networks","permalink":"/en/blog/tags/graph-convolutional-networks"},{"inline":true,"label":"transformer","permalink":"/en/blog/tags/transformer"}],"readingTime":14.18,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"graph-convolutional-networks","title":"A Brief Introduction to Graph Convolutional Networks","authors":"Zephyr","image":"/en/img/2024/1205.webp","tags":["graph-convolutional-networks","transformer"],"description":"A simple introduction to GCN"},"unlisted":false,"prevItem":{"title":"Add Author Info to Docusaurus Docs","permalink":"/en/blog/customized-docusaurus-author-to-plugin-content-docs"},"nextItem":{"title":"A Brief Introduction to Fourier Transform","permalink":"/en/blog/fourier-transform"}},"content":"import GraphDemo from \'@site/src/components/GraphDemo\';\\nimport GraphFeatureMatrixDemo from \'@site/src/components/GraphFeatureMatrixDemo\';\\n\\nThis article was also inspired by my experience while writing paper notes and encountering graph convolutional networks.\\n\\nThe content became too lengthy, so I decided to write a separate article to introduce it.\\n\\n\x3c!-- truncate --\x3e\\n\\nThanks to OpenAI, everyone is now very familiar with Transformers. (Or at least, I hope so?)\\n\\nTerms like self-attention mechanism, multi-head attention, and positional encoding are now household names.\\n\\nSo here, I\u2019ll borrow the concept of Transformer to explain graph convolutional networks.\\n\\n## Graph Convolutional Networks\\n\\nGraph Convolutional Networks, abbreviated as GCN, is a model designed for deep learning on graph-structured data. Unlike traditional Convolutional Neural Networks (CNNs) which mainly deal with regular grid data (like images), GCN can process irregular graph-structured data. It is widely applied in fields such as social networks, knowledge graphs, and bioinformatics.\\n\\nA graph consists of two basic elements:\\n\\n1. **Node**: Represents entities in the data, such as people, items, or concepts.\\n2. **Edge**: Represents relationships between nodes, such as friendships or item similarities.\\n\\nEach \\"node\\" has its own feature vector. For example, for a person, we might use features like height, weight, age, gender, and interests to describe them. These feature vectors form the \\"Feature Matrix\\". The \\"edges\\" are represented by the \\"Adjacency Matrix\\".\\n\\nThe adjacency matrix is used to describe the connection relationships between nodes in a graph. For a graph with $n$ nodes, the adjacency matrix $A$ is an $n \\\\times n$ matrix where:\\n\\n- $A_{ij} = 1$ indicates that there is an edge between node $i$ and node $j$.\\n- $A_{ij} = 0$ indicates that there is no edge between node $i$ and node $j$.\\n\\n:::tip\\nPause for a moment, does this concept feel familiar?\\n\\n- **Isn\u2019t this very similar to the attention matrix in Transformer?**\\n\\nSo, let\'s draw a parallel:\\n\\n- **Node**: This corresponds to a token in Transformer.\\n- **Edge**: This corresponds to the relationship between tokens.\\n  :::\\n\\nWe\u2019ll come back to compare Transformer and GCN later, but let\u2019s continue exploring the basic concepts of GCN:\\n\\nThe properties and characteristics of the adjacency matrix are:\\n\\n- **Symmetry**: If the graph is undirected, the adjacency matrix is symmetric, i.e., $A_{ij} = A_{ji}$.\\n- **Self-connections**: Some graphs allow nodes to have self-connections, i.e., $A_{ii} = 1$, but in most cases, this is set to $A_{ii} = 0$.\\n\\n## Example\\n\\nLet\u2019s consider three people: Alice, Bob, and Carol, and their friendship relationships:\\n\\n- Alice and Bob are friends.\\n- Bob and Carol are friends.\\n- Alice and Carol are not directly friends.\\n\\nThis relationship can be represented by the following adjacency matrix:\\n\\n$$\\nA =\\n\\\\begin{bmatrix}\\n0 & 1 & 0 \\\\\\\\\\n1 & 0 & 1 \\\\\\\\\\n0 & 1 & 0\\n\\\\end{bmatrix}\\n$$\\n\\nIn this matrix:\\n\\n- $A_{12} = A_{21} = 1$: Indicates Alice and Bob are friends.\\n- $A_{23} = A_{32} = 1$: Indicates Bob and Carol are friends.\\n- All other elements are 0, meaning no direct friendship exists.\\n\\nThis adjacency matrix is \\"symmetric\\", so this graph is an \\"undirected graph\\".\\n\\nIf we visualize it, it would look like this:\\n\\n<GraphDemo />\\n\\n## Expanded Adjacency Matrix\\n\\nIn practical applications, the adjacency matrix can be further expanded to represent additional information, such as:\\n\\n1. **Weighted Adjacency Matrix**:\\n\\n   If the strength of relationships between friends varies, we can use weight values to represent this. For example, if the number of interactions between Alice and Bob is 3, and the number of interactions between Bob and Carol is 5, the weighted adjacency matrix can be represented as:\\n\\n   $$\\n   A =\\n   \\\\begin{bmatrix}\\n   0 & 3 & 0 \\\\\\\\\\n   3 & 0 & 5 \\\\\\\\\\n   0 & 5 & 0\\n   \\\\end{bmatrix}\\n   $$\\n\\n2. **Directed Adjacency Matrix**:\\n\\n   If the friendship relationships are directed (e.g., Alice contacts Bob first, but Bob does not contact Alice), the adjacency matrix becomes non-symmetric, like this:\\n\\n   $$\\n   A =\\n   \\\\begin{bmatrix}\\n   0 & 1 & 0 \\\\\\\\\\n   0 & 0 & 1 \\\\\\\\\\n   0 & 1 & 0\\n   \\\\end{bmatrix}\\n   $$\\n\\n   Here, $A_{12} = 1$ indicates that Alice contacted Bob first, while $A_{21} = 0$ shows that Bob did not contact Alice.\\n\\n## Feature Matrix\\n\\nIn addition to the adjacency matrix, each node in the graph can also contain a feature vector, which together form the **Feature Matrix** $X$.\\n\\nFor a graph with $n$ nodes where each node has $d$-dimensional features, the feature matrix $X$ is an $n \\\\times d$ matrix, where the $i$-th row represents the feature vector of node $i$.\\n\\nSuppose each person has two features: age and exercise habits (represented by 1 for yes and 0 for no), we can construct the following feature matrix:\\n\\n$$\\nX =\\n\\\\begin{bmatrix}\\n35 & 1 \\\\\\\\\\n50 & 0 \\\\\\\\\\n22 & 1\\n\\\\end{bmatrix}\\n$$\\n\\nThis matrix can be interpreted as:\\n\\n- The first row $[35, 1]$ represents Alice, who is 35 years old and has exercise habits.\\n- The second row $[50, 0]$ represents Bob, who is 50 years old and does not have exercise habits.\\n- The third row $[22, 1]$ represents Carol, who is 22 years old and has exercise habits.\\n\\nWe use the size of the circles to represent the nodes\' ages, and the color to indicate whether they have exercise habits:\\n\\n<GraphFeatureMatrixDemo />\\n\\n## Mathematics of GCN\\n\\nAfter understanding the adjacency matrix and feature matrix, we can dive into the mathematical principles of Graph Convolutional Networks (GCN).\\n\\nThe core idea of GCN is to perform information propagation and aggregation on graph structures through the \\"convolution operation,\\" in order to learn the representation (i.e., embedding vectors) of the nodes.\\n\\nIn traditional Convolutional Neural Networks (CNNs), the convolution operation mainly operates on the spatial structure of images, extracting features from local regions using convolutional filters. Similarly, GCN operates on the neighborhood structure of graphs, using information from neighboring nodes to update the feature representation of each node.\\n\\nEach layer of a GCN can be seen as a **message-passing mechanism**, which primarily consists of the following steps:\\n\\n1. **Message Aggregation**: Collect information from each node\u2019s neighboring nodes.\\n2. **Message Update**: Combine the aggregated information with the node\u2019s own features and update them via a nonlinear function.\\n\\nThe basic operation of GCN can be described by the following formula:\\n\\n$$\\nH^{(l+1)} = \\\\sigma\\\\left(\\\\hat{A} H^{(l)} W^{(l)}\\\\right)\\n$$\\n\\nWhere:\\n\\n- $H^{(l)}$ is the node feature matrix at the $l$-th layer. For the first layer, $H^{(0)} = X$, which is the input feature matrix.\\n- $W^{(l)}$ is the trainable weight matrix at the $l$-th layer.\\n- $\\\\sigma$ is the nonlinear activation function, such as ReLU.\\n- $\\\\hat{A}$ is the **normalized adjacency matrix**, used to stabilize training and account for the degree of nodes.\\n\\nUsing the original adjacency matrix $A$ directly for message passing could lead to excessively large or small eigenvalues, affecting the model\u2019s stability.\\n\\nThus, we normalize the adjacency matrix as follows:\\n\\n$$\\n\\\\hat{A} = \\\\tilde{D}^{-1/2} \\\\tilde{A} \\\\tilde{D}^{-1/2}\\n$$\\n\\nWhere:\\n\\n- $\\\\tilde{A} = A + I_n$, and $I_n$ is the $n \\\\times n$ identity matrix. This step is called **adding self-loops**, meaning each node is connected to itself.\\n- $\\\\tilde{D}$ is the degree matrix of $\\\\tilde{A}$, where the diagonal elements $\\\\tilde{D}_{ii} = \\\\sum_j \\\\tilde{A}_{ij}$.\\n\\nThis normalization ensures that during message passing, the degree of nodes is taken into account, preventing certain nodes with overly high or low degrees from disproportionately affecting the overall learning process.\\n\\nLet\u2019s continue with the example mentioned earlier, where the adjacency matrix $A$ and feature matrix $X$ are as follows:\\n\\n$$\\nA =\\n\\\\begin{bmatrix}\\n0 & 1 & 0 \\\\\\\\\\n1 & 0 & 1 \\\\\\\\\\n0 & 1 & 0\\n\\\\end{bmatrix},\\n\\\\quad\\nX =\\n\\\\begin{bmatrix}\\n35 & 1 \\\\\\\\\\n50 & 0 \\\\\\\\\\n22 & 1\\n\\\\end{bmatrix}\\n$$\\n\\n- **Step 1: Add Self-Loops**\\n\\n  First, we add self-loops to obtain $\\\\tilde{A}$:\\n\\n  $$\\n  \\\\tilde{A} = A + I_3 =\\n  \\\\begin{bmatrix}\\n  1 & 1 & 0 \\\\\\\\\\n  1 & 1 & 1 \\\\\\\\\\n  0 & 1 & 1\\n  \\\\end{bmatrix}\\n  $$\\n\\n- **Step 2: Calculate the Degree Matrix $\\\\tilde{D}$**\\n\\n  $$\\n  \\\\tilde{D} =\\n  \\\\begin{bmatrix}\\n  2 & 0 & 0 \\\\\\\\\\n  0 & 3 & 0 \\\\\\\\\\n  0 & 0 & 2\\n  \\\\end{bmatrix}\\n  $$\\n\\n- **Step 3: Compute the Normalized Adjacency Matrix $\\\\hat{A}$**\\n\\n  $$\\n  \\\\hat{A} = \\\\tilde{D}^{-1/2} \\\\tilde{A} \\\\tilde{D}^{-1/2} =\\n  \\\\begin{bmatrix}\\n  \\\\frac{1}{\\\\sqrt{2}} & 0 & 0 \\\\\\\\\\n  0 & \\\\frac{1}{\\\\sqrt{3}} & 0 \\\\\\\\\\n  0 & 0 & \\\\frac{1}{\\\\sqrt{2}}\\n  \\\\end{bmatrix}\\n  \\\\begin{bmatrix}\\n  1 & 1 & 0 \\\\\\\\\\n  1 & 1 & 1 \\\\\\\\\\n  0 & 1 & 1\\n  \\\\end{bmatrix}\\n  \\\\begin{bmatrix}\\n  \\\\frac{1}{\\\\sqrt{2}} & 0 & 0 \\\\\\\\\\n  0 & \\\\frac{1}{\\\\sqrt{3}} & 0 \\\\\\\\\\n  0 & 0 & \\\\frac{1}{\\\\sqrt{2}}\\n  \\\\end{bmatrix}\\n  $$\\n\\n  The result of this calculation is:\\n\\n  $$\\n  \\\\hat{A} \\\\approx\\n  \\\\begin{bmatrix}\\n  0.5 & \\\\frac{1}{\\\\sqrt{6}} & 0 \\\\\\\\\\n  \\\\frac{1}{\\\\sqrt{6}} & \\\\frac{1}{3} & \\\\frac{1}{\\\\sqrt{6}} \\\\\\\\\\n  0 & \\\\frac{1}{\\\\sqrt{6}} & 0.5\\n  \\\\end{bmatrix}\\n  $$\\n\\n- **Step 4: Apply the GCN Layer**\\n\\n  Suppose we have a GCN layer\u2019s weight matrix $W^{(0)}$:\\n\\n  $$\\n  W^{(0)} =\\n  \\\\begin{bmatrix}\\n  w_{11} & w_{12} \\\\\\\\\\n  w_{21} & w_{22}\\n  \\\\end{bmatrix}\\n  $$\\n\\n  Then, the feature matrix $H^{(1)}$ for the next layer is:\\n\\n  $$\\n  H^{(1)} = \\\\sigma\\\\left(\\\\hat{A} X W^{(0)}\\\\right)\\n  $$\\n\\n  The specific computation steps are as follows:\\n\\n  1.  **Matrix Multiplication**: First, compute $\\\\hat{A} X$:\\n\\n      $$\\n      \\\\hat{A} X \\\\approx\\n      \\\\begin{bmatrix}\\n      0.5 & \\\\frac{1}{\\\\sqrt{6}} & 0 \\\\\\\\\\n      \\\\frac{1}{\\\\sqrt{6}} & \\\\frac{1}{3} & \\\\frac{1}{\\\\sqrt{6}} \\\\\\\\\\n      0 & \\\\frac{1}{\\\\sqrt{6}} & 0.5\\n      \\\\end{bmatrix}\\n      \\\\begin{bmatrix}\\n      35 & 1 \\\\\\\\\\n      50 & 0 \\\\\\\\\\n      22 & 1\\n      \\\\end{bmatrix}\\n      =\\n      \\\\begin{bmatrix}\\n      0.5 \\\\times 35 + \\\\frac{1}{\\\\sqrt{6}} \\\\times 50 + 0 \\\\times 22 & 0.5 \\\\times 1 + \\\\frac{1}{\\\\sqrt{6}} \\\\times 0 + 0 \\\\times 1 \\\\\\\\\\n      \\\\frac{1}{\\\\sqrt{6}} \\\\times 35 + \\\\frac{1}{3} \\\\times 50 + \\\\frac{1}{\\\\sqrt{6}} \\\\times 22 & \\\\frac{1}{\\\\sqrt{6}} \\\\times 1 + \\\\frac{1}{3} \\\\times 0 + \\\\frac{1}{\\\\sqrt{6}} \\\\times 1 \\\\\\\\\\n      0 \\\\times 35 + \\\\frac{1}{\\\\sqrt{6}} \\\\times 50 + 0.5 \\\\times 22 & 0 \\\\times 1 + \\\\frac{1}{\\\\sqrt{6}} \\\\times 0 + 0.5 \\\\times 1\\n      \\\\end{bmatrix}\\n      $$\\n\\n  2.  **Apply Weight Matrix $W^{(0)}$**: Multiply the result by $W^{(0)}$.\\n\\n  3.  **Apply Nonlinear Function $\\\\sigma$**: Typically, the ReLU function is used, i.e., $\\\\sigma(x) = \\\\max(0, x)$.\\n\\nThrough these steps, GCN is able to combine each node\u2019s features with those of its neighbors, generating new feature representations.\\n\\nThis message-passing and aggregation mechanism enables GCN to capture both local and global information within graph structures, making it effective for a wide range of graph-related tasks such as node classification, graph classification, and link prediction.\\n\\nIn practice, multiple layers of GCN are often stacked to capture information from nodes at further distances. The output of each layer serves as the input for the next, allowing the model to progressively extract higher-level feature representations. For instance, a two-layer GCN enables each node\u2019s representation to include information from its two-hop neighbors, while a three-layer GCN can incorporate information from three-hop neighbors, and so on.\\n\\n## GCN vs Transformer\\n\\nSo, returning to the question we raised earlier:\\n\\nAlthough the design intentions and application scenarios of Graph Neural Networks (GCNs) and Transformers are different, they share many core concepts, such as nodes, edges, and message passing and aggregation based on feature matrices. So what is the relationship between them?\\n\\n- **Can we view GCN as a special case of Transformer?**\\n\\nLet\u2019s first review the core formulas of GCN and Transformer:\\n\\n- **Basic Update Formula of GCN**\\n\\n  $$\\n  H^{(l+1)} = \\\\sigma\\\\left(\\\\hat{A} H^{(l)} W^{(l)}\\\\right)\\n  $$\\n\\n  Where:\\n\\n  - $H^{(l)}$: Node feature matrix at layer $l$;\\n  - $\\\\hat{A} = D^{-\\\\frac{1}{2}} A D^{-\\\\frac{1}{2}}$: Weighted normalized adjacency matrix;\\n  - $W^{(l)}$: Learnable weight matrix at layer $l$;\\n  - $\\\\sigma$: Nonlinear activation function.\\n\\n  This formula aggregates local neighborhood information of nodes using the adjacency matrix $\\\\hat{A}$, capturing both the structural information of the graph and the node features.\\n\\n- **Self-Attention Formula of Transformer**\\n\\n  $$\\n  \\\\text{Attention}(Q, K, V) = \\\\text{softmax}\\\\left(\\\\frac{QK^\\\\top}{\\\\sqrt{d_k}}\\\\right)V\\n  $$\\n\\n  Where:\\n\\n  - $Q, K, V$: Query, Key, and Value matrices;\\n  - $d_k$: The dimension of the key vector;\\n  - $\\\\text{softmax}$: Used for normalization, ensuring that the weights sum to 1.\\n\\n  This formula enables the learning of global dependencies, with message aggregation depending on the dynamic calculation of similarity between features, independent of a fixed graph structure.\\n\\n### Restricted Attention Mechanism\\n\\nIf we restrict the attention matrix of Transformer to the adjacency matrix of the graph (i.e., $\\\\hat{A}$) and further assume that the attention weights are fixed (determined by the static structure of the graph), then the self-attention formula of Transformer simplifies to:\\n\\n$$\\n\\\\text{Attention}(Q, K, V) = \\\\text{softmax}\\\\left(\\\\frac{QK^\\\\top}{\\\\sqrt{d_k}}\\\\right)V \\\\rightarrow \\\\text{softmax}(\\\\hat{A}) V\\n$$\\n\\nAssuming that the query, key, and value matrices $Q, K, V$ all come from the same node feature matrix $H^{(l)}$, and that the weight matrices $W_Q = W_K = W_V = I$ (identity matrix), the formula becomes:\\n\\n$$\\n\\\\text{Attention}(H^{(l)}, H^{(l)}, H^{(l)}) = \\\\text{softmax}\\\\left(\\\\frac{H^{(l)} H^{(l)\\\\top}}{\\\\sqrt{d_k}}\\\\right) H^{(l)}\\n$$\\n\\nIf we further assume that $\\\\text{softmax}\\\\left(\\\\frac{H^{(l)} H^{(l)\\\\top}}{\\\\sqrt{d_k}}\\\\right) = \\\\hat{A}$, i.e., the attention weights are fixed as the normalized adjacency matrix, then the self-attention formula simplifies to:\\n\\n$$\\n\\\\text{Attention}(H^{(l)}, H^{(l)}, H^{(l)}) = \\\\hat{A} H^{(l)}\\n$$\\n\\nAt this point, the update formula for Transformer becomes:\\n\\n$$\\nH^{(l+1)} = \\\\sigma\\\\left(\\\\hat{A} H^{(l)} W^{(l)}\\\\right)\\n$$\\n\\nWhen comparing the two, in Transformer, the self-attention mechanism allows each node to interact with every other node in the graph, forming global dependencies. Mathematically, this is reflected in the attention weight matrix $\\\\text{softmax}\\\\left(\\\\frac{QK^\\\\top}{\\\\sqrt{d_k}}\\\\right)$, which is a fully connected weight matrix, and the weights are dynamically calculated. In contrast, in GCN, message passing is limited to local neighborhoods, and the weight matrix $\\\\hat{A}$ is sparse and fixed.\\n\\n### Differences in Weight Learning\\n\\nIn Transformer, the attention weights are dynamically learned through the similarity between queries and keys, with the specific formula as follows:\\n\\n$$\\n\\\\alpha_{ij} = \\\\frac{\\\\exp\\\\left(\\\\frac{Q_i K_j^\\\\top}{\\\\sqrt{d_k}}\\\\right)}{\\\\sum_{k} \\\\exp\\\\left(\\\\frac{Q_i K_k^\\\\top}{\\\\sqrt{d_k}}\\\\right)}\\n$$\\n\\nWhere $\\\\alpha_{ij}$ represents the attention weight from node $i$ to node $j$. This dynamic calculation allows the model to adaptively adjust the weights based on different input data, capturing complex relationships.\\n\\nIn contrast, in GCN, the weights are determined by the graph\'s adjacency structure, with the formula:\\n\\n$$\\n\\\\hat{A}_{ij} = \\\\frac{A_{ij}}{\\\\sqrt{d_i d_j}}\\n$$\\n\\nWhere $A_{ij}$ is an element of the adjacency matrix, indicating whether node $i$ and node $j$ are connected, and $d_i$ and $d_j$ are the degrees of nodes $i$ and $j$, respectively.\\n\\nThis fixed weight calculation limits the expressive power of the model but also reduces computational complexity.\\n\\n### Information Propagation Range and Efficiency\\n\\nIn Transformer, information can propagate across the entire graph, which is mathematically reflected as a fully connected attention matrix. The computational complexity is $O(N^2)$, where $N$ is the number of nodes. This makes Transformer potentially face computational bottlenecks when dealing with large graphs.\\n\\nIn contrast, the message passing in GCN is limited to local neighborhoods, and the weight matrix $\\\\hat{A}$ is sparse, with computational complexity typically being $O(N \\\\cdot d)$, where $d$ is the average degree of nodes. This makes GCN more efficient for large-scale graph processing.\\n\\n---\\n\\nTherefore, from the perspective of formula simplification:\\n\\n1. **Attention matrix restricted to the graph\u2019s adjacency matrix $\\\\hat{A}$**:\\n   The original self-attention mechanism in Transformer allows message passing between any two nodes, while GCN limits it to local neighborhoods within the graph. This restriction means that the range of message passing is determined by the graph\'s structure, rather than being dynamically learned.\\n\\n2. **Attention weights are fixed**:\\n   In Transformer, self-attention weights are dynamically computed based on the similarity between queries and keys. If these weights are fixed as $\\\\hat{A}$, i.e., no longer relying on the similarity between node features but entirely dependent on the static structure of the graph, the weights become non-learnable and fixed.\\n\\nGiven these two conditions, we believe GCN can indeed be considered a special case of Transformer.\\n\\n:::tip\\nIt\u2019s important to note that this is just **our** understanding based on our learning process, and it represents a personal perspective.\\n\\nIf this interpretation is incorrect, feel free to correct us!\\n:::\\n\\n## Conclusion\\n\\nGraph Convolutional Networks (GCN) and Transformers have similarities and differences, each excelling in different areas.\\n\\nIn practical applications, they each have their advantages. For example, the self-attention mechanism in Transformer allows the model to dynamically adjust the weights of message passing based on data features, giving it an unparalleled advantage in handling complex and varied data patterns. On the other hand, while the fixed weights in GCN work excellently for some structured data, they are more limited in scenarios requiring dynamic relationships.\\n\\nFurthermore, GCN is more suitable for handling data with clear graph structures, such as social network analysis, knowledge graphs, and recommendation systems, efficiently utilizing topological information. Transformer, however, performs excellently in domains such as natural language processing and computer vision, where sequential or high-dimensional data is handled, capturing long-range dependencies and complex patterns.\\n\\nThe topic of GCN is vast, with various variants and applications, and we\u2019ve only introduced the basic concepts here.\\n\\nWe hope this article has helped you understand some of the fundamental principles and applications of GCN.\\n\\nInterested in learning more about the latest applications of GCN and Transformer? Let\u2019s take a look at the paper!\\n\\n- [**[24.07] Graph Transformers: A Survey**](https://arxiv.org/abs/2407.09777)\\n\\n   <div align=\\"center\\">\\n   <figure style={{\\"width\\": \\"80%\\"}}>\\n   ![Graph Transformers](./img/img1.jpg)\\n   </figure>\\n   </div>\\n\\n:::tip\\nThis paper contains over 200 references. If you read one a day, you\u2019ll have fun for the whole year! (~Just kidding~)\\n:::\\n\\n## References\\n\\n- [**[16.09] Semi-Supervised Classification with Graph Convolutional Networks**](https://arxiv.org/abs/1609.02907)\\n- [**[17.06] Attention is All You Need**](https://arxiv.org/abs/1706.03762)"},{"id":"fourier-transform","metadata":{"permalink":"/en/blog/fourier-transform","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/12-02-fourier-transform/index.md","title":"A Brief Introduction to Fourier Transform","description":"A simple introduction to the basic concepts of Fourier Transform.","date":"2024-12-02T00:00:00.000Z","tags":[{"inline":true,"label":"fourier-transform","permalink":"/en/blog/tags/fourier-transform"},{"inline":true,"label":"signal-processing","permalink":"/en/blog/tags/signal-processing"}],"readingTime":13.82,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"fourier-transform","title":"A Brief Introduction to Fourier Transform","authors":"Zephyr","image":"/en/img/2024/1202.webp","tags":["fourier-transform","signal-processing"],"description":"A simple introduction to the basic concepts of Fourier Transform."},"unlisted":false,"prevItem":{"title":"A Brief Introduction to Graph Convolutional Networks","permalink":"/en/blog/graph-convolutional-networks"},"nextItem":{"title":"Fixing pyenv Build Errors","permalink":"/en/blog/fixed-pyenv-install-error"}},"content":"import InteractiveSineWave from \'@site/src/components/InteractiveSineWave\';\\nimport WaveSuperposition from \'@site/src/components/WaveSuperposition\';\\nimport FourierTransformDemo from \'@site/src/components/FourierTransformDemo\';\\n\\nWhen writing my paper notes, I encountered the Fourier Transform and wanted to discuss it, but the topic became too long and started to overshadow the main content.\\n\\nSo I decided to separate this section and provide a simple introduction to the related concepts.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Trigonometric Functions\\n\\nWe all learned trigonometric functions when we were younger, and most of us are probably masters of trigonometry.\\n\\nTrigonometric functions have widespread applications in physics and engineering, particularly in describing waves and vibrations.\\n\\nA wave is essentially a way of transferring energy, and this transfer often appears in the form of \\"periodic oscillations.\\"\\n\\nPeriodic?\\n\\nA common example might be a pendulum, which swings back and forth in a periodic motion. When we observe its motion path, we can see that its displacement changes like a wave, moving from positive values to zero, then to negative values, and then repeating.\\n\\nSo we try to use trigonometric functions to describe the wave more precisely, mathematically represented as:\\n\\n$$\\ny(t) = A \\\\sin(2\\\\pi f t)\\n$$\\n\\nEach variable here is related to the pendulum\'s motion:\\n\\n- $y(t)$: The displacement of the pendulum at time $t$.\\n- $A$: The amplitude, representing the maximum distance the pendulum swings.\\n- $f$: The frequency, representing how many times the pendulum swings per second.\\n\\nWith the sine function, we can more accurately describe the characteristics of the wave.\\n\\nIf you look closely, you will notice that some waves do not start at zero but rather start oscillating after a certain time offset, which is represented by the \\"phase $\\\\phi$.\\"\\n\\nThe complete waveform formula can be written as:\\n\\n$$\\ny(t) = A \\\\sin(2\\\\pi f t + \\\\phi)\\n$$\\n\\nOr it can be expressed using the cosine function:\\n\\n$$\\ny(t) = A \\\\cos(2\\\\pi f t + \\\\phi)\\n$$\\n\\nThe difference between sine and cosine waves is in the phase shift, and both can be used to describe wave variations.\\n\\nAdditionally, to describe the rate of change of the wave more effectively, we can use the \\"angular velocity $\\\\omega$,\\" which represents the rate of phase change per second, with the formula:\\n\\n$$\\n\\\\omega = 2\\\\pi f\\n$$\\n\\nFor easier observation, I have created an interactive chart where you can adjust the amplitude, frequency, and phase to observe the changes in the sine wave.\\n\\n<InteractiveSineWave />\\n\\n### Superposition of Waves\\n\\nWith sine and cosine waves, it\'s like having the basic elements of the x-axis and y-axis; we can combine different waveforms to form more complex waves, such as:\\n\\n$$\\ny(t) = A \\\\cos(2\\\\pi f t) + B \\\\sin(2\\\\pi f t)\\n$$\\n\\nIn this equation, $A$ and $B$ are coefficients that determine the size of the cosine and sine components. By superimposing multiple waves, we can form complex waveforms.\\n\\nYou can use the following interactive chart to adjust the parameters of two sine waves and observe the waveform formed by their superposition.\\n\\n<WaveSuperposition />\\n\\n### Complex Form\\n\\nWhile the trigonometric representation of sine and cosine waves is very intuitive, using complex numbers to represent waveforms is more concise and powerful in mathematical and engineering applications.\\n\\nWhy?\\n\\nBecause complex numbers can unify the combination of sine and cosine into a single formula and make it easier to handle operations like superposition, differentiation, and integration.\\n\\nBefore understanding the complex form, let\'s quickly review the basic concept of complex numbers. A complex number consists of a real part and an imaginary part, written as:\\n\\n$$\\nz = a + bi\\n$$\\n\\nWhere:\\n\\n- $a$ is the real part.\\n- $b$ is the imaginary part.\\n- $i$ is the imaginary unit, satisfying $i^2 = -1$.\\n\\nComplex numbers can also be expressed in \\"polar form\\" as:\\n\\n$$\\nz = r(\\\\cos\\\\theta + i\\\\sin\\\\theta)\\n$$\\n\\nHere:\\n\\n- $r = \\\\sqrt{a^2 + b^2}$ is the modulus of the complex number, representing the distance from the origin to the point $(a, b)$.\\n- $\\\\theta = \\\\tan^{-1}(b/a)$ is the argument of the complex number, representing the angle of rotation from the positive real axis.\\n- $\\\\cos\\\\theta$ and $\\\\sin\\\\theta$ define the direction corresponding to the angle $\\\\theta$.\\n\\nIn Cartesian coordinates, the point $(a, b)$ can be converted to polar coordinates $(r, \\\\theta)$.\\n\\nSubstituting $r$ and $\\\\theta$ into the trigonometric expression, we get $z = r(\\\\cos\\\\theta + i\\\\sin\\\\theta)$.\\n\\n## Euler\'s Formula\\n\\nFrom a mathematical perspective, the exponential function $e^x$ can be expanded into a power series:\\n\\n$$\\ne^x = 1 + \\\\frac{x}{1!} + \\\\frac{x^2}{2!} + \\\\frac{x^3}{3!} + \\\\cdots\\n$$\\n\\nThis series is intuitive when $x$ is a real number, but it also applies when $x$ is a complex number.\\n\\nFor example, when $x = i\\\\theta$, we substitute into the formula to get:\\n\\n$$\\ne^{i\\\\theta} = 1 + \\\\frac{i\\\\theta}{1!} + \\\\frac{(i\\\\theta)^2}{2!} + \\\\frac{(i\\\\theta)^3}{3!} + \\\\cdots\\n$$\\n\\nExpanding $(i\\\\theta)^n$, and noting the periodicity of powers of $i$ ($i^2 = -1, i^3 = -i, i^4 = 1$), we can separate the real and imaginary parts of the expansion:\\n\\nThe real part is:\\n\\n$$\\n1 + \\\\frac{(i\\\\theta)^2}{2!} + \\\\frac{(i\\\\theta)^4}{4!} + \\\\cdots = 1 - \\\\frac{\\\\theta^2}{2!} + \\\\frac{\\\\theta^4}{4!} - \\\\cdots\\n$$\\n\\nThis is exactly the expansion of $\\\\cos\\\\theta$, and similarly, the imaginary part is:\\n\\n$$\\n\\\\frac{(i\\\\theta)}{1!} + \\\\frac{(i\\\\theta)^3}{3!} + \\\\frac{(i\\\\theta)^5}{5!} + \\\\cdots = i\\\\left(\\\\theta - \\\\frac{\\\\theta^3}{3!} + \\\\frac{\\\\theta^5}{5!} - \\\\cdots\\\\right)\\n$$\\n\\nThis is exactly the expansion of $\\\\sin\\\\theta$.\\n\\nTherefore, combining the real and imaginary parts, we obtain the famous Euler\'s formula:\\n\\n$$\\ne^{i\\\\theta} = \\\\cos\\\\theta + i\\\\sin\\\\theta\\n$$\\n\\nHere:\\n\\n- $e^{i\\\\theta}$ is the exponential representation of the complex number, containing the real part $\\\\cos\\\\theta$ and the imaginary part $i\\\\sin\\\\theta$.\\n- The real and imaginary parts of the complex number correspond to the horizontal and vertical movements of the waveform.\\n\\n## Complex Waves\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"40%\\"}}>\\n![ComplexWave](./img/Euler\'s_formula.png)\\n<figcaption>Geometric meaning of Euler\'s formula, source: [**Wikipedia**](https://en.wikipedia.org/wiki/Euler%27s_formula)</figcaption>\\n</figure>\\n</div>\\n\\n---\\n\\nWe can use Euler\'s formula to rewrite the waveform equation. For example, consider the following complex waveform:\\n\\n$$\\nz(t) = A e^{i(2\\\\pi f t + \\\\phi)}\\n$$\\n\\nExpanding $e^{i(2\\\\pi f t + \\\\phi)}$ and using Euler\'s formula, we get:\\n\\n$$\\nz(t) = A \\\\left[\\\\cos(2\\\\pi f t + \\\\phi) + i\\\\sin(2\\\\pi f t + \\\\phi)\\\\right]\\n$$\\n\\nThis represents the same waveform having both:\\n\\n- **Real part** $\\\\Re(z) = A \\\\cos(2\\\\pi f t + \\\\phi)$\\n- **Imaginary part** $\\\\Im(z) = A \\\\sin(2\\\\pi f t + \\\\phi)$\\n\\nThus, if we want to represent sine and cosine waves using complex numbers, we can use the real and imaginary parts of the complex number to represent them:\\n\\n1. **Sine wave** $y(t) = A \\\\sin(2\\\\pi f t + \\\\phi)$:\\n\\n   - We can represent it using the imaginary part of the complex number:\\n     $$\\n     y(t) = \\\\Im \\\\left(A e^{i(2\\\\pi f t + \\\\phi)}\\\\right)\\n     $$\\n\\n2. **Cosine wave** $y(t) = A \\\\cos(2\\\\pi f t + \\\\phi)$:\\n   - We can represent it using the real part of the complex number:\\n     $$\\n     y(t) = \\\\Re \\\\left(A e^{i(2\\\\pi f t + \\\\phi)}\\\\right)\\n     $$\\n\\nHere, $A e^{i(2\\\\pi f t + \\\\phi)}$ is the unified complex representation, where the real and imaginary parts correspond to the cosine and sine waves, respectively.\\n\\n### Superposition of Waves\\n\\nIf we directly use trigonometric functions to represent the superposition of two waveforms, we need to use the addition formulas for trigonometric functions, such as:\\n\\n$$\\n\\\\cos(A + B) = \\\\cos A \\\\cos B - \\\\sin A \\\\sin B\\n$$\\n\\nand\\n\\n$$\\n\\\\sin(A + B) = \\\\sin A \\\\cos B + \\\\cos A \\\\sin B\\n$$\\n\\nWhen superimposing two waveforms:\\n\\n$$\\ny_1(t) = A_1 \\\\cos(2\\\\pi f_1 t + \\\\phi_1), \\\\quad y_2(t) = A_2 \\\\sin(2\\\\pi f_2 t + \\\\phi_2)\\n$$\\n\\nWe would need to expand each waveform separately, apply the cosine and sine addition formulas, and then organize the real and imaginary parts.\\n\\nThis process can be tedious and prone to errors, especially when more waveforms are involved, as the complexity of the formulas increases exponentially.\\n\\n:::tip\\nAside from high school students in Taiwan, I doubt anyone would want to manually calculate this, right?\\n:::\\n\\nIn the complex form, each waveform is represented as:\\n\\n$$\\nz_1 = A_1 e^{i(2\\\\pi f_1 t + \\\\phi_1)}, \\\\quad z_2 = A_2 e^{i(2\\\\pi f_2 t + \\\\phi_2)}\\n$$\\n\\nThe superposed waveform becomes:\\n\\n$$\\nz(t) = z_1 + z_2 = A_1 e^{i(2\\\\pi f_1 t + \\\\phi_1)} + A_2 e^{i(2\\\\pi f_2 t + \\\\phi_2)}\\n$$\\n\\nThe key here is that the addition of complex numbers is \\"linear,\\" meaning the magnitudes and phases of the two waveforms can be directly added or kept separate without needing to expand the trigonometric formulas.\\n\\nOn the other hand, complex numbers inherently contain both real and imaginary parts, which already carry the information for the cosine and sine components of the waveform. Therefore, there is no need to manually handle the decomposition of trigonometric functions.\\n\\nAnother advantage of using complex numbers is that they allow us to clearly separate the \\"amplitude\\" and \\"phase\\" of the waveform:\\n\\n- The amplitude is determined by the magnitude $|z|$.\\n- The phase is determined by the argument $\\\\arg(z)$.\\n\\nWhen superimposing waveforms, these pieces of information can be handled separately or together in calculations, without needing to expand into trigonometric sum or difference formulas. For example, if we want to simply analyze the amplitude of the superposed waveform, we can directly calculate $|z| = \\\\sqrt{\\\\Re(z)^2 + \\\\Im(z)^2}$.\\n\\nFinally, phase rotation of the waveform corresponds to the shift of the complex number\'s argument. If we need to adjust the phase of the superposed waveform, we only need to add a rotation angle $\\\\Delta\\\\theta$ to $e^{i\\\\theta}$, without separately adjusting the phases of the cosine and sine components.\\n\\n## Fourier Transform\\n\\nAll that has been discussed so far serves to help us understand the mathematical formula of the Fourier Transform.\\n\\nThe core concept of the Fourier Transform is:\\n\\n- **Any signal can be represented as a sum of sine and cosine waves**.\\n\\nThis means that even if a signal looks very complex, such as a piece of music, an image, or a pulse, we can still decompose it into simple, basic waveforms. These basic waveforms are the familiar sine and cosine waves, and they combine in different frequencies, amplitudes, and phases to form the complete signal.\\n\\nSine and cosine waves have powerful mathematical properties. For any periodic phenomenon, sine and cosine waves can be viewed as a set of \\"basis functions,\\" just like the $x$, $y$, and $z$ coordinate axes are used to describe positions in space. By appropriately combining them, we can represent any complex shape or variation.\\n\\nSuppose a signal $y(t)$ is a time-varying function. The Fourier Transform helps us answer two key questions:\\n\\n1. **What frequencies exist in this signal?**\\n2. **What are the amplitude and phase of each frequency?**\\n\\nThis frequency decomposition allows us to understand the signal from a completely different perspective. Instead of directly observing the waveform changing over time, we can see the signal\'s spectral characteristics more clearly.\\n\\nThe mathematical definition of the Fourier Transform provides the method for converting a signal from the \\"time domain\\" to the \\"frequency domain,\\" with the core formula being:\\n\\n$$\\nY(f) = \\\\int_{-\\\\infty}^\\\\infty y(t) e^{-i 2\\\\pi f t} \\\\, dt\\n$$\\n\\nThe physical meaning of each part of the formula is as follows:\\n\\n1. **Original Signal $y(t)$**:\\n\\n   $y(t)$ is a function defined in the time domain. This can be any form of signal, such as the sound wave of a piece of music, the amplitude variations of an electrical signal, or a pulse sequence that jumps within a time interval.\\n\\n   $y(t)$ contains the amplitude values of the signal at each moment of time $t$.\\n\\n2. **Complex Exponential Function $e^{-i 2\\\\pi f t}$**:\\n\\n   This is the key part of the Fourier Transform, and it is actually a combination of sine and cosine waves:\\n\\n   $$\\n   e^{-i 2\\\\pi f t} = \\\\cos(2\\\\pi f t) - i \\\\sin(2\\\\pi f t)\\n   $$\\n\\n   In the Fourier Transform, $e^{-i 2\\\\pi f t}$ is used to match a complex waveform with frequency $f$ to $y(t)$, extracting the strength of the signal at that frequency.\\n\\n---\\n\\nThe integral operation is essentially an inner product calculation, used to measure the similarity between $y(t)$ and $e^{-i 2\\\\pi f t}$.\\n\\nThis \\"similarity\\" determines the contribution of the signal at frequency $f$.\\n\\nThe Fourier Transform scans over all possible frequencies $f$.\\n\\nFor each $f$, the value $Y(f)$ calculated by the integral gives the strength at that frequency, which is why $Y(f)$ is called the \\"spectrum.\\"\\n\\nInstead of talking more about it, let\'s try calculating it ourselves:\\n\\nConsider a signal with a single frequency:\\n\\n$$\\ny(t) = A \\\\cos(2\\\\pi f_0 t + \\\\phi)\\n$$\\n\\nUsing Euler\'s formula, we express it as:\\n\\n$$\\ny(t) = \\\\Re\\\\left\\\\{ A e^{i (2\\\\pi f_0 t + \\\\phi)} \\\\right\\\\}\\n$$\\n\\nNow, performing the Fourier Transform:\\n\\n$$\\nY(f) = \\\\int_{-\\\\infty}^\\\\infty y(t) e^{-i 2\\\\pi f t} \\\\, dt\\n$$\\n\\nSubstituting the expression for $y(t)$:\\n\\n$$\\nY(f) = \\\\int_{-\\\\infty}^\\\\infty \\\\Re\\\\left\\\\{ A e^{i (2\\\\pi f_0 t + \\\\phi)} \\\\right\\\\} e^{-i 2\\\\pi f t} \\\\, dt\\n$$\\n\\nSince the core of the Fourier Transform is the integral operation, its effect is to match every point in the time domain with a frequency waveform. If $f = f_0$, the $e^{-i 2\\\\pi f t}$ and $e^{i 2\\\\pi f_0 t}$ align perfectly, and the result of the integral will be non-zero.\\n\\nIf $f \\\\neq f_0$, these two waveforms do not match in phase, and the integral result approaches zero.\\n\\nWhen the frequency matches, we get:\\n\\n$$\\nY(f_0) = A e^{i \\\\phi}\\n$$\\n\\nThis shows that the spectrum $Y(f)$ contains not only the strength of the frequency (given by $A$) but also the phase of the frequency (given by $\\\\phi$).\\n\\nThis is the reason why the Fourier Transform can fully describe a signal.\\n\\n## Fourier Series\\n\\nThe Fourier Series is a special case of the Fourier Transform, mainly used for periodic signals.\\n\\nUnlike the Fourier Transform, which extends the signal\'s spectrum to a continuous range of frequencies, the Fourier Series focuses on using a set of \\"discrete frequencies\\" to describe a periodic signal.\\n\\nThe core concept of the Fourier Series is:\\n\\n- **Any periodic signal can be represented as a linear combination of sine and cosine waves at discrete frequencies**.\\n\\nThis means that as long as the signal is periodic, we can approximate it using a finite number of sine and cosine waves, and as the frequency combinations increase, the approximation becomes more accurate.\\n\\nSuppose a periodic signal $x(t)$ with period $T$ can be represented by the Fourier Series as:\\n\\n$$\\nx(t) = a_0 + \\\\sum_{n=1}^\\\\infty \\\\left[ a_n \\\\cos\\\\left(\\\\frac{2\\\\pi n t}{T}\\\\right) + b_n \\\\sin\\\\left(\\\\frac{2\\\\pi n t}{T}\\\\right) \\\\right]\\n$$\\n\\nHere, $a_0, a_n, b_n$ are the coefficients of the Fourier Series, representing the amplitudes of the sine and cosine waves at different frequencies, and these coefficients are determined by the following formulas:\\n\\n1. **DC Component ($a_0$)**:\\n\\n   $$\\n   a_0 = \\\\frac{1}{T} \\\\int_{0}^T x(t) \\\\, dt\\n   $$\\n\\n   It represents the average value of the signal, or the DC component over one period.\\n\\n2. **Cosine Coefficients ($a_n$)**:\\n\\n   $$\\n   a_n = \\\\frac{2}{T} \\\\int_{0}^T x(t) \\\\cos\\\\left(\\\\frac{2\\\\pi n t}{T}\\\\right) \\\\, dt\\n   $$\\n\\n   It represents the amplitude of the cosine wave at frequency $\\\\frac{n}{T}$.\\n\\n3. **Sine Coefficients ($b_n$)**:\\n\\n   $$\\n   b_n = \\\\frac{2}{T} \\\\int_{0}^T x(t) \\\\sin\\\\left(\\\\frac{2\\\\pi n t}{T}\\\\right) \\\\, dt\\n   $$\\n\\n   It represents the amplitude of the sine wave at frequency $\\\\frac{n}{T}$.\\n\\nSimilarly, to simplify the representation and computation, the Fourier Series is often written in complex form:\\n\\n$$\\nx(t) = \\\\sum_{n=-\\\\infty}^\\\\infty c_n e^{i \\\\frac{2\\\\pi n t}{T}}\\n$$\\n\\nWhere $c_n$ are the complex coefficients, defined as:\\n\\n$$\\nc_n = \\\\frac{1}{T} \\\\int_{0}^T x(t) e^{-i \\\\frac{2\\\\pi n t}{T}} \\\\, dt\\n$$\\n\\nIn this form:\\n\\n- The real part $\\\\Re\\\\{c_n\\\\}$ corresponds to $a_n$.\\n- The imaginary part $\\\\Im\\\\{c_n\\\\}$ corresponds to $b_n$.\\n\\nThe Fourier Series has wide applications in engineering and science, such as studying periodic vibrations in mechanical structures and analyzing periodic electrical signals, like square waves, triangle waves, and sawtooth waves.\\n\\n## Conclusion\\n\\nHere, we can only briefly introduce the relevant concepts of the Fourier Transform.\\n\\nThere is more to explore, such as the Discrete Fourier Transform (DFT), Fast Fourier Transform (FFT), the relationship between Fourier Transform and convolution, frequency-domain filter design and implementation, and the extensions of Fourier analysis in quantum physics and image processing, which could take days to fully discuss.\\n\\nInterested readers can consult further resources to learn more about the principles and applications of Fourier Transform.\\n\\nWith the remaining space, I\'ll add a fun interactive activity at the end to experience the charm of Fourier!\\n\\n## Interactive Activity\\n\\nBased on the settings, the program will plot the corresponding waveform in the time domain and show its analysis results in the frequency domain.\\n\\nYou will see that the frequency domain distribution matches the values on the \\"settings panel,\\" with other frequencies generated to approximate the waveform.\\n\\n<FourierTransformDemo />"},{"id":"fixed-pyenv-install-error","metadata":{"permalink":"/en/blog/fixed-pyenv-install-error","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/11-25-fixed-pyenv-install-error/index.md","title":"Fixing pyenv Build Errors","description":"Troubleshooting build errors","date":"2024-11-25T00:00:00.000Z","tags":[{"inline":true,"label":"pyenv","permalink":"/en/blog/tags/pyenv"},{"inline":true,"label":"python","permalink":"/en/blog/tags/python"}],"readingTime":2.025,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"fixed-pyenv-install-error","title":"Fixing pyenv Build Errors","authors":"Zephyr","image":"/en/img/2024/1125.webp","tags":["pyenv","python"],"description":"Troubleshooting build errors"},"unlisted":false,"prevItem":{"title":"A Brief Introduction to Fourier Transform","permalink":"/en/blog/fourier-transform"},"nextItem":{"title":"Update Docusaurus to 3.6.0","permalink":"/en/blog/update-docusaurus-to-3-6-0"}},"content":"Installing pyenv itself is fine.\\n\\nHowever, an error occurs when building the Python version.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Problem Description\\n\\nUsing the command:\\n\\n```shell\\npyenv install 3.10.15\\n```\\n\\nShortly after, the system throws a series of error messages:\\n\\n```shell\\nDownloading Python-3.10.15.tar.xz...\\n-> https://www.python.org/ftp/python/3.10.15/Python-3.10.15.tar.xz\\nInstalling Python-3.10.15...\\n\\nBUILD FAILED (Ubuntu 22.04 using python-build 20180424)\\n\\nInspect or clean up the working tree at /tmp/python-build.20241125102533.16978\\nResults logged to /tmp/python-build.20241125102533.16978.log\\n\\nLast 10 log lines:\\n        ./signal/../sysdeps/unix/sysv/linux/x86_64/libc_sigaction.c:0\\n0x7be2d6829d8f __libc_start_call_main\\n        ../sysdeps/nptl/libc_start_call_main.h:58\\n0x7be2d6829e3f __libc_start_main_impl\\n        ../csu/libc-start.c:392\\nPlease submit a full bug report,\\nwith preprocessed source if appropriate.\\nPlease include the complete backtrace with any bug report.\\nSee <file:///usr/share/doc/gcc-11/README.Bugs> for instructions.\\nmake: *** [Makefile:1856: Python/getargs.o] Error 1\\n```\\n\\nHuh? Just another day in the life of a developer!\\n\\n## Fixing the Problem\\n\\nHere are a few potential fixes:\\n\\n### 1. Install Dependencies\\n\\nFirst, update the system packages:\\n\\n```shell\\nsudo apt update && sudo apt upgrade -y\\n```\\n\\nThen, make sure the necessary packages are installed:\\n\\n```shell\\nsudo apt install -y build-essential libssl-dev zlib1g-dev libbz2-dev \\\\\\n    libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev \\\\\\n    libncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev\\n```\\n\\nThe system tells us that all the above packages are already up-to-date.\\n\\nSo, it\u2019s not the problem here.\\n\\n### 2. Check GCC Version\\n\\nUpdate the GCC version:\\n\\n```shell\\nsudo apt install --reinstall gcc\\n```\\n\\nThen try again, but the same error persists.\\n\\nLooks like this isn\u2019t the issue either.\\n\\n### 3. Check the Log File\\n\\nFrom the error messages, find the location of the log file and take a look:\\n\\n```shell\\nless /tmp/python-build.20241125102533.16978.log\\n```\\n\\nInside, there\u2019s a ton of information. Let\u2019s go straight to the last section:\\n\\n```shell\\ngcc -c -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall    -std=c99 -Wextra -Wno-unused-result -Wno-unused-parameter -Wno-missing-field-initializers -Werror=implicit-function-declaration -fvisibility=hidden  -I./Include/internal  -I. -I./Include -I/home/user/.pyenv/versions/3.10.15/include -I/home/user/.pyenv/versions/3.10.15/include -fPIC -DPy_BUILD_CORE -o Programs/_testembed.o ./Programs/_testembed.c\\nsed -e \\"s,@EXENAME@,/home/user/.pyenv/versions/3.10.15/bin/python3.10,\\" < ./Misc/python-config.in >python-config.py\\nLC_ALL=C sed -e \'s,\\\\$(\\\\([A-Za-z0-9_]*\\\\)),\\\\$\\\\{\\\\1\\\\},g\' < Misc/python-config.sh >python-config\\n/tmp/ccTVJtRi.s: Assembler messages:\\n/tmp/ccTVJtRi.s: Internal error in emit_inc_line_addr at ../../gas/dwarf2dbg.c:1643.\\nPlease report this bug.\\nmake: *** [Makefile:1856: Objects/typeobject.o] Error 1\\nmake: *** Waiting for unfinished jobs....\\n```\\n\\nThe error here says:\\n\\n- **\\"Internal error in emit_inc_line_addr at ../../gas/dwarf2dbg.c\\"**\\n\\nThis points to an issue with the assembler component of binutils, typically indicating a bug or incompatibility in the package.\\n\\n### 4. Reinstall Binutils\\n\\nGreat, now we know the problem. Let\u2019s update binutils:\\n\\n```shell\\nsudo apt update\\nsudo apt install --reinstall binutils\\n```\\n\\nAfter updating, try running:\\n\\n```shell\\npyenv install 3.10.15\\n```\\n\\nThis time, it works, and the problem is resolved."},{"id":"update-docusaurus-to-3-6-0","metadata":{"permalink":"/en/blog/update-docusaurus-to-3-6-0","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/11-09-update-docusaurus-to-360/index.md","title":"Update Docusaurus to 3.6.0","description":"Troubleshooting issues during the update process","date":"2024-11-09T00:00:00.000Z","tags":[{"inline":true,"label":"Docusaurus","permalink":"/en/blog/tags/docusaurus"},{"inline":true,"label":"Update","permalink":"/en/blog/tags/update"}],"readingTime":3.025,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"update-docusaurus-to-3-6-0","title":"Update Docusaurus to 3.6.0","authors":"Zephyr","image":"/en/img/2024/1109.webp","tags":["Docusaurus","Update"],"description":"Troubleshooting issues during the update process"},"unlisted":false,"prevItem":{"title":"Fixing pyenv Build Errors","permalink":"/en/blog/fixed-pyenv-install-error"},"nextItem":{"title":"Python Implementation of a Web File Downloader","permalink":"/en/blog/file-crawler-python-implementation"}},"content":"Docusaurus has released version 3.6.0, which includes updates to the bundling tool, significantly speeding up build times.\\n\\nHowever, we ran into some issues during the update!\\n\\n\x3c!-- truncate --\x3e\\n\\n## Update Details\\n\\nIf you\'re not familiar with the recent release, you can check out the latest blog post from the Docusaurus team:\\n\\n- [**Docusaurus 3.6**](https://docusaurus.io/blog/releases/3.6)\\n\\n  <iframe\\n    src=\\"https://docusaurus.io/blog/releases/3.6\\"\\n    width=\\"80%\\"\\n    height=\\"300px\\"\\n    center=\\"true\\"\\n    ></iframe>\\n\\n## Issue Description\\n\\nThe update itself proceeded without issues, but Docusaurus introduced a new feature in this version that allows adding a config setting:\\n\\n```js title=\\"docusaurus.config.js\\"\\nconst config = {\\n  future: {\\n    experimental_faster: true,\\n  },\\n};\\n```\\n\\nWhen we added this setting to our `docusaurus.config.js` file, we encountered the following error:\\n\\n```shell\\nyarn run v1.22.22\\n$ docusaurus start\\n[INFO] Starting the development server...\\n[SUCCESS] Docusaurus website is running at: http://localhost:3000/\\n\u25CF Client \u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0\u25A0 (83%) sealing chunk ids\\nSegmentation fault (core dumped)\\nerror Command failed with exit code 139.\\ninfo Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command.\\n```\\n\\n---\\n\\nWhen we saw this error, it was frustrating.\\n\\nA simple `Segmentation fault`? That\u2019s all? Really?\\n\\n## Troubleshooting\\n\\nSince we couldn\'t find any solutions in the official issue tracker, we had to troubleshoot this manually.\\n\\nAfter some investigation, we discovered that the issue stems from using certain Chinese characters in `_category_.json` files.\\n\\nOr, more accurately, specific Chinese characters cause the issue, though we\u2019re unsure exactly which ones.\\n\\nFor example, one of our files originally looked like this:\\n\\n```json title=\\"_category_.json\\"\\n{\\n  \\"label\\": \\"\u5143\u5BCC\u8B49\u5238\\",\\n  \\"position\\": 1,\\n  \\"link\\": {\\n    \\"type\\": \\"generated-index\\"\\n  }\\n}\\n```\\n\\nChanging `\u5143\u5BCC\u8B49\u5238` to `\u4E2D\u6587` allowed the project to run successfully!\\n\\n:::tip\\nBoth labels are in Chinese. Why does one work while the other doesn\u2019t?\\n:::\\n\\nReplacing `\u4E2D\u6587` with an English label also worked:\\n\\n```json title=\\"_category_.json\\"\\n{\\n  \\"label\\": \\"English Label\\",\\n  \\"position\\": 1,\\n  \\"link\\": {\\n    \\"type\\": \\"generated-index\\"\\n  }\\n}\\n```\\n\\n## Additional Issues\\n\\nWe also discovered another issue: the new setting doesn\u2019t support special characters in file names.\\n\\nFor instance, one of our files was named `B\xe9zier`, which caused an error due to the accented character.\\n\\nAfter removing the accent, everything ran smoothly.\\n\\n## Conclusion\\n\\nIn the end, we decided not to enable this new feature.\\n\\nSince our website is relatively small, build speed isn\u2019t a major bottleneck, but this feature would require us to change multiple files.\\n\\nMaybe we\u2019ll revisit it later!\\n\\n## 2024-11-20 Update\\n\\nThe official update notification has been received, and this time the version has been updated to **v3.6.2**, which resolves the issues mentioned in the previous update.\\n\\nIn this version, we can now successfully use the `experimental_faster` setting:\\n\\n```js title=\\"docusaurus.config.js\\"\\nconst config = {\\n  future: {\\n    experimental_faster: true,\\n  },\\n};\\n```\\n\\nTesting shows that the **Segmentation fault** issue no longer occurs.\\n\\nHowever...\\n\\nAfter starting the development environment, modifying files triggers the following error:\\n\\n```shell\\nPanic occurred at runtime. Please file an issue on GitHub with the backtrace below: https://github.com/web-infra-dev/rspack/issues\\nMessage:  Chunk(ChunkUkey(Ukey(606), PhantomData<rspack_core::chunk::Chunk>)) not found in ChunkByUkey\\nLocation: crates/rspack_core/src/lib.rs:328\\n\\nRun with COLORBT_SHOW_HIDDEN=1 environment variable to disable frame filtering.\\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 BACKTRACE \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\\n 1: start_thread\\n    at ./nptl/pthread_create.c:447\\n 2: clone3\\n    at ./misc/../sysdeps/unix/sysv/linux/x86_64/clone3.S:78\\nAborted (core dumped)\\nerror Command failed with exit code 134.\\ninfo Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command.\\n```\\n\\nIt seems to be an issue with Rspack. We quickly found a related issue on GitHub:\\n\\n- [**web-infra-dev/rspack: [Bug]: using docusaurus edit mdx or md file, process crash. #8480**](https://github.com/web-infra-dev/rspack/issues/8480)\\n\\nIt looks like we\'re not alone in this! We\'ll have to wait for a further fix.\\n\\n## 2024-11-24 Update\\n\\nContinuing from the previous issue, this time we updated to v3.6.3.\\n\\nThe Rspack issue has been fixed, and we can now happily use it as normal!"},{"id":"file-crawler-python-implementation","metadata":{"permalink":"/en/blog/file-crawler-python-implementation","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/09-23-file-crawler/index.md","title":"Python Implementation of a Web File Downloader","description":"Implement a simple web file downloader.","date":"2024-09-23T00:00:00.000Z","tags":[{"inline":true,"label":"Python","permalink":"/en/blog/tags/python"},{"inline":true,"label":"File Crawler","permalink":"/en/blog/tags/file-crawler"}],"readingTime":1.705,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"file-crawler-python-implementation","title":"Python Implementation of a Web File Downloader","authors":"Zephyr","image":"/en/img/2024/0923.webp","tags":["Python","File Crawler"],"description":"Implement a simple web file downloader."},"unlisted":false,"prevItem":{"title":"Update Docusaurus to 3.6.0","permalink":"/en/blog/update-docusaurus-to-3-6-0"},"nextItem":{"title":"Automatically Count Articles in Docusaurus Sidebar","permalink":"/en/blog/customized-docusaurus-sidebars-auto-count"}},"content":"We came across a webpage containing hundreds of PDF file links.\\n\\nAs engineers, if we were to download them manually, it would be highly inefficient, right?\\n\\nSo, what we need here is a small script that will help us download all the files.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Install Required Packages\\n\\nFirst, you need to install the necessary packages. If you haven\'t installed them yet, you can do so using the following command:\\n\\n```bash\\npip install requests beautifulsoup4 urllib3\\n```\\n\\n## The Code\\n\\nWithout further ado, since the script is already written, let\'s dive straight into the code!\\n\\nThe parts highlighted are the ones you\u2019ll need to modify yourself. Adjust the script according to your needs.\\n\\n```python {13,16} title=\\"file_crawler.py\\"\\nimport os\\nfrom urllib.parse import urljoin\\n\\nimport requests\\nfrom bs4 import BeautifulSoup\\n\\n# Simulating a browser\'s headers\\nheaders = {\\n    \\"User-Agent\\": \\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\\"\\n}\\n\\n# Web page URL\\nurl = \\"put_your_url_here\\"\\n\\n# Target file format\\ntarget_format = \\".pdf\\"\\n\\n# Send an HTTP GET request with headers\\nresponse = requests.get(url, headers=headers)\\n\\n# Check if the request was successful\\nif response.status_code == 200:\\n    # Use BeautifulSoup to parse the HTML\\n    soup = BeautifulSoup(response.text, \\"html.parser\\")\\n\\n    # Find all <a> tags and filter those with href attributes matching the target format\\n    target_links = []\\n    for link in soup.find_all(\\"a\\"):\\n        href = link.get(\\"href\\")\\n        if href and href.endswith(target_format):  # Specify the file format you want to download\\n            target_links.append(urljoin(url, href))\\n\\n    # Create a folder to save the files\\n    os.makedirs(\\"downloads\\", exist_ok=True)\\n\\n    # Download each file\\n    for url in target_links:\\n        file_name = url.split(\\"/\\")[-1]  # Extract the filename from the URL\\n        file_path = os.path.join(\\"downloads\\", file_name)\\n\\n        # Send a request to download the file\\n        response = requests.get(url, headers=headers)  # Add headers again\\n        if response.status_code == 200:\\n            with open(file_path, \\"wb\\") as f:\\n                f.write(response.content)\\n            print(f\\"Downloaded: {file_name}\\")\\n        else:\\n            print(f\\"Failed to download: {url}\\")\\nelse:\\n    print(f\\"Unable to access the webpage, status code: {response.status_code}\\")\\n```\\n\\n## Running the Script\\n\\nOnce you\u2019re done, you can simply run the script to download all the files matching the target format.\\n\\n```bash\\npython file_crawler.py\\n```"},{"id":"customized-docusaurus-sidebars-auto-count","metadata":{"permalink":"/en/blog/customized-docusaurus-sidebars-auto-count","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/09-14-customized-docusaurus-sidebars-auto-count/index.md","title":"Automatically Count Articles in Docusaurus Sidebar","description":"Adding some new features to the sidebar.","date":"2024-09-14T00:00:00.000Z","tags":[{"inline":true,"label":"Docusaurus","permalink":"/en/blog/tags/docusaurus"},{"inline":true,"label":"Sidebar","permalink":"/en/blog/tags/sidebar"}],"readingTime":4.315,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"customized-docusaurus-sidebars-auto-count","title":"Automatically Count Articles in Docusaurus Sidebar","authors":"Zephyr","image":"/en/img/2024/0914.webp","tags":["Docusaurus","Sidebar"],"description":"Adding some new features to the sidebar."},"unlisted":false,"prevItem":{"title":"Python Implementation of a Web File Downloader","permalink":"/en/blog/file-crawler-python-implementation"},"nextItem":{"title":"Customizing the Docusaurus 404 Page","permalink":"/en/blog/customized-docusaurus-404-page"}},"content":"Docusaurus provides a very feature-rich Sidebar by default, but sometimes it doesn\'t fit all our needs.\\n\\nLet\'s tweak it a bit this time.\\n\\n\x3c!-- truncate --\x3e\\n\\nThe goal is simple. The original Sidebar displays the categories we\'ve specified. When the site starts, it looks for the `_category_.json` in each directory level, which contains something like this:\\n\\n```json\\n{\\n  \\"label\\": \\"Classic CNNs\\",\\n  \\"link\\": {\\n    \\"type\\": \\"generated-index\\"\\n  }\\n}\\n```\\n\\nThis would display:\\n\\n- Classic CNNs\\n- ... (other categories)\\n\\nWhat I\'d like to do is count the number of items under each folder and display it directly on the page, like this:\\n\\n- Classic CNNs (8)\\n- ... (other categories)\\n\\n---\\n\\nCan we just add the count directly in the `_category_.json` file?\\n\\n```json\\n{\\n  \\"label\\": \\"Classic CNNs (8)\\",\\n  \\"link\\": {\\n    \\"type\\": \\"generated-index\\"\\n  }\\n}\\n```\\n\\nAnd manually update the count every time we add an article?\\n\\n**Absolutely not! We can\'t write code like that.**\\n\\n## Reference Material\\n\\nTo solve this issue, as usual, let\'s first check Docusaurus\' official documentation:\\n\\n- [**Docusaurus Sidebar**](https://docusaurus.io/docs/sidebar)\\n\\n---\\n\\nThe default Sidebar is autogenerated through the `autogenerated` option:\\n\\n```jsx\\n/**\\n * Creating a sidebar enables you to:\\n - create an ordered group of docs\\n - render a sidebar for each doc of that group\\n - provide next/previous navigation\\n\\n The sidebars can be generated from the filesystem, or explicitly defined here.\\n\\n Create as many sidebars as you want.\\n */\\n\\n// @ts-check\\n\\n/** @type {import(\'@docusaurus/plugin-content-docs\').SidebarsConfig} */\\nconst sidebars = {\\n  // By default, Docusaurus generates a sidebar from the docs folder structure\\n  tutorialSidebar: [{ type: \\"autogenerated\\", dirName: \\".\\" }],\\n\\n  // But you can create a sidebar manually\\n  /*\\n  tutorialSidebar: [\\n    \'intro\',\\n    \'hello\',\\n    {\\n      type: \'category\',\\n      label: \'Tutorial\',\\n      items: [\'tutorial-basics/create-a-document\'],\\n    },\\n  ],\\n   */\\n};\\n\\nexport default sidebars;\\n```\\n\\n---\\n\\nAfter reviewing it, it seems there is no built-in feature that fits our needs. Let\'s build one ourselves.\\n\\n## Implementation\\n\\nI\'ll include comments directly in the code. Here are a few places to note where modifications may be required based on your setup:\\n\\n1. Line 8: `const baseDir = path.join(__dirname, \\"papers\\");`\\n\\n   The `papers` here refers to our folder name. Ensure your directory path is correct.\\n\\n---\\n\\n2. Line 20: `sidebarItems.push(\\"intro\\");`\\n\\n   The `intro` here refers to the name of our homepage. Ensure your homepage name is correct. If there\'s no homepage, you can remove this line.\\n\\n---\\n\\n3. Line 72: `return stat.isDirectory() || (stat.isFile() && item.endsWith(\\".md\\"));`\\n\\n   Here, `.md` is the format of our articles. Adjust it based on your format.\\n\\n---\\n\\nHere\'s the implementation. You can see the result directly on the webpage: [**Papers**](/papers/intro).\\n\\n```jsx showLineNumbers title=\\"/sidebars.js\\"\\nconst fs = require(\\"fs\\"); // Import Node.js file system module to work with files and directories\\nconst path = require(\\"path\\"); // Import Node.js path module to handle file paths\\n\\n/** @type {import(\'@docusaurus/plugin-content-docs\').SidebarsConfig} */\\n// This is a type definition for Docusaurus sidebar configuration to enable IDE autocompletion\\nfunction generateSidebar() {\\n  // Set the base directory path, pointing to the \'papers\' folder. Modify as needed.\\n  const baseDir = path.join(__dirname, \\"papers\\");\\n\\n  // Read all subdirectories under \'papers\', filtering out hidden ones (starting with a dot)\\n  const categories = fs.readdirSync(baseDir).filter((item) => {\\n    const itemPath = path.join(baseDir, item);\\n    // Ensure it\'s a directory and not hidden\\n    return fs.statSync(itemPath).isDirectory() && !item.startsWith(\\".\\");\\n  });\\n\\n  const sidebarItems = []; // Array to store sidebar items\\n\\n  // Add a fixed \'intro\' item at the beginning\\n  sidebarItems.push(\\"intro\\");\\n\\n  // Iterate through all category directories\\n  categories.forEach((category) => {\\n    const categoryPath = path.join(baseDir, category); // Get the full path for each category\\n    const count = countItemsInDirectory(categoryPath); // Count the number of items in the directory\\n\\n    // Try to read the \'_category_.json\' file within the category directory to get label and link\\n    const categoryJsonPath = path.join(categoryPath, \\"_category_.json\\");\\n    let label = category; // Default label is the directory name\\n    let link = undefined; // Default link is undefined\\n    if (fs.existsSync(categoryJsonPath)) {\\n      // If the \'_category_.json\' file exists\\n      const categoryJson = JSON.parse(\\n        fs.readFileSync(categoryJsonPath, \\"utf8\\")\\n      ); // Read and parse the JSON file\\n      label = categoryJson.label || category; // Use the label from the JSON file or default to directory name\\n      link = categoryJson.link; // Use the link from the JSON file\\n    }\\n\\n    // Append the item count to the label\\n    label = `${label} (${count})`;\\n\\n    // Create a sidebar item, with type \'category\', indicating this is a category\\n    const sidebarItem = {\\n      type: \\"category\\",\\n      label: label, // Display label\\n      items: [{ type: \\"autogenerated\\", dirName: category }], // Automatically generate document items under the category\\n    };\\n\\n    if (link) {\\n      // If a link is provided, add it to the category\\n      sidebarItem.link = link;\\n    }\\n\\n    sidebarItems.push(sidebarItem); // Add the category item to the sidebar array\\n  });\\n\\n  // Return an object containing the sidebar configuration\\n  return {\\n    papersSidebar: sidebarItems,\\n  };\\n}\\n\\n// Count the valid items (including subdirectories and Markdown files) in a specified directory\\nfunction countItemsInDirectory(dirPath) {\\n  const items = fs.readdirSync(dirPath).filter((item) => {\\n    const itemPath = path.join(dirPath, item);\\n    // Exclude \'_category_.json\' and hidden files (starting with a dot)\\n    if (item === \\"_category_.json\\" || item.startsWith(\\".\\")) return false;\\n    const stat = fs.statSync(itemPath);\\n    // Only count directories and .md files\\n    return stat.isDirectory() || (stat.isFile() && item.endsWith(\\".md\\"));\\n  });\\n  return items.length; // Return the count of items\\n}\\n\\n// Export the generated sidebar configuration for Docusaurus to use\\nexport default generateSidebar();\\n```"},{"id":"customized-docusaurus-404-page","metadata":{"permalink":"/en/blog/customized-docusaurus-404-page","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/09-10-customized-docusaurus-404-page/index.md","title":"Customizing the Docusaurus 404 Page","description":"The default 404 page needs a revamp!","date":"2024-09-10T00:00:00.000Z","tags":[{"inline":true,"label":"Docusaurus","permalink":"/en/blog/tags/docusaurus"},{"inline":true,"label":"404NotFound","permalink":"/en/blog/tags/404-not-found"}],"readingTime":6.235,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"customized-docusaurus-404-page","title":"Customizing the Docusaurus 404 Page","authors":"Zephyr","image":"/en/img/2024/0910.webp","tags":["Docusaurus","404NotFound"],"description":"The default 404 page needs a revamp!"},"unlisted":false,"prevItem":{"title":"Automatically Count Articles in Docusaurus Sidebar","permalink":"/en/blog/customized-docusaurus-sidebars-auto-count"},"nextItem":{"title":"Discrepancy in LayerNorm Calculations?","permalink":"/en/blog/torch-layernorm-mismatch"}},"content":"Docusaurus is a static site generator developed by Meta, designed for building open-source documentation websites.\\n\\nIt provides a simple way to create and maintain websites, supporting custom themes and plugins.\\n\\n\x3c!-- truncate --\x3e\\n\\nIf you\'re unfamiliar with Docusaurus, you can check it out here: [**Docusaurus Official Website**](https://docusaurus.io/)\\n\\nOur site is also built using Docusaurus, but after launching, we noticed that the default 404 page was quite basic.\\n\\nTo enhance user experience, we decided to create a custom 404 page.\\n\\n## References\\n\\nTo solve this issue, we first found a discussion page within the Docusaurus project:\\n\\n- [**How can I customize the 404 page?**](https://github.com/facebook/docusaurus/discussions/6030)\\n\\nBased on this discussion, we implemented the solution.\\n\\nHere\'s our step-by-step process.\\n\\n## Exporting the 404 Page Configuration\\n\\n:::warning\\nStarting from this step, we\u2019ll be modifying Docusaurus\' source code.\\n\\nIf there are destructive version updates in the future, these modifications may cause the website to malfunction. Please make sure you have the ability to maintain the website before proceeding.\\n:::\\n\\nIn Docusaurus, when a 404 error occurs, it redirects to the `NotFound` page of the `@docusaurus/theme-classic` theme.\\n\\nWe need to export this page\u2019s configuration by running the following command:\\n\\n```bash\\nnpm run swizzle @docusaurus/theme-classic NotFound\\n```\\n\\nDuring the process, select `JavaScript`, and then choose `--eject`. This will generate a `NotFound` directory under the `src/theme` folder.\\n\\nIf you\'re curious about the original code, you can find it here:\\n\\n- [**docusaurus-theme-classic/src/theme/NotFound**](https://github.com/facebook/docusaurus/tree/e8c6787ec20adc975dd6cd292a731d01206afe92/packages/docusaurus-theme-classic/src/theme/NotFound)\\n\\nInside the folder, you\'ll find an `index.js` file. Initially, we don\u2019t need to worry about this file. Instead, look inside the `Content` subfolder, where you\'ll find another `index.js` file. This is the one we\u2019ll be modifying.\\n\\nHere\u2019s the original code:\\n\\n```jsx\\n/**\\n * Copyright (c) Facebook, Inc. and its affiliates.\\n *\\n * This source code is licensed under the MIT license found in the\\n * LICENSE file in the root directory of this source tree.\\n */\\n\\nimport React from \\"react\\";\\nimport clsx from \\"clsx\\";\\nimport Translate from \\"@docusaurus/Translate\\";\\nimport type { Props } from \\"@theme/NotFound/Content\\";\\nimport Heading from \\"@theme/Heading\\";\\n\\nexport default function NotFoundContent({ className }: Props): JSX.Element {\\n  return (\\n    <main className={clsx(\\"container margin-vert--xl\\", className)}>\\n      <div className=\\"row\\">\\n        <div className=\\"col col--6 col--offset-3\\">\\n          <Heading as=\\"h1\\" className=\\"hero__title\\">\\n            <Translate\\n              id=\\"theme.NotFound.title\\"\\n              description=\\"The title of the 404 page\\"\\n            >\\n              Page Not Found\\n            </Translate>\\n          </Heading>\\n          <p>\\n            <Translate\\n              id=\\"theme.NotFound.p1\\"\\n              description=\\"The first paragraph of the 404 page\\"\\n            >\\n              We could not find what you were looking for.\\n            </Translate>\\n          </p>\\n          <p>\\n            <Translate\\n              id=\\"theme.NotFound.p2\\"\\n              description=\\"The 2nd paragraph of the 404 page\\"\\n            >\\n              Please contact the owner of the site that linked you to the\\n              original URL and let them know their link is broken.\\n            </Translate>\\n          </p>\\n        </div>\\n      </div>\\n    </main>\\n  );\\n}\\n```\\n\\n## Start Modifying\\n\\nWe want to add a few features:\\n\\n1. A cute icon.\\n2. A countdown timer that automatically redirects to the homepage.\\n3. Custom text to provide more information to the reader.\\n\\n### Countdown Timer\\n\\nFirst, we\u2019ll add a countdown timer using `useEffect`.\\n\\n```jsx\\nimport React, { useEffect, useState } from \\"react\\";\\n\\nconst [countdown, setCountdown] = useState(15);\\n\\nuseEffect(() => {\\n  const timer = setInterval(() => {\\n    setCountdown((prevCountdown) =>\\n      prevCountdown > 0 ? prevCountdown - 1 : 0\\n    );\\n  }, 1000);\\n\\n  if (countdown === 0) {\\n    window.location.href = \\"/\\";\\n  }\\n\\n  return () => clearInterval(timer);\\n}, [countdown]);\\n```\\n\\nThis will automatically redirect to the homepage once the countdown reaches zero.\\n\\n### Adding an Icon\\n\\nWe found a cute icon on a free icon website:\\n\\n- [**Freepik**](https://www.freepik.com/icons/error)\\n\\nAfter downloading it, we placed it in the `static/img` directory and referenced it in `index.js`.\\n\\n```jsx\\n<img\\n  src=\\"/img/error-icon.png\\"\\n  alt=\\"Error icon\\"\\n  style={{\\n    width: \\"150px\\",\\n    height: \\"150px\\",\\n    marginBottom: \\"20px\\",\\n    animation: \\"bounce 1s infinite\\",\\n  }}\\n/>\\n\\n<style>{`\\n    @keyframes bounce {\\n    0%, 100% {\\n        transform: translateY(0);\\n    }\\n    50% {\\n        transform: translateY(-10px);\\n    }\\n    }\\n`}</style>\\n```\\n\\nThis `<img>` tag displays an error icon, with some additional styling to make it bounce:\\n\\n- `src=\\"/img/error-icon.png\\"`: The image source, pointing to a local file.\\n- `alt=\\"Error icon\\"`: Alternative text, displayed if the image can\u2019t load.\\n- The `style` attribute defines the icon\'s size and adds a bounce animation.\\n\\n### Custom Text\\n\\nThe default 404 page looks something like this:\\n\\n<div style={{ textAlign: \'center\' }}>\\n<iframe\\n  src=\\"https://docusaurus.io/non-exist\\"\\n  width=\\"80%\\"\\n  height=\\"500px\\"\\n  center=\\"true\\"\\n></iframe>\\n</div>\\n\\n---\\n\\nWe updated it with the following text:\\n\\n```jsx\\n<p style={{ fontSize: \'1.2rem\', marginBottom: \'20px\' }}>\\nSorry, we couldn\'t find the page you were looking for.\\n</p>\\n<p style={{ fontSize: \'1.2rem\', marginBottom: \'20px\' }}>\\nIt\u2019s possible that the site structure has changed, and you might have clicked an outdated link.\\n</p>\\n<p style={{ fontSize: \'1.2rem\', marginBottom: \'20px\' }}>\\nPlease use the navigation bar above to find the information you\'re looking for.\\n</p>\\n```\\n\\nSince we frequently update our site, some paths may be outdated in Google\u2019s index, causing users to land on the wrong page.\\n\\nWe use this opportunity to inform users that:\\n\\n- The page they\u2019re looking for likely still exists, but has been moved!\\n\\nWe hope that with this message, users can navigate the site and find what they need.\\n\\n---\\n\\nFeel free to customize this section to suit your needs.\\n\\n### Final Result\\n\\nHere\u2019s what our final 404 page looks like:\\n\\n<br /><br />\\n\\n<div className=\\"row\\" style={{\\n    display: \'flex\',\\n    justifyContent: \'center\',\\n    alignItems: \'center\',\\n    flexDirection: \'column\',\\n    textAlign: \'center\',\\n    animation: \'fadeIn 0.5s ease-in-out\',\\n  }}>\\n\\n<img\\nsrc=\\"/img/error-icon.png\\"\\nalt=\\"Error icon\\"\\nstyle={{\\n      width: \'150px\',\\n      height: \'150px\',\\n      marginBottom: \'20px\',\\n      animation: \'bounce 1s infinite\',\\n    }}\\n/>\\n\\n  <div>\\n    <p style={{ fontSize: \'1.2rem\', marginBottom: \'20px\' }}>\\n      \u5F88\u62B1\u6B49\uFF0C\u6211\u5011\u7121\u6CD5\u627E\u5230\u60A8\u8981\u7684\u9801\u9762\u3002\\n    </p>\\n    <p style={{ fontSize: \'1.2rem\', marginBottom: \'20px\' }}>\\n      \u7DB2\u9801\u7D50\u69CB\u5DF2\u7D93\u4FEE\u6539\u4E86\uFF0C\u800C\u60A8\u53EF\u80FD\u9078\u5230\u904E\u6642\u7684\u9023\u7D50\u3002\\n    </p>\\n    <p style={{ fontSize: \'1.2rem\', marginBottom: \'20px\' }}>\\n      \u8ACB\u9EDE\u64CA\u4E0A\u65B9\u5C0E\u822A\u6B04\uFF0C\u6216\u8A31\u53EF\u4EE5\u627E\u5230\u60A8\u8981\u7684\u8CC7\u8A0A\u3002\\n    </p>\\n  </div>\\n\\n  <style>{`\\n    @keyframes fadeIn {\\n      from { opacity: 0; }\\n      to { opacity: 1; }\\n    }\\n    @keyframes bounce {\\n      0%, 100% {\\n        transform: translateY(0);\\n      }\\n      50% {\\n        transform: translateY(-10px);\\n      }\\n    }\\n  `}</style>\\n\\n</div>\\n\\n### Full Code\\n\\nFinally, here is the complete code:\\n\\n```jsx title=\'src/theme/NotFound/Content/index.js\'\\nimport Translate from \\"@docusaurus/Translate\\";\\nimport Heading from \\"@theme/Heading\\";\\nimport clsx from \\"clsx\\";\\nimport React, { useEffect, useState } from \\"react\\";\\n\\nexport default function NotFoundContent({ className }) {\\n  const [countdown, setCountdown] = useState(15);\\n\\n  useEffect(() => {\\n    const timer = setInterval(() => {\\n      setCountdown((prevCountdown) =>\\n        prevCountdown > 0 ? prevCountdown - 1 : 0\\n      );\\n    }, 1000);\\n\\n    if (countdown === 0) {\\n      window.location.href = \\"/\\";\\n    }\\n\\n    return () => clearInterval(timer);\\n  }, [countdown]);\\n\\n  return (\\n    <main className={clsx(\\"container margin-vert--xl\\", className)}>\\n      <div\\n        className=\\"row\\"\\n        style={{\\n          display: \\"flex\\",\\n          justifyContent: \\"center\\",\\n          alignItems: \\"center\\",\\n          flexDirection: \\"column\\",\\n          textAlign: \\"center\\",\\n          animation: \\"fadeIn 0.5s ease-in-out\\",\\n        }}\\n      >\\n        <img\\n          src=\\"/img/error-icon.png\\"\\n          alt=\\"Error icon\\"\\n          style={{\\n            width: \\"150px\\",\\n            height: \\"150px\\",\\n            marginBottom: \\"20px\\",\\n            animation: \\"bounce 1s infinite\\",\\n          }}\\n        />\\n\\n        <div>\\n          <Heading as=\\"h1\\" className=\\"hero__title\\">\\n            <Translate\\n              id=\\"theme.NotFound.title\\"\\n              description=\\"The title of the 404 page\\"\\n            >\\n              Page Not Found\\n            </Translate>\\n          </Heading>\\n          <p style={{ fontSize: \\"1.2rem\\", marginBottom: \\"20px\\" }}>\\n            Sorry, we couldn\'t find the page you were looking for.\\n          </p>\\n          <p style={{ fontSize: \\"1.2rem\\", marginBottom: \\"20px\\" }}>\\n            It\u2019s possible that the site structure has changed, and you might\\n            have clicked an outdated link.\\n          </p>\\n          <p style={{ fontSize: \\"1.2rem\\", marginBottom: \\"20px\\" }}>\\n            Please use the navigation bar above to find the information you\'re\\n            looking for.\\n          </p>\\n          <p aria-live=\\"polite\\" style={{ fontSize: \\"1rem\\", color: \\"#555\\" }}>\\n            {countdown > 0\\n              ? `Redirecting to the homepage in ${countdown} seconds...`\\n              : \\"Redirecting...\\"}\\n          </p>\\n        </div>\\n\\n        <style>{`\\n          @keyframes fadeIn {\\n            from { opacity: 0; }\\n            to { opacity: 1; }\\n          }\\n          @keyframes bounce {\\n            0%, 100% {\\n              transform: translateY(0);\\n            }\\n            50% {\\n              transform: translateY(-10px);\\n            }\\n          }\\n        `}</style>\\n      </div>\\n    </main>\\n  );\\n}\\n```"},{"id":"torch-layernorm-mismatch","metadata":{"permalink":"/en/blog/torch-layernorm-mismatch","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/08-20-torch-layernorm-mismatch/index.md","title":"Discrepancy in LayerNorm Calculations?","description":"Curious about the numbers? Let\'s calculate and compare.","date":"2024-08-20T00:00:00.000Z","tags":[{"inline":true,"label":"PyTorch","permalink":"/en/blog/tags/py-torch"},{"inline":true,"label":"LayerNorm","permalink":"/en/blog/tags/layer-norm"}],"readingTime":3.255,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"torch-layernorm-mismatch","title":"Discrepancy in LayerNorm Calculations?","authors":"Zephyr","image":"/en/img/2024/0820.webp","tags":["PyTorch","LayerNorm"],"description":"Curious about the numbers? Let\'s calculate and compare."},"unlisted":false,"prevItem":{"title":"Customizing the Docusaurus 404 Page","permalink":"/en/blog/customized-docusaurus-404-page"},"nextItem":{"title":"NIST & FRVT","permalink":"/en/blog/nist-and-frvt"}},"content":"Today, I decided to manually calculate the values of LayerNorm.\\n\\n\x3c!-- truncate --\x3e\\n\\nWe all know that the formula for LayerNorm is as follows:\\n\\n$$\\n\\\\text{LayerNorm}(x) = \\\\frac{x - \\\\mu}{\\\\sqrt{\\\\text{Var[}x\\\\text{]} + \\\\epsilon}} \\\\times \\\\gamma + \\\\beta\\n$$\\n\\nWhere $\\\\mu$ is the mean of $x$, and $\\\\text{Var}$ is the variance of $x$.\\n\\nWith this information, let\'s calculate it ourselves, ignoring $\\\\gamma$ and $\\\\beta$ for simplicity:\\n\\n```python\\nimport torch\\n\\nx = torch.rand(16, 768)\\nmu = x.mean(dim=-1, keepdim=True)\\nvar = x.var(dim=-1, keepdim=True)\\neps = 1e-5\\ny = (x - mu) / (var + eps).sqrt()\\n```\\n\\nThis yields the following values:\\n\\n```python\\n# tensor([[ 0.1219, -0.0222, -1.4742,  ...,  0.1738, -0.6124, -0.3001],\\n#         [-1.6009, -1.5814,  1.5357,  ...,  0.1917,  1.3787, -0.2772],\\n#         [ 0.3738,  1.0520,  0.4403,  ...,  1.1353, -0.7488, -0.9137],\\n#         ...,\\n#         [ 0.8823, -1.5427,  0.4725,  ..., -1.2544, -1.5354, -0.4305],\\n#         [ 1.4548,  0.3059, -0.6732,  ..., -0.7109,  0.4908, -1.2447],\\n#         [-0.4067,  0.5974, -0.9113,  ..., -0.2511, -0.2279, -0.9675]])\\n```\\n\\nNext, let\'s compare these results with PyTorch\'s `torch.nn.LayerNorm`:\\n\\n```python\\nlayer_norm = torch.nn.LayerNorm(768, elementwise_affine=False, bias=False)\\n\\ny_ln = layer_norm(x)\\n```\\n\\nThis yields:\\n\\n```python\\n# tensor([[ 0.1220, -0.0222, -1.4752,  ...,  0.1739, -0.6128, -0.3003],\\n#         [-1.6020, -1.5824,  1.5367,  ...,  0.1918,  1.3796, -0.2774],\\n#         [ 0.3741,  1.0527,  0.4406,  ...,  1.1360, -0.7493, -0.9143],\\n#         ...,\\n#         [ 0.8829, -1.5437,  0.4728,  ..., -1.2552, -1.5364, -0.4308],\\n#         [ 1.4557,  0.3061, -0.6736,  ..., -0.7113,  0.4911, -1.2455],\\n#         [-0.4069,  0.5978, -0.9119,  ..., -0.2513, -0.2281, -0.9681]])\\n```\\n\\nWhen we compare the two, why are they different?\\n\\n## Unbiased Estimation\\n\\nAfter a quick search, I found that `torch.var` has a parameter called `correction`, which defaults to `1`, meaning it uses an unbiased estimate.\\n\\nThis means that it divides by `N-1` instead of `N`, whereas `torch.nn.LayerNorm` uses `N`.\\n\\nSo let\'s modify the `torch.var` function by setting `correction=0`:\\n\\n```python\\nvar = x.var(dim=-1, correction=0, keepdim=True)\\n```\\n\\n:::tip\\n`correction` is an alias for `unbiased`, introduced in PyTorch 2.0.0.\\n\\nIn earlier versions, you would set it using `unbiased=False`:\\n\\n```python\\nvar = x.var(dim=-1, unbiased=False, keepdim=True)\\n```\\n\\n:::\\n\\nNow, let\'s compare the results again:\\n\\n```python\\n# tensor([[ 0.1220, -0.0222, -1.4752,  ...,  0.1739, -0.6128, -0.3003],\\n#         [-1.6020, -1.5824,  1.5367,  ...,  0.1918,  1.3796, -0.2774],\\n#         [ 0.3741,  1.0527,  0.4406,  ...,  1.1360, -0.7493, -0.9143],\\n#         ...,\\n#         [ 0.8829, -1.5437,  0.4728,  ..., -1.2552, -1.5364, -0.4308],\\n#         [ 1.4557,  0.3061, -0.6736,  ..., -0.7113,  0.4911, -1.2455],\\n#         [-0.4069,  0.5978, -0.9119,  ..., -0.2513, -0.2281, -0.9681]])\\n```\\n\\nNow the numbers match perfectly!\\n\\n## Why Doesn\'t LayerNorm Use Unbiased Estimation?\\n\\nTo summarize briefly, it\'s about stability and simplification of calculations.\\n\\nIf you\'re interested in a deeper dive, here are some key points:\\n\\n- **Stability in Small Batch Calculations**\\n\\n  LayerNorm is typically applied to the features of individual samples (e.g., each neuron or feature) rather than across the entire batch. The number of features per sample is usually much larger than the number of samples. Thus, using population variance provides a more stable and accurate estimate, especially with small sample sizes.\\n\\n- **Reduced Importance of Unbiased Estimation**\\n\\n  The unbiased nature of sample variance (i.e., dividing by n-1 instead of n) is crucial when estimating population parameters from a sample. However, in deep learning regularization and normalization, like in LayerNorm, the impact of this bias is relatively minor. This is because these computations are used to normalize activations rather than to estimate overall statistics. Using population variance simplifies calculations with minimal effect on training outcomes.\\n\\n- **Stability in Gradient Calculations**\\n\\n  Stable gradients are vital during backpropagation. Using population variance leads to smoother and more stable gradient calculations, avoiding additional noise that might arise from small sample sizes. This contributes to better convergence and training performance.\\n\\n- **Simplified Calculations**\\n\\n  From a computational perspective, calculating population variance is slightly simpler than sample variance because it omits a subtraction operation (i.e., dividing by n rather than n-1). While this isn\'t a decisive factor, it\'s a consideration in the design process.\\n\\n## Conclusion\\n\\nThis article was inspired by a sudden curiosity.\\n\\nI hope this explanation helps clarify the issue for you."},{"id":"nist-and-frvt","metadata":{"permalink":"/en/blog/nist-and-frvt","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/06-23-nist-and-frvt/index.md","title":"NIST & FRVT","description":"A brief introduction to NIST and FRVT.","date":"2024-06-23T00:00:00.000Z","tags":[{"inline":true,"label":"NIST","permalink":"/en/blog/tags/nist"},{"inline":true,"label":"FRVT","permalink":"/en/blog/tags/frvt"}],"readingTime":2.575,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"nist-and-frvt","title":"NIST & FRVT","authors":"Zephyr","image":"/en/img/2024/0623.webp","tags":["NIST","FRVT"],"description":"A brief introduction to NIST and FRVT."},"unlisted":false,"prevItem":{"title":"Discrepancy in LayerNorm Calculations?","permalink":"/en/blog/torch-layernorm-mismatch"},"nextItem":{"title":"Get All Stock Code Information from TWSE","permalink":"/en/blog/get-taiwan-all-stocks-info"}},"content":"The National Institute of Standards and Technology (NIST) was founded in 1901 and is part of the United States Department of Commerce.\\n\\n- [**FRVT Official**](https://www.nist.gov/)\\n\\nAs a non-profit organization, NIST\'s mission is to advance U.S. innovation and competitiveness in science and technology through the development of standards, scientific research, and technology development, thereby promoting economic security and enhancing the quality of life.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Core Missions and Values of NIST\\n\\nNIST\'s core missions include:\\n\\n- **Measurement Science**: Providing world-class measurement standards that support scientific research, business activities, and public safety.\\n- **Rigorous Traceability**: Establishing and maintaining a comprehensive system of measurement standards to ensure international traceability and accuracy of measurement results.\\n- **Standardization and Application**: Promoting the development and implementation of technical standards, particularly in information technology, environmental science, and manufacturing.\\n\\nNIST\'s core values emphasize perseverance, integrity, inclusivity, and excellence, which are foundational to its current and future work.\\n\\n## FRVT Program\\n\\nThe Face Recognition Vendor Test (FRVT) program is a key initiative by NIST.\\n\\nIts primary goal is to evaluate the performance of facial recognition technologies globally, providing an objective and impartial testing platform.\\n\\nFRVT encompasses various testing scenarios, including static image recognition and real-time recognition in dynamic environments, thereby helping users and developers comprehensively understand the performance of these technologies in practical applications.\\n\\n## Importance and Impact of the FRVT Program\\n\\nThe FRVT program significantly influences government agencies, businesses, and other organizations in selecting and deploying facial recognition systems by providing scientifically rigorous testing methods and objective performance assessment data.\\n\\nThese test results not only help determine which technologies best suit specific security needs and operational environments but also foster innovation and advancement in the field of facial recognition technology.\\n\\n## Participation in the FRVT Program\\n\\nParticipation in the FRVT program involves several steps:\\n\\n1. **Submission of Participation Agreement**: Developers need to submit a detailed participation agreement to NIST, indicating compliance with all FRVT regulations and standards.\\n2. **Software Packaging and API Integration**: Participants must encapsulate their algorithms behind the C++ API provided by NIST to ensure compatibility and functionality of the algorithms.\\n3. **Execution of Verification Suites**: Developers need to run their software through verification suites provided by NIST to ensure that the algorithm outputs submitted can be accurately reproduced by NIST.\\n4. **Encryption and Data Submission**: All algorithm submissions must be encrypted, correctly signed, and transmitted securely to NIST to ensure data security and integrity.\\n\\n## FRTE Program and Its Projects\\n\\nThe FRVT program has been split and renamed into Face Recognition Technology Evaluation (FRTE) and Face Analysis Technology Evaluation (FATE).\\n\\nThe FRTE includes several subprojects:\\n\\n- 1:1 Verification\\n- 1:N Identification\\n- Demographic Effects\\n- Face Mask Effects\\n- Paperless Travel\\n- Twins Demonstration\\n\\n## Conclusion\\n\\nAs a key driver of global standardization and innovation in facial recognition technology, NIST continues to support technological advancements through its FRVT and FRTE programs, ensuring that these advancements not only serve public interests but also meet the needs of business and security.\\n\\nThese initiatives not only enhance the accuracy and reliability of technologies but also promote sustained development across related industries."},{"id":"get-taiwan-all-stocks-info","metadata":{"permalink":"/en/blog/get-taiwan-all-stocks-info","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/06-10-get-taiwan-all-stocks-info/index.md","title":"Get All Stock Code Information from TWSE","description":"Get information on all stocks listed on TWSE using Python.","date":"2024-06-10T00:00:00.000Z","tags":[{"inline":true,"label":"beautifulsoup4","permalink":"/en/blog/tags/beautifulsoup-4"},{"inline":true,"label":"TWSE","permalink":"/en/blog/tags/twse"}],"readingTime":2.565,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"get-taiwan-all-stocks-info","title":"Get All Stock Code Information from TWSE","authors":"Zephyr","image":"/en/img/2024/0610.webp","tags":["beautifulsoup4","TWSE"],"description":"Get information on all stocks listed on TWSE using Python."},"unlisted":false,"prevItem":{"title":"NIST & FRVT","permalink":"/en/blog/nist-and-frvt"},"nextItem":{"title":"Simple Configuration of Python Environment on Win11","permalink":"/en/blog/windows-python-settings"}},"content":"The stock codes in the Taiwanese market change periodically, making manual tracking impractical.\\n\\nIt\'s time to automate!\\n\\n\x3c!-- truncate --\x3e\\n\\n## Setup Environment\\n\\nLet\'s tackle the challenge by writing a program. First, install the necessary packages:\\n\\n```bash\\npip install requests beautifulsoup4 json\\n```\\n\\n:::tip\\nAssuming you have a functional Python environment.\\n:::\\n\\n## Target Webpages\\n\\nStock-related data resides on the website of the Taiwan Stock Exchange (TWSE). Let\'s identify the target pages:\\n\\n- [**Taiwan Stock Exchange/Securities Code Announcement**](https://www.twse.com.tw/en/products/code/announcement.html)\\n\\n    <div align=\\"center\\">\\n    <figure style={{\\"width\\": \\"80%\\"}}>\\n    ![TWSE](./img/img1.jpg)\\n    </figure>\\n    </div>\\n\\nNote down these three URLs:\\n\\n```python\\nurls = [\\n    \\"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\\", # Listed securities\\n    \\"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\\", # OTC securities\\n    \\"https://isin.twse.com.tw/isin/C_public.jsp?strMode=5\\"  # Emerging stocks\\n]\\n```\\n\\n## Parsing the Webpage\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"80%\\"}}>\\n![stock_table](./img/img2.jpg)\\n</figure>\\n</div>\\n\\nUpon inspecting the webpage, we identify that the main table corresponds to the HTML tag `class=h4`.\\n\\nNow that we\'ve located our target, let\'s start coding:\\n\\n```python title=\\"update_stocks_code.py\\"\\nimport json\\nimport requests\\nfrom bs4 import BeautifulSoup\\n\\n# Retrieve content from Taiwan Stock Exchange announcements\\nurls = [\\n    \\"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\\", # Listed securities\\n    \\"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\\", # OTC securities\\n    \\"https://isin.twse.com.tw/isin/C_public.jsp?strMode=5\\"  # Emerging stocks\\n]\\n\\n# All data infos\\ndata = {}\\n\\ntotal_urls = len(urls)\\nfor index, url in enumerate(urls, start=1):\\n    print(f\\"Processing URL {index}/{total_urls}: {url}\\")\\n\\n    response = requests.get(url)\\n    response.encoding = \'big5\'  # Set the correct encoding\\n\\n    # Parse HTML using BeautifulSoup\\n    soup = BeautifulSoup(response.text, \'html.parser\')\\n    table = soup.find(\'table\', {\'class\': \'h4\'})\\n\\n    if not table:\\n        print(f\\"Table not found for URL: {url}\\")\\n        continue\\n\\n    for row in table.find_all(\'tr\')[1:]:  # Skip header row\\n        cells = row.find_all(\'td\')\\n        if len(cells) != 7:\\n            continue\\n\\n        code, name = cells[0].text.split(\\"\\\\u3000\\")\\n        internationality = cells[1].text\\n        list_date = cells[2].text\\n        market_type = cells[3].text\\n        industry_type = cells[4].text\\n\\n        data[code] = {\\n            \\"Name\\": name,\\n            \\"Code\\": code,\\n            \\"Market Type\\": market_type,\\n            \\"Industry Type\\": industry_type,\\n            \\"Listing Date\\": list_date,\\n            \\"International Code\\": internationality\\n        }\\n\\nwith open(\\"stock_infos.json\\", \\"w\\", encoding=\\"utf-8\\") as f:\\n    json.dump(data, f, ensure_ascii=False, indent=2)\\n\\nprint(\\"All data has been processed and saved to stock_infos.json\\")\\n```\\n\\n## Output Results\\n\\n```json title=\\"stock_infos.json\\"\\n{\\n  \\"1101\\": {\\n    \\"Name\\": \\"Taiwan Cement\\",\\n    \\"Code\\": \\"1101\\",\\n    \\"Market Type\\": \\"Listed\\",\\n    \\"Industry Type\\": \\"Cement Industry\\",\\n    \\"Listing Date\\": \\"1962/02/09\\",\\n    \\"International Code\\": \\"TW0001101004\\"\\n  },\\n  \\"1102\\": {\\n    \\"Name\\": \\"Asia Cement\\",\\n    \\"Code\\": \\"1102\\",\\n    \\"Market Type\\": \\"Listed\\",\\n    \\"Industry Type\\": \\"Cement Industry\\",\\n    \\"Listing Date\\": \\"1962/06/08\\",\\n    \\"International Code\\": \\"TW0001102002\\"\\n  },\\n  ...omitting the rest...\\n}\\n```\\n\\nWe output the result as a JSON file for convenient integration with other programs.\\n\\n## FAQs\\n\\n### I only want ordinary stocks.\\n\\nI assume you mean stocks with \\"four-digit\\" codes, excluding ETFs, warrants, etc. To achieve this, simply add a filtering condition in the program:\\n\\n```python\\nif len(code) != 4:\\n    continue\\n```\\n\\n### I only want specific industries.\\n\\nThis requirement can be extended to specific market types, industry types, listing dates, or even the previous \\"ordinary stocks\\" question. We just need to load the output JSON file into Pandas and filter with conditions:\\n\\n```python\\nimport pandas as pd\\n\\ndf = pd.read_json(\\"stock_infos.json\\", orient=\\"index\\")\\ntarget = df[df[\\"Industry Type\\"] == \\"Cement Industry\\"]\\n```\\n\\n### The program is broken.\\n\\nThat could be due to changes in the TWSE website\'s layout, causing the HTML structure to alter. We\'ll need to adjust the code accordingly.\\n\\n## Conclusion\\n\\nBy periodically running this program, we can obtain the latest stock information."},{"id":"windows-python-settings","metadata":{"permalink":"/en/blog/windows-python-settings","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/06-05-windows-python-settings/index.md","title":"Simple Configuration of Python Environment on Win11","description":"Setting up Python on Windows.","date":"2024-06-05T00:00:00.000Z","tags":[{"inline":true,"label":"win11","permalink":"/en/blog/tags/win-11"},{"inline":true,"label":"python","permalink":"/en/blog/tags/python"}],"readingTime":5.305,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"windows-python-settings","title":"Simple Configuration of Python Environment on Win11","authors":"Zephyr","image":"/en/img/2024/0605.webp","tags":["win11","python"],"description":"Setting up Python on Windows."},"unlisted":false,"prevItem":{"title":"Get All Stock Code Information from TWSE","permalink":"/en/blog/get-taiwan-all-stocks-info"},"nextItem":{"title":"LaTeX Syntax Quick Reference","permalink":"/en/blog/latex-usage"}},"content":"We recently received a task that required development on a Windows-based system.\\n\\nIt\'s been a long time! It\'s been several years since we last used Windows.\\n\\n\x3c!-- truncate --\x3e\\n\\nWe tried a few methods and finally settled on using PowerShell to set up the Python environment.\\n\\nWe initially thought about using WSL for configuration, but that would turn the environment into a Linux environment... (?)\\n\\nIf we already have a Linux environment at hand, why bother configuring one on Windows?\\n\\n## Operating Environment\\n\\nWe\'re using the virtual environment tool provided by Mac: [**Parallels Desktop**](https://www.parallels.com/products/desktop/).\\n\\nWith Parallels Desktop, we can smoothly run a Windows system on Mac, and the currently installed one is Windows 11.\\n\\n:::tip\\nThe Apple M1 chip is ARM-based, and it faced many compatibility issues when it was first launched, but it has improved a lot over the years.\\n:::\\n\\n## Installing Chocolatey\\n\\nFirst, we need to launch PowerShell.\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"70%\\"}}>\\n![PowerShell](./img/img1.jpg)\\n</figure>\\n</div>\\n\\nChocolatey is a package manager for Windows. It automates the process of installing, upgrading, and managing software using NuGet and PowerShell technologies. It\'s similar to `apt-get` or `yum` on Linux, allowing Windows users to manage software in a simple and consistent way.\\n\\nInstalling Chocolatey is relatively simple. Just run the following command in PowerShell with administrative privileges:\\n\\n```powershell\\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\'https://community.chocolatey.org/install.ps1\'))\\n```\\n\\nAfter installation, enter the following command to verify if Chocolatey was installed successfully:\\n\\n```powershell\\nchoco -v\\n```\\n\\nIf you see the version number of Chocolatey, it means the installation was successful.\\n\\n:::tip\\nHere\'s what the above command does:\\n\\n1. **Set-ExecutionPolicy Bypass -Scope Process -Force**:\\n\\n   - This command sets the PowerShell execution policy.\\n   - `Set-ExecutionPolicy` is used to change the execution policy to allow or disallow the execution of PowerShell scripts.\\n   - `Bypass` means bypassing all execution policies without any restrictions.\\n   - `-Scope Process` means applying this change only to the current PowerShell session, not affecting the entire system.\\n   - `-Force` is used to forcefully execute this operation without prompting for confirmation.\\n\\n2. **[System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072**:\\n\\n   - This command sets the network security protocol.\\n   - `[System.Net.ServicePointManager]::SecurityProtocol` is used to get or set the protocol type.\\n   - `-bor 3072` adds the TLS 1.2 (3072) protocol to the existing protocols. `-bor` is a bitwise operator, indicating a bitwise OR operation, allowing multiple protocols to be enabled simultaneously.\\n\\n3. **iex ((New-Object System.Net.WebClient).DownloadString(\'https://community.chocolatey.org/install.ps1\'))**:\\n   - This command downloads and executes the Chocolatey installation script.\\n   - `iex` is shorthand for `Invoke-Expression`, used to execute the content passed to it as a string.\\n   - `New-Object System.Net.WebClient` is used to create a new WebClient object, which is used for downloading data.\\n   - `.DownloadString(\'https://community.chocolatey.org/install.ps1\')` is used to download the script content from the specified URL.\\n   - Overall, the command `iex ((New-Object System.Net.WebClient).DownloadString(\'https://community.chocolatey.org/install.ps1\'))` downloads and immediately executes the PowerShell script located at \'https://community.chocolatey.org/install.ps1\', which is responsible for installing Chocolatey.\\n\\nIn simple terms, the purpose of this command is: temporarily set the PowerShell execution policy to allow script execution, configure the network security protocol to support TLS 1.2, and then download and execute the Chocolatey installation script.\\n:::\\n\\n:::info\\n**Common Chocolatey Commands:**\\n\\n- **Install**\\n  ```powershell\\n  choco install <packageName>\\n  ```\\n- **Upgrade**\\n  ```powershell\\n  choco upgrade <packageName>\\n  ```\\n- **List installed packages**\\n  ```powershell\\n  choco list --localonly\\n  ```\\n- **Uninstall**\\n  ```powershell\\n  choco uninstall <packageName>\\n  ```\\n  :::\\n\\n## Installing git\\n\\nAfter installation, continue running PowerShell as an administrator, and execute the following command to install Git:\\n\\n```powershell\\nchoco install git -y\\n```\\n\\nAfter installation, enter the following command to verify if Git was installed successfully:\\n\\n```powershell\\ngit --version\\n# >>> git version 2.45.2.windows.1\\n```\\n\\n## Installing Python\\n\\nWe use pyenv to manage Python versions.\\n\\n:::tip\\nAlthough there are many choices on the market, such as Anaconda, Miniconda, WinPython, etc., we still chose pyenv.\\n\\nBecause we often develop on Linux, seeing pyenv feels familiar.\\n:::\\n\\nInstalling and using `pyenv` on Windows is not usually straightforward because `pyenv` is designed for Unix-like environments. However, you can use the `pyenv-win` project, which is a Windows port of `pyenv`.\\n\\nFollow these steps:\\n\\n### Step 1: Installing `pyenv-win`\\n\\n- [**Reference: pyenv-win/docs/installation.md**](https://github.com/pyenv-win/pyenv-win/blob/master/docs/installation.md)\\n\\nDownload the `pyenv-win` project:\\n\\n```powershell\\nInvoke-WebRequest -UseBasicParsing -Uri \\"https://raw.githubusercontent.com/pyenv-win/pyenv-win/master/pyenv-win/install-pyenv-win.ps1\\" -OutFile \\"./install-pyenv-win.ps1\\"; &\\"./install-pyenv-win.ps1\\"\\n```\\n\\nIf you encounter any `UnauthorizedAccess` errors as shown below, please launch Windows PowerShell with the \\"Run as Administrator\\" option and execute:\\n\\n```powershell\\nSet-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope LocalMachine\\n```\\n\\nAfter completion, rerun the installation command above.\\n\\n### Step 2: Verify Installation\\n\\n1. **Restart PowerShell**:\\n\\n   - Close and reopen the PowerShell window to apply the environment variable changes.\\n\\n2. **Check `pyenv` installation**:\\n\\n   - Enter the following command to check the `pyenv` version:\\n\\n     ```powershell\\n     pyenv --version\\n     ```\\n\\n### Step 3: Use `pyenv` to install Python versions\\n\\n1. **View available Python versions**:\\n\\n   - List all available Python versions with the following command:\\n\\n     ```powershell\\n     pyenv install --list\\n     ```\\n\\n2. **Install a specific Python version**:\\n\\n- For example, to install Python 3.10.11:\\n\\n  ```powershell\\n  pyenv install 3.10.11\\n  ```\\n\\n3. **Set a global Python version**:\\n\\n   - This step is not necessary, but if you want to use the same Python version across all shells, you can set the installed Python version as the global default:\\n\\n     ```powershell\\n     pyenv global 3.10.11\\n     ```\\n\\n4. **Verify Python installation**:\\n\\n   - Enter the following command to verify if Python was installed successfully:\\n\\n     ```powershell\\n     python --version\\n     ```\\n\\n## Installing VS Code\\n\\nFinally, we install Visual Studio Code as our development tool.\\n\\nHere, we\'ll go to the [**VS Code official website**](https://code.visualstudio.com/Download) to download the installer and then proceed with the installation.\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"70%\\"}}>\\n![VS Code](./img/img2.jpg)\\n</figure>\\n</div>\\n\\nAfter installation, we want to be able to use the `code` command directly in PowerShell to open VS Code.\\n\\nSo, we need to add the installation path of VS Code to the environment variables. Copy the following path:\\n\\n```powershell\\nC:\\\\Users\\\\your_user_name\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin\\n```\\n\\n:::tip\\nRemember to replace `your_user_name` with your username.\\n:::\\n\\n## Side Note\\n\\nActually, we find the PowerShell display screen really hard to look at.\\n\\nFor this part, we suggest using [**oh-my-posh**](https://ohmyposh.dev/) to beautify the appearance of PowerShell.\\n\\nBut this part is not the focus of this article. Interested readers can check out:\\n\\n- [**Tutorial - Customize Your Prompt with Oh My Posh for PowerShell or WSL**](https://learn.microsoft.com/en-us/windows/terminal/tutorials/custom-prompt-setup)\\n\\n## Conclusion\\n\\nThrough PowerShell, we can quickly set up the Python environment and install development tools.\\n\\nOf course, the above only covers the most basic configurations, leaving this article as a reference."},{"id":"latex-usage","metadata":{"permalink":"/en/blog/latex-usage","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/06-04-latex-usage/index.md","title":"LaTeX Syntax Quick Reference","description":"Quick reference guide for LaTeX syntax","date":"2024-06-04T00:00:00.000Z","tags":[{"inline":true,"label":"LaTeX","permalink":"/en/blog/tags/la-te-x"},{"inline":true,"label":"Math","permalink":"/en/blog/tags/math"}],"readingTime":4.625,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"latex-usage","title":"LaTeX Syntax Quick Reference","authors":"Zephyr","image":"/en/img/2024/0604.webp","tags":["LaTeX","Math"],"description":"Quick reference guide for LaTeX syntax"},"unlisted":false,"prevItem":{"title":"Simple Configuration of Python Environment on Win11","permalink":"/en/blog/windows-python-settings"},"nextItem":{"title":"Implementing ANLS","permalink":"/en/blog/impl-normalized-levenshtein-similarity"}},"content":"Every time you need it, it\'s always a hassle to find, so we decided to write a LaTeX syntax quick reference table.\\n\\n\x3c!-- truncate --\x3e\\n\\n| **Category**           | **Description**          |                   **Syntax**                   |                  **Display**                  |\\n| ---------------------- | ------------------------ | :--------------------------------------------: | :-------------------------------------------: |\\n| **Text Styles**        | Bold                     |                 `\\\\textbf{AB}`                  |                 $\\\\textbf{AB}$                 |\\n|                        | Italic                   |                 `\\\\textit{AB}`                  |                 $\\\\textit{AB}$                 |\\n|                        | Underline                |                `\\\\underline{AB}`                |               $\\\\underline{AB}$                |\\n|                        | Overline                 |                `\\\\overline{AB}`                 |                $\\\\overline{AB}$                |\\n|                        | Typewriter Font          |                 `\\\\texttt{AB}`                  |                 $\\\\texttt{AB}$                 |\\n| **Math Structures**    | Fraction                 |                 `\\\\frac{A}{B}`                  |                 $\\\\frac{A}{B}$                 |\\n|                        | Fraction (Display)       |                 `\\\\dfrac{a}{b}`                 |                $\\\\dfrac{a}{b}$                 |\\n|                        | Fraction (Inline)        |                 `\\\\tfrac{a}{b}`                 |                $\\\\tfrac{a}{b}$                 |\\n|                        | Old-Style Fraction       |                 `{A \\\\over B}`                  |                 $\\\\frac{A}{B}$                 |\\n|                        | Binomial Coeff.          |                 `\\\\binom{n}{k}`                 |                $\\\\binom{n}{k}$                 |\\n|                        | Old-Style Binomial       |                `{n \\\\choose k}`                 |                $\\\\binom{n}{k}$                 |\\n|                        | Square Root              |                   `\\\\sqrt{x}`                   |                  $\\\\sqrt{x}$                   |\\n|                        | n-th Root                |                 `\\\\sqrt[n]{x}`                  |                 $\\\\sqrt[n]{x}$                 |\\n|                        | Exponent                 |                     `a^b`                      |                     $a^b$                     |\\n|                        | Subscript                |                     `a_b`                      |                     $a_b$                     |\\n|                        | Integral                 |          `\\\\int_a^b x^2 \\\\mathrm{d} x`           |          $\\\\int_a^b x^2 \\\\mathrm{d} x$          |\\n|                        | Summation                |        `\\\\sum_{n=1}^\\\\infty \\\\frac{1}{n}`         |        $\\\\sum_{n=1}^\\\\infty \\\\frac{1}{n}$        |\\n|                        | Limit                    |       `\\\\lim_{x \\\\to \\\\infty} \\\\frac{1}{x}`        |       $\\\\lim_{x \\\\to \\\\infty} \\\\frac{1}{x}$       |\\n|                        | Product                  |               `\\\\prod_{i=1}^n i`                |               $\\\\prod_{i=1}^n i$               |\\n| **Math Symbols**       | Sine                     |                 `\\\\sin{\\\\theta}`                 |                $\\\\sin{\\\\theta}$                 |\\n|                        | Cosine                   |                 `\\\\cos{\\\\theta}`                 |                $\\\\cos{\\\\theta}$                 |\\n|                        | Plus-Minus               |                     `\\\\pm`                      |                     $\\\\pm$                     |\\n|                        | Multiplication           |                    `\\\\times`                    |                   $\\\\times$                    |\\n|                        | Division                 |                     `\\\\div`                     |                    $\\\\div$                     |\\n|                        | Subset Equal             |                  `\\\\subseteq`                   |                  $\\\\subseteq$                  |\\n|                        | Superset Equal           |                  `\\\\supseteq`                   |                  $\\\\supseteq`                  |\\n|                        | Implies                  |                   `\\\\implies`                   |                  $\\\\implies$                   |\\n|                        | Implied By               |                  `\\\\impliedby`                  |                 $\\\\impliedby$                  |\\n|                        | If and Only If           |                     `\\\\iff`                     |                    $\\\\iff$                     |\\n|                        | Intersection             |                     `\\\\cap`                     |                    $\\\\cap$                     |\\n|                        | Union                    |                     `\\\\cup`                     |                    $\\\\cup$                     |\\n|                        | Logical And              |                    `\\\\land`                     |                    $\\\\land$                    |\\n|                        | Logical Or               |                     `\\\\lor`                     |                    $\\\\lor$                     |\\n|                        | Logical Not              |                     `\\\\neg`                     |                    $\\\\neg$                     |\\n|                        | Not Equal To             |                     `\\\\neq`                     |                    $\\\\neq$                     |\\n|                        | Approximately Equal      |                   `\\\\approx`                    |                   $\\\\approx$                   |\\n| **Greek Letters**      | Lowercase \u03B1              |                    `\\\\alpha`                    |                   $\\\\alpha$                    |\\n|                        | Uppercase \u0391              |                    `\\\\Alpha`                    |                   $\\\\Alpha$                    |\\n|                        | Lowercase \u03B2              |                    `\\\\beta`                     |                    $\\\\beta$                    |\\n|                        | Uppercase \u0392              |                    `\\\\Beta`                     |                    $\\\\Beta$                    |\\n|                        | Lowercase \u03B3              |                    `\\\\gamma`                    |                   $\\\\gamma$                    |\\n|                        | Uppercase \u0393              |                    `\\\\Gamma`                    |                   $\\\\Gamma$                    |\\n|                        | Lowercase \u03B4              |                    `\\\\delta`                    |                   $\\\\delta$                    |\\n|                        | Uppercase \u0394              |                    `\\\\Delta`                    |                   $\\\\Delta$                    |\\n|                        | Lowercase \u03B5              |                   `\\\\epsilon`                   |                  $\\\\epsilon$                   |\\n|                        | Uppercase \u0395              |                   `\\\\Epsilon`                   |                  $\\\\Epsilon$                   |\\n|                        | Variant Lowercase \u03C6      |                   `\\\\varphi`                    |                   $\\\\varphi$                   |\\n|                        | Uppercase \u03A6              |                     `\\\\Phi`                     |                    $\\\\Phi$                     |\\n|                        | Lowercase \u03C7              |                     `\\\\chi`                     |                    $\\\\chi$                     |\\n|                        | Uppercase \u03A7              |                     `\\\\Chi`                     |                    $\\\\Chi$                     |\\n|                        | Lowercase \u03BC              |                     `\\\\mu`                      |                     $\\\\mu$                     |\\n|                        | Uppercase \u039C              |                     `\\\\Mu`                      |                     $\\\\Mu$                     |\\n|                        | Lowercase \u03C9              |                    `\\\\omega`                    |                   $\\\\omega$                    |\\n|                        | Uppercase \u03A9              |                    `\\\\Omega`                    |                   $\\\\Omega$                    |\\n| **Matrices & Vectors** | Matrix (with brackets)   | `\\\\begin{pmatrix} a & b \\\\\\\\ c & d \\\\end{pmatrix}` | $\\\\begin{pmatrix} a & b\\\\\\\\ c & d \\\\end{pmatrix}$ |\\n|                        | Matrix (no brackets)     |  `\\\\begin{matrix} x & y \\\\\\\\ z & w \\\\end{matrix}`  | $\\\\begin{matrix} x & y \\\\\\\\ z & w \\\\end{matrix}$  |\\n|                        | Vector                   |                   `\\\\vec{v}`                    |                   $\\\\vec{v}$                   |\\n|                        | Identity Matrix          |                  `\\\\mathbf{I}`                  |                 $\\\\mathbf{I}$                  |\\n|                        | Zero Matrix              |                  `\\\\mathbf{0}`                  |                 $\\\\mathbf{0}$                  |\\n| **Miscellaneous**      | Angle                    |                    `\\\\angle`                    |                   $\\\\angle$                    |\\n|                        | Triangle                 |                  `\\\\triangle`                   |                  $\\\\triangle$                  |\\n|                        | Square                   |                   `\\\\square`                    |                   $\\\\square$                   |\\n|                        | Space                    |                    `\\\\quad`                     |                    $\\\\quad$                    |\\n|                        | Proportional To          |                   `\\\\propto`                    |                   $\\\\propto$                   |\\n|                        | Because                  |                   `\\\\because`                   |                  $\\\\because$                   |\\n|                        | Therefore                |                  `\\\\therefore`                  |                 $\\\\therefore$                  |\\n|                        | Integer Set              |                  `\\\\mathbb{Z}`                  |                 $\\\\mathbb{Z}$                  |\\n|                        | Probability Set          |                  `\\\\mathbb{P}`                  |                 $\\\\mathbb{P}$                  |\\n|                        | Real Number Set          |                  `\\\\mathbb{R}`                  |                 $\\\\mathbb{R}$                  |\\n|                        | Complex Number Set       |                  `\\\\mathbb{C}`                  |                 $\\\\mathbb{C}$                  |\\n|                        | Imaginary Part           |                     `\\\\Im`                      |                     $\\\\Im$                     |\\n|                        | Real Part                |                     `\\\\Re`                      |                     $\\\\Re`                     |\\n|                        | Empty Set                |                  `\\\\emptyset`                   |                  $\\\\emptyset$                  |\\n|                        | Fancy Empty Set          |                 `\\\\varnothing`                  |                 $\\\\varnothing$                 |\\n|                        | Element Of               |                     `\\\\in`                      |                     $\\\\in$                     |\\n|                        | Not Element Of           |                   `\\\\not\\\\in`                    |                   $\\\\not\\\\in$                   |\\n|                        | Counterclockwise Arrow   |               `\\\\circlearrowleft`               |              $\\\\circlearrowleft$               |\\n|                        | Clockwise Arrow          |              `\\\\circlearrowright`               |              $\\\\circlearrowright$              |\\n|                        | Planck\'s Constant        |                    `\\\\hbar`                     |                    $\\\\hbar$                    |\\n|                        | Natural Log              |                     `\\\\ln`                      |                     $\\\\ln$                     |\\n|                        | Constant $\\\\pi$           |                     `\\\\pi`                      |                     $\\\\pi$                     |\\n| **Formatting**         | Function Color           |         `f(x) = a{\\\\color{red}{x}} + b`         |        $f(x) = a{\\\\color{red}{x}} + b$         |\\n|                        | Color Box                |        `\\\\colorbox{#eeeeee}{Color Box}`         |        $\\\\colorbox{#eeeeee}{Color Box}$        |\\n|                        | Calligraphic Font        |            `{\\\\cal ABCDE12345abced}`            |           ${\\\\cal ABCDE12345abced}$            |\\n|                        | Framed Text              |              `\\\\fbox{boxed text}`               |              $\\\\fbox{boxed text}$              |\\n|                        | Boxed Display Style Text |             `\\\\boxed{boxed\\\\ text}`              |             $\\\\boxed{boxed\\\\ text}$             |\\n|                        | Fraktur Font             |           `{\\\\frak ABCDE12345abcde}`            |           ${\\\\frak ABCDE12345abcde}$           |\\n|                        | Italic Font              |        `{\\\\it abefg12345}\\\\ abcdefg12345`        |       ${\\\\it abefg12345}\\\\ abcdefg12345$        |\\n|                        | Minimum                  |               `\\\\min\\\\limits_{n}`                |               $\\\\min\\\\limits_{n}$               |\\n|                        | Bold Greek Letter        |             `\\\\boldsymbol{\\\\alpha}`              |             $\\\\boldsymbol{\\\\alpha}$             |"},{"id":"impl-normalized-levenshtein-similarity","metadata":{"permalink":"/en/blog/impl-normalized-levenshtein-similarity","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/05-16-impl-normalized-levenshtein-similarity/index.md","title":"Implementing ANLS","description":"Average Normalized Levenshtein Similarity","date":"2024-05-16T00:00:00.000Z","tags":[{"inline":true,"label":"pytorch","permalink":"/en/blog/tags/pytorch"},{"inline":true,"label":"anls","permalink":"/en/blog/tags/anls"}],"readingTime":5.72,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"impl-normalized-levenshtein-similarity","title":"Implementing ANLS","authors":"Zephyr","image":"/en/img/2024/0516.webp","tags":["pytorch","anls"],"description":"Average Normalized Levenshtein Similarity"},"unlisted":false,"prevItem":{"title":"LaTeX Syntax Quick Reference","permalink":"/en/blog/latex-usage"},"nextItem":{"title":"Equivalent Basic Commands between Python and JS","permalink":"/en/blog/python-js-basic-command-equivalents"}},"content":"Average Normalized Levenshtein Similarity, abbreviated as ANLS, is a metric used to compute the similarity between two strings.\\n\\n\x3c!-- truncate --\x3e\\n\\nIn natural language processing (NLP), it\'s often necessary to compare the similarity of two strings.\\n\\nLevenshtein Similarity is a common measure that assesses the \\"edit distance\\" between two strings, which is the minimum number of single-character edits (insertions, deletions, or substitutions) required to change one string into the other. However, Levenshtein Similarity itself isn\'t intuitive as it depends on the lengths of the strings.\\n\\nTo address this issue, we can normalize Levenshtein Similarity to the [0, 1] range, making it easier to understand and compare the similarity between different strings, known as Normalized Levenshtein Similarity (NLS).\\n\\nAs NLS refers to the similarity between sets of strings, we can further extend it to ANLS, which computes the average similarity among multiple sets of strings, thereby quantifying the performance of a model.\\n\\nAnd then...\\n\\nWe always struggle to find implementations, so we decided to write one ourself.\\n\\n## References\\n\\n- [**torchmetrics.text.EditDistance**](https://lightning.ai/docs/torchmetrics/stable/text/edit.html)\\n\\n## Import Necessary Libraries\\n\\nFirst, we need to import some necessary libraries, especially the `EditDistance` implemented by `torchmetrics`:\\n\\n```python\\nfrom typing import Any, Literal, Optional, Sequence, Union\\n\\nimport torch\\nfrom torch import Tensor\\nfrom torchmetrics.metric import Metric\\nfrom torchmetrics.text import EditDistance\\nfrom torchmetrics.utilities.data import dim_zero_cat\\n```\\n\\nSince `EditDistance` can already compute the Levenshtein distance, we can directly use it to calculate the edit distance between two strings. However, `EditDistance` doesn\'t provide normalization functionality, so we need to implement this part ourselves.\\n\\n## Implement Normalization Functionality\\n\\nHere, we inherit the interface of `torchmetrics.metric.Metric`, so we need to implement the `update` and `compute` methods:\\n\\n```python\\nclass NormalizedLevenshteinSimilarity(Metric):\\n\\n    def __init__(\\n        self,\\n        substitution_cost: int = 1,\\n        reduction: Optional[Literal[\\"mean\\", \\"sum\\", \\"none\\"]] = \\"mean\\",\\n        **kwargs: Any\\n    ) -> None:\\n        super().__init__(**kwargs)\\n        self.edit_distance = EditDistance(\\n            substitution_cost=substitution_cost,\\n            reduction=None  # Set to None to get distances for all string pairs\\n        )\\n\\n        # ...\\n```\\n\\nHere are a few key points:\\n\\n1. Ensure that the input `preds` and `target` are lists of strings, otherwise the function will calculate on a character level.\\n2. Calculate the maximum length of each string, so that we can perform normalization.\\n\\n```python\\ndef update(self, preds: Union[str, Sequence[str]], target: Union[str, Sequence[str]]) -> None:\\n    \\"\\"\\"Update state with predictions and targets.\\"\\"\\"\\n\\n    if isinstance(preds, str):\\n        preds = [preds]\\n    if isinstance(target, str):\\n        target = [target]\\n\\n    distances = self.edit_distance(preds, target)\\n    max_lengths = torch.tensor([\\n        max(len(p), len(t))\\n        for p, t in zip(preds, target)\\n    ], dtype=torch.float)\\n\\n    ratio = torch.where(\\n        max_lengths == 0,\\n        torch.zeros_like(distances).float(),\\n        distances.float() / max_lengths\\n    )\\n\\n    nls_values = 1 - ratio\\n\\n    # ...\\n```\\n\\n## Implement the `reduction` Parameter\\n\\nWe also need to accommodate the `reduction` parameter, where if we specify `mean`, it will be the common ANLS score.\\n\\nIn addition to the usual `mean`, we can also use `sum` or `none` to fulfill different needs.\\n\\n```python\\ndef _compute(\\n    self,\\n    nls_score: Tensor,\\n    num_elements: Union[Tensor, int],\\n) -> Tensor:\\n    \\"\\"\\"Compute the ANLS over state.\\"\\"\\"\\n    if nls_score.numel() == 0:\\n        return torch.tensor(0, dtype=torch.int32)\\n    if self.reduction == \\"mean\\":\\n        return nls_score.sum() / num_elements\\n    if self.reduction == \\"sum\\":\\n        return nls_score.sum()\\n    if self.reduction is None or self.reduction == \\"none\\":\\n        return nls_score\\n\\ndef compute(self) -> torch.Tensor:\\n    \\"\\"\\"Compute the NLS over state.\\"\\"\\"\\n    if self.reduction == \\"none\\" or self.reduction is None:\\n        return self._compute(dim_zero_cat(self.nls_values_list), 1)\\n    return self._compute(self.nls_score, self.num_elements)\\n```\\n\\nHere, it\'s noteworthy that when we specify `reduction` as `none`, we need to return all NLS values instead of computing the average. In this case, I referenced the implementation of `torchmetrics.text.EditDistance`, using `dim_zero_cat` to concatenate values in the list together, ensuring that the return value is a `Tensor`.\\n\\n## Implementation\\n\\nThe complete implementation is as follows:\\n\\n```python\\nfrom typing import Any, Literal, Optional, Sequence, Union\\n\\nimport torch\\nfrom torch import Tensor\\nfrom torchmetrics.metric import Metric\\nfrom torchmetrics.text import EditDistance\\nfrom torchmetrics.utilities.data import dim_zero_cat\\n\\n\\nclass NormalizedLevenshteinSimilarity(Metric):\\n    \\"\\"\\"\\n    Normalized Levenshtein Similarity (NLS) is a metric that computes the\\n    normalized Levenshtein similarity between two sequences.\\n    This metric is calculated as 1 - (levenshtein_distance / max_length),\\n    where `levenshtein_distance` is the Levenshtein distance between the two\\n    sequences and `max_length` is the maximum length of the two sequences.\\n\\n    NLS aims to provide a similarity measure for character sequences\\n    (such as text), making it useful in areas like text similarity analysis,\\n    Optical Character Recognition (OCR), and Natural Language Processing (NLP).\\n\\n    This class inherits from `Metric` and uses the `EditDistance` class to\\n    compute the Levenshtein distance.\\n\\n    Inputs to the ``update`` and ``compute`` methods are as follows:\\n\\n    - ``preds`` (:class:`~Union[str, Sequence[str]]`):\\n        Predicted text sequences or a collection of sequences.\\n    - ``target`` (:class:`~Union[str, Sequence[str]]`):\\n        Target text sequences or a collection of sequences.\\n\\n    Output from the ``compute`` method is as follows:\\n\\n    - ``nls`` (:class:`~torch.Tensor`): A tensor containing the NLS value.\\n        Returns 0.0 when there are no samples; otherwise, it returns the NLS.\\n\\n    Args:\\n        substitution_cost:\\n            The cost of substituting one character for another. Default is 1.\\n        reduction:\\n            Method to aggregate metric scores.\\n            Default is \'mean\', options are \'sum\' or None.\\n\\n            - ``\'mean\'``: takes the mean over samples, which is ANLS.\\n            - ``\'sum\'``: takes the sum over samples\\n            - ``None`` or ``\'none\'``: returns the score per sample\\n\\n        kwargs: Additional keyword arguments.\\n\\n    Example::\\n        Multiple strings example:\\n\\n        >>> metric = NormalizedLevenshteinSimilarity(reduction=None)\\n        >>> preds = [\\"rain\\", \\"lnaguaeg\\"]\\n        >>> target = [\\"shine\\", \\"language\\"]\\n        >>> metric(preds, target)\\n        tensor([0.4000, 0.5000])\\n        >>> metric = NormalizedLevenshteinSimilarity(reduction=\\"mean\\")\\n        >>> metric(preds, target)\\n        tensor(0.4500)\\n    \\"\\"\\"\\n\\n    def __init__(\\n        self,\\n        substitution_cost: int = 1,\\n        reduction: Optional[Literal[\\"mean\\", \\"sum\\", \\"none\\"]] = \\"mean\\",\\n        **kwargs: Any\\n    ) -> None:\\n        super().__init__(**kwargs)\\n        self.edit_distance = EditDistance(\\n            substitution_cost=substitution_cost,\\n            reduction=None  # Set to None to get distances for all string pairs\\n        )\\n\\n        allowed_reduction = (None, \\"mean\\", \\"sum\\", \\"none\\")\\n        if reduction not in allowed_reduction:\\n            raise ValueError(\\n                f\\"Expected argument `reduction` to be one of {allowed_reduction}, but got {reduction}\\")\\n        self.reduction = reduction\\n\\n        if self.reduction == \\"none\\" or self.reduction is None:\\n            self.add_state(\\n                \\"nls_values_list\\",\\n                default=[],\\n                dist_reduce_fx=\\"cat\\"\\n            )\\n        else:\\n            self.add_state(\\n                \\"nls_score\\",\\n                default=torch.tensor(0.0),\\n                dist_reduce_fx=\\"sum\\"\\n            )\\n            self.add_state(\\n                \\"num_elements\\",\\n                default=torch.tensor(0),\\n                dist_reduce_fx=\\"sum\\"\\n            )\\n\\n    def update(self, preds: Union[str, Sequence[str]], target: Union[str, Sequence[str]]) -> None:\\n        \\"\\"\\"Update state with predictions and targets.\\"\\"\\"\\n        if isinstance(preds, str):\\n            preds = [preds]\\n        if isinstance(target, str):\\n            target = [target]\\n\\n        distances = self.edit_distance(preds, target)\\n        max_lengths = torch.tensor([\\n            max(len(p), len(t))\\n            for p, t in zip(preds, target)\\n        ], dtype=torch.float)\\n\\n        ratio = torch.where(\\n            max_lengths == 0,\\n            torch.zeros_like(distances).float(),\\n            distances.float() / max_lengths\\n        )\\n\\n        nls_values = 1 - ratio\\n\\n        if self.reduction == \\"none\\" or self.reduction is None:\\n            self.nls_values_list.append(nls_values)\\n        else:\\n            self.nls_score += nls_values.sum()\\n            self.num_elements += nls_values.shape[0]\\n\\n    def _compute(\\n        self,\\n        nls_score: Tensor,\\n        num_elements: Union[Tensor, int],\\n    ) -> Tensor:\\n        \\"\\"\\"Compute the ANLS over state.\\"\\"\\"\\n        if nls_score.numel() == 0:\\n            return torch.tensor(0, dtype=torch.int32)\\n        if self.reduction == \\"mean\\":\\n            return nls_score.sum() / num_elements\\n        if self.reduction == \\"sum\\":\\n            return nls_score.sum()\\n        if self.reduction is None or self.reduction == \\"none\\":\\n            return nls_score\\n\\n    def compute(self) -> torch.Tensor:\\n        \\"\\"\\"Compute the NLS over state.\\"\\"\\"\\n        if self.reduction == \\"none\\" or self.reduction is None:\\n            return self._compute(dim_zero_cat(self.nls_values_list), 1)\\n        return self._compute(self.nls_score, self.num_elements)\\n\\n\\nif __name__ == \\"__main__\\":\\n    anls = NormalizedLevenshteinSimilarity(reduction=\'mean\')\\n    preds = [\\"rain\\", \\"lnaguaeg\\"]\\n    target = [\\"shine\\", \\"language\\"]\\n    print(anls(preds, target))\\n```\\n\\n## At Last\\n\\nCan we guarantee that this implementation is correct?\\n\\nThe answer is no. If you find any issues, please let us know. Thank you very much!"},{"id":"python-js-basic-command-equivalents","metadata":{"permalink":"/en/blog/python-js-basic-command-equivalents","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/04-07-cmd-js-vs-python/index.md","title":"Equivalent Basic Commands between Python and JS","description":"Mapping basic cmds between Py and JS.","date":"2024-04-07T00:00:00.000Z","tags":[{"inline":true,"label":"npm","permalink":"/en/blog/tags/npm"},{"inline":true,"label":"pip","permalink":"/en/blog/tags/pip"}],"readingTime":2.715,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"python-js-basic-command-equivalents","title":"Equivalent Basic Commands between Python and JS","authors":"Zephyr","image":"/en/img/2024/0407.webp","tags":["npm","pip"],"description":"Mapping basic cmds between Py and JS."},"unlisted":false,"prevItem":{"title":"Implementing ANLS","permalink":"/en/blog/impl-normalized-levenshtein-similarity"},"nextItem":{"title":"Common VSCode Configuration Settings","permalink":"/en/blog/vscode-settings"}},"content":"As engineers, we are destined to keep learning new technologies.\\n\\nWhile we are more accustomed to Python, we discovered some similar commands when starting to learn JavaScript, such as `npm`, `npx`, and `nvm`.\\n\\nSo we tried to map these commands, hoping it might ease the transition into new skills.\\n\\n\x3c!-- truncate --\x3e\\n\\nI\'m interested in aligning these commands, hoping it might ease the transition into new skills.\\n\\n## npm vs. pip\\n\\n:::tip\\n**They are both: Package Managers**\\n:::\\n\\nnpm (Node Package Manager) and pip essentially serve the same purpose: they are package managers for Node.js and Python respectively. Package managers are crucial for sharing, reusing, and managing repositories or modules.\\n\\n- **Installing Packages**: In npm, we use the `npm install <package-name>` command to add a library to our project. Similarly, pip achieves the same goal through `pip install <package-name>`.\\n- **Version Control**: npm tracks package versions through the `package.json` file, ensuring that every member of a development team uses the same version of a library. Pip relies on `requirements.txt` or newer tools like pipenv and poetry to achieve similar functionality.\\n- **Package Publishing**: npm enables developers to publish their packages to the npm registry for use by the global Node.js community. Pip provides this capability through PyPI (Python Package Index), allowing the sharing of Python packages.\\n\\n## npx vs. -m Flag\\n\\n:::tip\\n**They are both: Tools for Direct Command Execution**\\n:::\\n\\nnpx (npm package runner) and Python\'s `-m` flag address the need to execute package commands directly in the terminal without global installation.\\n\\n- **Direct Execution**: npx allows you to directly execute any package installed in the project\'s local `node_modules` folder (or fetch it from the npm registry if not installed), while Python achieves similar results through the `-m` flag, allowing direct execution of modules, such as starting a simple HTTP server with `python -m http.server`.\\n\\n:::note\\n**npm run vs. npx run**\\n\\n- npm run: In JavaScript projects, npm run is used to execute scripts defined in the package.json file. This is a common approach to perform project-specific tasks like testing, building, or deploying.\\n- npx run: While npx is typically used to execute single commands or packages, it primarily serves to execute packages not globally installed. npx run is not a standard command; common usage of npx doesn\'t include the keyword \\"run\\" but directly follows with the package name or command.\\n  :::\\n\\n## nvm, pyenv, and conda\\n\\n:::tip\\n**They are all: Version Management Tools**\\n:::\\n\\nSwitching between different versions of Node.js or Python can be cumbersome without proper tools. nvm (Node Version Manager), pyenv, and conda provide solutions to this problem, allowing developers to install and switch between multiple versions of Node.js or Python on the same machine.\\n\\n- **Version Switching**: nvm uses commands like `nvm use <version>` to switch Node.js versions. Pyenv and conda offer similar functionalities for Python; pyenv switches versions through `pyenv global <version>` or `pyenv local <version>`, while conda uses `conda activate <environment-name>` to switch to different environments, each capable of having different Python versions and packages.\\n- **Multi-Version Management**: These tools facilitate managing multiple versions on the same machine, addressing potential conflicts due to version discrepancies.\\n\\n## Conclusion\\n\\nWhile these commands may not align perfectly, they do share some similarities, hopefully making the transition a bit smoother."},{"id":"vscode-settings","metadata":{"permalink":"/en/blog/vscode-settings","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/03-31-vscode-settings/index.md","title":"Common VSCode Configuration Settings","description":"VSCode settings for future reference.","date":"2024-03-31T00:00:00.000Z","tags":[{"inline":true,"label":"vscode","permalink":"/en/blog/tags/vscode"},{"inline":true,"label":"settings","permalink":"/en/blog/tags/settings"}],"readingTime":2.68,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"vscode-settings","title":"Common VSCode Configuration Settings","authors":"Zephyr","tags":["vscode","settings"],"image":"/en/img/2024/0331.webp","description":"VSCode settings for future reference."},"unlisted":false,"prevItem":{"title":"Equivalent Basic Commands between Python and JS","permalink":"/en/blog/python-js-basic-command-equivalents"},"nextItem":{"title":"Setting Up Nextcloud Guide","permalink":"/en/blog/setting-up-nextcloud"}},"content":"A while ago, due to unknown reasons, the VSCode configuration file disappeared, and we had to reconfigure it, which took us some time.\\n\\nIt also provided an opportunity to review our own configuration files and record some commonly used configuration files.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Configuration Settings\\n\\n```json\\n{\\n  \\"editor.fontFamily\\": \\"Fira Code, MesloLGS NF\\",\\n  \\"editor.fontLigatures\\": true,\\n  \\"files.associations\\": {\\n    \\"Dockerfile_base\\": \\"dockerfile\\"\\n  },\\n  \\"markdown.preview.fontSize\\": 15,\\n  \\"debug.console.fontSize\\": 14,\\n  \\"explorer.confirmDragAndDrop\\": true,\\n  \\"editor.minimap.enabled\\": true,\\n  \\"editor.minimap.maxColumn\\": 80,\\n  \\"editor.smoothScrolling\\": true,\\n  \\"editor.rulers\\": [80, 120],\\n  \\"workbench.colorCustomizations\\": {\\n    \\"editorRuler.foreground\\": \\"#ff4081\\",\\n    \\"minimap.background\\": \\"#00000050\\",\\n    \\"editor.background\\": \\"#1e1e1e\\",\\n    \\"editor.foreground\\": \\"#d4d4d4\\"\\n  },\\n  \\"terminal.integrated.fontFamily\\": \\"Fira Code, MesloLGS NF\\",\\n  \\"files.trimTrailingWhitespace\\": true,\\n  \\"files.trimFinalNewlines\\": true,\\n  \\"diffEditor.ignoreTrimWhitespace\\": true,\\n  \\"python.terminal.activateEnvironment\\": true,\\n  \\"git.ignoreLegacyWarning\\": true,\\n  \\"git.autofetch\\": true,\\n  \\"editor.largeFileOptimizations\\": false,\\n  \\"editor.mouseWheelZoom\\": true,\\n  \\"editor.codeActionsOnSave\\": {\\n    \\"source.organizeImports\\": true,\\n    \\"source.fixAll\\": true\\n  },\\n  \\"editor.formatOnSave\\": true,\\n  \\"workbench.editorAssociations\\": {\\n    \\"*.ipynb\\": \\"jupyter-notebook\\"\\n  },\\n  \\"debug.onTaskErrors\\": \\"abort\\",\\n  \\"explorer.confirmDelete\\": true,\\n  \\"terminal.integrated.copyOnSelection\\": true,\\n  \\"terminal.integrated.cursorBlinking\\": true,\\n  \\"terminal.integrated.cursorStyle\\": \\"line\\",\\n  \\"remote.downloadExtensionsLocally\\": true,\\n  \\"terminal.integrated.scrollback\\": 10000,\\n  \\"editor.cursorStyle\\": \\"line\\",\\n  \\"editor.insertSpaces\\": true,\\n  \\"editor.lineNumbers\\": \\"on\\",\\n  \\"editor.wordWrap\\": \\"on\\",\\n  \\"workbench.editor.wrapTabs\\": false,\\n  \\"files.watcherExclude\\": {\\n    \\"**/.git/objects/**\\": true,\\n    \\"**/.git/subtree-cache/**\\": true,\\n    \\"**/node_modules/*/**\\": true\\n  },\\n  \\"notebook.cellToolbarLocation\\": {\\n    \\"default\\": \\"right\\",\\n    \\"jupyter-notebook\\": \\"left\\"\\n  },\\n  \\"github.copilot.editor.enableAutoCompletions\\": true,\\n  \\"github.copilot.enable\\": {\\n    \\"*\\": true,\\n    \\"plaintext\\": false,\\n    \\"markdown\\": true,\\n    \\"scminput\\": false\\n  },\\n  \\"workbench.colorTheme\\": \\"Monokai Pro\\",\\n  \\"editor.multiCursorModifier\\": \\"ctrlCmd\\",\\n  \\"editor.wordWrapColumn\\": 120,\\n  \\"files.autoSave\\": \\"onFocusChange\\"\\n}\\n```\\n\\n## Parameter Descriptions\\n\\n- `editor.fontFamily`: Sets the font family; here, Fira Code and MesloLGS NF fonts are used.\\n- `editor.fontLigatures`: Sets whether ligatures in the font are enabled.\\n- `files.associations`: Sets file associations; here, Dockerfile_base is associated with dockerfile.\\n- `markdown.preview.fontSize`: Sets the font size for markdown preview.\\n- `debug.console.fontSize`: Sets the font size for the debug console.\\n- `explorer.confirmDragAndDrop`: Sets whether drag and drop confirmation is enabled.\\n- `editor.minimap.enabled`: Sets whether the minimap is enabled.\\n- `editor.minimap.maxColumn`: Sets the maximum number of columns in the minimap.\\n- `editor.smoothScrolling`: Sets whether smooth scrolling is enabled.\\n- `editor.rulers`: Sets the column numbers for indentation guides.\\n- `workbench.colorCustomizations`: Sets color customizations.\\n- `terminal.integrated.fontFamily`: Sets the terminal font family.\\n- `files.trimTrailingWhitespace`: Sets whether trailing whitespace is trimmed.\\n- `files.trimFinalNewlines`: Sets whether final newlines are trimmed.\\n- `diffEditor.ignoreTrimWhitespace`: Sets whether whitespace in diffs is ignored.\\n- `python.terminal.activateEnvironment`: Sets whether the Python environment is activated.\\n- `git.ignoreLegacyWarning`: Sets whether Git warnings are ignored.\\n- `git.autofetch`: Sets whether autofetch is enabled.\\n- `editor.largeFileOptimizations`: Sets whether optimizations for large files are enabled.\\n- `editor.mouseWheelZoom`: Sets whether mouse wheel zoom is enabled.\\n- `editor.codeActionsOnSave`: Sets code actions on save.\\n- `editor.formatOnSave`: Sets whether formatting is applied on save.\\n- `workbench.editorAssociations`: Sets editor associations.\\n- `debug.onTaskErrors`: Sets action on task errors.\\n- `explorer.confirmDelete`: Sets whether delete confirmation is enabled.\\n- `terminal.integrated.copyOnSelection`: Sets whether copying is done on selection.\\n- `terminal.integrated.cursorBlinking`: Sets terminal cursor blinking.\\n- `terminal.integrated.cursorStyle`: Sets terminal cursor style.\\n- `remote.downloadExtensionsLocally`: Sets whether extensions are downloaded locally.\\n- `terminal.integrated.scrollback`: Sets terminal scrollback buffer size.\\n- `editor.cursorStyle`: Sets cursor style.\\n- `editor.insertSpaces`: Sets whether spaces are inserted.\\n- `editor.lineNumbers`: Sets whether line numbers are displayed.\\n- `editor.wordWrap`: Sets whether word wrap is enabled.\\n- `workbench.editor.wrapTabs`: Sets whether tab wrapping is enabled.\\n- `files.watcherExclude`: Sets file watcher exclusion patterns.\\n- `notebook.cellToolbarLocation`: Sets notebook cell toolbar location.\\n- `github.copilot.editor.enableAutoCompletions`: Sets whether auto completions are enabled in GitHub Copilot.\\n- `github.copilot.enable`: Sets whether GitHub Copilot is enabled.\\n- `workbench.colorTheme`: Sets the color theme.\\n- `editor.multiCursorModifier`: Sets the multi-cursor modifier.\\n- `editor.wordWrapColumn`: Sets the column for word wrapping.\\n- `files.autoSave`: Sets auto-save behavior."},{"id":"setting-up-nextcloud","metadata":{"permalink":"/en/blog/setting-up-nextcloud","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/03-04-setup-nextcloud/index.md","title":"Setting Up Nextcloud Guide","description":"Setting up Nextcloud on Ubuntu 22.04.","date":"2024-03-04T00:00:00.000Z","tags":[{"inline":true,"label":"Nextcloud","permalink":"/en/blog/tags/nextcloud"},{"inline":true,"label":"Docker","permalink":"/en/blog/tags/docker"}],"readingTime":4.05,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"setting-up-nextcloud","title":"Setting Up Nextcloud Guide","authors":"Zephyr","tags":["Nextcloud","Docker"],"image":"/en/img/2024/0304.webp","description":"Setting up Nextcloud on Ubuntu 22.04."},"unlisted":false,"prevItem":{"title":"Common VSCode Configuration Settings","permalink":"/en/blog/vscode-settings"},"nextItem":{"title":"The Pitfall of Lists in PyTorch","permalink":"/en/blog/pytorch-training-out-of-memory"}},"content":"Previously, We used to store files on Google Drive and would download them using the wget command.\\n\\nHowever, one day, the download command suddenly stopped working.\\n\\nSo, We decided to give Nextcloud a try.\\n\\n\x3c!-- truncate --\x3e\\n\\nBelow, we\'ll go through the setup process based on Ubuntu 22.04.\\n\\n:::tip\\nBefore we begin, make sure you have a domain name ready and pointed to your server.\\n\\nIf you\'re unsure how to do this, simply Google search: \\"how to use namecheap\\".\\n:::\\n\\n## Installing Nextcloud\\n\\n**First Question: Why use Nextcloud?**\\n\\n- I wanted a private cloud where I could store files without relying on someone else\'s servers.\\n\\n**Second Question: What\'s the difference between Nextcloud and Owncloud?**\\n\\n- Nextcloud forked from Owncloud, offering similar functionalities, but Nextcloud\'s development pace is faster.\\n\\n**Third Question: How do you install Nextcloud?**\\n\\n- This is a bit complex because Nextcloud offers various installation methods, each with its pros and cons.\\n- In this article, I only recommend using Docker for installation.\\n\\n## Configuring Nextcloud All-in-One\\n\\n- Reference the official documentation: [**Nextcloud All-in-One**](https://github.com/nextcloud/all-in-one)\\n\\nFirst, ensure you\'ve installed Docker and Docker Compose.\\n\\n:::tip\\nIf not, Google search \\"Docker & Docker Compose installation\\".\\n:::\\n\\nNext, create a NextCloud folder and write a Docker Compose configuration file `docker-compose.yml`:\\n\\n```bash\\nmkdir nextcloud\\nvim nextcloud/docker-compose.yml\\n```\\n\\nPaste the following content into `docker-compose.yml`:\\n\\n```yaml\\nservices:\\n  nextcloud-aio-mastercontainer:\\n    image: nextcloud/all-in-one:latest\\n    init: true\\n    restart: always\\n    container_name: nextcloud-aio-mastercontainer\\n    volumes:\\n      - nextcloud_aio_mastercontainer:/mnt/docker-aio-config\\n      - /var/run/docker.sock:/var/run/docker.sock:ro\\n    ports:\\n      - 80:80\\n      - 8080:8080\\n      - 8443:8443\\nvolumes:\\n  nextcloud_aio_mastercontainer:\\n    name: nextcloud_aio_mastercontainer\\n```\\n\\nHere\'s a brief explanation of the commands:\\n\\n- `--init`: Ensures no zombie processes are created.\\n- `--name nextcloud-aio-mastercontainer`: Sets the container name, which shouldn\'t be changed to avoid update failures.\\n- `--restart always`: Sets the container\'s restart policy to always accompany the Docker daemon.\\n- `--publish 80:80`, `--publish 8080:8080`, `--publish 8443:8443`: Publishes container ports to host ports.\\n- `--volume nextcloud_aio_mastercontainer:/mnt/docker-aio-config`: Sets where the mastercontainer files are stored.\\n- `--volume /var/run/docker.sock:/var/run/docker.sock:ro`: Mounts Docker socket into the container.\\n\\nFor more detailed configurations, refer to the official documentation: [compose.yaml](https://github.com/nextcloud/all-in-one/blob/main/compose.yaml)\\n\\n## Configuring System Services\\n\\n```bash\\nsudo vim /etc/systemd/system/nextcloud.service\\n```\\n\\nPaste the following content:\\n\\n```bash {7}\\n[Unit]\\nDescription=NextCloud Docker Compose\\nRequires=docker.service\\nAfter=docker.service\\n\\n[Service]\\nWorkingDirectory=/home/[YourName]/nextcloud\\nExecStart=/usr/bin/docker compose up --remove-orphans\\nExecStop=/usr/bin/docker compose down\\nRestart=always\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nMake sure to replace `[YourName]` with your username.\\n\\n## Starting Nextcloud\\n\\n```bash\\nsudo systemctl enable nextcloud\\nsudo systemctl start nextcloud\\n```\\n\\n## Setting Up Nextcloud\\n\\n1. **Accessing Nextcloud AIO Interface**:\\n\\n   - After initial setup, access Nextcloud AIO interface via `https://ip.address.of.this.server:8080`, replacing `ip.address.of.this.server` with your server\'s IP address.\\n   - It\'s important to use the IP address instead of the domain name to avoid HTTP Strict Transport Security (HSTS) issues.\\n\\n2. **Using Self-Signed Certificates**:\\n\\n   - Accessing port 8080 might use a self-signed certificate, which browsers might flag as untrusted. You\'ll need to manually accept this certificate in your browser to proceed.\\n\\n3. **Automating Certificate Acquisition**:\\n\\n   - If your firewall or router has ports 80 and 8443 open or forwarded and you\'ve pointed a domain to your server, accessing `https://your-domain-that-points-to-this-server.tld:8443` will automatically fetch a trusted certificate from a CA, enhancing security and convenience.\\n\\n4. **Opening Ports for Nextcloud Talk**:\\n\\n   - To ensure Nextcloud Talk features like video calls and messages work, it\'s crucial to open ports 3478/TCP and 3478/UDP for the Talk container in your firewall or router. These ports are essential for handling NAT traversal, a technique allowing devices inside and outside a network to connect directly, crucial for real-time communication applications.\\n\\n- **Common Issues**:\\n\\n  - **Dynamic IP for Home Network**: If you have a dynamic IP, services like No-IP or obtaining a static IP from your ISP might be solutions.\\n  - **Alternative Installation Methods**: You can install Nextcloud directly, but be prepared to handle dependencies on your own.\\n  - **Can\'t Connect After Setup**: If your firewall isn\'t the issue, it might be your router blocking connections.\\n\\n---\\n\\nUpon entering the setup URL, you\'ll find yourself in what can be called an admin panel\'s admin panel.\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"60%\\"}}>\\n![login_1](./img/login_1.jpg)\\n</figure>\\n</div>\\n\\nAt this point, you might panic, realizing you don\'t have a password!\\n\\nTo retrieve the password, use the following command:\\n\\n```bash\\nsudo grep password /var/lib/docker/volumes/nextcloud_aio_mastercontainer/_data/data/configuration.json\\n```\\n\\nAfter logging in, you\'ll encounter a setup screen:\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"60%\\"}}>\\n![login_2](./img/login_2.jpg)\\n</figure>\\n</div>\\n\\nThis setup screen reflects my completed configuration. For your first login, enter your prepared domain. The system will prompt you to download additional docker images, which it will then automatically launch.\\n\\nOnce launched, you can start using Nextcloud.\\n\\n## Conclusion\\n\\nAfter completing the above steps, entering your domain in the address bar will lead you to a beautifully designed interface, your private cloud.\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"60%\\"}}>\\n![login_3](./img/login_3.jpg)\\n</figure>\\n</div>\\n\\nThis interface offers numerous functionalities for file management and sharing. Additionally, you can download the Nextcloud app on your mobile device for file management on-the-go.\\n\\nWith Nextcloud, you no longer need to worry about Google Drive\'s storage limitations."},{"id":"pytorch-training-out-of-memory","metadata":{"permalink":"/en/blog/pytorch-training-out-of-memory","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/02-20-pytorch-training-oom/index.md","title":"The Pitfall of Lists in PyTorch","description":"Resolving PyTorch OOM Issues.","date":"2024-02-20T00:00:00.000Z","tags":[{"inline":true,"label":"PyTorch","permalink":"/en/blog/tags/py-torch"},{"inline":true,"label":"OOM","permalink":"/en/blog/tags/oom"}],"readingTime":1.625,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"pytorch-training-out-of-memory","title":"The Pitfall of Lists in PyTorch","authors":"Zephyr","tags":["PyTorch","OOM"],"image":"/en/img/2024/0220.webp","description":"Resolving PyTorch OOM Issues."},"unlisted":false,"prevItem":{"title":"Setting Up Nextcloud Guide","permalink":"/en/blog/setting-up-nextcloud"},"nextItem":{"title":"Convert PDF to Images using Python","permalink":"/en/blog/convert-pdf-to-images"}},"content":"As a seasoned PyTorch user, you\'re likely well-versed in training models, hyperparameter tuning, and optimization techniques.\\n\\nHow could you possibly write code that runs out of memory (OOM)?\\n\\n\x3c!-- truncate --\x3e\\n\\n:::tip\\nWe\'re talking about system memory here, not GPU memory.\\n:::\\n\\n## Problem Description\\n\\nWith OOM issues stemming from various causes, this time we\'ll focus on one commonly encountered by professionals:\\n\\n- You might be using a List structure!\\n\\nAfter investigation, we\'ve pinpointed the exact scenario where leaks occur.\\n\\nConsider the following code snippet:\\n\\n```python\\nfrom torch.utils.data import Dataset, DataLoader\\nimport numpy as np\\nimport torch\\n\\n\\nclass DataIter(Dataset):\\n\\n    def __init__(self):\\n        self.data_np = np.array([x for x in range(10000000)])\\n        self.data = [x for x in range(10000000)]\\n\\n    def __len__(self):\\n        return len(self.data)\\n\\n    def __getitem__(self, idx):\\n        data = self.data[idx]\\n        data = np.array([data], dtype=np.int64)\\n        return torch.tensor(data)\\n\\n\\ntrain_data = DataIter()\\ntrain_loader = DataLoader(train_data, batch_size=300, num_workers=18)\\n\\nfor i, item in enumerate(train_loader):\\n    if i % 1000 == 0:\\n        print(i)\\n```\\n\\n---\\n\\nCutting to the chase after examining this example:\\n\\nSee the `self.data` List? That\'s what leads to the OOM problem.\\n\\nWe attempted to find related information and it seems this isn\'t a PyTorch issue but rather a Python one.\\n\\nIn essence, refrain from using Lists; use NumPy or Tensors to store data, and you won\'t encounter OOM problems.\\n\\nAt least, that\'s effective in this example.\\n\\n## What About Me?\\n\\nYou might be wondering: I\'ve written code like this, why haven\'t I encountered any issues?\\n\\n---\\n\\nThe world is a beautiful place until you encounter a large dataset.\\n\\nBased on my own testing, when the dataset is small, using Lists doesn\'t trigger memory leaks.\\n\\nMore specifically:\\n\\n- When we use over 10,000 data points, no issues arise!\\n- When we use over 1.2 million data points, it blows up!\\n\\nSo, if your dataset isn\'t large, you might never encounter this problem.\\n\\nAs for the threshold of data volume, we\'re unsure...\\n\\nWe speculate this anomaly arises at a certain point during Python or PyTorch interaction."},{"id":"convert-pdf-to-images","metadata":{"permalink":"/en/blog/convert-pdf-to-images","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/02-14-pdf2imgs/index.md","title":"Convert PDF to Images using Python","description":"Using open-source library pdf2image.","date":"2024-02-14T00:00:00.000Z","tags":[{"inline":true,"label":"Python","permalink":"/en/blog/tags/python"},{"inline":true,"label":"pdf2image","permalink":"/en/blog/tags/pdf-2-image"}],"readingTime":1.31,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"convert-pdf-to-images","title":"Convert PDF to Images using Python","authors":"Zephyr","tags":["Python","pdf2image"],"image":"/en/img/2024/0214.webp","description":"Using open-source library pdf2image."},"unlisted":false,"prevItem":{"title":"The Pitfall of Lists in PyTorch","permalink":"/en/blog/pytorch-training-out-of-memory"},"nextItem":{"title":"Reading HEIC Images in Python","permalink":"/en/blog/opencv-imread"}},"content":"We often need to convert PDF files into image formats.\\n\\nSo here, we recommend a handy Python module: [pdf2image](https://github.com/Belval/pdf2image/tree/master), which can convert PDF files into PIL images.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Install Dependencies\\n\\n`pdf2image` relies on `pdftoppm` and `pdftocairo`, and installation varies slightly across different operating systems:\\n\\n- **Mac**: Install Poppler via Homebrew: `brew install poppler`.\\n- **Linux**: Most Linux distributions come pre-installed with `pdftoppm` and `pdftocairo`. If not, install `poppler-utils` via your package manager.\\n- **Using `conda`**: Poppler can be installed via `conda` on any platform: `conda install -c conda-forge poppler`, then proceed to install `pdf2image`.\\n\\n## Install `pdf2image`\\n\\nFirst, you need to install `pdf2image`. Enter the following command in your terminal to install:\\n\\n```shell\\npip install pdf2image\\n```\\n\\n## Convert PDF using `pdf2image`\\n\\nConverting PDF to images is straightforward:\\n\\n```python\\nfrom pdf2image import convert_from_path\\n\\nimages = convert_from_path(\'/path/to/your/pdf/file.pdf\')\\n```\\n\\nThis will convert each page of the PDF into a PIL image object and store them in the `images` list.\\n\\nYou can also convert PDF from binary data:\\n\\n```python\\nimages = convert_from_bytes(open(\'/path/to/your/pdf/file.pdf\', \'rb\').read())\\n```\\n\\n## Optional Parameters\\n\\n`pdf2image` provides extensive optional parameters, allowing you to customize DPI, output format, page ranges, etc. For example: use `dpi=300` to enhance the clarity of the output images, or use `first_page` and `last_page` to specify the conversion range.\\n\\nYou can refer to the:\\n\\n- [**official documentation**](https://github.com/Belval/pdf2image/tree/master) of `pdf2image`;\\n\\nfunction for more usage examples.\\n\\n## Conclusion\\n\\n`pdf2image` is a powerful and easy-to-use tool that meets your needs for converting PDF to images. Whether it\'s for document processing, data organization, or content presentation, it provides an efficient solution."},{"id":"opencv-imread","metadata":{"permalink":"/en/blog/opencv-imread","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/02-13-imread/index.md","title":"Reading HEIC Images in Python","description":"Optimizing imread for reading HEIC images!","date":"2024-02-13T00:00:00.000Z","tags":[{"inline":true,"label":"HEIC","permalink":"/en/blog/tags/heic"},{"inline":true,"label":"TurboJPEG","permalink":"/en/blog/tags/turbo-jpeg"}],"readingTime":2.845,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"opencv-imread","title":"Reading HEIC Images in Python","authors":"Zephyr","tags":["HEIC","TurboJPEG"],"image":"/en/img/2024/0213.webp","description":"Optimizing imread for reading HEIC images!"},"unlisted":false,"prevItem":{"title":"Convert PDF to Images using Python","permalink":"/en/blog/convert-pdf-to-images"},"nextItem":{"title":"Daily Error Troubleshooting Log","permalink":"/en/blog/error-record"}},"content":"When you want to read an image, you might use the `imread` function from OpenCV.\\n\\nUnfortunately, this function is not universal, and you may encounter some problems.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Basic Usage\\n\\nThe basic usage of the `imread` function is straightforward; you just need to pass the path to the image:\\n\\n```python\\nimport cv2\\n\\nimage = cv2.imread(\'path/to/image.jpg\')\\n```\\n\\nYou can use common image formats such as BMP, JPG, PNG, TIF, and others.\\n\\n## Limitation 1: HEIC Format\\n\\nImages captured on iOS devices are typically in HEIC format, which is not supported in OpenCV. If you try to use the `imread` function to read HEIC format images, you will get a `None` return value.\\n\\nTo address this issue, we need to use the `pyheif` package to read HEIC format images and then convert them into `numpy.ndarray` variables.\\n\\nFirst, install the necessary packages:\\n\\n```bash\\nsudo apt install libheif-dev\\npip install pyheif\\n```\\n\\nThen, write a simple function:\\n\\n```python\\nimport cv2\\nimport pyheif\\nimport numpy as np\\n\\ndef read_heic_to_numpy(file_path: str):\\n    heif_file = pyheif.read(file_path)\\n    data = heif_file.data\\n    if heif_file.mode == \\"RGB\\":\\n        numpy_array = np.frombuffer(data, dtype=np.uint8).reshape(\\n            heif_file.size[1], heif_file.size[0], 3)\\n    elif heif_file.mode == \\"RGBA\\":\\n        numpy_array = np.frombuffer(data, dtype=np.uint8).reshape(\\n            heif_file.size[1], heif_file.size[0], 4)\\n    else:\\n        raise ValueError(\\"Unsupported HEIC color mode\\")\\n    return numpy_array\\n\\n\\nimg = read_heic_to_numpy(\'path/to/image.heic\')\\nimg = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\\n```\\n\\n## Limitation 2: Slow JPG Reading\\n\\nIn some cases, the `imread` function\'s performance in reading JPG format images can be slow. This is because OpenCV uses the `libjpeg` library to read JPG format images, and `libjpeg` itself is not very efficient.\\n\\nHere, we introduce the `TurboJPEG` package, an alternative to `libjpeg` with better performance. We can use `TurboJPEG` to accelerate the reading of JPG format images.\\n\\nSimilarly, install the necessary packages:\\n\\n```bash\\nsudo apt install libturbojpeg exiftool\\npip install PyTurboJPEG\\n```\\n\\nThen, let\'s optimize it a bit:\\n\\nGenerally, this can speed up the process by about 2-3 times.\\n\\n```python\\nimport cv2\\nimport piexif\\nfrom enum import IntEnum\\nfrom pathlib import Path\\nfrom turbojpeg import TurboJPEG\\n\\n\\njpeg = TurboJPEG()\\n\\n\\nclass ROTATE(IntEnum):\\n    ROTATE_90 = cv2.ROTATE_90_CLOCKWISE\\n    ROTATE_180 = cv2.ROTATE_180\\n    ROTATE_270 = cv2.ROTATE_90_COUNTERCLOCKWISE\\n\\n\\ndef imrotate90(img, rotate_code: ROTATE) -> np.ndarray:\\n    return cv2.rotate(img.copy(), rotate_code)\\n\\n\\ndef get_orientation_code(stream: Union[str, Path, bytes]):\\n    code = None\\n    try:\\n        exif_dict = piexif.load(stream)\\n        if piexif.ImageIFD.Orientation in exif_dict[\\"0th\\"]:\\n            orientation = exif_dict[\\"0th\\"][piexif.ImageIFD.Orientation]\\n            if orientation == 3:\\n                code = ROTATE.ROTATE_180\\n            elif orientation == 6:\\n                code = ROTATE.ROTATE_90\\n            elif orientation == 8:\\n                code = ROTATE.ROTATE_270\\n    finally:\\n        return code\\n\\n\\ndef jpgdecode(byte_: bytes) -> Union[np.ndarray, None]:\\n    try:\\n        bgr_array = jpeg.decode(byte_)\\n        code = get_orientation_code(byte_)\\n        bgr_array = imrotate90(\\n            bgr_array, code) if code is not None else bgr_array\\n    except:\\n        bgr_array = None\\n\\n    return bgr_array\\n\\n\\ndef jpgread(img_file: Union[str, Path]) -> Union[np.ndarray, None]:\\n    with open(str(img_file), \'rb\') as f:\\n        binary_img = f.read()\\n        bgr_array = jpgdecode(binary_img)\\n\\n    return bgr_array\\n\\nimg = jpgread(\'path/to/image.jpg\')\\n```\\n\\nThis way, reading JPG format images can be accelerated.\\n\\n## Conclusion\\n\\nWhat if we want this program to be more intelligent, choosing a suitable way to load images on its own?\\n\\nWe can write a function to select the appropriate loading method based on the image\'s format:\\n\\n```python\\ndef imread(\\n    path: Union[str, Path],\\n    color_base: str = \'BGR\',\\n    verbose: bool = False\\n) -> Union[np.ndarray, None]:\\n\\n    if not Path(path).exists():\\n        raise FileExistsError(f\'{path} can not be found.\')\\n\\n    if Path(path).suffix.lower() == \'.heic\':\\n        img = read_heic_to_numpy(str(path))\\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\\n    else:\\n        img = jpgread(path)\\n        img = cv2.imread(str(path)) if img is None else img\\n\\n    if img is None:\\n        if verbose:\\n            warnings.warn(\\"Got a None type image.\\")\\n        return\\n\\n    if color_base != \'BGR\':\\n        img = imcvtcolor(img, cvt_mode=f\'BGR2{color_base}\')\\n\\n    return img\\n```"},{"id":"error-record","metadata":{"permalink":"/en/blog/error-record","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/02-04-error-record/index.md","title":"Daily Error Troubleshooting Log","description":"A log of simple issues and their solutions.","date":"2024-02-04T00:00:00.000Z","tags":[{"inline":true,"label":"error","permalink":"/en/blog/tags/error"},{"inline":true,"label":"record","permalink":"/en/blog/tags/record"}],"readingTime":3.665,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"error-record","title":"Daily Error Troubleshooting Log","authors":"Zephyr","tags":["error","record"],"image":"/en/img/2024/0204.webp","description":"A log of simple issues and their solutions."},"unlisted":false,"prevItem":{"title":"Reading HEIC Images in Python","permalink":"/en/blog/opencv-imread"},"nextItem":{"title":"User Switching Tool in Containers: gosu","permalink":"/en/blog/gosu-usage"}},"content":"We always encounter a lot of problems when writing code.\\n\\nHere we record some trivial issues and their solutions.\\n\\n:::tip\\nThis article will be continuously updated.\\n:::\\n\\n\x3c!-- truncate --\x3e\\n\\n## 1. Error when running `npx docusaurus start`\\n\\n- **Error Message:**\\n\\n  ```bash\\n  file:///home/user/workspace/blog/node_modules/@docusaurus/core/bin/docusaurus.mjs:30\\n  process.env.BABEL_ENV ??= \'development\';\\n                      ^^^\\n\\n  SyntaxError: Unexpected token \'??=\'\\n  ```\\n\\n- **Solution:**\\n\\n  The `??=` operator requires Node.js version 15.0.0 or higher.\\n\\n  ```bash\\n  nvm install node\\n  nvm use node\\n  ```\\n\\n## 2. \'choco\' command not recognized\\n\\n- **Error Message:**\\n\\n  ```shell\\n  PS C:\\\\Windows\\\\System32> choco install git -y\\n  >>\\n  choco : The term \'choco\' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.\\n  At line:1 char:1\\n  + choco install git -y\\n  + ~~~~~\\n      + CategoryInfo          : ObjectNotFound: (choco:String) [], CommandNotFoundException\\n      + FullyQualifiedErrorId : CommandNotFoundException\\n  ```\\n\\n- **Solution:**\\n\\n  This indicates that Chocolatey was not successfully installed, often due to not running PowerShell as an Administrator.\\n\\n  Run PowerShell as an Administrator, and then execute the Chocolatey installation command again.\\n\\n  ```shell\\n  Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\'https://community.chocolatey.org/install.ps1\'))\\n  ```\\n\\n## 3. Chocolatey installation failure\\n\\n- **Error Message:**\\n\\n  ```shell\\n  Warning: An existing Chocolatey installation was detected. Installation will not continue. This script will not overwrite existing installations.\\n  If there is no Chocolatey installation at \'C:\\\\ProgramData\\\\chocolatey\', delete the folder and attempt the installation again.\\n\\n  Please use choco upgrade chocolatey to handle upgrades of Chocolatey itself.\\n  If the existing installation is not functional or a prior installation did not complete, follow these steps:\\n  - Backup the files at the path listed above so you can restore your previous installation if needed.\\n  - Remove the existing installation manually.\\n  - Rerun this installation script.\\n  - Reinstall any packages previously installed, if needed (refer to the lib folder in the backup).\\n\\n  Once installation is completed, the backup folder is no longer needed and can be deleted.\\n  ```\\n\\n- **Solution:**\\n\\n  This indicates that Chocolatey is already installed. Please remove the old installation before reinstalling.\\n\\n  ```shell\\n  Remove-Item \\"C:\\\\ProgramData\\\\chocolatey\\" -Recurse -Force\\n  ```\\n\\n## 4. Remote port forwarding\\n\\n- **Description:**\\n\\n  You\u2019ve started a service on a remote machine, such as TensorBoard, but can\'t access it directly, so you need to forward the port through your local machine.\\n\\n- **Solution:**\\n\\n  Assuming the service is running on port 6006 on the remote machine, and you want to access it on the same port on your local machine.\\n\\n  When using SSH to log in, you can forward the port using the `-L` parameter:\\n\\n  ```bash\\n  ssh -L 6006:localhost:6006 user@remote_ip_address\\n  ```\\n\\n  This way, you can access the TensorBoard service on the remote machine via `http://localhost:6006` on your local machine.\\n\\n## 5. Inconsistent Web Rendering Behavior in Development and Deployment Environments\\n\\n- **Description:**\\n\\n  You\'ve set the layout style of the blog in `custom.css`:\\n\\n  ```css\\n  .container {\\n    max-width: 90%;\\n    padding: 0 15px;\\n    margin: 0 auto;\\n  }\\n  ```\\n\\n  In the deployment phase, this style seems to be overridden by other higher-priority styles, but in the development phase, this style is normal.\\n\\n- **Solution:**\\n\\n  Be more specific in selecting the target:\\n\\n  ```css\\n  body .container {\\n    max-width: 90%;\\n    padding: 0 15px;\\n    margin: 0 auto;\\n  }\\n  ```\\n\\n## 6. Turbojpeg Warning When Reading Images\\n\\n- **Description**\\n\\n  When reading images, the following warning messages appear:\\n\\n  ```shell\\n  turbojpeg.py:940: UserWarning: Corrupt JPEG data: 18 extraneous bytes before marker 0xc4\\n  turbojpeg.py:940: UserWarning: Corrupt JPEG data: bad Huffman code\\n  turbojpeg.py:940: UserWarning: Corrupt JPEG data: premature end of data segment\\n  ```\\n\\n- **Solution**\\n\\n  To avoid these annoying warnings, you should filter out the problematic images:\\n\\n  ```python\\n  import cv2\\n  import warnings\\n\\n  data = [\'test1.jpg\', \'test2.jpg\', \'test3.jpg\']\\n\\n  for d in data:\\n    with warnings.catch_warnings(record=True) as w:\\n      warnings.simplefilter(\\"always\\", UserWarning)\\n\\n      # Read the image and see if there are any warnings\\n      cv2.imread(d)\\n\\n      # Remove the data if warnings are present\\n      if w:\\n        data.remove(d)\\n\\n  # Saving the filtered data\\n  ```\\n\\n## 7. `Docusaurus` Deployment: `showLastUpdateTime: true` Not Working\\n\\n- **Description**\\n\\n  In `docusaurus.config.js`, you set `showLastUpdateTime: true` and `showLastUpdateAuthor: true,` but after deployment, you find that it has no effect. The rendered page displays the same time and author?\\n\\n- **Solution**\\n\\n  The problem is caused by an incorrect setting when checking out the branch during deployment, which prevents `git` from correctly obtaining the last update time and author.\\n\\n  Change it like this:\\n\\n  ```yaml\\n  steps:\\n    - uses: actions/checkout@v4\\n      with:\\n        fetch-depth: 0\\n  ```\\n\\n  Setting `fetch-depth: 0` will solve the problem."},{"id":"gosu-usage","metadata":{"permalink":"/en/blog/gosu-usage","source":"@site/i18n/en/docusaurus-plugin-content-blog/2024/02-03-usage-gosu/index.md","title":"User Switching Tool in Containers: gosu","description":"A tool worth learning how to use.","date":"2024-02-03T00:00:00.000Z","tags":[{"inline":true,"label":"docker","permalink":"/en/blog/tags/docker"},{"inline":true,"label":"gosu","permalink":"/en/blog/tags/gosu"}],"readingTime":3.99,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"gosu-usage","title":"User Switching Tool in Containers: gosu","authors":"Zephyr","tags":["docker","gosu"],"image":"/en/img/2024/0203.webp","description":"A tool worth learning how to use."},"unlisted":false,"prevItem":{"title":"Daily Error Troubleshooting Log","permalink":"/en/blog/error-record"},"nextItem":{"title":"Building a New Computer","permalink":"/en/blog/buy-a-new-computer"}},"content":"Docker technology has been widely adopted for deployment and management purposes.\\n\\nWe typically package various applications and their dependencies together to ensure consistent operation across different environments.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Common Issues\\n\\nHowever, with frequent use, you can\'t escape encountering a few common problems.\\n\\n### TTY Conversion\\n\\nA common scenario is when you output a file within a container, exit the container, and then realize that the file permissions are all set to root. You then have to use `chown` to change the file permissions repeatedly, which can be quite cumbersome.\\n\\n---\\n\\nOr, when running an application within a Docker container using sudo that requires interaction with the terminal (TTY), these applications might fail to properly detect the terminal because sudo might not handle terminal ownership and control properly when creating a new session. As a result, these applications requiring terminal interaction may not run correctly or encounter input/output errors when attempting to use them.\\n\\n### Signal Forwarding\\n\\nSuppose you have a container running a web server like Apache or Nginx. Typically, you might use command-line tools to manage this container, including starting and stopping it. Inside the container, if you use sudo to start the web server, sudo will create a new process to run the web server.\\n\\nThe problem arises when you want to stop or restart the container. The container management system sends signals (like SIGTERM) to the container to notify processes inside it to prepare for shutdown. However, if the web server was started via sudo, this signal might only be sent to the sudo process, not the actual web server process. This means the web server might not receive the stop signal, preventing proper cleanup and safe shutdown.\\n\\n:::tip\\nThe design intention of sudo is to enhance security by allowing regular users to execute commands as other users (usually the root user). In this process, sudo starts a new session to execute the command. While this behavior typically poses no issues in traditional operating system environments, it can lead to signal delivery problems in lightweight virtualized environments like containers, as the new session created by sudo might be incompatible with how the container management system sends signals.\\n:::\\n\\n## What is gosu?\\n\\n- [**gosu GitHub repository**](https://github.com/tianon/gosu)\\n\\ngosu is a tool specifically designed for containers, aiming to simplify and secure command execution within containers. When you need to run a command as a different user (e.g., switching from an administrator to a regular user) within a container, gosu comes in handy. Its core mechanism directly borrows from how `Docker/libcontainer` starts applications within containers (in fact, it directly uses code from the `libcontainer` library for handling `/etc/passwd`).\\n\\nIf you\'re not interested in its inner workings, think of gosu as a helper. When you tell it to \\"run this command as this user,\\" it does just that, then exits, leaving no trace behind.\\n\\n### Practical Use Cases\\n\\nUsing gosu in the ENTRYPOINT script of a Docker container is a typical use case, especially when we need to downgrade from the root user to a non-privileged user to perform certain operations. This practice is crucial for safeguarding the security of the container runtime environment, as it effectively reduces potential security risks.\\n\\nInstalling gosu is straightforward, usually requiring just a few lines in the Dockerfile for installation and configuration. The following example demonstrates how to install gosu in a Dockerfile and dynamically create users and groups using an entrypoint script, then use gosu to execute commands with the specified user identity.\\n\\n```Dockerfile title=\\"Dockerfile\\"\\n# Based on an existing base image\\nFROM some_base_image:latest\\n\\nWORKDIR /app\\n\\n# Install gosu\\nRUN apt-get update && apt-get install -y gosu && rm -rf /var/lib/apt/lists/*\\n\\n# Prepare entrypoint script\\nCOPY entrypoint.sh /entrypoint.sh\\nRUN chmod +x /entrypoint.sh\\n\\nENTRYPOINT [\\"/entrypoint.sh\\"]\\nCMD [\\"default_command\\"]\\n```\\n\\nThe example content of the `entrypoint.sh` script is as follows. It dynamically creates a user and group based on the environment variables USER_ID and GROUP_ID, then executes a command using gosu:\\n\\n```bash title=\\"entrypoint.sh\\"\\n#!/bin/bash\\n# Check if USER_ID and GROUP_ID environment variables are set\\nif [ ! -z \\"$USER_ID\\" ] && [ ! -z \\"$GROUP_ID\\" ]; then\\n    # Create group and user\\n    groupadd -g \\"$GROUP_ID\\" usergroup\\n    useradd -u \\"$USER_ID\\" -g usergroup -m user\\n    # Execute command using gosu\\n    exec gosu user \\"$@\\"\\nelse\\n    exec \\"$@\\"\\nfi\\n```\\n\\nFor a real-world example, refer to: [**Example training docker**](https://github.com/DocsaidLab/Otter/blob/main/docker/Dockerfile)\\n\\n### Security Considerations\\n\\nWhile gosu\'s primary purpose is to switch from the `root` user to a non-privileged user during container startup, its developers also emphasize potential security risks associated with using gosu in certain contexts.\\n\\nThis is because any tool that allows user switching, if misused, could open doors to security vulnerabilities. Therefore, development and operations teams need to have a thorough understanding of gosu\'s usage scenarios and ensure it is only used in secure environments."},{"id":"buy-a-new-computer","metadata":{"permalink":"/en/blog/buy-a-new-computer","source":"@site/i18n/en/docusaurus-plugin-content-blog/2023/10-12-buy-a-new-computer/index.md","title":"Building a New Computer","description":"Documenting the process of assembling a new computer.","date":"2023-10-12T00:00:00.000Z","tags":[{"inline":true,"label":"rtx4090","permalink":"/en/blog/tags/rtx-4090"},{"inline":true,"label":"13900k","permalink":"/en/blog/tags/13900-k"}],"readingTime":11.425,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"buy-a-new-computer","title":"Building a New Computer","authors":"Zephyr","tags":["rtx4090","13900k"],"image":"/en/img/2023/1012.webp","description":"Documenting the process of assembling a new computer."},"unlisted":false,"prevItem":{"title":"User Switching Tool in Containers: gosu","permalink":"/en/blog/gosu-usage"},"nextItem":{"title":"Managing Python Versions with pyenv","permalink":"/en/blog/pyenv-installation"}},"content":"We suddenly decided to buy a new computer.\\n\\nThe main reason? To use an RTX 4090 for model training.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Disclaimer\\n\\nWe were busy and decided to build a training rig, so we documented the process.\\n\\n1. If you assemble a computer based on this documentation and encounter any issues or losses, we are not responsible.\\n2. This article is for personal documentation purposes only and is not intended as a recommendation or advertisement.\\n3. All products or brands mentioned in the article are for documentation purposes only and do not represent any commercial cooperation or endorsement.\\n\\n## Purchase Details\\n\\nBelow is the list of items we purchased:\\n\\n| Item           | Description                                                                        | Quantity | Total Price (NTD) |\\n| -------------- | ---------------------------------------------------------------------------------- | -------- | ----------------- |\\n| CPU            | Intel i9-13900K \u301024 cores/32 threads\u30113.0GHz-5.8GHz 36MB LGA1700 125W             | 1        | $ 19,500          |\\n| Motherboard    | Gigabyte Z790 AORUS ELITE (ATX/Realtek 2.5Gb) 16+1+2 Power Phases                  | 1        | $ 7,990           |\\n| Graphics Card  | Gigabyte RTX 4090 AERO OC 24G White Windforce Cooling Metal Backplate              | 1        | $ 60,990          |\\n| Memory         | Kingston 64 GB (Dual Channel 32GBx2) DDR5 6000 CL36 FURY Beast White               | 2        | $ 12,258          |\\n| SSD            | Micron Crucial P5 Plus 2TB (Gen4 M.2 PCIe 4.0) NVMe SSD (Read 6600M / Write 5500M) | 2        | $ 7,800           |\\n| Liquid Cooling | NZXT Kraken 360 RGB White                                                          | 1        | $ 7,990           |\\n| Case           | ASUS TUF Gaming GT502 White ATX                                                    | 1        | $ 5,490           |\\n| Case Fans      | ASUS TUF Gaming TF120 ARGB White Triple Fan Pack (Case Gift)                       | 1        | -                 |\\n| Case Fans      | ASUS TUF Gaming TF120 ARGB White Triple Fan Pack (Additional Purchase)             | 1        | $ 1,690           |\\n| Case Fans      | ASUS TUF Gaming TF120 ARGB White Single Fan (Additional Purchase)                  | 4        | $ 2,196           |\\n| PSU            | FSP HYDRO PTM PRO 1200W ATX3.0 Platinum Fully Modular                              | 1        | $ 5,790           |\\n| Cables         | SilverStone 1 to 4 A.RGB Splitter Cable (SST-CPL03)                                | 2        | $ 250             |\\n\\n- **Total Price (including tax)**: NTD 131,944, approximately 4,100 USD\\n- **Date**: September 2023\\n\\n:::info\\nWe checked the prices of pre-built computers with similar specs, which were around NT$180,000.\\n:::\\n\\n## RTX 4090\\n\\nIt all started with this.\\n\\nWe first checked out some options at a local retailer and found that there were a few brands offering the RTX 4090: ASUS, Gigabyte, and MSI.\\n\\nThen we watched a review video:\\n\\n- [**MSI RTX 4090 Suprim X vs. RTX 4090 Gaming X Trio, Thermals, Power & Overclocking**](https://www.youtube.com/watch?v=uyMnMPLYk2w)\\n\\nIt seemed that MSI\u2019s cards ran particularly hot, while the other two brands had similar temperatures.\\n\\nNext, we found a relevant article:\\n\\n- [**[Info] 6 RTX 4090 Cooling Comparisons**](https://forum.gamer.com.tw/C.php?bsn=60030&snA=615853)\\n\\nOverall, Gigabyte performed the best, so we chose the best-looking white Windforce version from their lineup:\\n\\nSpecifications:\\n\\n- Item: GIGABYTE RTX 4090 AERO OC 24G White Windforce Cooling Metal Backplate\\n- Price: NT$60,900 from the local retailer\\n- Length: 34.2 cm\\n\\n  ![gigabyte](./img/img2.jpg)\\n\\n:::tip\\nThis generation of GPUs also involves the ATX standard, which we\u2019ll discuss further in the PSU section.\\n:::\\n\\n## Motherboard\\n\\nAfter deciding on the graphics card, the next step was the motherboard.\\n\\nHere we encountered the issue of \\"socket compatibility,\\" as different motherboards support different CPUs. So we did some research:\\n\\n- Intel 12th Gen pairs with 600 series motherboards, using the 1700 socket.\\n- Intel 13th Gen pairs with 700 series motherboards, using the 1700 socket.\\n- Intel 14th Gen pairs with 700 series motherboards, using the 1700 socket.\\n\\nIt seems that the 1700 socket is a more long-term choice, so we went with a 700 series motherboard:\\n\\n### 1700 Socket\\n\\nAccording to [**Wikipedia\u2019s description of LGA 1700**](https://zh.wikipedia.org/zh-tw/LGA_1700):\\n\\nLGA 1700 is a socket designed by Intel for its Alder Lake microarchitecture (12th Gen Intel Core) and Raptor Lake microarchitecture (13th and 14th Gen Intel Core) desktop processors, launched in 2021. It replaces the LGA 1200 and supports DDR5 memory. Due to the increased number of contact points, previous heatsinks compatible with LGA 1200 and LGA 1151 (37.5 mm x 37.5 mm) are incompatible with LGA 1700 (45.0 mm x 37.5 mm).\\n\\n### Chipset Specifications\\n\\nDuring our research, we also came across various motherboards like B660, H670, Z690, etc. So we dug deeper:\\n\\n<details>\\n  <summary>Click to expand</summary>\\n\\n| **Feature**                                                   | **H610**                                     | **B660**                                     | **H670**                                     | **Z690**                                     | **W680**                                     | **Z790**                                     |\\n| ------------------------------------------------------------- | -------------------------------------------- | -------------------------------------------- | -------------------------------------------- | -------------------------------------------- | -------------------------------------------- | -------------------------------------------- |\\n| **CPU Overclocking**                                          | No                                           | No (Supports memory overclocking)            | No (Supports memory overclocking)            | Yes                                          | Yes                                          | Yes                                          |\\n| **Bus Interface**                                             | DMI 4.0 x4                                   | DMI 4.0 x8                                   | DMI 4.0 x8                                   | DMI 4.0 x8                                   | DMI 4.0 x8                                   | DMI 4.0 x8                                   |\\n| **Supported CPUs**                                            | Alder Lake, Raptor Lake, Raptor Lake Refresh | Alder Lake, Raptor Lake, Raptor Lake Refresh | Alder Lake, Raptor Lake, Raptor Lake Refresh | Alder Lake, Raptor Lake, Raptor Lake Refresh | Alder Lake, Raptor Lake, Raptor Lake Refresh | Alder Lake, Raptor Lake, Raptor Lake Refresh |\\n| **Supported Memory**                                          | Up to 64GB, DDR4 3200 / DDR5 4800            | Up to 128GB, DDR4 3200 / DDR5 4800           | Up to 128GB, DDR4 3200 / DDR5 4800           | Up to 128GB, DDR4 3200 / DDR5 4800           | Up to 128GB, DDR4 3200 / DDR5 4800           | Up to 128GB, DDR4 3200 / DDR5 4800           |\\n| **Maximum DIMM Slots**                                        | 2                                            | 4                                            | 4                                            | 4                                            | 4                                            | 4                                            |\\n| **Maximum USB 2.0 Ports**                                     | 10                                           | 12                                           | 14                                           | 14                                           | 14                                           | 14                                           |\\n| **USB 3.2 Gen 1 (5 Gbit/s)**                                  | Up to 4                                      | Up to 6                                      | Up to 8                                      | Up to 10                                     | Up to 10                                     | Up to 10                                     |\\n| **USB 3.2 Gen 2 (10 Gbit/s)**                                 | Up to 1                                      | Up to 2                                      | Up to 4                                      | Up to 4                                      | Up to 4                                      | Up to 10                                     |\\n| **USB 3.2 Gen 2x2 (20 Gbit/s)**                               | No                                           | Up to 2                                      | Up to 4                                      | Up to 4                                      | Up to 4                                      | Up to 5                                      |\\n| **Maximum SATA 3.0 Ports**                                    | 4                                            | 4                                            | 8                                            | 8                                            | 8                                            | 8                                            |\\n| **Processor PCI Express 5.0 Configuration**                   | 1x16                                         | 1x16+1x4                                     | 1x16+1x4 or 2x8+1x4                          | 1x16+1x4 or 2x8+1x4                          | 1x16+1x4 or 2x8+1x4                          | 1x16 or 2x8                                  |\\n| **PCH PCI Express 4.0 Configuration**                         | No                                           | 6                                            | 12                                           | 16                                           | 16                                           | 16                                           |\\n| **PCH PCI Express 3.0 Configuration**                         | 8                                            | 12                                           | 12                                           | 12                                           | 12                                           | 12                                           |\\n| **Built-in Display Support (Digital Ports/Pipelines)**        | 3                                            | 4                                            | 4                                            | 4                                            | 4                                            | 4                                            |\\n| **Built-in Wireless (802.11ax / Wi-Fi 6E)**                   | Yes                                          | Yes                                          | Yes                                          | Yes                                          | Yes                                          | Yes                                          |\\n| **SATA RAID 0/1/5/10 Support**                                | No                                           | Yes                                          | Yes                                          | Yes                                          | Yes                                          | Yes                                          |\\n| **Intel Optane Memory Support**                               | No                                           | Yes                                          | Yes                                          | Yes                                          | Yes                                          | Yes                                          |\\n| **Intel Smart Sound Technology**                              | Yes                                          | Yes                                          | Yes                                          | Yes                                          | Yes                                          | Yes                                          |\\n| **Intel Active Management, Trusted Execution & vPro Support** | No                                           | No                                           | No                                           | No                                           | Yes                                          | No                                           |\\n| **Chipset TDP**                                               | 6W                                           | 6W                                           | 6W                                           | 6W                                           | 6W                                           | 6W                                           |\\n| **Release Date**                                              | Q1 2022                                      | Q1 2022                                      | Q1 2022                                      | Q4 2021                                      | Q2 2022                                      | Q4 2022                                      |\\n\\n</details>\\n\\nWhoa! That\u2019s a lot of information. In short, we went with the best option and chose a Z790!\\n\\nSpecifications:\\n\\n- Item: GIGABYTE Z790 AORUS ELITE (ATX/Realtek 2.5Gb) 16+1+2 Power Phases\\n- Price: NT$7,990 from the local retailer\\n\\n  ![gigabyte](./img/img3.jpg)\\n\\n## CPU\\n\\nWe\u2019ve heard that Intel\u2019s 13th and 14th Gen CPUs have some peculiar issues.\\n\\nBut since we\u2019re not overclocking, it shouldn\u2019t be a big deal. So, we decided to go with the 13th Gen Intel CPU!\\n\\nSpecifications:\\n\\n- Item: Intel i9-13900K \u301024 cores/32 threads\u30113.0GHz-5.8GHz 36MB 1700 Socket 125W\\n- Price: NT$19,500 from the local retailer\\n\\n:::tip\\nWe\u2019re running Ubuntu, and we did experience some crashes initially.\\n\\nHowever, after a system update, the issue disappeared, so we\u2019re not sure if it was a CPU defect.\\n:::\\n\\n## Memory\\n\\nWe believe that the three major memory manufacturers are Micron, Kingston, and Adata. Since we\u2019re not hardcore gamers, we decided to stick with one of these three.\\n\\nCapacity is key here. Since this rig is for model training, filling it up with 128GB is a basic requirement, right?\\n\\nSpecifications:\\n\\n- Item: Kingston 64 GB (Dual Channel 32GBx2) DDR5 6000 CL36 FURY Beast White\\n- Price: NT$6,129 per set from the local retailer\\n- Quantity: 2 sets\\n\\n  ![kingston](./img/img4.jpg)\\n\\n## SSD\\n\\nFor this part, we found a guide from a storage expert on PTT:\\n\\n- [**SSD (Solid State Drive) Purchasing Guide**](https://www.ptt.cc/bbs/PC_Shopping/M.1675587557.A.3D3.html)\\n\\nThere\u2019s a lot of extended reading and comparisons of various manufacturers, but honestly, there\u2019s too much technical knowledge here.\\n\\nWhile we were getting overwhelmed, we seemed to catch a conclusion that recommended Micron, so we went with that! (~Seems a bit too casual?~)\\n\\n---\\n\\nAfter some more research, we concluded that we should avoid QLC SSDs due to their slower write speeds and shorter lifespan. On the other hand, PCIe 5 SSDs seem to have some issues (link below), so we chose TLC technology and PCIe 4.0 SSDs.\\n\\n- [**Crucial, Corsair PCIe 5.0 SSDs running hot, throttling, and shutting down without heatsink**](https://www.neowin.net/news/crucial-corsair-pcie-50-ssds-running-hot-throttling-and-shutting-down-without-heatsink/?fbclid=IwAR0aM7igqoPCImgSMKCtPTNLRw5nOeGJPxLN3HYN89CsTSFEEtl2YsDqbCU)\\n\\n:::tip\\nHowever, technology advances quickly, so these issues might not be a concern in the near future! It\u2019s always best to check the latest information.\\n:::\\n\\n---\\n\\nSince we\u2019re training models, we opted for 4TB of storage to accommodate the datasets.\\n\\nSpecifications:\\n\\n- Item: Micron Crucial P5 Plus 2TB PCIe 4.0 NVMe SSD (Read 6600M / Write 5500M) TLC\\n- Price: NT$3,900 per unit from the local retailer\\n- Quantity: 2 units\\n\\n  ![micron](./img/img5.jpg)\\n\\n## Liquid Cooling\\n\\nIn this category, there are brands like ASUS, MSI, Corsair, and NZXT. Although there seemed to be plenty of choices, we couldn\u2019t find any particularly reliable comparison reviews online, so our focus shifted to warranty duration.\\n\\nMost brands offer a 3-year warranty, but NZXT offers 6+1 years, so we chose NZXT.\\n\\nSpecifications:\\n\\n- Item: NZXT Kraken 360 RGB White\\n- Price: NT$7,990 from the local retailer\\n- Thickness: 5.6 cm\\n\\n  ![nzxt](./img/img6.jpg)\\n\\n:::tip\\nIf you\u2019re an expert in this field, feel free to provide us with more professional advice. We\u2019ll prioritize it when building our next rig.\\n:::\\n\\n## Case and Fans\\n\\nFor this part, we just chose a case that could fit everything and then bought some additional fans to install.\\n\\nSpecifications:\\n\\n- Items:\\n  - ASUS TUF Gaming GT502 White ATX\\n  - TUF Gaming TF120 ARGB White Triple Fan Pack (Case Gift) x1\\n  - TUF Gaming TF120 ARGB White Triple Fan Pack (Additional Purchase) x1\\n  - TUF Gaming TF120 ARGB White Single Fan (Additional Purchase) x4\\n- Prices:\\n\\n  - Case with Gift: NT$5,490 from the local retailer\\n  - Additional Triple Fan Pack: NT$1,690 per set from the local retailer\\n  - Additional Single Fan: NT$549 per fan from the local retailer\\n\\n    ![asus case](./img/img7.jpg)\\n\\n## Power Supply Unit\\n\\nFor this part, we just searched online for recommended power supply brands of the year.\\n\\nAny brand that appeared on the lists seemed reliable to us, so we focused on warranty duration and price and went with FSP.\\n\\nSpecifications:\\n\\n- Item: FSP HYDRO PTM PRO 1200W ATX3.0 Platinum Fully Modular\\n- Price: NT$5,790 from the local retailer\\n\\n  ![fsp](./img/img8.jpg)\\n\\n---\\n\\nContinuing the discussion about the GPU, we need to add some information about the ATX 3.0 standard:\\n\\n- [**ATX 3.0 Standard**](https://zh.wikipedia.org/zh-tw/ATX%E8%A6%8F%E6%A0%BC)\\n\\n  The ATX 3.0 standard was released in February 2022. It includes a new 16-Pin 12VHPWR power interface, capable of delivering up to 600W of power to the graphics card. These components contain data lines used to negotiate power functions with the power supply unit, ensuring they do not consume more power than the PSU can provide. The standard also has stricter requirements for handling power spikes.\\n\\nTo meet the power demands of the RTX 4090, it\u2019s important to consider ATX 3.0 compatibility when selecting a power supply. Shortly after the RTX 4090\u2019s release, many cases of power issues were reported, mostly due to insufficient power supply, causing instability in the system.\\n\\n## Completion\\n\\nAfter buying all these components, we weren\u2019t entirely confident in our ability to assemble everything correctly, so we entrusted the final assembly to a technician at the store. Our photography skills aren\u2019t great, but you can check out the video below to see what the final product looks like\u2014it\u2019s quite similar, except our graphics card and all four memory sticks are also white.\\n\\n- [**ASUS TUF GT502 CUSTOM SETUP | Black & White PC BUILD | i9-13900k | ASUS TUF RTX 4070TI | ProArt Z790**](https://www.youtube.com/watch?v=puMYF4wpzTQ)\\n\\n  ![final](./img/img9.jpg)\\n\\n---\\n\\nThat wraps up the assembly process. Now it\u2019s time to enjoy training some models with our new rig!\\n\\n## Afterword 1\\n\\n:::info\\nUpdated in June 2024\\n:::\\n\\nLoaded with model training, based on Taiwan\'s residential electricity meter billing, the monthly electricity bill is about NT$5,000.\\n\\n## Afterword 2\\n\\n:::info\\nUpdated in October 2024\\n:::\\n\\nAfter using it for a year, I feel that buying a 4TB hard drive is too conservative:\\n\\n1. The WebFace42M dataset requires 0.9TB.\\n2. The ImageNet 21k dataset requires 1.3TB.\\n3. ...\\n\\nThere are other large-scale datasets, and 4TB is simply not enough. Next time, I need to buy at least 16TB."},{"id":"pyenv-installation","metadata":{"permalink":"/en/blog/pyenv-installation","source":"@site/i18n/en/docusaurus-plugin-content-blog/2023/10-10-pyenv-installation/index.md","title":"Managing Python Versions with pyenv","description":"Documenting the installation and usage of pyenv.","date":"2023-10-10T00:00:00.000Z","tags":[{"inline":true,"label":"pyenv","permalink":"/en/blog/tags/pyenv"},{"inline":true,"label":"virtualenv","permalink":"/en/blog/tags/virtualenv"}],"readingTime":2.295,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"pyenv-installation","title":"Managing Python Versions with pyenv","authors":"Zephyr","tags":["pyenv","virtualenv"],"image":"/en/img/2023/1010.webp","description":"Documenting the installation and usage of pyenv."},"unlisted":false,"prevItem":{"title":"Building a New Computer","permalink":"/en/blog/buy-a-new-computer"},"nextItem":{"title":"Recording Model Training Environment Issues","permalink":"/en/blog/python-env-info-collector"}},"content":"In earlier years, Conda was predominantly used for managing Python environments. Nowadays, pyenv is commonly employed.\\n\\nThis article aims to document the installation and usage of pyenv.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Prerequisites\\n\\nBefore installing `pyenv`, ensure that `Git` is installed on your system.\\n\\n:::info\\nThe pyenv package provides a [**Common build problems guide**](https://github.com/pyenv/pyenv/wiki/Common-build-problems) to address installation issues.\\n\\nIf you encounter any problems during installation, refer to this page.\\n:::\\n\\n## Installing `pyenv`\\n\\n1. **Execute Installation Command**:\\n\\n   You can quickly install `pyenv` by running the following command:\\n\\n   ```bash\\n   curl https://pyenv.run | bash\\n   ```\\n\\n   This command fetches and executes the installation script from the `pyenv-installer` repository on GitHub.\\n\\n2. **Configure Your Shell Environment**:\\n\\n   After installation, follow the [**setup guide**](https://github.com/pyenv/pyenv#set-up-your-shell-environment-for-pyenv) to configure your shell environment to ensure that `pyenv` works correctly.\\n\\n   If you are using `bash`, add the following code to your `.bashrc` file:\\n\\n   ```bash\\n   export PATH=\\"$HOME/.pyenv/bin:$PATH\\"\\n   eval \\"$(pyenv init --path)\\"\\n   eval \\"$(pyenv virtualenv-init -)\\"\\n   ```\\n\\n   For `zsh` users, add the above code to your `.zshrc` file.\\n\\n3. **Restart Your Shell**:\\n\\n   After completing the above steps, reload the new configuration.\\n\\n   ```bash\\n   exec $SHELL\\n   ```\\n\\n## Using `pyenv`\\n\\nOnce installed and configured, you can start using `pyenv` to manage multiple Python versions:\\n\\n- **Install a New Python Version**:\\n\\n  ```bash\\n  pyenv install 3.10.14\\n  ```\\n\\n- **Switch the Global Python Version**:\\n\\n  ```bash\\n  pyenv global 3.10.14\\n  ```\\n\\n- **Use a Specific Version in a Directory**:\\n  ```bash\\n  pyenv local 3.8.5\\n  ```\\n\\n## Virtual Environments\\n\\nVirtual environments are crucial in Python development.\\n\\nThey allow us to use different Python versions and dependencies in different projects.\\n\\nAt the very least, when you accidentally mess up your Python environment, you can simply delete the virtual environment and start over.\\n\\n:::tip\\nIt\'s highly recommended to use virtual environments when developing Python projects.\\n:::\\n\\n### Installation\\n\\n`pyenv` also provides a `pyenv-virtualenv` plugin, making it easier to manage Python virtual environments.\\n\\nPreviously, this feature required separate installation, but it\'s now integrated into `pyenv`, and we can directly use:\\n\\n```bash\\npyenv virtualenv 3.10.14 your-env-name\\n```\\n\\nHere, `3.10.14` is the Python version you want to use, which you\'ve already installed in the previous step, and `your-env-name` is the name of the virtual environment.\\n\\n### Usage\\n\\nTo activate the virtual environment, run:\\n\\n```bash\\npyenv activate your-env-name\\n```\\n\\n### Removal\\n\\nFinally, when you no longer need the virtual environment, you can run the following command to delete it:\\n\\n```bash\\npyenv virtualenv-delete your-env-name\\n```\\n\\n## Updating `pyenv`\\n\\nTo update `pyenv` to the latest version, simply run:\\n\\n```bash\\npyenv update\\n```\\n\\n## Uninstalling `pyenv`\\n\\nIf you decide to no longer use `pyenv`, follow these steps to uninstall:\\n\\n1. **Remove the `pyenv` Installation Directory**:\\n\\n   ```bash\\n   rm -fr ~/.pyenv\\n   ```\\n\\n2. **Clean Your `.bashrc`**:\\n\\n   Remove or comment out the relevant `pyenv` configuration lines, then restart your shell:\\n\\n   ```bash\\n   exec $SHELL\\n   ```"},{"id":"python-env-info-collector","metadata":{"permalink":"/en/blog/python-env-info-collector","source":"@site/i18n/en/docusaurus-plugin-content-blog/2023/09-22-python-env-info-collector/index.md","title":"Recording Model Training Environment Issues","description":"A custom logging tool.","date":"2023-09-22T00:00:00.000Z","tags":[{"inline":true,"label":"python","permalink":"/en/blog/tags/python"},{"inline":true,"label":"training-log","permalink":"/en/blog/tags/training-log"}],"readingTime":5.93,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"python-env-info-collector","title":"Recording Model Training Environment Issues","authors":"Zephyr","tags":["python","training-log"],"image":"/en/img/2023/0922.webp","description":"A custom logging tool."},"unlisted":false,"prevItem":{"title":"Managing Python Versions with pyenv","permalink":"/en/blog/pyenv-installation"},"nextItem":{"title":"Setting Up PyPiServer on Ubuntu","permalink":"/en/blog/setting-up-pypiserver-on-ubuntu-with-docker"}},"content":"When a model\'s training goes awry, we always want to know the reasons behind it. At such times, it\'s essential to inspect the environment information of the training host, such as Python version, PyTorch version, CUDA version, GPU information, CPU information, RAM information, disk information, IP address, and more.\\n\\n\x3c!-- truncate --\x3e\\n\\nIn this article, we share a custom Python tool we\'ve crafted to swiftly review this information. While it\'s not exhaustive, it should suffice for basic troubleshooting needs.\\n\\nTypically, we record environment information in the training host\'s logs at the start of training.\\n\\n## Installation\\n\\nLet\'s start by installing the necessary packages:\\n\\n```bash\\npip install psutil requests\\n```\\n\\n:::tip\\nThe complete code is available on GitHub, and we\'ve also included it at the end of this article.\\n\\n- [**system_info.py**](https://github.com/DocsaidLab/Capybara/blob/main/capybara/utils/system_info.py)\\n  :::\\n\\n## `get_package_versions`\\n\\nAssuming you have installed `capybara` and it\'s already in your project, you can test it with the following command:\\n\\n```python\\nfrom capybara import get_package_versions\\n\\nget_package_versions()\\n```\\n\\nUpon execution, you\'ll receive the following result:\\n\\n```json\\n{\\n  \\"PyTorch Version\\": \\"2.1.1+cu121\\",\\n  \\"PyTorch Lightning Version\\": \\"2.1.2\\",\\n  \\"TensorFlow Error\\": \\"No module named \'tensorflow\'\\",\\n  \\"Keras Error\\": \\"No module named \'keras\'\\",\\n  \\"NumPy Version\\": \\"1.24.4\\",\\n  \\"Pandas Version\\": \\"2.0.3\\",\\n  \\"Scikit-learn Version\\": \\"1.3.2\\",\\n  \\"OpenCV Version\\": \\"4.8.1\\"\\n}\\n```\\n\\n- PyTorch Version: PyTorch version\\n- PyTorch Lightning Version: PyTorch Lightning version\\n- TensorFlow Error: TensorFlow version\\n- Keras Error: Keras version\\n- NumPy Version: NumPy version\\n- Pandas Version: Pandas version\\n- Scikit-learn Version: Scikit-learn version\\n- OpenCV Version: OpenCV version\\n\\n## `get_gpu_cuda_versions`\\n\\nTest program:\\n\\n```python\\nfrom capybara import get_gpu_cuda_versions\\n\\nget_gpu_cuda_versions()\\n```\\n\\nUpon execution, you\'ll receive the following result:\\n\\n```json\\n{\\n  \\"CUDA Version\\": \\"12.1\\",\\n  \\"NVIDIA Driver Version\\": \\"535.129.03\\"\\n}\\n```\\n\\n- CUDA Version: CUDA version\\n- NVIDIA Driver Version: NVIDIA driver version\\n\\n## `get_system_info`\\n\\nTest program:\\n\\n```python\\nfrom capybara import get_system_info\\n\\nget_system_info()\\n```\\n\\nUpon execution, you\'ll receive the following result:\\n\\n```json\\n{\\n  \\"OS Version\\": \\"Linux-6.2.0-37-generic-x86_64-with-glibc2.34\\",\\n  \\"CPU Model\\": \\"13th Gen Intel(R) Core(TM) i9-13900K\\",\\n  \\"Physical CPU Cores\\": 24,\\n  \\"Logical CPU Cores (incl. hyper-threading)\\": 32,\\n  \\"Total RAM (GB)\\": 125.56,\\n  \\"Available RAM (GB)\\": 110.9,\\n  \\"Disk Total (GB)\\": 1832.21,\\n  \\"Disk Used (GB)\\": 188.94,\\n  \\"Disk Free (GB)\\": 1550.12,\\n  \\"GPU Info\\": \\"NVIDIA GeForce RTX 4090\\",\\n  \\"IPV4 Address\\": [\\"192.168.---.---\\"],\\n  \\"IPV4 Address (External)\\": \\"---.---.---.---\\",\\n  \\"MAC Address\\": [\\"--.--.--.--.--.--\\"]\\n}\\n```\\n\\n- OS Version: Operating system version\\n- CPU Model: CPU model\\n- Physical CPU Cores: Number of physical CPU cores\\n- Logical CPU Cores (incl. hyper-threading): Number of logical CPU cores (including hyper-threading)\\n- Total RAM (GB): Total RAM capacity (GB)\\n- Available RAM (GB): Available RAM capacity (GB)\\n- Disk Total (GB): Total disk capacity (GB)\\n- Disk Used (GB): Used disk capacity (GB)\\n- Disk Free (GB): Free disk capacity (GB)\\n- GPU Info: GPU information\\n- IPV4 Address: Internal IPV4 address\\n- IPV4 Address (External): External IPV4 address\\n- MAC Address: MAC address\\n\\n## Considerations and Alternatives\\n\\nSince we\'re writing this function on Ubuntu, there might be unexpected developments on other operating systems.\\n\\nHere are a few points to note:\\n\\n- Due to OS limitations, some functions may not run on all platforms. For example, `get_cpu_info` won\'t display the complete CPU model on Windows. In such cases, consider using other tools or manually obtaining this information.\\n- If you\'re on Windows, you can\'t directly use `nvidia-smi` to get GPU information. Make sure you have NVIDIA drivers and related tools installed and execute it in a command prompt window.\\n- External IP address is fetched from `https://httpbin.org/ip`, so ensure an active internet connection.\\n\\n## Code\\n\\n```python showLineNumbers\\nimport platform\\nimport socket\\nimport subprocess\\n\\nimport psutil\\nimport requests\\n\\n\\ndef get_package_versions():\\n    \\"\\"\\"\\n    Get versions of commonly used packages in deep learning and data science.\\n\\n    Returns:\\n        dict: Dictionary containing versions of installed packages.\\n    \\"\\"\\"\\n    versions_info = {}\\n\\n    # PyTorch\\n    try:\\n        import torch\\n        versions_info[\\"PyTorch Version\\"] = torch.__version__\\n    except Exception as e:\\n        versions_info[\\"PyTorch Error\\"] = str(e)\\n\\n    # PyTorch Lightning\\n    try:\\n        import pytorch_lightning as pl\\n        versions_info[\\"PyTorch Lightning Version\\"] = pl.__version__\\n    except Exception as e:\\n        versions_info[\\"PyTorch Lightning Error\\"] = str(e)\\n\\n    # TensorFlow\\n    try:\\n        import tensorflow as tf\\n        versions_info[\\"TensorFlow Version\\"] = tf.__version__\\n    except Exception as e:\\n        versions_info[\\"TensorFlow Error\\"] = str(e)\\n\\n    # Keras\\n    try:\\n        import keras\\n        versions_info[\\"Keras Version\\"] = keras.__version__\\n    except Exception as e:\\n        versions_info[\\"Keras Error\\"] = str(e)\\n\\n    # NumPy\\n    try:\\n        import numpy as np\\n        versions_info[\\"NumPy Version\\"] = np.__version__\\n    except Exception as e:\\n        versions_info[\\"NumPy Error\\"] = str(e)\\n\\n    # Pandas\\n    try:\\n        import pandas as pd\\n        versions_info[\\"Pandas Version\\"] = pd.__version__\\n    except Exception as e:\\n        versions_info[\\"Pandas Error\\"] = str(e)\\n\\n    # Scikit-learn\\n    try:\\n        import sklearn\\n        versions_info[\\"Scikit-learn Version\\"] = sklearn.__version__\\n    except Exception as e:\\n        versions_info[\\"Scikit-learn Error\\"] = str(e)\\n\\n    # OpenCV\\n    try:\\n        import cv2\\n        versions_info[\\"OpenCV Version\\"] = cv2.__version__\\n    except Exception as e:\\n        versions_info[\\"OpenCV Error\\"] = str(e)\\n\\n    # ... and so on for any other packages you\\"re interested in\\n\\n    return versions_info\\n\\n\\ndef get_gpu_cuda_versions():\\n    \\"\\"\\"\\n    Get GPU and CUDA versions using popular Python libraries.\\n\\n    Returns:\\n        dict: Dictionary containing CUDA and GPU driver versions.\\n    \\"\\"\\"\\n\\n    cuda_version = None\\n\\n    # Attempt to retrieve CUDA version using PyTorch\\n    try:\\n        import torch\\n        cuda_version = torch.version.cuda\\n    except ImportError:\\n        pass\\n\\n    # If not retrieved via PyTorch, try using TensorFlow\\n    if not cuda_version:\\n        try:\\n            import tensorflow as tf\\n            cuda_version = tf.version.COMPILER_VERSION\\n        except ImportError:\\n            pass\\n\\n    # If still not retrieved, try using CuPy\\n    if not cuda_version:\\n        try:\\n            import cupy\\n            cuda_version = cupy.cuda.runtime.runtimeGetVersion()\\n        except ImportError:\\n            cuda_version = \\"Error: None of PyTorch, TensorFlow, or CuPy are installed.\\"\\n\\n    # Try to get Nvidia driver version using nvidia-smi command\\n    try:\\n        smi_output = subprocess.check_output([\\n            \\"nvidia-smi\\",\\n            \\"--query-gpu=driver_version\\",\\n            \\"--format=csv,noheader,nounits\\"\\n        ]).decode(\\"utf-8\\").strip()\\n        nvidia_driver_version = smi_output.split(\\"\\\\n\\")[0]\\n    except Exception as e:\\n        nvidia_driver_version = f\\"Error getting NVIDIA driver version: {e}\\"\\n\\n    return {\\n        \\"CUDA Version\\": cuda_version,\\n        \\"NVIDIA Driver Version\\": nvidia_driver_version\\n    }\\n\\n\\ndef get_cpu_info():\\n    \\"\\"\\"\\n    Retrieve the CPU model name based on the platform.\\n\\n    Returns:\\n        str: CPU model name or \\"N/A\\" if not found.\\n    \\"\\"\\"\\n    if platform.system() == \\"Windows\\":\\n        return platform.processor()\\n    elif platform.system() == \\"Darwin\\":\\n        # For macOS\\n        command = \\"sysctl -n machdep.cpu.brand_string\\"\\n        return subprocess.check_output(command, shell=True).strip().decode()\\n    elif platform.system() == \\"Linux\\":\\n        # For Linux\\n        command = \\"cat /proc/cpuinfo | grep \\"model name\\" | uniq\\"\\n        return subprocess.check_output(command, shell=True).strip().decode().split(\\":\\")[1].strip()\\n    else:\\n        return \\"N/A\\"\\n\\n\\ndef get_external_ip():\\n    try:\\n        response = requests.get(\\"https://httpbin.org/ip\\")\\n        return response.json()[\\"origin\\"]\\n    except Exception as e:\\n        return f\\"Error obtaining IP: {e}\\"\\n\\n\\ndef get_system_info():\\n    \\"\\"\\"\\n    Fetch system information like OS version, CPU info, RAM, Disk usage, etc.\\n\\n    Returns:\\n        dict: Dictionary containing system information.\\n    \\"\\"\\"\\n    info = {\\n        \\"OS Version\\": platform.platform(),\\n        \\"CPU Model\\": get_cpu_info(),\\n        \\"Physical CPU Cores\\": psutil.cpu_count(logical=False),\\n        \\"Logical CPU Cores (incl. hyper-threading)\\": psutil.cpu_count(logical=True),\\n        \\"Total RAM (GB)\\": round(psutil.virtual_memory().total / (1024 ** 3), 2),\\n        \\"Available RAM (GB)\\": round(psutil.virtual_memory().available / (1024 ** 3), 2),\\n        \\"Disk Total (GB)\\": round(psutil.disk_usage(\\"/\\").total / (1024 ** 3), 2),\\n        \\"Disk Used (GB)\\": round(psutil.disk_usage(\\"/\\").used / (1024 ** 3), 2),\\n        \\"Disk Free (GB)\\": round(psutil.disk_usage(\\"/\\").free / (1024 ** 3), 2)\\n    }\\n\\n    # Try to fetch GPU information using nvidia-smi command\\n    try:\\n        gpu_info = subprocess.check_output(\\n            [\\"nvidia-smi\\", \\"--query-gpu=name\\", \\"--format=csv,noheader,nounits\\"]\\n        ).decode(\\"utf-8\\").strip()\\n        info[\\"GPU Info\\"] = gpu_info\\n    except Exception:\\n        info[\\"GPU Info\\"] = \\"N/A or Error\\"\\n\\n    # Get network information\\n    addrs = psutil.net_if_addrs()\\n    info[\\"IPV4 Address\\"] = [\\n        addr.address for addr in addrs.get(\\"enp5s0\\", []) if addr.family == socket.AF_INET\\n    ]\\n\\n    info[\\"IPV4 Address (External)\\"] = get_external_ip()\\n\\n    # Determine platform and choose correct address family for MAC\\n    if hasattr(socket, \\"AF_LINK\\"):\\n        AF_LINK = socket.AF_LINK\\n    elif hasattr(psutil, \\"AF_LINK\\"):\\n        AF_LINK = psutil.AF_LINK\\n    else:\\n        raise Exception(\\n            \\"Cannot determine the correct AF_LINK value for this platform.\\")\\n\\n    info[\\"MAC Address\\"] = [\\n        addr.address for addr in addrs.get(\\"enp5s0\\", []) if addr.family == AF_LINK\\n    ]\\n\\n    return info\\n```"},{"id":"setting-up-pypiserver-on-ubuntu-with-docker","metadata":{"permalink":"/en/blog/setting-up-pypiserver-on-ubuntu-with-docker","source":"@site/i18n/en/docusaurus-plugin-content-blog/2023/09-13-ubuntu-docker-pypiserver/index.md","title":"Setting Up PyPiServer on Ubuntu","description":"Setting up PyPiServer on Ubuntu using Docker.","date":"2023-09-13T00:00:00.000Z","tags":[{"inline":true,"label":"docker","permalink":"/en/blog/tags/docker"},{"inline":true,"label":"pypiserver","permalink":"/en/blog/tags/pypiserver"}],"readingTime":4.065,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"setting-up-pypiserver-on-ubuntu-with-docker","title":"Setting Up PyPiServer on Ubuntu","authors":"Zephyr","tags":["docker","pypiserver"],"image":"/en/img/2023/0913.webp","description":"Setting up PyPiServer on Ubuntu using Docker."},"unlisted":false,"prevItem":{"title":"Recording Model Training Environment Issues","permalink":"/en/blog/python-env-info-collector"},"nextItem":{"title":"Setting Up SSH Server on Ubuntu","permalink":"/en/blog/ubuntu-install-ssh"}},"content":"Today, we\u2019ll document the process of setting up a PyPi Server using Docker on Ubuntu.\\n\\nWe assume you have Docker installed on Ubuntu and are familiar with basic Docker operations.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Pull the Image\\n\\n```bash\\ndocker pull pypiserver/pypiserver:latest\\n```\\n\\n## Create a Directory\\n\\nLet\u2019s quickly create a directory in the home directory to store Python packages.\\n\\n```bash\\nmkdir ~/packages\\n```\\n\\nYou can use a different name if you prefer, but remember to adjust it in the configuration files.\\n\\n## Set up htpasswd\\n\\n:::tip\\nIf you don\u2019t want to set a password, you can skip this step.\\n:::\\n\\nhtpasswd is a file format for storing usernames and passwords, which pypiserver uses for user authentication. This is a simple and effective way to enhance pypiserver\u2019s security.\\n\\nFirst, install `apache2-utils`:\\n\\n```bash\\nsudo apt install apache2-utils\\n```\\n\\nThen, use the following command to create a new `.htpasswd` file:\\n\\n```bash\\nhtpasswd -c ~/.htpasswd [username]\\n```\\n\\nYou will be prompted to enter a password for `username`. After entering the password, the `.htpasswd` file will be created in your home directory.\\n\\nOnce the file is created, you can run `pypiserver` with the `docker run` command and enable authentication with the `.htpasswd` file.\\n\\n## Run as a Background Service\\n\\nTo run the Docker container as a background service, we\u2019ll use Docker Compose with Systemd.\\n\\n### Install Docker Compose\\n\\nIf you haven\u2019t installed Docker Compose, start by doing so:\\n\\n- [**Official Docker Compose Installation Guide**](https://docs.docker.com/compose/install/)\\n\\nDocker Compose has recently undergone major updates, changing many commands. Notably, `docker-compose` has been replaced by `docker compose`.\\n\\nInstall the latest version of Docker Compose:\\n\\n```bash\\nsudo apt update\\nsudo apt install docker-compose-plugin\\n```\\n\\nVerify the installation:\\n\\n```bash\\ndocker compose version\\n```\\n\\n### Create a Configuration File\\n\\nFind a location to create the `docker-compose.yml` file and add the following content:\\n\\n```yaml\\nversion: \\"3.3\\"\\nservices:\\n  pypiserver:\\n    image: pypiserver/pypiserver:latest\\n    volumes:\\n      - /home/[username]/auth:/data/auth\\n      - /home/[username]/packages:/data/packages\\n    command: run -P /data/auth/.htpasswd -a update,download,list /data/packages\\n    ports:\\n      - \\"8080:8080\\"\\n```\\n\\n- Replace `[username]` with your actual username.\\n- You can modify the external port mapping if needed, for example: `\\"18080:8080\\"`.\\n\\n:::tip\\nYou can refer to `pypiserver`\u2019s example file here: [**docker-compose.yml**](https://github.com/pypiserver/pypiserver/blob/master/docker-compose.yml)\\n:::\\n\\nIf you want to skip setting a password, modify the `command` line as follows:\\n\\n```yaml\\ncommand: run -a . -P . /data/packages --server wsgiref\\n```\\n\\n### Set up a Systemd Service\\n\\nCreate a configuration file:\\n\\n```bash\\nsudo vim /etc/systemd/system/pypiserver.service\\n```\\n\\nAdd the following content:\\n\\n```bash\\n[Unit]\\nDescription=PypiServer Docker Compose\\nRequires=docker.service\\nAfter=docker.service\\n\\n[Service]\\nWorkingDirectory=/path/to/your/docker-compose/directory\\nExecStart=/usr/bin/docker compose up --remove-orphans\\nExecStop=/usr/bin/docker compose down\\nRestart=always\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\n- Replace `/path/to/your/docker-compose/directory` with the actual path to the `docker-compose.yml` file (only the path, not the filename).\\n- Ensure the Docker path is correct by using `which docker` to confirm.\\n- This setup uses the new `docker compose` command instead of `docker-compose`.\\n\\n### Start the Service\\n\\nLet systemd know about the new service configuration:\\n\\n```bash\\nsudo systemctl daemon-reload\\n```\\n\\nStart the service:\\n\\n```bash\\nsudo systemctl enable pypiserver.service\\nsudo systemctl start pypiserver.service\\n```\\n\\n## Check the Status\\n\\nTo check the current status of the service, use:\\n\\n```bash\\nsudo systemctl status pypiserver.service\\n```\\n\\nThis will display the current status of the `pypiserver` service, including whether it\u2019s running and the latest log output.\\n\\n## Start Using the Server\\n\\nYou can now use `pip` to install and upload packages.\\n\\n### Uploading Packages\\n\\nLet\u2019s say you have a package named `example_package-0.1-py3-none-any.whl`.\\n\\nUse `twine` to upload the package:\\n\\n```bash\\npip install twine\\ntwine upload --repository-url http://localhost:8080/ example_package-0.1-py3-none-any.whl\\n```\\n\\n- Make sure that `localhost:8080` is the address and port of your pypiserver.\\n\\n### Downloading and Installing Packages\\n\\nUse `pip` to install packages by specifying the address and port of `pypiserver`:\\n\\n```bash\\npip install --index-url http://localhost:8080/ example_package\\n```\\n\\n### Using Basic Authentication\\n\\nIf you set up basic authentication for your pypiserver, you\u2019ll need to provide credentials when uploading or downloading:\\n\\n- To upload a package:\\n\\n  ```bash\\n  twine upload \\\\\\n    --repository-url http://localhost:8080/ \\\\\\n    --username [username] \\\\\\n    --password [password] \\\\\\n    example_package-0.1-py3-none-any.whl\\n  ```\\n\\n- To install a package:\\n\\n  ```bash\\n  pip install \\\\\\n    --index-url http://[username]:[password]@localhost:8080/ \\\\\\n    example_package\\n  ```\\n\\n## Configuring `pip.conf`\\n\\nTo avoid specifying `--index-url` each time you use `pip install`, we can add the relevant configuration to `pip.conf`.\\n\\n### Configuration File\\n\\nThe `pip.conf` file can be located in several places, with the following order of precedence:\\n\\n- Level 1: Site-level configuration:\\n\\n  - `/home/[username]/.pyenv/versions/3.8.18/envs/main/pip.conf`\\n\\n- Level 2: User-level configuration:\\n\\n  - `/home/[username]/.pip/pip.conf`\\n  - `/home/[username]/.config/pip/pip.conf`\\n\\n- Level 3: Global configuration:\\n\\n  - `/etc/pip.conf`\\n  - `/etc/xdg/pip/pip.conf`\\n\\nIdentify the file that corresponds to your Python environment and add the following content:\\n\\n```bash\\n[global]\\nindex-url = http://[server_ip]:8080/\\ntrusted-host = [server_ip]\\n```\\n\\nAgain, replace `[server_ip]:8080` with the correct address and port of your `pypiserver`.\\n\\nAfter setting this up, the server address configured in `pip.conf` will automatically be used as the package source when you use `pip install [package_name]`.\\n\\n## Conclusion\\n\\nYou\u2019ve now successfully set up your own PyPI server, and you know how to upload and download packages.\\n\\nWe hope this guide solves your problem."},{"id":"ubuntu-install-ssh","metadata":{"permalink":"/en/blog/ubuntu-install-ssh","source":"@site/i18n/en/docusaurus-plugin-content-blog/2023/09-12-ubuntu-install-ssh/index.md","title":"Setting Up SSH Server on Ubuntu","description":"Tutorial on configuring ssh server.","date":"2023-09-12T00:00:00.000Z","tags":[{"inline":true,"label":"ubuntu","permalink":"/en/blog/tags/ubuntu"},{"inline":true,"label":"ssh","permalink":"/en/blog/tags/ssh"}],"readingTime":1.565,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"ubuntu-install-ssh","title":"Setting Up SSH Server on Ubuntu","authors":"Zephyr","tags":["ubuntu","ssh"],"image":"/en/img/2023/0912.webp","description":"Tutorial on configuring ssh server."},"unlisted":false,"prevItem":{"title":"Setting Up PyPiServer on Ubuntu","permalink":"/en/blog/setting-up-pypiserver-on-ubuntu-with-docker"},"nextItem":{"title":"Automating GitHub Runner with Systemd","permalink":"/en/blog/ubuntu-github-runner-systemd"}},"content":"SSH is a network protocol that allows users to securely access and manage remote servers. This time, we will set up passwordless login.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Installing the OpenSSH Server\\n\\nOpen the terminal.\\n\\nEnter the following commands to install the OpenSSH server:\\n\\n```bash\\nsudo apt update\\nsudo apt install openssh-server\\n```\\n\\n## Check SSH Server Status\\n\\nUse the following command to check the status of the SSH server:\\n\\n```bash\\nsudo systemctl status ssh\\n```\\n\\nIf you see \u201CActive: active (running),\u201D then the SSH server has started successfully.\\n\\n## SSH Passwordless Login Setup:\\n\\n### Generate SSH Key Pair on the Client Side\\n\\nOpen the terminal.\\n\\nEnter the following command to generate an SSH key pair:\\n\\n```bash\\nssh-keygen\\n```\\n\\nFollow the prompts. The default settings are usually sufficient. When prompted for a passphrase, you can simply press Enter to create a key pair without a password.\\n\\n### Copy the Public Key to the Server\\n\\nUse the `ssh-copy-id` command to copy the public key to the server. Replace `[username]` and `[server-ip]` with your server details.\\n\\n```bash\\nssh-copy-id [username]@[server-ip]\\n```\\n\\nFor example:\\n\\n```bash\\nssh-copy-id john@192.168.0.100\\n```\\n\\nIf your server uses a non-default SSH port (e.g., 2222), use the `-p` parameter:\\n\\n```bash\\nssh-copy-id -p 2222 john@192.168.0.100\\n```\\n\\nThis command will prompt you to enter the server password.\\n\\nOnce authentication is successful, your public key will be added to the server\u2019s `~/.ssh/authorized_keys` file.\\n\\n### Test Passwordless Login\\n\\nTry SSH-ing into the server:\\n\\n```bash\\nssh [username]@[server-ip]\\n```\\n\\nIf everything is set up correctly, you should be able to log in to the server without a password.\\n\\n## Disable Password Authentication\\n\\nWith SSH keys configured, you may consider disabling password authentication for added security.\\n\\nThis can be set in the server\u2019s `/etc/ssh/sshd_config` file:\\n\\n```bash\\nsudo vim /etc/ssh/sshd_config\\n```\\n\\nFind the `PasswordAuthentication` option in the file and set it to `no`.\\n\\nAfter completing these steps, you\u2019re ready to enjoy using SSH!"},{"id":"ubuntu-github-runner-systemd","metadata":{"permalink":"/en/blog/ubuntu-github-runner-systemd","source":"@site/i18n/en/docusaurus-plugin-content-blog/2023/09-10-ubuntu-github-action-runner-systemd/index.md","title":"Automating GitHub Runner with Systemd","description":"Running automatically with Ubuntu Systemd.","date":"2023-09-10T00:00:00.000Z","tags":[{"inline":true,"label":"github-action","permalink":"/en/blog/tags/github-action"},{"inline":true,"label":"runner","permalink":"/en/blog/tags/runner"}],"readingTime":2.245,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"ubuntu-github-runner-systemd","title":"Automating GitHub Runner with Systemd","authors":"Zephyr","tags":["github-action","runner"],"image":"/en/img/2023/0910.webp","description":"Running automatically with Ubuntu Systemd."},"unlisted":false,"prevItem":{"title":"Setting Up SSH Server on Ubuntu","permalink":"/en/blog/ubuntu-install-ssh"},"nextItem":{"title":"Logging into RTF8207W Router","permalink":"/en/blog/login-rtf8207w"}},"content":"In collaborative development on GitHub, we often use private hosts to manage CI/CD workflows. GitHub provides documentation for setting up a self-hosted runner, and by following these steps, you can get the runner up and running quickly.\\n\\n\x3c!-- truncate --\x3e\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"80%\\"}}>\\n![github_set_runner](./img/github_set_runner.jpg)\\n</figure>\\n<figcaption>Documentation Screenshot</figcaption>\\n</div>\\n\\n## The Issue\\n\\nHowever, after setup, if the host machine is restarted for any reason, the runner does not automatically start. Often, this issue goes unnoticed until someone realizes that CI/CD jobs have stopped running, sometimes several days later.\\n\\nThis situation can happen repeatedly and become quite a nuisance. So, to prevent this, we need to configure the runner to start automatically on boot!\\n\\n## Setup Process\\n\\nTo automatically run a task on system startup, we\u2019ll use `systemd`.\\n\\n1. **Create a New `systemd` Service File:**\\n\\n   ```bash\\n   sudo vim /etc/systemd/system/actions-runner.service\\n   ```\\n\\n2. **Paste the Following Content into the File:**\\n\\n   ```bash {7-9}\\n   [Unit]\\n   Description=GitHub Action Runner\\n   After=network.target\\n\\n   [Service]\\n   Type=simple\\n   User=your-username\\n   WorkingDirectory=/home/your-username/actions-runner\\n   ExecStart=/home/your-username/actions-runner/run.sh\\n   Restart=always\\n   RestartSec=5\\n\\n   [Install]\\n   WantedBy=multi-user.target\\n   ```\\n\\n   Pay close attention to the following fields:\\n\\n   - `User`, `ExecStart`, and `WorkingDirectory` should be updated with your specific username.\\n\\n3. **Reload `systemd` to Apply the New Service Configuration:**\\n\\n   ```bash\\n   sudo systemctl daemon-reload\\n   ```\\n\\n4. **Enable the Service to Start on Boot:**\\n\\n   ```bash\\n   sudo systemctl enable actions-runner.service\\n   ```\\n\\n5. **Start the Service Manually or Reboot to Test:**\\n\\n   ```bash\\n   sudo systemctl start actions-runner.service\\n   ```\\n\\nWith this setup, the `actions-runner` will automatically run in the background whenever your machine boots.\\n\\nTo stop the service, you can use the following command:\\n\\n```bash\\nsudo systemctl stop actions-runner.service\\n```\\n\\n:::warning\\nEnsure that `run.sh` has executable permissions.\\n:::\\n\\n## Checking Service Status\\n\\nWith `systemd` managing the service, you can check the logs to monitor the runner\u2019s status.\\n\\nUse the following command to view logs:\\n\\n```bash\\nsudo journalctl -u actions-runner.service -f\\n```\\n\\nExplanation:\\n\\n- `-u actions-runner.service`: Displays logs for the `actions-runner` service only.\\n- `-f`: Follows the log output, allowing you to monitor new entries in real-time.\\n\\nIf you want to check the service\u2019s current status, use:\\n\\n```bash\\nsudo systemctl status actions-runner.service\\n```\\n\\nThis command displays the current status of the `actions-runner` service, including whether it\u2019s running and recent log output:\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"80%\\"}}>\\n![action-service](./img/action-service.jpg)\\n</figure>\\n</div>\\n\\n## Reconfiguring the Runner\\n\\nIf the original runner configuration is missing, this might occur when switching the repository\u2019s visibility between Public and Private, or if the runner has been inactive for a long time. In such cases, you\u2019ll need to reconfigure the runner.\\n\\nTo do this, go to the `actions-runner` directory, delete the `.runner` file, and re-run the configuration script:\\n\\n```bash\\n./config.sh --url ... (use the new token configuration)\\n```\\n\\nAfter completing the setup, restart the service to ensure everything is running smoothly."},{"id":"login-rtf8207w","metadata":{"permalink":"/en/blog/login-rtf8207w","source":"@site/i18n/en/docusaurus-plugin-content-blog/2023/09-04-login-rtf8207w/index.md","title":"Logging into RTF8207W Router","description":"RTF8207W account and password.","date":"2023-09-04T00:00:00.000Z","tags":[{"inline":true,"label":"rtf8207w","permalink":"/en/blog/tags/rtf-8207-w"}],"readingTime":0.69,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"login-rtf8207w","title":"Logging into RTF8207W Router","authors":"Zephyr","tags":["rtf8207w"],"image":"/en/img/2023/0904.webp","description":"RTF8207W account and password."},"unlisted":false,"prevItem":{"title":"Automating GitHub Runner with Systemd","permalink":"/en/blog/ubuntu-github-runner-systemd"},"nextItem":{"title":"Fail2ban: Protecting SSH Service","permalink":"/en/blog/fail2ban-settings"}},"content":"Today, we\'re going to talk about logging into Chunghwa Telecom\'s little turtle, the RTF8207W modem.\\n\\n\x3c!-- truncate --\x3e\\n\\n### 1. Accessing the Management Interface\\n\\nTypically, you can access it through a web browser by entering `192.168.1.1` or another IP address. The specific address might vary depending on your router model.\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"60%\\"}}>\\n![login-rtf8207w](./img/RTF8207W-login.jpg)\\n</figure>\\n</div>\\n\\n### 2. Default Credentials\\n\\nUsually, the username is: `cht`, and the password is `last four digits of the model + last four digits of the MAC address`.\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"60%\\"}}>\\n![password](./img/RTF8207W.jpg)\\n</figure>\\n</div>\\n\\n### 3. Logging In\\n\\nAnd then, you\'re free to do as you please.\\n\\n:::danger\\nIf you accidentally mess up the settings, causing a network collapse and loss of connection, please contact **Chunghwa Telecom technicians**.\\n\\nThis article is for reference only and assumes no responsibility.\\n:::"},{"id":"fail2ban-settings","metadata":{"permalink":"/en/blog/fail2ban-settings","source":"@site/i18n/en/docusaurus-plugin-content-blog/2023/09-03-fail2ban-settings/index.md","title":"Fail2ban: Protecting SSH Service","description":"Keeping the malicious out.","date":"2023-09-03T00:00:00.000Z","tags":[{"inline":true,"label":"ubuntu","permalink":"/en/blog/tags/ubuntu"},{"inline":true,"label":"fail2ban","permalink":"/en/blog/tags/fail-2-ban"}],"readingTime":1.75,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"fail2ban-settings","title":"Fail2ban: Protecting SSH Service","authors":"Zephyr","tags":["ubuntu","fail2ban"],"image":"/en/img/2023/0903.webp","description":"Keeping the malicious out."},"unlisted":false,"prevItem":{"title":"Logging into RTF8207W Router","permalink":"/en/blog/login-rtf8207w"},"nextItem":{"title":"Unicode Table","permalink":"/en/blog/unicode-table"}},"content":"As soon as you successfully open an external SSH channel, you\'ll notice a barrage of malicious connections attempting to log into your host.\\n\\n\x3c!-- truncate --\x3e\\n\\n<div align=\\"center\\">\\n<figure style={{\\"width\\": \\"40%\\"}}>\\n![attack from ssh](./img/ban_1.jpg)\\n</figure>\\n<figcaption>Malicious Attack Illustration</figcaption>\\n</div>\\n\\n---\\n\\nCommon practice is to use Fail2ban to protect our host. It\'s software designed to protect servers from brute force attacks.\\n\\nIt automatically adjusts firewall rules to block attackers\' IP addresses when suspicious behavior, such as repeated login failures, occurs.\\n\\n## 1. Installation of Fail2ban\\n\\nOn most Linux distributions, you can install Fail2ban using package management tools.\\n\\nOn Ubuntu, you can use apt to install:\\n\\n```bash\\nsudo apt install fail2ban\\n```\\n\\n## 2. Configuration\\n\\nThe configuration file is located at `/etc/fail2ban/jail.conf`.\\n\\nIt\'s recommended not to modify this file directly but to make a copy named `jail.local` and edit it:\\n\\n```bash\\nsudo cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local\\n```\\n\\nEdit `jail.local`:\\n\\n```bash\\nsudo vim /etc/fail2ban/jail.local\\n```\\n\\n**Important configuration parameters:**\\n\\n- **ignoreip:** Ignored IP addresses or networks, e.g., 127.0.0.1/8\\n- **bantime:** Duration of the ban in seconds (default is 600 seconds)\\n- **findtime:** How many failures within this time frame (default is 600 seconds)\\n- **maxretry:** Maximum number of failed attempts allowed within findtime.\\n\\n## 3. Start and Monitor\\n\\nStart Fail2ban:\\n\\n```bash\\nsudo service fail2ban start\\n```\\n\\nCheck Fail2ban\'s status:\\n\\n```bash\\nsudo fail2ban-client status\\n```\\n\\n## 4. Adding Custom Rules\\n\\nIf you want to set specific rules for particular services (e.g., SSH or Apache), you can add or modify corresponding sections in `jail.local`, for example, SSH settings:\\n\\n```bash\\n[sshd]\\nenabled = true\\nport = ssh\\nfilter = sshd\\nlogpath = /var/log/auth.log\\nmaxretry = 3\\n```\\n\\n## 5. Testing\\n\\nAfter making configuration changes, restart Fail2ban to apply the changes:\\n\\n```bash\\nsudo service fail2ban restart\\n```\\n\\nThen, from another machine or using a different IP, attempt multiple failed logins to see if it gets blocked.\\n\\n## 6. Review\\n\\nEnsure to periodically check log files and update rules for the best protection.\\n\\n```bash\\nsudo fail2ban-client status sshd\\n```\\n\\n## Conclusion\\n\\nThe entire process is somewhat meticulous but not overly complex.\\n\\nHopefully, this guide helps you smoothly complete the setup."},{"id":"unicode-table","metadata":{"permalink":"/en/blog/unicode-table","source":"@site/i18n/en/docusaurus-plugin-content-blog/2023/09-02-unicode-table/index.md","title":"Unicode Table","description":"Unicode Table for easy reference.","date":"2023-09-02T00:00:00.000Z","tags":[{"inline":true,"label":"unicode","permalink":"/en/blog/tags/unicode"}],"readingTime":25.63,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"unicode-table","title":"Unicode Table","authors":"Zephyr","tags":["unicode"],"image":"/en/img/2023/0902.webp","description":"Unicode Table for easy reference."},"unlisted":false,"prevItem":{"title":"Fail2ban: Protecting SSH Service","permalink":"/en/blog/fail2ban-settings"},"nextItem":{"title":"Setting Up Selective Traffic Routing for VPN on Mac","permalink":"/en/blog/mac-selective-vpn-routing"}},"content":"Unicode is an international character encoding standard maintained by the non-profit organization Unicode Consortium. The standard unifies most of the world\'s writing systems, enabling information exchange across platforms and languages.\\n\\n\x3c!-- truncate --\x3e\\n\\nIn the Unicode standard, each character corresponds to a unique numerical code, known as a \\"code point.\\" The code point is an essential concept in the Unicode standard, used to determine the position of each unique character. The code points range from `U+0000` to `U+10FFFF`, meaning it can accommodate 1,114,112 different characters.\\n\\nThese code points are divided into multiple subsets based on different functions and purposes, such as:\\n\\n- **Basic Multilingual Plane (BMP)**: Includes common characters like Latin letters, Greek letters, Chinese characters, etc.\\n- **Supplementary Planes**: Includes additional ideographic characters, supplementary characters, etc.\\n\\nGiven that we always spend half an hour looking up Unicode encoding every time we need it, it\'s better to store some basic information.\\n\\n:::tip\\nIf you require further details, we recommend consulting the original table: [**Unicode Code Points**](https://en.wikipedia.org/wiki/Unicode#Code_points)\\n:::\\n\\n## \u53C3\u8003\u8CC7\u6599\\n\\n- [Unicode \u5B57\u5143\u5E73\u9762\u5C0D\u6620](https://zh.wikipedia.org/zh-tw/Unicode%E5%AD%97%E7%AC%A6%E5%B9%B3%E9%9D%A2%E6%98%A0%E5%B0%84)\\n- [Unicode \u5340\u6BB5](https://zh.wikipedia.org/zh-tw/Unicode%E5%8D%80%E6%AE%B5)\\n\\n## Unicode Code Point Range Table\\n\\nIf you require further details, we recommend consulting the original table: [**Unicode Code Points**](https://en.wikipedia.org/wiki/Unicode#Code_points)\\n\\n|  Plane   | Code Point Range |         Chinese Name         |                   English Name                   |\\n| :------: | :--------------: | :--------------------------: | :----------------------------------------------: |\\n|  0 BMP   |    0000-007F     |         \u57FA\u672C\u62C9\u4E01\u5B57\u6BCD         |                   Basic Latin                    |\\n|  0 BMP   |    0080-00FF     |        \u62C9\u4E01\u5B57\u6BCD\u88DC\u5145-1        |                Latin-1 Supplement                |\\n|  0 BMP   |    0100-017F     |        \u62C9\u4E01\u5B57\u6BCD\u64F4\u5C55-A        |                 Latin Extended-A                 |\\n|  0 BMP   |    0180-024F     |        \u62C9\u4E01\u5B57\u6BCD\u64F4\u5C55-B        |                 Latin Extended-B                 |\\n|  0 BMP   |    0250-02AF     |         \u570B\u969B\u97F3\u6A19\u64F4\u5C55         |                  IPA Extensions                  |\\n|  0 BMP   |    02B0-02FF     |         \u4F54\u4F4D\u4FEE\u98FE\u7B26\u865F         |             Spacing Modifier Letters             |\\n|  0 BMP   |    0300-036F     |         \u7D44\u5408\u9644\u52A0\u7B26\u865F         |           Combining Diacritical Marks            |\\n|  0 BMP   |    0370-03FF     |     \u5E0C\u81D8\u5B57\u6BCD\u548C\u79D1\u666E\u7279\u5B57\u6BCD     |                 Greek and Coptic                 |\\n|  0 BMP   |    0400-04FF     |          \u897F\u91CC\u723E\u5B57\u6BCD          |                     Cyrillic                     |\\n|  0 BMP   |    0500-052F     |        \u897F\u91CC\u723E\u5B57\u6BCD\u88DC\u5145        |               Cyrillic Supplement                |\\n|  0 BMP   |    0530-058F     |         \u4E9E\u7F8E\u5C3C\u4E9E\u5B57\u6BCD         |                     Armenian                     |\\n|  0 BMP   |    0590-05FF     |         \u5E0C\u4F2F\u4F86\u6587\u5B57\u6BCD         |                      Hebrew                      |\\n|  0 BMP   |    0600-06FF     |         \u963F\u62C9\u4F2F\u6587\u5B57\u6BCD         |                      Arabic                      |\\n|  0 BMP   |    0700-074F     |          \u6558\u5229\u4E9E\u5B57\u6BCD          |                      Syriac                      |\\n|  0 BMP   |    0750-077F     |         \u963F\u62C9\u4F2F\u6587\u88DC\u5145         |                Arabic Supplement                 |\\n|  0 BMP   |    0780-07BF     |           \u5B83\u62FF\u5B57\u6BCD           |                      Thaana                      |\\n|  0 BMP   |    07C0-07FF     |         \u897F\u975E\u66F8\u9762\u6587\u5B57         |                       NKo                        |\\n|  0 BMP   |    0800-083F     |         \u6492\u746A\u5229\u4E9E\u5B57\u6BCD         |                    Samaritan                     |\\n|  0 BMP   |    0840-085F     |          \u66FC\u9054\u5B89\u5B57\u6BCD          |                     Mandaic                      |\\n|  0 BMP   |    0860-086F     |         \u6558\u5229\u4E9E\u6587\u88DC\u5145         |                Syriac Supplement                 |\\n|  0 BMP   |    0870-089F     |       \u963F\u62C9\u4F2F\u5B57\u6BCD\u64F4\u5C55-B       |                Arabic Extended-B                 |\\n|  0 BMP   |    08A0-08FF     |       \u963F\u62C9\u4F2F\u5B57\u6BCD\u64F4\u5C55-A       |                Arabic Extended-A                 |\\n|  0 BMP   |    0900-097F     |            \u5929\u57CE\u6587            |                    Devanagari                    |\\n|  0 BMP   |    0980-09FF     |           \u5B5F\u52A0\u62C9\u6587           |                     Bengali                      |\\n|  0 BMP   |    0A00-0A7F     |           \u53E4\u6728\u57FA\u6587           |                     Gurmukhi                     |\\n|  0 BMP   |    0A80-0AFF     |          \u53E4\u5409\u62C9\u7279\u6587          |                     Gujarati                     |\\n|  0 BMP   |    0B00-0B7F     |           \u5967\u91CC\u4E9E\u6587           |                      Oriya                       |\\n|  0 BMP   |    0B80-0BFF     |           \u6CF0\u7C73\u723E\u6587           |                      Tamil                       |\\n|  0 BMP   |    0C00-0C7F     |           \u6CF0\u76E7\u56FA\u6587           |                      Telugu                      |\\n|  0 BMP   |    0C80-0CFF     |           \u5361\u7D0D\u9054\u6587           |                     Kannada                      |\\n|  0 BMP   |    0D00-0D7F     |         \u99AC\u62C9\u96C5\u62C9\u59C6\u6587         |                    Malayalam                     |\\n|  0 BMP   |    0D80-0DFF     |           \u50E7\u4F3D\u7F85\u6587           |                     Sinhala                      |\\n|  0 BMP   |    0E00-0E7F     |             \u6CF0\u6587             |                       Thai                       |\\n|  0 BMP   |    0E80-0EFF     |             \u5BEE\u6587             |                       Lao                        |\\n|  0 BMP   |    0F00-0FFF     |             \u85CF\u6587             |                     Tibetan                      |\\n|  0 BMP   |    1000-109F     |            \u7DEC\u7538\u6587            |                     Myanmar                      |\\n|  0 BMP   |    10A0-10FF     |          \u55AC\u6CBB\u4E9E\u5B57\u6BCD          |                     Georgian                     |\\n|  0 BMP   |    1100-11FF     |           \u8AFA\u6587\u5B57\u6BCD           |                   Hangul Jamo                    |\\n|  0 BMP   |    1200-137F     |         \u8863\u7D22\u6BD4\u4E9E\u5B57\u6BCD         |                     Ethiopic                     |\\n|  0 BMP   |    1380-139F     |       \u8863\u7D22\u6BD4\u4E9E\u5B57\u6BCD\u88DC\u5145       |               Ethiopic Supplement                |\\n|  0 BMP   |    13A0-13FF     |           \u5207\u7F85\u57FA\u6587           |                     Cherokee                     |\\n|  0 BMP   |    1400-167F     |   \u7D71\u4E00\u52A0\u62FF\u5927\u539F\u4F4F\u6C11\u97F3\u7BC0\u6587\u5B57   |      Unified Canadian Aboriginal Syllabics       |\\n|  0 BMP   |    1680-169F     |           \u6B50\u7518\u5B57\u6BCD           |                      Ogham                       |\\n|  0 BMP   |    16A0-16FF     |           \u76E7\u6069\u5B57\u6BCD           |                      Runic                       |\\n|  0 BMP   |    1700-171F     |          \u4ED6\u52A0\u797F\u5B57\u6BCD          |                     Tagalog                      |\\n|  0 BMP   |    1720-173F     |           \u54C8\u52AA\u8AFE\u6587           |                     Hanunoo                      |\\n|  0 BMP   |    1740-175F     |          \u5E03\u5E0C\u5FB7\u5B57\u6BCD          |                      Buhid                       |\\n|  0 BMP   |    1760-177F     |         \u5854\u683C\u73ED\u74E6\u5B57\u6BCD         |                     Tagbanwa                     |\\n|  0 BMP   |    1780-17FF     |            \u9AD8\u68C9\u6587            |                      Khmer                       |\\n|  0 BMP   |    1800-18AF     |            \u8499\u53E4\u6587            |                    Mongolian                     |\\n|  0 BMP   |    18B0-18FF     | \u7D71\u4E00\u52A0\u62FF\u5927\u539F\u4F4F\u6C11\u97F3\u7BC0\u6587\u5B57\u64F4\u5145 |  Unified Canadian Aboriginal Syllabics Extended  |\\n|  0 BMP   |    1900-194F     |            \u6797\u5E03\u6587            |                      Limbu                       |\\n|  0 BMP   |    1950-197F     |           \u5FB7\u5B8F\u50A3\u6587           |                      Tai Le                      |\\n|  0 BMP   |    1980-19DF     |           \u65B0\u50A3\u4EC2\u6587           |                    New Tai Le                    |\\n|  0 BMP   |    19E0-19FF     |          \u9AD8\u68C9\u6587\u7B26\u865F          |                  Khmer Symbols                   |\\n|  0 BMP   |    1A00-1A1F     |            \u5E03\u5409\u6587            |                     Buginese                     |\\n|  0 BMP   |    1A20-1AAF     |            \u8001\u50A3\u6587            |                     Tai Tham                     |\\n|  0 BMP   |    1AB0-1AFF     |       \u7D44\u5408\u9644\u52A0\u7B26\u865F\u64F4\u5C55       |       Combining Diacritical Marks Extended       |\\n|  0 BMP   |    1B00-1B7F     |           \u5CC7\u91CC\u5B57\u6BCD           |                     Balinese                     |\\n|  0 BMP   |    1B80-1BBF     |           \u5DFD\u4ED6\u5B57\u6BCD           |                    Sundanese                     |\\n|  0 BMP   |    1BC0-1BFF     |          \u5DF4\u5854\u514B\u5B57\u6BCD          |                      Batak                       |\\n|  0 BMP   |    1C00-1C4F     |            \u7D68\u5DF4\u6587            |                      Lepcha                      |\\n|  0 BMP   |    1C50-1C7F     |           \u6851\u5854\u5229\u6587           |                     Ol Chiki                     |\\n|  0 BMP   |    1C80-1C8F     |       \u897F\u91CC\u723E\u5B57\u6BCD\u64F4\u5C55-C       |               Cyrillic Extended-C                |\\n|  0 BMP   |    1C90-1CBF     |        \u55AC\u6CBB\u4E9E\u5B57\u6BCD\u64F4\u5C55        |                Georgian Extended                 |\\n|  0 BMP   |    1CC0-1CCF     |         \u5DFD\u4ED6\u5B57\u6BCD\u88DC\u5145         |               Sundanese Supplement               |\\n|  0 BMP   |    1CD0-1CFF     |           \u5420\u9640\u64F4\u5C55           |                 Vedic Extensions                 |\\n|  0 BMP   |    1D00-1D7F     |           \u97F3\u6A19\u64F4\u5C55           |               Phonetic Extensions                |\\n|  0 BMP   |    1D80-1DBF     |         \u97F3\u6A19\u64F4\u5C55\u88DC\u5145         |          Phonetic Extensions Supplement          |\\n|  0 BMP   |    1DC0-1DFF     |       \u7D44\u5408\u9644\u52A0\u7B26\u865F\u88DC\u5145       |      Combining Diacritical Marks Supplement      |\\n|  0 BMP   |    1E00-1EFF     |       \u62C9\u4E01\u5B57\u6BCD\u64F4\u5C55\u9644\u52A0       |            Latin Extended Additional             |\\n|  0 BMP   |    1F00-1FFF     |         \u5E0C\u81D8\u5B57\u6BCD\u64F4\u5C55         |                  Greek Extended                  |\\n|  0 BMP   |    2000-206F     |           \u4E00\u822C\u6A19\u9EDE           |               General Punctuation                |\\n|  0 BMP   |    2070-209F     |          \u4E0A\u6A19\u53CA\u4E0B\u6A19          |           Superscripts and Subscripts            |\\n|  0 BMP   |    20A0-20CF     |           \u8CA8\u5E63\u7B26\u865F           |                 Currency Symbols                 |\\n|  0 BMP   |    20D0-20FF     |      \u7B26\u865F\u7528\u7D44\u5408\u9644\u52A0\u7B26\u865F      |     Combining Diacritical Marks for Symbols      |\\n|  0 BMP   |    2100-214F     |          \u985E\u5B57\u6BCD\u7B26\u865F          |                Letterlike Symbols                |\\n|  0 BMP   |    2150-218F     |           \u6578\u5B57\u5F62\u5F0F           |                   Number Forms                   |\\n|  0 BMP   |    2190-21FF     |             \u7BAD\u982D             |                      Arrows                      |\\n|  0 BMP   |    2200-22FF     |          \u6578\u5B78\u904B\u7B97\u5B50          |              Mathematical Operators              |\\n|  0 BMP   |    2300-23FF     |         \u96DC\u9805\u6280\u8853\u7B26\u865F         |             Miscellaneous Technical              |\\n|  0 BMP   |    2400-243F     |           \u63A7\u5236\u5716\u5F62           |                 Control Pictures                 |\\n|  0 BMP   |    2440-245F     |         \u5149\u5B78\u5B57\u5143\u8FA8\u8B58         |          Optical Character Recognition           |\\n|  0 BMP   |    2460-24FF     |         \u570D\u7E5E\u5B57\u6BCD\u6578\u5B57         |              Enclosed Alphanumerics              |\\n|  0 BMP   |    2500-257F     |            \u5236\u8868\u7B26            |                   Box Drawing                    |\\n|  0 BMP   |    2580-259F     |           \u65B9\u584A\u5143\u7D20           |                  Block Elements                  |\\n|  0 BMP   |    25A0-25FF     |           \u5E7E\u4F55\u5716\u5F62           |                 Geometric Shapes                 |\\n|  0 BMP   |    2600-26FF     |           \u96DC\u9805\u7B26\u865F           |              Miscellaneous Symbols               |\\n|  0 BMP   |    2700-27BF     |           \u88DD\u98FE\u7B26\u865F           |                     Dingbats                     |\\n|  0 BMP   |    27C0-27EF     |        \u96DC\u9805\u6578\u5B78\u7B26\u865F-A        |       Miscellaneous Mathematical Symbols-A       |\\n|  0 BMP   |    27F0-27FF     |          \u8FFD\u52A0\u7BAD\u982D-A          |              Supplemental Arrows-A               |\\n|  0 BMP   |    2800-28FF     |           \u9EDE\u5B57\u5716\u6848           |                 Braille Patterns                 |\\n|  0 BMP   |    2900-297F     |          \u8FFD\u52A0\u7BAD\u982D-B          |              Supplemental Arrows-B               |\\n|  0 BMP   |    2980-29FF     |        \u96DC\u9805\u6578\u5B78\u7B26\u865F-B        |       Miscellaneous Mathematical Symbols-B       |\\n|  0 BMP   |    2A00-2AFF     |        \u88DC\u5145\u6578\u5B78\u904B\u7B97\u5B50        |       Supplemental Mathematical Operators        |\\n|  0 BMP   |    2B00-2BFF     |        \u96DC\u9805\u7B26\u865F\u548C\u7BAD\u982D        |         Miscellaneous Symbols and Arrows         |\\n|  0 BMP   |    2C00-2C5F     |         \u683C\u62C9\u54E5\u91CC\u5B57\u6BCD         |                    Glagolitic                    |\\n|  0 BMP   |    2C60-2C7F     |        \u62C9\u4E01\u5B57\u6BCD\u64F4\u5C55-C        |                 Latin Extended-C                 |\\n|  0 BMP   |    2C80-2CFF     |          \u79D1\u666E\u7279\u5B57\u6BCD          |                      Coptic                      |\\n|  0 BMP   |    2D00-2D2F     |        \u55AC\u6CBB\u4E9E\u5B57\u6BCD\u88DC\u5145        |               Georgian Supplement                |\\n|  0 BMP   |    2D30-2D7F     |           \u63D0\u975E\u7D0D\u6587           |                     Tifinagh                     |\\n|  0 BMP   |    2D80-2DDF     |       \u8863\u7D22\u6BD4\u4E9E\u5B57\u6BCD\u64F4\u5145       |                Ethiopic Extended                 |\\n|  0 BMP   |    2DE0-2DFF     |       \u897F\u91CC\u723E\u5B57\u6BCD\u64F4\u5C55-A       |               Cyrillic Extended-A                |\\n|  0 BMP   |    2E00-2E7F     |           \u88DC\u5145\u6A19\u9EDE           |             Supplemental Punctuation             |\\n|  0 BMP   |    2E80-2EFF     |      \u4E2D\u65E5\u97D3\u6F22\u5B57\u90E8\u9996\u88DC\u5145      |             CJK Radicals Supplement              |\\n|  0 BMP   |    2F00-2FDF     |           \u5EB7\u7199\u90E8\u9996           |                 Kangxi Radicals                  |\\n|  0 BMP   |    2FF0-2FFF     |       \u8868\u610F\u6587\u5B57\u63CF\u8FF0\u5B57\u5143       |        Ideographic Description Characters        |\\n|  0 BMP   |    3000-303F     |       \u4E2D\u65E5\u97D3\u7B26\u865F\u548C\u6A19\u9EDE       |           CJK Symbols and Punctuation            |\\n|  0 BMP   |    3040-309F     |            \u5E73\u5047\u540D            |                     Hiragana                     |\\n|  0 BMP   |    30A0-30FF     |            \u7247\u5047\u540D            |                     Katakana                     |\\n|  0 BMP   |    3100-312F     |           \u6CE8\u97F3\u7B26\u865F           |                     Bopomofo                     |\\n|  0 BMP   |    3130-318F     |         \u8AFA\u6587\u76F8\u5BB9\u5B57\u6BCD         |            Hangul Compatibility Jamo             |\\n|  0 BMP   |    3190-319F     |         \u6F22\u6587\u8A13\u8B80\u7B26\u865F         |                      Kanbun                      |\\n|  0 BMP   |    31A0-31BF     |         \u6CE8\u97F3\u7B26\u865F\u64F4\u5C55         |                Bopomofo Extended                 |\\n|  0 BMP   |    31C0-31EF     |          \u4E2D\u65E5\u97D3\u7B46\u756B          |                   CJK Strokes                    |\\n|  0 BMP   |    31F0-31FF     |        \u7247\u5047\u540D\u8A9E\u97F3\u64F4\u5C55        |           Katakana Phonetic Extensions           |\\n|  0 BMP   |    3200-32FF     |     \u4E2D\u65E5\u97D3\u570D\u7E5E\u5B57\u5143\u53CA\u6708\u4EFD     |         Enclosed CJK Letters and Months          |\\n|  0 BMP   |    3300-33FF     |        \u4E2D\u65E5\u97D3\u76F8\u5BB9\u5B57\u5143        |                CJK Compatibility                 |\\n|  0 BMP   |    3400-4DBF     |  \u4E2D\u65E5\u97D3\u7D71\u4E00\u8868\u610F\u6587\u5B57\u64F4\u5145\u5340 A  |        CJK Unified Ideographs Extension A        |\\n|  0 BMP   |    4DC0-4DFF     |       \u6613\u7D93\u516D\u5341\u56DB\u5366\u7B26\u865F       |             Yijing Hexagram Symbols              |\\n|  0 BMP   |    4E00-9FFF     | \u4E2D\u65E5\u97D3\u7D71\u4E00\u8868\u610F\u6587\u5B57 (\u57FA\u672C\u5340)  |              CJK Unified Ideographs              |\\n|  0 BMP   |    A000-A48F     |           \u5F5D\u6587\u97F3\u7BC0           |                   Yi Syllables                   |\\n|  0 BMP   |    A490-A4CF     |           \u5F5D\u6587\u90E8\u9996           |                   Yi Radicals                    |\\n|  0 BMP   |    A4D0-A4FF     |            \u5088\u50F3\u6587            |                       Lisu                       |\\n|  0 BMP   |    A500-A63F     |            \u74E6\u4F0A\u6587            |                       Vai                        |\\n|  0 BMP   |    A640-A69F     |       \u897F\u91CC\u723E\u5B57\u6BCD\u64F4\u5C55-B       |               Cyrillic Extended-B                |\\n|  0 BMP   |    A6A0-A6FF     |          \u5DF4\u59C6\u7A46\u6587\u5B57          |                      Bamum                       |\\n|  0 BMP   |    A700-A71F     |         \u8072\u8ABF\u4FEE\u98FE\u7B26\u865F         |              Modifier Tone Letters               |\\n|  0 BMP   |    A720-A7FF     |        \u62C9\u4E01\u5B57\u6BCD\u64F4\u5C55-D        |                 Latin Extended-D                 |\\n|  0 BMP   |    A800-A82F     |          \u932B\u723E\u8D6B\u7279\u6587          |                   Syloti Nagri                   |\\n|  0 BMP   |    A830-A83F     |       \u901A\u7528\u5370\u5EA6\u6578\u5B57\u5F62\u5F0F       |            Common Indic Number Forms             |\\n|  0 BMP   |    A840-A87F     |           \u516B\u601D\u5DF4\u6587           |                     Phags-pa                     |\\n|  0 BMP   |    A880-A8DF     |         \u7D22\u62C9\u4EC0\u7279\u62C9\u6587         |                    Saurashtra                    |\\n|  0 BMP   |    A8E0-A8FF     |          \u5929\u57CE\u6587\u64F4\u5C55          |               Devanagari Extended                |\\n|  0 BMP   |    A900-A92F     |           \u514B\u8036\u5B57\u6BCD           |                     Kayah Li                     |\\n|  0 BMP   |    A930-A95F     |           \u52D2\u59DC\u5B57\u6BCD           |                      Rejang                      |\\n|  0 BMP   |    A960-A97F     |        \u8AFA\u6587\u5B57\u6BCD\u64F4\u5C55-A        |              Hangul Jamo Extended-A              |\\n|  0 BMP   |    A980-A9DF     |           \u722A\u54C7\u5B57\u6BCD           |                     Javanese                     |\\n|  0 BMP   |    A9E0-A9FF     |         \u7DEC\u7538\u6587\u64F4\u5C55-B         |                Myanmar Extended-B                |\\n|  0 BMP   |    AA00-AA5F     |             \u5360\u6587             |                       Cham                       |\\n|  0 BMP   |    AA60-AA7F     |         \u7DEC\u7538\u6587\u64F4\u5C55-A         |                Myanmar Extended-A                |\\n|  0 BMP   |    AA80-AADF     |            \u50A3\u8D8A\u6587            |                     Tai Viet                     |\\n|  0 BMP   |    AAE0-AAFF     |          \u6885\u6CF0\u6587\u64F4\u5145          |             Meetei Mayek Extensions              |\\n|  0 BMP   |    AB00-AB2F     |      \u8863\u7D22\u6BD4\u4E9E\u5B57\u6BCD\u64F4\u5145-A      |               Ethiopic Extended-A                |\\n|  0 BMP   |    AB30-AB6F     |        \u62C9\u4E01\u5B57\u6BCD\u64F4\u5C55-E        |                 Latin Extended-E                 |\\n|  0 BMP   |    AB70-ABBF     |         \u5207\u7F85\u57FA\u6587\u88DC\u5145         |               Cherokee Supplement                |\\n|  0 BMP   |    ABC0-ABFF     |            \u6885\u6CF0\u6587            |                   Meetei Mayek                   |\\n|  0 BMP   |    AC00-D7AF     |           \u8AFA\u6587\u97F3\u7BC0           |                 Hangul Syllables                 |\\n|  0 BMP   |    D7B0-D7FF     |        \u8AFA\u6587\u5B57\u6BCD\u64F4\u5C55-B        |              Hangul Jamo Extended-B              |\\n|  0 BMP   |    D800-DB7F     |          \u9AD8\u534A\u4EE3\u7528\u5340          |                 High Surrogates                  |\\n|  0 BMP   |    DB80-DBFF     |        \u9AD8\u534A\u79C1\u4EBA\u4EE3\u7528\u5340        |           High Private Use Surrogates            |\\n|  0 BMP   |    DC00-DFFF     |          \u4F4E\u534A\u4EE3\u7528\u5340          |                  Low Surrogates                  |\\n|  0 BMP   |    E000-F8FF     |            \u79C1\u7528\u5340            |                 Private Use Area                 |\\n|  0 BMP   |    F900-FAFF     |      \u4E2D\u65E5\u97D3\u76F8\u5BB9\u8868\u610F\u6587\u5B57      |           CJK Compatibility Ideographs           |\\n|  0 BMP   |    FB00-FB4F     |         \u5B57\u6BCD\u8868\u9054\u5F62\u5F0F         |          Alphabetic Presentation Forms           |\\n|  0 BMP   |    FB50-FDFF     |     \u963F\u62C9\u4F2F\u5B57\u6BCD\u8868\u9054\u5F62\u5F0F-A     |           Arabic Presentation Forms-A            |\\n|  0 BMP   |    FE00-FE0F     |          \u8B8A\u9AD4\u9078\u64C7\u7B26          |               Variation Selectors                |\\n|  0 BMP   |    FE10-FE1F     |           \u8C4E\u6392\u5F62\u5F0F           |                  Vertical Forms                  |\\n|  0 BMP   |    FE20-FE2F     |         \u7D44\u5408\u7528\u534A\u7B26\u865F         |               Combining Half Marks               |\\n|  0 BMP   |    FE30-FE4F     |        \u4E2D\u65E5\u97D3\u76F8\u5BB9\u5F62\u5F0F        |             CJK Compatibility Forms              |\\n|  0 BMP   |    FE50-FE6F     |         \u5C0F\u5BEB\u8B8A\u9AD4\u5F62\u5F0F         |               Small Form Variants                |\\n|  0 BMP   |    FE70-FEFF     |     \u963F\u62C9\u4F2F\u5B57\u6BCD\u8868\u9054\u5F62\u5F0F-B     |           Arabic Presentation Forms-B            |\\n|  0 BMP   |    FF00-FFEF     |        \u534A\u5F62\u53CA\u5168\u5F62\u5B57\u5143        |          Halfwidth and Fullwidth Forms           |\\n|  0 BMP   |    FFF0-FFFF     |             \u7279\u6B8A             |                     Specials                     |\\n|  1 SMP   |   10000-1007F    |     \u7DDA\u5F62\u6587\u5B57 B \u97F3\u7BC0\u6587\u5B57      |                Linear B Syllabary                |\\n|  1 SMP   |   10080-100FF    |     \u7DDA\u5F62\u6587\u5B57 B \u8868\u610F\u6587\u5B57      |                Linear B Ideograms                |\\n|  1 SMP   |   10100-1013F    |          \u611B\u7434\u6D77\u6578\u5B57          |                  Aegean Numbers                  |\\n|  1 SMP   |   10140-1018F    |          \u53E4\u5E0C\u81D8\u6578\u5B57          |              Ancient Greek Numbers               |\\n|  1 SMP   |   10190-101CF    |           \u53E4\u4EE3\u7B26\u865F           |                 Ancient Symbols                  |\\n|  1 SMP   |   101D0-101FF    |         \u6590\u65AF\u6258\u65AF\u5713\u76E4         |                  Phaistos Disc                   |\\n|  1 SMP   |   10280-1029F    |          \u5442\u57FA\u4E9E\u5B57\u6BCD          |                      Lycian                      |\\n|  1 SMP   |   102A0-102DF    |          \u5361\u91CC\u4E9E\u5B57\u6BCD          |                      Carian                      |\\n|  1 SMP   |   102E0-102FF    |        \u79D1\u666E\u7279\u958F\u9918\u6578\u5B57        |               Coptic Epact Numbers               |\\n|  1 SMP   |   10300-1032F    |         \u53E4\u7FA9\u5927\u5229\u5B57\u6BCD         |                    Old Italic                    |\\n|  1 SMP   |   10330-1034F    |           \u54E5\u7279\u5B57\u6BCD           |                      Gothic                      |\\n|  1 SMP   |   10350-1037F    |          \u53E4\u5F7C\u723E\u59C6\u6587          |                    Old Permic                    |\\n|  1 SMP   |   10380-1039F    |         \u70CF\u52A0\u91CC\u7279\u5B57\u6BCD         |                     Ugaritic                     |\\n|  1 SMP   |   103A0-103DF    |        \u53E4\u6CE2\u65AF\u6954\u5F62\u6587\u5B57        |                   Old Persian                    |\\n|  1 SMP   |   10400-1044F    |         \u5FB7\u745F\u96F7\u7279\u5B57\u6BCD         |                     Deseret                      |\\n|  1 SMP   |   10450-1047F    |          \u856D\u4F2F\u7D0D\u5B57\u6BCD          |                     Shavian                      |\\n|  1 SMP   |   10480-104AF    |         \u5967\u65AF\u66FC\u4E9E\u5B57\u6BCD         |                     Osmanya                      |\\n|  1 SMP   |   104B0-104FF    |          \u6B50\u585E\u5947\u5B57\u6BCD          |                      Osage                       |\\n|  1 SMP   |   10500-1052F    |         \u611B\u723E\u5DF4\u6851\u5B57\u6BCD         |                     Elbasan                      |\\n|  1 SMP   |   10530-1056F    |     \u9AD8\u52A0\u7D22\u963F\u723E\u5DF4\u5C3C\u4E9E\u5B57\u6BCD     |                Caucasian Albanian                |\\n|  1 SMP   |   10570-105BF    |          \u7DAD\u65AF\u5EAB\u5947\u6587          |                     Vithkuqi                     |\\n|  1 SMP   |   10600-1077F    |          \u7DDA\u5F62\u6587\u5B57 A          |                     Linear A                     |\\n|  1 SMP   |   10780-107BF    |        \u62C9\u4E01\u5B57\u6BCD\u64F4\u5C55-F        |                 Latin Extended-F                 |\\n|  1 SMP   |   10800-1083F    |       \u8CFD\u666E\u52D2\u65AF\u97F3\u7BC0\u6587\u5B57       |                Cypriot Syllabary                 |\\n|  1 SMP   |   10840-1085F    |         \u5E1D\u570B\u4E9E\u62C9\u59C6\u6587         |                 Imperial Aramaic                 |\\n|  1 SMP   |   10860-1087F    |         \u5E15\u723E\u9081\u62C9\u5B57\u6BCD         |                    Palmyrene                     |\\n|  1 SMP   |   10880-108AF    |          \u7D0D\u5DF4\u6CF0\u5B57\u6BCD          |                    Nabataean                     |\\n|  1 SMP   |   108E0-108FF    |           \u54C8\u7279\u62C9\u6587           |                      Hatran                      |\\n|  1 SMP   |   10900-1091F    |          \u8153\u5C3C\u57FA\u5B57\u6BCD          |                    Phoenician                    |\\n|  1 SMP   |   10920-1093F    |          \u5442\u5E95\u4E9E\u5B57\u6BCD          |                      Lydian                      |\\n|  1 SMP   |   10980-1099F    |        \u9EA5\u7F85\u57C3\u6587\u8056\u66F8\u9AD4        |               Meroitic Hieroglyphs               |\\n|  1 SMP   |   109A0-109FF    |        \u9EA5\u7F85\u57C3\u6587\u8349\u66F8\u9AD4        |                 Meroitic Cursive                 |\\n|  1 SMP   |   10A00-10A5F    |            \u4F49\u76E7\u6587            |                    Kharoshthi                    |\\n|  1 SMP   |   10A60-10A7F    |        \u53E4\u5357\u963F\u62C9\u4F2F\u5B57\u6BCD        |                Old South Arabian                 |\\n|  1 SMP   |   10A80-10A9F    |        \u53E4\u5317\u963F\u62C9\u4F2F\u5B57\u6BCD        |                Old North Arabian                 |\\n|  1 SMP   |   10AC0-10AFF    |           \u6469\u5C3C\u5B57\u6BCD           |                    Manichaean                    |\\n|  1 SMP   |   10B00-10B3F    |         \u963F\u7DAD\u65AF\u9640\u5B57\u6BCD         |                     Avestan                      |\\n|  1 SMP   |   10B40-10B5F    |         \u7891\u523B\u5E15\u63D0\u4E9E\u6587         |              Inscriptional Parthian              |\\n|  1 SMP   |   10B60-10B7F    |         \u7891\u523B\u5DF4\u5217\u7DAD\u6587         |              Inscriptional Pahlavi               |\\n|  1 SMP   |   10B80-10BAF    |         \u8A69\u7BC7\u5DF4\u5217\u7DAD\u6587         |                 Psalter Pahlavi                  |\\n|  1 SMP   |   10C00-10C4F    |           \u53E4\u7A81\u53A5\u6587           |                    Old Turkic                    |\\n|  1 SMP   |   10C80-10CFF    |         \u53E4\u5308\u7259\u5229\u5B57\u6BCD         |                  Old Hungarian                   |\\n|  1 SMP   |   10D00-10D3F    |       \u54C8\u4E43\u6590\u7F85\u8208\u4E9E\u6587\u5B57       |                 Hanifi Rohingya                  |\\n|  1 SMP   |   10E60-10E7F    |          \u76E7\u7C73\u6587\u6578\u5B57          |               Rumi Numeral Symbols               |\\n|  1 SMP   |   10E80-10EBF    |           \u96C5\u8332\u8FEA\u6587           |                      Yezidi                      |\\n|  1 SMP   |   10EC0-10EFF    |       \u963F\u62C9\u4F2F\u5B57\u6BCD\u64F4\u5C55-C       |                Arabic Extended-C                 |\\n|  1 SMP   |   10F00-10F2F    |          \u53E4\u7C9F\u7279\u5B57\u6BCD          |                   Old Sogdian                    |\\n|  1 SMP   |   10F30-10F6F    |           \u7C9F\u7279\u5B57\u6BCD           |                     Sogdian                      |\\n|  1 SMP   |   10F70-10FAF    |           \u56DE\u9DBB\u5B57\u6BCD           |                    Old Uyghur                    |\\n|  1 SMP   |   10FB0-10FDF    |         \u82B1\u524C\u5B50\u6A21\u5B57\u6BCD         |                    Chorasmian                    |\\n|  1 SMP   |   10FE0-10FFF    |           \u57C3\u5229\u9081\u6587           |                     Elymaic                      |\\n|  1 SMP   |   11000-1107F    |           \u5A46\u7F85\u7C73\u6587           |                      Brahmi                      |\\n|  1 SMP   |   11080-110CF    |            \u51F1\u63D0\u6587            |                      Kaithi                      |\\n|  1 SMP   |   110D0-110FF    |         \u7D22\u62C9\u50E7\u5E73\u6587\u5B57         |                   Sora Sompeng                   |\\n|  1 SMP   |   11100-1114F    |           \u67E5\u514B\u99AC\u6587           |                      Chakma                      |\\n|  1 SMP   |   11150-1117F    |          \u99AC\u54C8\u4F73\u5C3C\u6587          |                     Mahajani                     |\\n|  1 SMP   |   11180-111DF    |           \u590F\u62C9\u9054\u6587           |                     Sharada                      |\\n|  1 SMP   |   111E0-111FF    |        \u53E4\u50E7\u4F3D\u7F85\u6587\u6578\u5B57        |             Sinhala Archaic Numbers              |\\n|  1 SMP   |   11200-1124F    |            \u53EF\u5409\u6587            |                      Khojki                      |\\n|  1 SMP   |   11280-112AF    |          \u7A46\u723E\u5854\u5C3C\u6587          |                     Multani                      |\\n|  1 SMP   |   112B0-112FF    |          \u5EAB\u9054\u74E6\u8FEA\u6587          |                    Khudawadi                     |\\n|  1 SMP   |   11300-1137F    |           \u53E4\u862D\u5854\u6587           |                     Grantha                      |\\n|  1 SMP   |   11400-1147F    |           \u7D10\u74E6\u5B57\u6BCD           |                       Newa                       |\\n|  1 SMP   |   11480-114DF    |          \u5E95\u7F85\u50D5\u591A\u6587          |                     Tirhuta                      |\\n|  1 SMP   |   11580-115FF    |           \u6089\u66C7\u6587\u5B57           |                     Siddham                      |\\n|  1 SMP   |   11600-1165F    |            \u83AB\u8FEA\u6587            |                       Modi                       |\\n|  1 SMP   |   11660-1167F    |          \u8499\u53E4\u6587\u88DC\u5145          |               Mongolian Supplement               |\\n|  1 SMP   |   11680-116CF    |           \u5854\u514B\u91CC\u6587           |                      Takri                       |\\n|  1 SMP   |   11700-1174F    |           \u963F\u6D2A\u59C6\u6587           |                       Ahom                       |\\n|  1 SMP   |   11800-1184F    |           \u591A\u683C\u62C9\u6587           |                      Dogra                       |\\n|  1 SMP   |   118A0-118FF    |          \u74E6\u862D\u9F4A\u5730\u6587          |                   Warang Citi                    |\\n|  1 SMP   |   11900-1195F    |           \u5CF6\u5DBC\u5B57\u6BCD           |            Dhives Akuru (Dives Akuru)            |\\n|  1 SMP   |   119A0-119FF    |           \u5357\u8FEA\u57CE\u6587           |                   Nandinagari                    |\\n|  1 SMP   |   11A00-11A4F    |      \u672D\u90A3\u5DF4\u672D\u723E\u65B9\u5F62\u5B57\u6BCD      |                 Zanabazar Square                 |\\n|  1 SMP   |   11A50-11AAF    |          \u7D22\u6C38\u5E03\u6587\u5B57          |                     Soyombo                      |\\n|  1 SMP   |   11AB0-11ABF    |  \u52A0\u62FF\u5927\u539F\u4F4F\u6C11\u97F3\u7BC0\u6587\u5B57\u64F4\u5C55-A  | Unified Canadian Aboriginal Syllabics Extended-A |\\n|  1 SMP   |   11AC0-11AFF    |           \u5305\u6B3D\u8C6A\u6587           |                   Pau Cin Hau                    |\\n|  1 SMP   |   11B00-11B5F    |         \u5929\u57CE\u6587\u64F4\u5C55-A         |              Devanagari Extended-A               |\\n|  1 SMP   |   11C00-11C6F    |          \u62DC\u514B\u8212\u57FA\u6587          |                    Bhaiksuki                     |\\n|  1 SMP   |   11C70-11CBF    |            \u746A\u6B3D\u6587            |                     Marchen                      |\\n|  1 SMP   |   11D00-11D5F    |       \u99AC\u85A9\u62C9\u59C6\u8CA2\u5FB7\u6587\u5B57       |                  Masaram Gondi                   |\\n|  1 SMP   |   11D60-11DAF    |        \u8CA2\u8CC8\u62C9\u8CA2\u5FB7\u6587\u5B57        |                  Gunjala Gondi                   |\\n|  1 SMP   |   11EE0-11EFF    |           \u671B\u52A0\u932B\u6587           |                     Makasar                      |\\n|  1 SMP   |   11F00-11F5F    |            \u5361\u7DAD\u6587            |                       Kawi                       |\\n|  1 SMP   |   11FB0-11FBF    |         \u8001\u5088\u50F3\u6587\u88DC\u5145         |                 Lisu Supplement                  |\\n|  1 SMP   |   11FC0-11FFF    |         \u6CF0\u7C73\u723E\u6587\u88DC\u5145         |                 Tamil Supplement                 |\\n|  1 SMP   |   12000-123FF    |           \u6954\u5F62\u6587\u5B57           |                    Cuneiform                     |\\n|  1 SMP   |   12400-1247F    |    \u6954\u5F62\u6587\u5B57\u6578\u5B57\u548C\u6A19\u9EDE\u7B26\u865F    |        Cuneiform Numbers and Punctuation         |\\n|  1 SMP   |   12480-1254F    |       \u65E9\u671F\u738B\u671D\u6954\u5F62\u6587\u5B57       |             Early Dynastic Cuneiform             |\\n|  1 SMP   |   12F90-12FFF    |     \u8CFD\u666E\u52D2\u65AF-\u7C73\u8AFE\u65AF\u6587\u5B57      |                   Cypro-Minoan                   |\\n|  1 SMP   |   13000-1342F    |          \u57C3\u53CA\u8056\u66F8\u9AD4          |               Egyptian Hieroglyphs               |\\n|  1 SMP   |   13430-1345F    |      \u57C3\u53CA\u8056\u66F8\u9AD4\u683C\u5F0F\u63A7\u5236      |       Egyptian Hieroglyph Format Controls        |\\n|  1 SMP   |   14400-1467F    |      \u5B89\u7D0D\u6258\u5229\u4E9E\u8C61\u5F62\u6587\u5B57      |              Anatolian Hieroglyphs               |\\n|  1 SMP   |   16800-16A3F    |        \u5DF4\u59C6\u7A46\u6587\u5B57\u88DC\u5145        |                 Bamum Supplement                 |\\n|  1 SMP   |   16A40-16A6F    |            \u9ED8\u797F\u6587            |                       Mro                        |\\n|  1 SMP   |   16A70-16ACF    |            \u5510\u85A9\u6587            |                      Tangsa                      |\\n|  1 SMP   |   16AD0-16AFF    |            \u5DF4\u85A9\u6587            |                    Bassa Vah                     |\\n|  1 SMP   |   16B00-16B8F    |           \u6551\u4E16\u82D7\u6587           |                   Pahawh Hmong                   |\\n|  1 SMP   |   16E40-16E9F    |        \u6885\u5FB7\u6CD5\u4F0A\u5FB7\u6797\u6587        |                   Medefaidrin                    |\\n|  1 SMP   |   16F00-16F9F    |          \u67CF\u683C\u7406\u82D7\u6587          |                       Miao                       |\\n|  1 SMP   |   16FE0-16FFF    |      \u8868\u610F\u7B26\u865F\u548C\u6A19\u9EDE\u7B26\u865F      |       Ideographic Symbols and Punctuation        |\\n|  1 SMP   |   17000-187FF    |            \u897F\u590F\u6587            |                      Tangut                      |\\n|  1 SMP   |   18800-18AFF    |          \u897F\u590F\u6587\u90E8\u4EF6          |                Tangut Components                 |\\n|  1 SMP   |   18B00-18CFF    |           \u5951\u4E39\u5C0F\u5B57           |               Khitan Small Script                |\\n|  1 SMP   |   18D00-18D7F    |          \u897F\u590F\u6587\u88DC\u5145          |                Tangut Supplement                 |\\n|  1 SMP   |   1AFF0-1AFFF    |          \u5047\u540D\u64F4\u5C55-B          |                 Kana Extended-B                  |\\n|  1 SMP   |   1B000-1B0FF    |           \u5047\u540D\u88DC\u5145           |                 Kana Supplement                  |\\n|  1 SMP   |   1B100-1B12F    |          \u5047\u540D\u64F4\u5C55-A          |                 Kana Extended-A                  |\\n|  1 SMP   |   1B130-1B16F    |         \u5C0F\u578B\u5047\u540D\u64F4\u5145         |               Small Kana Extension               |\\n|  1 SMP   |   1B170-1B2FF    |             \u5973\u66F8             |                      Nushu                       |\\n|  1 SMP   |   1BC00-1BC9F    |          \u675C\u666E\u96F7\u901F\u8A18          |                     Duployan                     |\\n|  1 SMP   |   1BCA0-1BCAF    |        \u901F\u8A18\u683C\u5F0F\u63A7\u5236\u7B26        |            Shorthand Format Controls             |\\n|  1 SMP   |   1CF00-1CFCF    |      \u8D0A\u73AB\u5C3C\u8056\u6B4C\u97F3\u6A02\u7B26\u865F      |            Znamenny Musical Notation             |\\n|  1 SMP   |   1D000-1D0FF    |        \u62DC\u5360\u5EAD\u97F3\u6A02\u7B26\u865F        |            Byzantine Musical Symbols             |\\n|  1 SMP   |   1D100-1D1FF    |           \u97F3\u6A02\u7B26\u865F           |                 Musical Symbols                  |\\n|  1 SMP   |   1D200-1D24F    |        \u53E4\u5E0C\u81D8\u97F3\u6A02\u8A18\u865F        |          Ancient Greek Musical Notation          |\\n|  1 SMP   |   1D2C0-1D2DF    |        \u5361\u514B\u6258\u7DAD\u514B\u6578\u5B57        |                Kaktovik Numerals                 |\\n|  1 SMP   |   1D2E0-1D2FF    |           \u746A\u96C5\u6578\u5B57           |                  Mayan Numerals                  |\\n|  1 SMP   |   1D300-1D35F    |          \u592A\u7384\u7D93\u7B26\u865F          |              Tai Xuan Jing Symbols               |\\n|  1 SMP   |   1D360-1D37F    |             \u7B97\u7C4C             |              Counting Rod Numerals               |\\n|  1 SMP   |   1D400-1D7FF    |        \u5B57\u6BCD\u548C\u6578\u5B57\u5143\u865F        |        Mathematical Alphanumeric Symbols         |\\n|  1 SMP   |   1D800-1DAAF    |         \u85A9\u9813\u66F8\u5BEB\u7B26\u865F         |                Sutton SignWriting                |\\n|  1 SMP   |   1DF00-1DFFF    |        \u62C9\u4E01\u5B57\u6BCD\u64F4\u5C55-G        |                 Latin Extended-G                 |\\n|  1 SMP   |   1E000-1E02F    |       \u683C\u62C9\u54E5\u91CC\u5B57\u6BCD\u88DC\u5145       |              Glagolitic Supplement               |\\n|  1 SMP   |   1E030-1E08F    |       \u897F\u91CC\u723E\u5B57\u6BCD\u64F4\u5C55-D       |               Cyrillic Extended-D                |\\n|  1 SMP   |   1E100-1E14F    |          \u5275\u4E16\u7D00\u82D7\u6587          |              Nyiakeng Puachue Hmong              |\\n|  1 SMP   |   1E290-1E2BF    |            \u6295\u6295\u6587            |                       Toto                       |\\n|  1 SMP   |   1E2C0-1E2FF    |           \u6587\u55AC\u5B57\u6BCD           |                      Wancho                      |\\n|  1 SMP   |   1E4D0-1E4FF    |          \u8499\u9054\u91CC\u5B57\u6BCD          |                   Nag Mundari                    |\\n|  1 SMP   |   1E7E0-1E7FF    |      \u8863\u7D22\u6BD4\u4E9E\u5B57\u6BCD\u64F4\u5145-B      |               Ethiopic Extended-B                |\\n|  1 SMP   |   1E800-1E8DF    |         \u9580\u5FB7\u57FA\u5361\u5EAB\u6587         |                  Mende Kikakui                   |\\n|  1 SMP   |   1E900-1E95F    |         \u963F\u5FB7\u62C9\u59C6\u5B57\u6BCD         |                      Adlam                       |\\n|  1 SMP   |   1EC70-1ECBF    |        \u5370\u5EA6\u897F\u4E9E\u683C\u6578\u5B57        |               Indic Siyaq Numbers                |\\n|  1 SMP   |   1ED00-1ED4F    |       \u5967\u65AF\u66FC\u897F\u4E9E\u683C\u6578\u5B57       |              Ottoman Siyaq Numbers               |\\n|  1 SMP   |   1EE00-1EEFF    |      \u963F\u62C9\u4F2F\u5B57\u6BCD\u6578\u5B57\u5143\u865F      |      Arabic Mathematical Alphabetic Symbols      |\\n|  1 SMP   |   1F000-1F02F    |            \u9EBB\u5C07\u724C            |                  Mahjong Tiles                   |\\n|  1 SMP   |   1F030-1F09F    |          \u591A\u7C73\u8AFE\u9AA8\u724C          |                   Domino Tiles                   |\\n|  1 SMP   |   1F0A0-1F0FF    |            \u64B2\u514B\u724C            |                  Playing Cards                   |\\n|  1 SMP   |   1F100-1F1FF    |       \u570D\u7E5E\u5B57\u6BCD\u6578\u5B57\u88DC\u5145       |         Enclosed Alphanumeric Supplement         |\\n|  1 SMP   |   1F200-1F2FF    |       \u570D\u7E5E\u8868\u610F\u6587\u5B57\u88DC\u5145       |         Enclosed Ideographic Supplement          |\\n|  1 SMP   |   1F300-1F5FF    |      \u96DC\u9805\u7B26\u865F\u548C\u8C61\u5F62\u6587\u5B57      |      Miscellaneous Symbols and Pictographs       |\\n|  1 SMP   |   1F600-1F64F    |           \u8868\u60C5\u7B26\u865F           |                    Emoticons                     |\\n|  1 SMP   |   1F650-1F67F    |           \u88DD\u98FE\u7B26\u865F           |               Ornamental Dingbats                |\\n|  1 SMP   |   1F680-1F6FF    |        \u4EA4\u901A\u548C\u5730\u5716\u7B26\u865F        |            Transport and Map Symbols             |\\n|  1 SMP   |   1F700-1F77F    |          \u934A\u91D1\u8853\u7B26\u865F          |                Alchemical Symbols                |\\n|  1 SMP   |   1F780-1F7FF    |         \u5E7E\u4F55\u5716\u5F62\u64F4\u5C55         |            Geometric Shapes Extended             |\\n|  1 SMP   |   1F800-1F8FF    |          \u8FFD\u52A0\u7BAD\u982D-C          |              Supplemental Arrows-C               |\\n|  1 SMP   |   1F900-1F9FF    |      \u88DC\u5145\u7B26\u865F\u548C\u8C61\u5F62\u6587\u5B57      |       Supplemental Symbols and Pictographs       |\\n|  1 SMP   |   1FA00-1FA6F    |           \u68CB\u985E\u7B26\u865F           |                  Chess Symbols                   |\\n|  1 SMP   |   1FA70-1FAFF    |     \u7B26\u865F\u548C\u8C61\u5F62\u6587\u5B57\u64F4\u5145-A     |        Symbols and Pictographs Extended-A        |\\n|  1 SMP   |   1FB00-1FBFF    |         \u907A\u7559\u8A08\u7B97\u7B26\u865F         |           Symbols for Legacy Computing           |\\n|  2 SIP   |   20000-2A6DF    |  \u4E2D\u65E5\u97D3\u7D71\u4E00\u8868\u610F\u6587\u5B57\u64F4\u5145\u5340 B  |        CJK Unified Ideographs Extension B        |\\n|  2 SIP   |   2A700-2B73F    |  \u4E2D\u65E5\u97D3\u7D71\u4E00\u8868\u610F\u6587\u5B57\u64F4\u5145\u5340 C  |        CJK Unified Ideographs Extension C        |\\n|  2 SIP   |   2B740-2B81F    |  \u4E2D\u65E5\u97D3\u7D71\u4E00\u8868\u610F\u6587\u5B57\u64F4\u5145\u5340 D  |        CJK Unified Ideographs Extension D        |\\n|  2 SIP   |   2B820-2CEAF    |  \u4E2D\u65E5\u97D3\u7D71\u4E00\u8868\u610F\u6587\u5B57\u64F4\u5145\u5340 E  |        CJK Unified Ideographs Extension E        |\\n|  2 SIP   |   2CEB0-2EBEF    |  \u4E2D\u65E5\u97D3\u7D71\u4E00\u8868\u610F\u6587\u5B57\u64F4\u5145\u5340 F  |        CJK Unified Ideographs Extension F        |\\n|  2 SIP   |   2F800-2FA1F    |   \u4E2D\u65E5\u97D3\u76F8\u5BB9\u8868\u610F\u6587\u5B57\u88DC\u5145\u5340   |     CJK Compatibility Ideographs Supplement      |\\n|  3 TIP   |   30000-3134F    |  \u4E2D\u65E5\u97D3\u7D71\u4E00\u8868\u610F\u6587\u5B57\u64F4\u5145\u5340 G  |        CJK Unified Ideographs Extension G        |\\n|  3 TIP   |   31350-323AF    |  \u4E2D\u65E5\u97D3\u7D71\u4E00\u8868\u610F\u6587\u5B57\u64F4\u5145\u5340 H  |        CJK Unified Ideographs Extension H        |\\n|  14 SSP  |   E0000-E007F    |             \u6A19\u7C64             |                       Tags                       |\\n|  14 SSP  |   E0100-E01EF    |        \u8B8A\u9AD4\u9078\u64C7\u7B26\u88DC\u5145        |          Variation Selectors Supplement          |\\n| 15 PUA-A |   F0000-FFFFF    |       \u88DC\u5145\u79C1\u4EBA\u4F7F\u7528\u5340-A       |         Supplementary Private Use Area-A         |\\n| 16 PUA-B |  100000-10FFFF   |       \u88DC\u5145\u79C1\u4EBA\u4F7F\u7528\u5340-B       |         Supplementary Private Use Area-B         |"},{"id":"mac-selective-vpn-routing","metadata":{"permalink":"/en/blog/mac-selective-vpn-routing","source":"@site/i18n/en/docusaurus-plugin-content-blog/2023/09-01-mac-selective-vpn-routing/index.md","title":"Setting Up Selective Traffic Routing for VPN on Mac","description":"Configuring VPN routing on Mac.","date":"2023-09-01T00:00:00.000Z","tags":[{"inline":true,"label":"routing-vpn","permalink":"/en/blog/tags/routing-vpn"},{"inline":true,"label":"macos","permalink":"/en/blog/tags/macos"}],"readingTime":2.66,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Engineer","url":"https://github.com/zephyr-sh","imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"mac-selective-vpn-routing","title":"Setting Up Selective Traffic Routing for VPN on Mac","authors":"Zephyr","tags":["routing-vpn","macos"],"image":"/en/img/2023/0901.webp","description":"Configuring VPN routing on Mac."},"unlisted":false,"prevItem":{"title":"Unicode Table","permalink":"/en/blog/unicode-table"}},"content":"When working remotely with a company VPN setup, sometimes you still need access to local devices and resources on your home network.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Configuration Guide\\n\\nWe\u2019ll use Mac as the operating system for this setup.\\n\\n## Problem Overview\\n\\nFor example:\\n\\n- Company VPN network range: 192.168.25.XXX\\n- Home network range: 192.168.1.XXX\\n\\nWhen the VPN is active, all traffic is routed through the company\'s network, preventing access to devices on your home network within the same domain.\\n\\nIn other words, even if you\'re at home streaming a funny video, the company\'s network admin might inadvertently catch a glimpse too. Something doesn\u2019t feel quite right about this, does it?\\n\\nOur goal here is to **route only the traffic meant for the company network through the VPN, while all other traffic stays on the local network.**\\n\\n:::tip\\nThis guide assumes that your VPN is already configured and functioning correctly. Here, we\u2019ll only address the selective routing issue.\\n\\nIf the VPN isn\u2019t working, please ensure your VPN settings are correct before proceeding.\\n:::\\n\\n## Solving the Problem\\n\\n### Step 1: Identify Your Company\u2019s Internal Network Range\\n\\nFirst, identify the network range for your company, for example:\\n\\n192.168.25.XXX\\n\\nNext, let\u2019s open a system file to configure routing rules:\\n\\n```bash\\nsudo vim /etc/ppp/ip-up\\n```\\n\\nAdd the following content, replacing the network range with your company\u2019s network range:\\n\\n:::warning\\nNote: This example assumes the VPN network range is 192.168.25.XXX. Modify according to your actual network setup.\\n:::\\n\\n```bash\\n#!/bin/sh\\n/sbin/route add -net 192.168.25.0/24 -interface ppp0\\n```\\n\\nLet\u2019s break down what this command does:\\n\\n1. **/sbin/route**: This is the path to the `route` command, which is used for configuring and displaying routing tables.\\n2. **-net 192.168.25.0/24**: This specifies that the route is a network route, not a host route. `192.168.25.0/24` represents the range of IP addresses from `192.168.25.0` to `192.168.25.255`.\\n3. **-interface ppp0**: This specifies the network interface for the route, in this case, `ppp0` (point-to-point protocol interface 0).\\n\\nThis command effectively adds a route through the `ppp0` interface for the `192.168.25.0/24` network range. When your system tries to access any IP address within this range, it will route the traffic through the `ppp0` interface.\\n\\n---\\n\\nAfter editing the file, save and exit, then give it the necessary permissions:\\n\\n```bash\\nsudo chmod 755 /etc/ppp/ip-up\\n```\\n\\n## Still Not Working?\\n\\nAt this point, some devices might still have trouble accessing the internet, so let\u2019s try adjusting the network service order in macOS.\\n\\nOpen macOS\u2019s System Preferences, and go to Network:\\n\\n<figure style={{\\"width\\": \\"80%\\"}}>\\n![vpn-setting](./img/vpn-setting.jpg)\\n</figure>\\n\\n- Step 1: Open System Preferences, and select \u201CNetwork\u201D\\n- Step 2: Click the small options button (three dots)\\n- Step 3: Select \u201CSet Service Order\u201D\\n- Step 4: Drag the VPN service below Wi-Fi in the order\\n\\n---\\n\\nMany people set the VPN at the top of the network service order, prioritizing all traffic through the VPN. Here, we\u2019re lowering the VPN service order so that our custom network configuration can take effect.\\n\\nThat\u2019s it! To route additional traffic through the VPN in the future, simply add the specific addresses in the `ip-up` file.\\n\\n## References\\n\\n1. [shalyf/vpn_route.md](https://gist.github.com/shalyf/d50b0bbf30a4b5020d2b84f4ae8eb4e0)\\n2. [How to selectively route network traffic through VPN on Mac OS X Leopard?](https://superuser.com/questions/4904/how-to-selectively-route-network-traffic-through-vpn-on-mac-os-x-leopard)"}]}}')}}]);