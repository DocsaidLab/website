"use strict";(self.webpackChunkdocsaid_website=self.webpackChunkdocsaid_website||[]).push([["48400"],{24556:function(e,n,i){i.r(n),i.d(n,{frontMatter:()=>s,default:()=>h,contentTitle:()=>r,assets:()=>l,toc:()=>d,metadata:()=>t});var t=JSON.parse('{"id":"docaligner/quickstart","title":"Quick Start","description":"We provide a simple model inference interface, including the preprocessing and postprocessing logic.","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/docaligner/quickstart.md","sourceDirName":"docaligner","slug":"/docaligner/quickstart","permalink":"/en/docs/docaligner/quickstart","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedBy":"zephyr-sh","lastUpdatedAt":1735543244000,"sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Installation","permalink":"/en/docs/docaligner/installation"},"next":{"title":"Advanced","permalink":"/en/docs/docaligner/advance"}}'),a=i(85893),o=i(50065);let s={sidebar_position:3},r="Quick Start",l={},d=[{value:"Model Inference",id:"model-inference",level:2},{value:"Output Results",id:"output-results",level:2},{value:"Draw Polygon",id:"draw-polygon",level:3},{value:"Extract Flattened Image",id:"extract-flattened-image",level:3},{value:"Why Can&#39;t the Model Detect the Document?",id:"why-cant-the-model-detect-the-document",level:2},{value:"Document Size in the Image",id:"document-size-in-the-image",level:3},{value:"Missing Document Corners",id:"missing-document-corners",level:3},{value:"Blurry Document in the Image",id:"blurry-document-in-the-image",level:3},{value:"Document Not Recognized by the Model",id:"document-not-recognized-by-the-model",level:3},{value:"Model Visualization",id:"model-visualization",level:2},{value:"Contact Us",id:"contact-us",level:2}];function c(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"quick-start",children:"Quick Start"})}),"\n",(0,a.jsx)(n.p,{children:"We provide a simple model inference interface, including the preprocessing and postprocessing logic."}),"\n",(0,a.jsxs)(n.p,{children:["First, you need to import the required dependencies and create a ",(0,a.jsx)(n.code,{children:"DocAligner"})," class."]}),"\n",(0,a.jsx)(n.h2,{id:"model-inference",children:"Model Inference"}),"\n",(0,a.jsx)(n.admonition,{type:"info",children:(0,a.jsx)(n.p,{children:"We have designed an automatic model download feature. When the program detects that you are missing a model, it will automatically connect to our server for download."})}),"\n",(0,a.jsx)(n.p,{children:"Here is a simple example:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import cv2\nfrom skimage import io\nfrom docaligner import DocAligner\n\n# build model\nmodel = DocAligner()\n\n# read image\nimg = io.imread('https://github.com/DocsaidLab/DocAligner/blob/main/docs/run_test_card.jpg?raw=true')\nimg = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n\n# inference\npolygon = model(img)\n\n# output four corner coordinates of the document\n# print(polygon)\n#    [[ 48.151894 223.47687 ]\n#    [387.1344   198.09961 ]\n#    [423.0362   345.51334 ]\n#    [ 40.148613 361.38782 ]]\n"})}),"\n",(0,a.jsxs)(n.admonition,{type:"tip",children:[(0,a.jsxs)(n.p,{children:["In the example above, the image download link is available here: ",(0,a.jsx)(n.a,{href:"https://github.com/DocsaidLab/DocAligner/blob/main/docs/run_test_card.jpg",children:(0,a.jsx)(n.strong,{children:"run_test_card.jpg"})})]}),(0,a.jsx)("div",{align:"center",children:(0,a.jsx)("figure",{style:{width:"50%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"test_card",src:i(41109).Z+"",width:"512",height:"512"})})})})]}),"\n",(0,a.jsxs)(n.admonition,{type:"tip",children:[(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"DocAligner"})," is already encapsulated with ",(0,a.jsx)(n.code,{children:"__call__"}),", so you can directly invoke the instance for inference."]}),(0,a.jsxs)(n.p,{children:["In the latest version, the model directly returns results in ",(0,a.jsx)(n.code,{children:"numpy.ndarray"})," format, which we believe offers more flexibility for users and facilitates subsequent applications."]})]}),"\n",(0,a.jsx)(n.h2,{id:"output-results",children:"Output Results"}),"\n",(0,a.jsx)(n.h3,{id:"draw-polygon",children:"Draw Polygon"}),"\n",(0,a.jsx)(n.p,{children:"Draw and save the image with the document polygon."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import cv2\nimport numpy as np\n\ndef draw_polygon_image(\n    img: np.ndarray,\n    polygon: np.ndarray,\n    thickness: int = 3\n) -> np.ndarray:\n\n    colors = [(0, 255, 255), (255, 255, 0), (0, 255, 0), (0, 0, 255)]\n    export_img = img.copy()\n    _polys = polygon.astype(int)\n    _polys_roll = np.roll(_polys, 1, axis=0)\n    for p1, p2, color in zip(_polys, _polys_roll, colors):\n        export_img = cv2.circle(\n            export_img, p2, radius=thickness*2,\n            color=color, thickness=-1, lineType=cv2.LINE_AA\n        )\n        export_img = cv2.arrowedLine(\n            export_img, p2, p1, color=color,\n            thickness=thickness, line_type=cv2.LINE_AA\n        )\n    return export_img\n\n# draw\nexport_img = draw_polygon_image(img, polygon)\n"})}),"\n",(0,a.jsx)("div",{align:"center",children:(0,a.jsx)("figure",{style:{width:"50%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"output_image",src:i(34540).Z+"",width:"512",height:"512"})})})}),"\n",(0,a.jsx)(n.h3,{id:"extract-flattened-image",children:"Extract Flattened Image"}),"\n",(0,a.jsxs)(n.p,{children:["If you know the original size of the document, you can call the ",(0,a.jsx)(n.code,{children:"Capybara.imwarp_quadrangle"})," method to convert the document polygon image into a rectangular image."]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Refer to the source code: ",(0,a.jsx)(n.a,{href:"https://github.com/DocsaidLab/Capybara/blob/40dbe8a58c959023ed87c7d48c1c378de5bcf038/capybara/vision/geometric.py#L155",children:(0,a.jsx)(n.strong,{children:"Capybara.imwarp_quadrangle"})})]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from capybara import imwarp_quadrangle\n\nH, W = 480, 800\nflat_img = imwarp_quadrangle(img, polygon, dst_size=(W, H))\n"})}),"\n",(0,a.jsx)(n.p,{children:"The result will look like the image below:"}),"\n",(0,a.jsx)("div",{align:"center",children:(0,a.jsx)("figure",{style:{width:"50%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"output_image",src:i(51106).Z+"",width:"800",height:"480"})})})}),"\n",(0,a.jsxs)(n.p,{children:["If it's an unknown image type, you can omit the ",(0,a.jsx)(n.code,{children:"dst_size"}),' parameter, and the smallest "rectangular" image based on the document polygon\'s boundaries will be calculated automatically, with the width and height set to ',(0,a.jsx)(n.code,{children:"W"})," and ",(0,a.jsx)(n.code,{children:"H"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"flat_img = imwarp_quadrangle(img, polygon)\n"})}),"\n",(0,a.jsxs)(n.admonition,{type:"tip",children:[(0,a.jsx)(n.p,{children:"When your document appears heavily tilted in the image, the smallest rectangle may be quite flat, causing some deformation during flattening."}),(0,a.jsxs)(n.p,{children:["Therefore, in such cases, it's recommended to manually set the ",(0,a.jsx)(n.code,{children:"dst_size"})," parameter."]})]}),"\n",(0,a.jsx)(n.h2,{id:"why-cant-the-model-detect-the-document",children:"Why Can't the Model Detect the Document?"}),"\n",(0,a.jsx)(n.p,{children:"This is a difficult question to answer immediately, so we need to break it down step by step."}),"\n",(0,a.jsx)(n.p,{children:"Below, we use an image from MIDV-2020 as an example, and readers can download this image for testing:"}),"\n",(0,a.jsx)("div",{align:"center",children:(0,a.jsx)("figure",{style:{width:"30%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"example",src:i(87603).Z+"",width:"2160",height:"3840"})})})}),"\n",(0,a.jsx)(n.h3,{id:"document-size-in-the-image",children:"Document Size in the Image"}),"\n",(0,a.jsx)(n.p,{children:"The first thing to consider is the size of the document in the image. Documents that are too large or too small may cause the model to fail in detection."}),"\n",(0,a.jsx)(n.p,{children:"We have reviewed the training data, and the scale of documents is generally between 1/2 and 1/8, as shown in the diagram below:"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"scale",src:i(79826).Z+"",width:"3002",height:"1856"})}),"\n",(0,a.jsx)(n.p,{children:'This means that if your document size in the image is smaller than 1/8 of the "single grid" size shown in the diagram above, the model is likely to ignore it, as it might consider it background.'}),"\n",(0,a.jsx)(n.p,{children:"We believe that detecting a document is for subsequent downstream tasks, so detecting very small documents may not be meaningful in practical applications. Therefore, we kept this characteristic when designing the training data."}),"\n",(0,a.jsx)(n.h3,{id:"missing-document-corners",children:"Missing Document Corners"}),"\n",(0,a.jsx)(n.p,{children:"A document that is too large generally does not affect the model. However, in this case, the document corners may be clipped by the image edge or extend beyond the image."}),"\n",(0,a.jsx)(n.p,{children:"Since the model primarily performs corner detection, missing document corners will result in unstable estimation. If the missing corners are near the edges of the document, the model is likely to treat the document as invalid and will not output the Polygon result, as shown below:"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"missing corner",src:i(52829).Z+"",width:"3762",height:"1640"})}),"\n",(0,a.jsx)(n.h3,{id:"blurry-document-in-the-image",children:"Blurry Document in the Image"}),"\n",(0,a.jsx)(n.p,{children:"Another reason for detection failure is a blurry document. A blurry document may prevent the model from finding the document's edges, leading to detection failure, as shown in the image below:"}),"\n",(0,a.jsx)("div",{align:"center",children:(0,a.jsx)("figure",{style:{width:"80%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"blurry",src:i(22383).Z+"",width:"2401",height:"1650"})})})}),"\n",(0,a.jsx)(n.h3,{id:"document-not-recognized-by-the-model",children:"Document Not Recognized by the Model"}),"\n",(0,a.jsx)(n.p,{children:"The model we trained is relatively small, around 5MB to 20MB in size. Although it has some generalization ability, it may fail to detect special documents that were not included in the training dataset."}),"\n",(0,a.jsx)(n.p,{children:'For example, suppose the blue calculator in the image below is a "special document":'}),"\n",(0,a.jsx)("div",{align:"center",children:(0,a.jsx)("figure",{style:{width:"60%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"unknown",src:i(60891).Z+"",width:"540",height:"360"})})})}),"\n",(0,a.jsx)(n.p,{children:'When this image is passed to the model, an empty Polygon will be returned because the model does not recognize "calculator" as a document. The solution is to manually annotate this "special document," include it in the training dataset, and fine-tune the model.'}),"\n",(0,a.jsx)(n.h2,{id:"model-visualization",children:"Model Visualization"}),"\n",(0,a.jsx)(n.p,{children:"We haven't encapsulated this feature because it's just an intermediate process, and there are other image postprocessing steps afterward."}),"\n",(0,a.jsx)(n.p,{children:"However, if you're really interested, here's some example code for visualizing the model's output. If you're using a heatmap model, you can visualize the output as follows:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import cv2\nimport numpy as np\nfrom capybara import imresize, imread\nfrom docaligner import DocAligner\nfrom docaligner.heatmap_reg.infer import preprocess\n\nmodel = DocAligner()\n\nimg = imread('midv2020_example.jpg')\n\nimg_infos = preprocess(\n    img=img,\n    img_size_infer=(256, 256)\n)\n\nheatmap = model.detector.model(**img_infos['input'])['heatmap'][0].sum(0)\nheatmap = np.uint8(heatmap * 255)\nheatmap = imresize(heatmap, size=img.shape[:2])\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\noutput = cv2.addWeighted(img, 0.5, heatmap, 0.5, 0)\nD.imwrite(output)\n"})}),"\n",(0,a.jsx)("div",{align:"center",children:(0,a.jsx)("figure",{style:{width:"80%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"heatmap",src:i(15027).Z+"",width:"2300",height:"1677"})})})}),"\n",(0,a.jsx)(n.p,{children:"By running the code above, you can see the model's output, which is a heatmap. The deeper the color, the more likely that area is a document corner. In cases of detection failure, you might be able to spot the issue in this image."}),"\n",(0,a.jsx)(n.h2,{id:"contact-us",children:"Contact Us"}),"\n",(0,a.jsx)(n.p,{children:"If the above answers are not helpful, perhaps you can email us the image you think has issues. If we have time, we will help you check it."}),"\n",(0,a.jsxs)(n.p,{children:["Please contact us via email: ",(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.a,{href:"mailto:docsaidlab@gmail.com",children:"docsaidlab@gmail.com"})})]})]})}function h(e={}){let{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},22383:function(e,n,i){i.d(n,{Z:()=>t});let t=i.p+"assets/images/blur_corner-643dea1ec620aba6a9bdeba1b321ee3d.jpg"},34540:function(e,n,i){i.d(n,{Z:()=>t});let t=i.p+"assets/images/flat_result-d8d626f2c82ccace8b1dbefe9efee53b.jpg"},51106:function(e,n,i){i.d(n,{Z:()=>t});let t=i.p+"assets/images/flat_result_2-76259c821bbdca099ae8d3fcea2a8841.jpg"},15027:function(e,n,i){i.d(n,{Z:()=>t});let t=i.p+"assets/images/heatmap_corner-ebd0a2a2c078504ad41dff39ae1bd65a.jpg"},87603:function(e,n,i){i.d(n,{Z:()=>t});let t=i.p+"assets/images/midv2020_example-de86f77781eb201f4fd33fb575648822.jpg"},52829:function(e,n,i){i.d(n,{Z:()=>t});let t=i.p+"assets/images/missing_corner-ec7a0a3366653774e2d2da9bf5cafb38.jpg"},41109:function(e,n,i){i.d(n,{Z:()=>t});let t=i.p+"assets/images/run_test_card-fb53e9375df9e395862eba27eea849e7.jpg"},79826:function(e,n,i){i.d(n,{Z:()=>t});let t=i.p+"assets/images/scale_corner-766b948def2434e7983bd193560edf3d.jpg"},60891:function(e,n,i){i.d(n,{Z:()=>t});let t=i.p+"assets/images/unknown_corner-b2a8fc1e98c2a15bdf50fb460810ab1a.jpg"},50065:function(e,n,i){i.d(n,{Z:()=>r,a:()=>s});var t=i(67294);let a={},o=t.createContext(a);function s(e){let n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);