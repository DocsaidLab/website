<!doctype html><html lang=zh-hant dir=ltr class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.8.0"><title data-rh=true>Face Anti-Spoofing 技術地圖 | DOCSAID</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:url content=https://docsaid.org/blog/fas-paper-roadmap><meta data-rh=true property=og:locale content=zh_hant><meta data-rh=true property=og:locale:alternate content=en><meta data-rh=true property=og:locale:alternate content=ja><meta data-rh=true name=docusaurus_locale content=zh-hant><meta data-rh=true name=docusaurus_tag content=default><meta data-rh=true name=docsearch:language content=zh-hant><meta data-rh=true name=docsearch:docusaurus_tag content=default><meta data-rh=true property=og:title content="Face Anti-Spoofing 技術地圖 | DOCSAID"><meta data-rh=true name=description content="FAS 的 40 篇論文導讀。"><meta data-rh=true property=og:description content="FAS 的 40 篇論文導讀。"><meta data-rh=true property=og:image content=https://docsaid.org/img/2025/0401.jpg><meta data-rh=true name=twitter:image content=https://docsaid.org/img/2025/0401.jpg><meta data-rh=true property=og:type content=article><meta data-rh=true property=article:published_time content=2025-04-01T00:00:00.000Z><meta data-rh=true property=article:author content=https://github.com/zephyr-sh><meta data-rh=true property=article:tag content=face-anti-spoofing,liveness-detection><link data-rh=true rel=icon href=/img/favicon.ico><link data-rh=true rel=canonical href=https://docsaid.org/blog/fas-paper-roadmap><link data-rh=true rel=alternate href=https://docsaid.org/blog/fas-paper-roadmap hreflang=zh-hant><link data-rh=true rel=alternate href=https://docsaid.org/en/blog/fas-paper-roadmap hreflang=en><link data-rh=true rel=alternate href=https://docsaid.org/ja/blog/fas-paper-roadmap hreflang=ja><link data-rh=true rel=alternate href=https://docsaid.org/blog/fas-paper-roadmap hreflang=x-default><link data-rh=true rel=preconnect href=https://S9NC0RYCHF-dsn.algolia.net crossorigin=anonymous><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@id":"https://docsaid.org/blog/fas-paper-roadmap","@type":"BlogPosting","author":{"@type":"Person","description":"Dosaid maintainer, Full-Stack AI Engineer","image":"https://github.com/zephyr-sh.png","name":"Z. Yuan","url":"https://github.com/zephyr-sh"},"datePublished":"2025-04-01T00:00:00.000Z","description":"FAS 的 40 篇論文導讀。","headline":"Face Anti-Spoofing 技術地圖","image":{"@id":"https://docsaid.org/img/2025/0401.jpg","@type":"ImageObject","caption":"title image for the blog post: Face Anti-Spoofing 技術地圖","contentUrl":"https://docsaid.org/img/2025/0401.jpg","url":"https://docsaid.org/img/2025/0401.jpg"},"isPartOf":{"@id":"https://docsaid.org/blog","@type":"Blog","name":"Blog"},"keywords":[],"mainEntityOfPage":"https://docsaid.org/blog/fas-paper-roadmap","name":"Face Anti-Spoofing 技術地圖","url":"https://docsaid.org/blog/fas-paper-roadmap"}</script><link rel=alternate type=application/rss+xml href=/blog/rss.xml title="DOCSAID RSS Feed"><link rel=alternate type=application/atom+xml href=/blog/atom.xml title="DOCSAID Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=DOCSAID href=/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><link rel=stylesheet href=/assets/css/styles.8e7b88e9.css><script src=/assets/js/runtime~main.b1c97900.js defer></script><script src=/assets/js/main.32613df0.js defer></script><body class=navigation-with-keyboard><svg xmlns=http://www.w3.org/2000/svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light",e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label=跳至主要内容><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>跳至主要内容</a></div><nav aria-label=主導航 class="navbar navbar--fixed-top navbarHideable_jvwV"><div class=navbar__inner><div class=navbar__items><button aria-label=切換導覽列 aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><div class=navbar__logo><img src=/img/docsaid_logo.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/img/docsaid_logo_white.png alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href=/docs/>開源專案</a><a class="navbar__item navbar__link" href=/papers/intro>論文筆記</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/blog>部落格</a><a class="navbar__item navbar__link" href=/playground/intro>遊樂場</a><a class="navbar__item navbar__link" href=/services>技術服務</a><a class="navbar__item navbar__link" href=/aboutus>關於我們</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>繁體中文</a><ul class=dropdown__menu><li><a href=/blog/fas-paper-roadmap target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=zh-hant>繁體中文</a><li><a href=/en/blog/fas-paper-roadmap target=_self rel="noopener noreferrer" class=dropdown__link lang=en>English</a><li><a href=/ja/blog/fas-paper-roadmap target=_self rel="noopener noreferrer" class=dropdown__link lang=ja>日本語</a></ul></div><div class=navbarSearchContainer_dCNk><button type=button class="DocSearch DocSearch-Button" aria-label="搜尋 (Command+K)"><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 20 20" aria-hidden=true><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke=currentColor fill=none fill-rule=evenodd stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>搜尋</span></span><span class=DocSearch-Button-Keys></span></button></div><button type=button class="ant-btn css-5uvb3z ant-btn-circle ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-btn-icon-only"><span class=ant-btn-icon><span role=img aria-label=user style=font-size:18px class="anticon anticon-user"><svg viewBox="64 64 896 896" focusable=false data-icon=user width=1em height=1em fill=currentColor aria-hidden=true><path d="M858.5 763.6a374 374 0 00-80.6-119.5 375.63 375.63 0 00-119.5-80.6c-.4-.2-.8-.3-1.2-.5C719.5 518 760 444.7 760 362c0-137-111-248-248-248S264 225 264 362c0 82.7 40.5 156 102.8 201.1-.4.2-.8.3-1.2.5-44.8 18.9-85 46-119.5 80.6a375.63 375.63 0 00-80.6 119.5A371.7 371.7 0 00136 901.8a8 8 0 008 8.2h60c4.4 0 7.9-3.5 8-7.8 2-77.2 33-149.5 87.8-204.3 56.7-56.7 132-87.9 212.2-87.9s155.5 31.2 212.2 87.9C779 752.7 810 825 812 902.2c.1 4.4 3.6 7.8 8 7.8h60a8 8 0 008-8.2c-1-47.8-10.9-94.3-29.5-138.2zM512 534c-45.9 0-89.1-17.9-121.6-50.4S340 407.9 340 362c0-45.9 17.9-89.1 50.4-121.6S466.1 190 512 190s89.1 17.9 121.6 50.4S684 316.1 684 362c0 45.9-17.9 89.1-50.4 121.6S557.9 534 512 534z"/></svg></span></span></button></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="main-wrapper mainWrapper_eExm"><div class=blog-hero-fullwidth><div class=postHero_mmE7 style=background-image:url(/img/2025/0401.jpg)><div class=postHeroOverlay_UDxJ><h1 class=postTitle_weFP>Face Anti-Spoofing 技術地圖</h1><div class=postMeta_oUa9><div class=postAuthors_wLk4><div class=postAuthor_NvIn><img class=postAuthorImg_omQD src=https://github.com/zephyr-sh.png alt="Z. Yuan"><div class=postAuthorText_C6S8><a href=https://github.com/zephyr-sh target=_blank rel="noopener noreferrer" class=postAuthorLink_uKn3><span class=postAuthorName_SaVw>Z. Yuan</span></a><span class=postAuthorTitle_UTso>Dosaid maintainer, Full-Stack AI Engineer</span></div></div></div><div class=postMetaInfo__nS4><div class=postMetaRow_zK0w><span class=postDate_B0aP>2025年4月1日</span><span class=postReadingTime_roVj>19<!-- --> min read</span></div><div class=postTags_nipL><a class=postTag_inik href=/blog/tags/face-anti-spoofing>face-anti-spoofing</a><a class=postTag_inik href=/blog/tags/liveness-detection>liveness-detection</a></div></div></div></div></div></div><div class="container margin-vert--lg"><div class=row><main class="col col--9"><article class=markdown style="max-width:800px;margin:2rem auto"><article class=""><div><div id=__blog-post-container class=markdown><p>Face Anti-Spoofing 是什麼？為什麼它重要？我該怎麼入門？</p>
<p>這篇文章是我閱讀大量文獻後，為正在學習、研究、或開發 FAS 系統的你所整理的完整導讀地圖。</p>
<p>我挑出最具代表性的 40 篇論文，依照時間與技術發展劃分為八大主題，每一篇都會告訴你該讀的理由、關鍵貢獻與適合定位。從傳統 LBP、rPPG、CNN 到 Transformer、CLIP、Vision-Language Model，全部一次掌握。</p>
<p>後續我會在「論文筆記」中分享每篇論文的細節，現在讓我們先掌握整體脈絡。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第一章起源的低解析光>第一章：起源的低解析光<a href=#第一章起源的低解析光 class=hash-link aria-label=第一章：起源的低解析光的直接連結 title=第一章：起源的低解析光的直接連結>​</a></h2>
<blockquote>
<p><strong>從傳統特徵工程到深度學習的第一道曙光</strong></p>
</blockquote>
<p>Face Anti-Spoofing 的早期研究主要建立在傳統影像處理技術之上，研究者多仰賴紋理、對比、頻率等手工特徵來描述人臉的真實性，並透過經典分類器進行二元辨識。</p>
<ol>
<li>
<p><a href=https://parnec.nuaa.edu.cn/_upload/article/files/4d/43/8a227f2c46bda4c20da97715f010/db1eef47-b25f-4af9-88d4-a8afeccda889.pdf target=_blank rel="noopener noreferrer"><strong>[10.09] Face Liveness Detection from a Single Image with Sparse Low Rank Bilinear Discriminative Model</strong></a>
利用 Lambertian 模型與稀疏低秩表示建構特徵空間，有效分離真臉與照片，為早期單張影像活體檢測提供理論與實作依據。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/slrbd/ target=_blank rel="noopener noreferrer"><strong>[10.09] SLRBD: 沈默的反射光</strong></a></div></div>
</li>
<li>
<p><a href=https://ieeexplore.ieee.org/document/6313548 target=_blank rel="noopener noreferrer"><strong>[12.09] On the Effectiveness of Local Binary Patterns in Face Anti-Spoofing</strong></a>
使用 LBP 與其變種特徵，針對平面照片與螢幕重播攻擊進行辨識，並建立 REPLAY-ATTACK 資料集，是最早公開資料集與經典 baseline 組合之一。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/lbp/ target=_blank rel="noopener noreferrer"><strong>[12.09] LBP: 輕快的微紋理</strong></a></div></div>
</li>
<li>
<p><a href=https://ieeexplore.ieee.org/document/6810829 target=_blank rel="noopener noreferrer"><strong>[14.05] Spoofing Face Recognition with 3D Masks</strong></a>
系統性分析 3D 假面對不同臉部辨識系統（2D/2.5D/3D）的攻擊效果，指出傳統對平面假臉的假設在 3D 印製技術下已不再成立。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/three-d-mad/ target=_blank rel="noopener noreferrer"><strong>[14.05] 3DMAD: 真實的假面</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/1909.08848 target=_blank rel="noopener noreferrer"><strong>[19.09] Biometric Face Presentation Attack Detection with Multi-Channel Convolutional Neural Network</strong></a>
提出多通道 CNN 架構，結合 RGB、深度、紅外與熱感訊號進行辨識，並釋出 WMCA 資料集，提升對高階假臉（如矽膠面具）的偵測能力。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/wmca/ target=_blank rel="noopener noreferrer"><strong>[19.09] WMCA: 看不見的臉</strong></a></div></div>
</li>
<li>
<p><a href=https://ieeexplore.ieee.org/abstract/document/9925105 target=_blank rel="noopener noreferrer"><strong>[22.10] Deep Learning for Face Anti-Spoofing: A Survey</strong></a>
為 FAS 領域第一篇以深度學習為主軸的系統性綜述，涵蓋 pixel-wise 監督、多模態感測器與 domain generalization 等新趨勢，建立知識全景。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/fas-survey/ target=_blank rel="noopener noreferrer"><strong>[22.10] FAS Survey: 攻與防的編年史</strong></a></div></div>
</li>
</ol>
<hr>
<p>這些方法雖簡單，但奠定了辨識平面假臉（如照片與螢幕重播）的基礎認知，也為後來深度學習技術的導入打下概念框架。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第二章真實世界的舞台>第二章：真實世界的舞台<a href=#第二章真實世界的舞台 class=hash-link aria-label=第二章：真實世界的舞台的直接連結 title=第二章：真實世界的舞台的直接連結>​</a></h2>
<blockquote>
<p><strong>FAS 技術從實驗室走向真實場景的里程碑</strong></p>
</blockquote>
<p>資料集與 benchmark 決定了一個領域能否穩定成長。</p>
<p>FAS 技術從單一場景走向多設備、多光源、多攻擊手法，是透過這些具代表性的公開資料集推動而來。</p>
<ol start=6>
<li>
<p><a href=https://ieeexplore.ieee.org/document/7961798 target=_blank rel="noopener noreferrer"><strong>[17.06] OULU-NPU: A Mobile Face Presentation Attack Database with Real-World Variations</strong></a>
針對手機場景設計的 FAS 資料集，涵蓋裝置、環境光與攻擊手法等多種變因，並設計四種測試協定，成為「泛化能力」評估的里程碑。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/oulu-npu/ target=_blank rel="noopener noreferrer"><strong>[17.06] OULU-NPU: 四道關卡</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2003.05136 target=_blank rel="noopener noreferrer"><strong>[20.03] CASIA-SURF CeFA: A Benchmark for Multi-modal Cross-ethnicity Face Anti-Spoofing</strong></a>
全球首個具有「族群標註」的大型多模態 FAS 資料集，涵蓋 RGB、Depth、IR 與多種攻擊類型，特別用於研究族群偏差與模態融合策略。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/cefa/ target=_blank rel="noopener noreferrer"><strong>[20.03] CeFA: 模型的歧視</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2007.12342 target=_blank rel="noopener noreferrer"><strong>[20.07] CelebASpoof: Large-scale Face Anti-Spoofing Dataset with Rich Annotations</strong></a>
目前最大規模的 FAS 資料集，超過 62 萬張影像，並含 10 類 spoof 標註與原始 CelebA 的 40 個屬性，可進行多任務與 spoof trace 學習。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/celeba-spoof/ target=_blank rel="noopener noreferrer"><strong>[20.07] CelebA-Spoof: 大規模防偽試煉</strong></a></div></div>
</li>
<li>
<p><a href=https://openaccess.thecvf.com/content/WACV2022W/MAP-A/html/Belli_A_Personalized_Benchmark_for_Face_Anti-Spoofing_WACVW_2022_paper.html target=_blank rel="noopener noreferrer"><strong>[22.01] A Personalized Benchmark for Face Anti-Spoofing</strong></a>
主張將使用者註冊時的活體影像納入辨識流程，提出 CelebA-Spoof-Enroll 與 SiW-Enroll 兩個新測試配置，探索個人化 FAS 系統的可能性。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/personalized-fas/ target=_blank rel="noopener noreferrer"><strong>[22.01] Personalized-FAS: 個人化的嘗試</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2402.04178 target=_blank rel="noopener noreferrer"><strong>[24.02] SHIELD: An Evaluation Benchmark for Face Spoofing and Forgery Detection with Multimodal Large Language Models</strong></a>
結合 LLM 與多模態輸入，提出以 QA 任務形式評估 MLLM 在 spoof/forgery 檢測的推理能力，開啟「以語言建模理解攻擊」的新場域。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/shield/ target=_blank rel="noopener noreferrer"><strong>[24.02] SHIELD: 告訴我，為什麼？</strong></a></div></div>
</li>
</ol>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第三章跨域的修羅場>第三章：跨域的修羅場<a href=#第三章跨域的修羅場 class=hash-link aria-label=第三章：跨域的修羅場的直接連結 title=第三章：跨域的修羅場的直接連結>​</a></h2>
<blockquote>
<p><strong>從單一資料學習到多場景部署的核心技術</strong></p>
</blockquote>
<p>Face Anti-Spoofing 最棘手的問題之一是泛化能力：如何讓模型不只在訓練資料上有效，也能應對新裝置、新環境與新攻擊。</p>
<ol start=11>
<li>
<p><a href=https://arxiv.org/abs/2004.14043 target=_blank rel="noopener noreferrer"><strong>[20.04] Single-Side Domain Generalization for Face Anti-Spoofing</strong></a>
提出單邊對抗學習策略，只對真臉進行跨域對齊，讓假臉特徵在不同 domain 中自然分散，避免過度壓縮錯誤資訊，是 DG 設計上極具啟發性的方向。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/ssdg/ target=_blank rel="noopener noreferrer"><strong>[20.04] SSDG: 穩定的真實</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2105.02453 target=_blank rel="noopener noreferrer"><strong>[21.05] Generalizable Representation Learning for Mixture Domain Face Anti-Spoofing</strong></a>
不假設已知 domain label，而是透過 instance normalization 與 MMD 做無監督聚類與對齊，實現不依賴人工分群的泛化訓練流程。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/d2am/ target=_blank rel="noopener noreferrer"><strong>[21.05] D²AM: 千域鍛魂術</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2303.13662 target=_blank rel="noopener noreferrer"><strong>[23.03] Rethinking Domain Generalization for Face Anti-Spoofing: Separability and Alignment</strong></a>
提出 SA-FAS 框架，強調在不同 domain 保留 feature separability，同時讓 live→spoof 的轉變軌跡在各 domain 中一致，是 IRM 理論在 FAS 上的深度應用。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/sa-fas/ target=_blank rel="noopener noreferrer"><strong>[23.03] SA-FAS: 超平面的律令</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2402.19298 target=_blank rel="noopener noreferrer"><strong>[24.02] Suppress and Rebalance: Towards Generalized Multi-Modal Face Anti-Spoofing</strong></a>
對多模態 DG 問題進行深入剖析，透過 U-Adapter 壓制不穩定模態的干擾，搭配 ReGrad 動態調節各模態收斂速度，是模態不均與可靠性問題的完整解法。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/mmdg/ target=_blank rel="noopener noreferrer"><strong>[24.02] MMDG: 信任管理學</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2403.14333 target=_blank rel="noopener noreferrer"><strong>[24.03] CFPL-FAS: Class Free Prompt Learning for Generalizable Face Anti-spoofing</strong></a>
聚焦於 prompt learning 的手法，強調「無需手動定義類別」的 prompt 設計，屬於一種利用語言提示來協助 FAS 模型泛化的新思路。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/cfpl-fas/ target=_blank rel="noopener noreferrer"><strong>[24.03] CFPL-FAS: 無類別提示學習</strong></a></div></div>
</li>
</ol>
<hr>
<p>這五篇論文構成了當前 Domain Generalization（DG）主題下的技術主軸，從單邊對抗、無標籤聚類、可分性分析，到融合語言的監督方式，描繪出對跨域挑戰的完整應戰策略。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第四章新世界的崛起>第四章：新世界的崛起<a href=#第四章新世界的崛起 class=hash-link aria-label=第四章：新世界的崛起的直接連結 title=第四章：新世界的崛起的直接連結>​</a></h2>
<blockquote>
<p><strong>從 CNN 到 ViT，FAS 模型的架構革新之路</strong></p>
</blockquote>
<p>Vision Transformer（ViT）的崛起讓影像任務從局部卷積邁入全局建模時代，Face Anti-Spoofing 也不例外。</p>
<ol start=16>
<li>
<p><a href=https://openaccess.thecvf.com/content/WACV2023/papers/Liao_Domain_Invariant_Vision_Transformer_Learning_for_Face_Anti-Spoofing_WACV_2023_paper.pdf target=_blank rel="noopener noreferrer"><strong>[23.01] Domain Invariant Vision Transformer Learning for Face Anti-Spoofing</strong></a>
提出 DiVT 架構，透過兩個核心損失函數強化跨域泛化，聚合真臉特徵，形成更一致的 domain-invariant 表徵。實驗顯示，DiVT 在多項 DG-FAS 任務上達成 SOTA 成績，方法精簡卻能有效捕捉跨域辨識的關鍵資訊。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/divt/ target=_blank rel="noopener noreferrer"><strong>[23.01] DiVT: 全明星錦標賽</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2302.05744 target=_blank rel="noopener noreferrer"><strong>[23.02] Rethinking Vision Transformer and Masked Autoencoder in Multimodal Face Anti-Spoofing</strong></a>
全面檢討 ViT 在多模態 FAS 中的核心議題，包含輸入設計、預訓練策略與參數微調流程，並提出 AMA adapter 與 M2A2E 預訓練架構，建構跨模態、無標註的自監督流程。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/m2a2e/ target=_blank rel="noopener noreferrer"><strong>[23.02] M²A²E: 舉一反三</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2304.07549 target=_blank rel="noopener noreferrer"><strong>[23.04] MA-ViT: Modality-Agnostic Vision Transformers for Face Anti-Spoofing</strong></a>
採單分支 early fusion 架構，透過 Modal-Disentangle Attention 與 Cross-Modal Attention，實現模態不可知的辨識能力，兼顧記憶效率與彈性部署，是 ViT 在實用性上邁出的重要一步。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/ma-vit/ target=_blank rel="noopener noreferrer"><strong>[23.04] MA-ViT: 凡所有相，皆是虛妄</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2309.04038 target=_blank rel="noopener noreferrer"><strong>[23.09] S-Adapter: Generalizing Vision Transformer for Face Anti-Spoofing with Statistical Tokens</strong></a>
利用 Efficient Parameter Transfer Learning 架構，在 ViT 上插入 statistical adapters 並固定主網參數，搭配 Token Style Regularization 抑制風格差異，是專為 cross-domain FAS 設計的輕量方案。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/s-adapter/ target=_blank rel="noopener noreferrer"><strong>[23.09] S-Adapter: 真實筆記本</strong></a></div></div>
</li>
<li>
<p><a href=https://dl.acm.org/doi/pdf/10.1145/3664647.3680856 target=_blank rel="noopener noreferrer"><strong>[24.10] FM-CLIP: Flexible Modal CLIP for Face Anti-Spoofing</strong></a>
透過跨模態頻率提取 (CMS-Enhancer) 與文字引導 (LGPA) 動態對齊假臉線索，能於多模態訓練、單一或多模態測試中維持高偵測準確度，在多組資料集上均展現優異的泛化能力。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/fm-clip/ target=_blank rel="noopener noreferrer"><strong>[24.10] FM-CLIP: 來自語言的指引</strong></a></div></div>
</li>
</ol>
<hr>
<p>這一階段的五篇論文展示了 Transformer 架構如何處理多模態輸入、模態缺失、跨域風格與 local patch 表徵等關鍵挑戰，代表 FAS 模型設計邏輯的全面轉變。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第五章風格之戰>第五章：風格之戰<a href=#第五章風格之戰 class=hash-link aria-label=第五章：風格之戰的直接連結 title=第五章：風格之戰的直接連結>​</a></h2>
<blockquote>
<p><strong>當 spoof 來自不同世界，如何打造風格不敏感模型？</strong></p>
</blockquote>
<p>FAS 模型的泛化不只受到 domain shift 的挑戰，更受到不同風格（style）間資訊不對稱的干擾。</p>
<p>這一章聚焦於風格解耦、對抗學習、測試時自適應（test-time adaptation）與 instance-aware 設計，這些方法嘗試讓模型能在未知風格與樣本分布下，依然保持穩定的辨識性能。</p>
<ol start=21>
<li>
<p><a href=https://arxiv.org/abs/2203.05340 target=_blank rel="noopener noreferrer"><strong>[22.03] Domain Generalization via Shuffled Style Assembly for Face Anti-Spoofing</strong></a>
採內容與風格分離策略，重組風格空間來模擬 style shift，搭配對比學習強調活體相關風格，是 style-aware DG 設計的重要突破。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/ssan/ target=_blank rel="noopener noreferrer"><strong>[22.03] SSAN: 風格的殘影</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2212.03651 target=_blank rel="noopener noreferrer"><strong>[22.12] Cyclically Disentangled Feature Translation for Face Anti-spoofing</strong></a>
提出 CDFTN，透過對抗式學習將活體與風格成分分離，生成結合真實標籤與目標域樣貌的 pseudo-labeled 样本，顯著提升跨域偽裝辨識的準確度與穩健性。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/cdftn/ target=_blank rel="noopener noreferrer"><strong>[22.12] CDFTN: 風格的糾纏</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2304.05640 target=_blank rel="noopener noreferrer"><strong>[23.04] Instance-Aware Domain Generalization for Face Anti-Spoofing</strong></a>
拋棄粗略的 domain label，改採 instance-level 的風格對齊策略，透過不對稱 whitening、風格增強與動態 kernel 設計，提煉出對風格不敏感的辨識特徵。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/iadg/ target=_blank rel="noopener noreferrer"><strong>[23.04] IADG: 風格的獨白</strong></a></div></div>
</li>
<li>
<p><a href=https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Towards_Unsupervised_Domain_Generalization_for_Face_Anti-Spoofing_ICCV_2023_paper.html target=_blank rel="noopener noreferrer"><strong>[23.10] Towards Unsupervised Domain Generalization for Face Anti-Spoofing</strong></a>
將 unlabeled 資料納入學習流程，透過分割重組與跨域相似度尋找機制，提煉出能適應多種未標註場景的泛化表徵，達成真正無監督的 DG FAS。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/udg-fas/ target=_blank rel="noopener noreferrer"><strong>[23.10] UDG-FAS: 風格的碎片</strong></a></div></div>
</li>
<li>
<p><a href=https://papers.bmvc2023.org/0379.pdf target=_blank rel="noopener noreferrer"><strong>[23.11] Test-Time Adaptation for Robust Face Anti-Spoofing</strong></a>
在推理階段針對新場景動態調整模型，結合 activation-based pseudo-labeling 與對比學習防止遺忘，使預先訓練的 FAS 模型能在測試時自我優化，提升對未知攻擊的敏銳度。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/three-a-tta/ target=_blank rel="noopener noreferrer"><strong>[23.11] 3A-TTA: 荒野求生</strong></a></div></div>
</li>
</ol>
<hr>
<p>這五篇從不同角度挑戰了「風格泛化」這個主題，尤其在 instance-based 與 test-time adaptation 的嘗試上，逐步接近實際應用場景的需求。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第六章多模態的召喚術>第六章：多模態的召喚術<a href=#第六章多模態的召喚術 class=hash-link aria-label=第六章：多模態的召喚術的直接連結 title=第六章：多模態的召喚術的直接連結>​</a></h2>
<blockquote>
<p><strong>當圖像不再是唯一，聲音與生理訊號進場了</strong></p>
</blockquote>
<p>在傳統 RGB 模型遇到高仿真攻擊與跨域挑戰的瓶頸時，FAS 社群開始探索非視覺訊號，例如 <strong>rPPG、生理訊號、聲波回音</strong> 等輔助資訊，從「人本訊號」出發，建立更難被偽造的辨識依據。</p>
<p>本章精選五篇橫跨生理信號、3D 幾何與聲學感知的代表作，展示多模態 FAS 技術的潛力與未來性。</p>
<ol start=26>
<li>
<p><a href=https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICPR-2016/media/files/1223.pdf target=_blank rel="noopener noreferrer"><strong>[16.12] Generalized face anti-spoofing by detecting pulse from face videos</strong></a>
在早期 FAS 場景，就示範了如何在沒有深度或紅外感測器的條件下，光靠人臉心跳訊號也能辨識假臉，凸顯 rPPG 的潛力。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/rppg target=_blank rel="noopener noreferrer"><strong>[16.12] rPPG: 生命的光斑</strong></a></div></div>
</li>
<li>
<p><a href=https://dl.acm.org/doi/10.1007/978-3-030-01270-0_34 target=_blank rel="noopener noreferrer"><strong>[18.09] Remote Photoplethysmography Correspondence Feature for 3D Mask Face Presentation Attack Detection</strong></a>
首度提出 CFrPPG（對應式 rPPG）特徵來強化活體訊號擷取，在低光源或攝影機晃動情況下也能準確提取心跳軌跡，對抗 3D 面具攻擊表現優異。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/cfrppg target=_blank rel="noopener noreferrer"><strong>[18.09] CFrPPG: 心跳的殘響</strong></a></div></div>
</li>
<li>
<p><a href=https://ieeexplore.ieee.org/document/8761776 target=_blank rel="noopener noreferrer"><strong>[19.05] Multi-Modal Face Authentication Using Deep Visual and Acoustic Features</strong></a>
利用智慧型手機內建喇叭與麥克風，發射超音波並解析臉部回音，結合 CNN 提取的圖像特徵，打造不需額外硬體的雙模態安全驗證系統。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/vafas target=_blank rel="noopener noreferrer"><strong>[19.05] VA-FAS: 聲波裡的臉</strong></a></div></div>
</li>
<li>
<p><a href=https://ieeexplore.ieee.org/document/9868051 target=_blank rel="noopener noreferrer"><strong>[22.08] Beyond the Pixel World: A Novel Acoustic-Based Face Anti-Spoofing System for Smartphones</strong></a>
建立 Echo-Spoof 聲學 FAS 資料集，並設計 Echo-FAS 架構，利用聲波重建 3D 幾何與材料資訊，完全不依賴攝影機，是行動裝置中低成本、高抗性的應用典範。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/echo-fas target=_blank rel="noopener noreferrer"><strong>[22.08] Echo-FAS: 仿冒的回音</strong></a></div></div>
</li>
<li>
<p><a href=https://dl.acm.org/doi/10.1145/3643510 target=_blank rel="noopener noreferrer"><strong>[24.03] AFace: Range-Flexible Anti-Spoofing Face Authentication via Smartphone Acoustic Sensing</strong></a>
延伸 Echo-FAS 思路，加入 iso-depth 模型與距離自適應演算法，能對抗 3D 列印面具，並根據使用者距離自我調整，是聲波式活體驗證走向實用化的關鍵設計。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/aface target=_blank rel="noopener noreferrer"><strong>[24.03] AFace: 波動的邊界</strong></a></div></div>
</li>
</ol>
<hr>
<p>這五篇構成非影像模態在 FAS 領域的重要開端，若想要避開傳統攝影機的限制，這將是值得深究的方向。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第七章拆解假象的軌跡>第七章：拆解假象的軌跡<a href=#第七章拆解假象的軌跡 class=hash-link aria-label=第七章：拆解假象的軌跡的直接連結 title=第七章：拆解假象的軌跡的直接連結>​</a></h2>
<blockquote>
<p><strong>深入建模 spoof 的結構與語義，提升模型判別力</strong></p>
</blockquote>
<p>隨著 FAS 模型邁向可解釋性與泛化能力的雙重挑戰，研究者開始關注「spoof trace」這一概念：即假臉在影像中留下的細微模式，例如顏色偏差、邊緣輪廓或頻率異常。</p>
<p>這一章的五篇論文皆從<strong>表徵解耦</strong>（disentanglement）的角度切入，試圖將 spoof 特徵從人臉內容中分離出來，進而重建、分析、甚至合成 spoof 樣本，讓模型真正學會「看穿偽裝」。</p>
<ol start=31>
<li>
<p><a href=https://arxiv.org/abs/2003.04092 target=_blank rel="noopener noreferrer"><strong>[20.03] Searching Central Difference Convolutional Networks for Face Anti-Spoofing</strong></a>
提出中心差分（CDC）方法：藉由人工定義出「假象應該在局部梯度中留有差異」的假設，將真實臉與潛在偽裝的梯度訊號分開。再搭配多尺度注意力模組，實現高效部署與跨資料集泛化能力的 FAS 解法，有非常高的引用數。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/cdcn target=_blank rel="noopener noreferrer"><strong>[20.03] CDCN: 真與假的錯落之間</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2007.09273 target=_blank rel="noopener noreferrer"><strong>[20.07] On Disentangling Spoof Trace for Generic Face Anti-Spoofing</strong></a>
提出多尺度 spoof trace 分離模型，將偽裝訊號視為多層圖樣組合，透過對抗學習重建真實臉部與 spoof mask，可應用於合成新攻擊樣本，是 spoof-aware 表徵學習的代表作。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/stdn target=_blank rel="noopener noreferrer"><strong>[20.07] STDN: 偽裝的痕跡</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2008.08250 target=_blank rel="noopener noreferrer"><strong>[20.08] Face Anti-Spoofing via Disentangled Representation Learning</strong></a>
將人臉特徵解構為 liveness 與 identity 兩種子空間，透過 CNN 架構分離低階與高階訊號，建立更具可遷移性的活體分類器，提升在不同攻擊類型上的穩定性。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/disentangle-fas target=_blank rel="noopener noreferrer"><strong>[20.08] Disentangle-FAS: 斷開魂結</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2110.09157 target=_blank rel="noopener noreferrer"><strong>[21.10] Disentangled representation with dual-stage feature learning for face anti-spoofing</strong></a>
透過雙階段解耦訓練機制，將人臉影像分離成與活體相關及無關的兩種子空間，並有效增進模型對未知攻擊類型的辨識能力，是加強泛化性能的關鍵設計。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/dualstage target=_blank rel="noopener noreferrer"><strong>[21.10] DualStage: 複解耦之術</strong></a></div></div>
</li>
<li>
<p><a href=https://arxiv.org/abs/2112.00568 target=_blank rel="noopener noreferrer"><strong>[21.12] Dual spoof disentanglement generation for face anti-spoofing with depth uncertainty learning</strong></a>
提出 DSDG 生成架構，利用 VAE 進行身份與攻擊紋理的因子化潛在表示，能大規模合成多樣化偽臉影像，並引入深度不確定性模組來穩定深度監督，是「以生成對抗偽裝」的典範之一。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg></span>資訊</div><div class=admonitionContent_BuS1><p><strong>論文筆記</strong>：<a href=https://docsaid.org/papers/face-antispoofing/dsdg target=_blank rel="noopener noreferrer"><strong>[21.12] DSDG: 假象重組的前夜</strong></a></div></div>
</li>
</ol>
<hr>
<p>本章指出了一個關鍵轉捩點：從辨識活體 → 分析偽裝 → 模擬攻擊，Face Anti-Spoofing 的研究正逐漸走向「可生成、可解釋、可操控」的下一階段。這些方法不僅提升模型準確率，更可能啟發未來的攻防演化路徑。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=第八章未來的混沌之境>第八章：未來的混沌之境<a href=#第八章未來的混沌之境 class=hash-link aria-label=第八章：未來的混沌之境的直接連結 title=第八章：未來的混沌之境的直接連結>​</a></h2>
<blockquote>
<p><strong>從 CLIP 到人類知覺，FAS 的下一個邊界</strong></p>
</blockquote>
<p>當單一模態、單一攻擊型態都已難以滿足實戰需求，FAS 正邁入更高層次的挑戰：<strong>物理 + 數位雙重攻擊、語意導向辨識、多樣環境的零樣本泛化</strong>。</p>
<p>這五篇代表作是未來 FAS 的三大發展主軸：<strong>融合辨識、語言建模、與人本感知</strong>。</p>
<ol start=36>
<li>
<p><a href=https://arxiv.org/abs/2309.16649 target=_blank rel="noopener noreferrer"><strong>[23.09] FLIP: Cross-domain Face Anti-Spoofing with Language Guidance</strong></a>
將 CLIP 模型應用於 FAS 任務，透過自然語言描述導引視覺表徵空間，提升跨 domain 的泛化能力，並提出語義對齊與多模態對比學習策略，達成真正語言引導下的 zero-shot FAS。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2404.08450 target=_blank rel="noopener noreferrer"><strong>[24.04] Joint Physical-Digital Facial Attack Detection via Simulating Spoofing Clues</strong></a>
提出 SPSC 與 SDSC 資料擴增策略，模擬物理與數位攻擊線索，讓單一模型能學習同時辨識兩類攻擊，成功在 CVPR2024 比賽中奪冠，樹立融合式模型新典範。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2404.06211 target=_blank rel="noopener noreferrer"><strong>[24.04] Unified Physical-Digital Attack Detection Challenge</strong></a>
發起首屆統一攻擊辨識挑戰賽，釋出 2.8 萬筆複合型攻擊資料集 UniAttackData，並分析各隊模型架構，是研究界邁向 Unified Attack Detection 的催化劑。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2408.12793 target=_blank rel="noopener noreferrer"><strong>[24.08] La-SoftMoE CLIP for Unified Physical-Digital Face Attack Detection</strong></a>
將 CLIP 與 Mixture of Experts 架構結合，引入 soft-adaptive 機制動態分配子模型以應對複雜決策邊界，為物理與數位攻擊融合處理提供高效參數選擇方案。</p>
</li>
<li>
<p><a href=https://arxiv.org/abs/2501.01720 target=_blank rel="noopener noreferrer"><strong>[25.01] Interpretable Face Anti-Spoofing: Enhancing Generalization with Multimodal Large Language Models</strong></a>
提出一種結合多模態大型語言模型的全新架構 I-FAS，將人臉活體辨識任務轉化為具可解釋性的視覺問答問題，並透過語意標註、非對稱語言損失與全域感知連結器三項關鍵設計，大幅提升模型的跨域泛化與推理能力。</p>
</li>
</ol>
<hr>
<p>這一章標誌著 FAS 領域的未來趨勢：<strong>從辨識假臉 → 推測攻擊類型 → 理解語義 → 結合多模態語言邏輯推理</strong>。研究正從「視覺理解」進化到「語意認知」，而攻擊也正從單一模式演化為複雜混合型。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id=結語>結語<a href=#結語 class=hash-link aria-label=結語的直接連結 title=結語的直接連結>​</a></h2>
<p>真實世界最不缺的就是惡意，只要人臉辨識的需求存在，防偽的需求就不會停止。</p>
<p>從最初的紋理分析、光影建模，到卷積網路的入場，再到 ViT、CLIP、聲波與人類知覺的加入，FAS 技術不斷擴展其邊界。這幾篇論文不只是經典與趨勢的整理，更是一張跨越數十年技術進化的地圖，串連了過去、現在與未來。</p>
<p>在這張地圖中，我們看見：</p>
<ul>
<li><strong>從單模態到多模態</strong>：不只看畫面，更感測深度、聲音、脈動與材質。</li>
<li><strong>從分類到解耦</strong>：不只判斷真假，更試圖理解每一種偽裝的構成方式。</li>
<li><strong>從辨識到推理</strong>：不只區分活體，更開始理解語意、材料與語言描述背後的真實。</li>
<li><strong>從防禦到生成</strong>：不只是被動防守，也開始主動模擬、重建與干預。</li>
</ul>
<p>如果你正打算進入這個領域，這份技術導讀不會給你「一套萬用解法」，但它能幫你找到自己的出發點：是著迷於 spoof trace 的可視化？還是想探索 CLIP 如何協助安全辨識？或是對聲波與材料辨識感興趣？</p>
<p>無論你來自哪個背景，FAS 都是一個橫跨影像辨識、生物認證、人因感知、語意推理與跨模態融合的交會點。</p>
<p>這場戰役，還遠遠沒到結束的時候。<section class=ctaSection_iCjC><div class="
        simpleCta_ji_Y
        simple-cta__coffee_YwC8
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>☕ 一杯咖啡，就是我創作的燃料！</h3><p class=simple-cta__subtitle_ol86>贊助我持續分享 AI 實作、全端架構與開源經驗，讓好文章不斷更新。<div class=simple-cta__buttonWrapper_jk1Y><img src=/img/bmc-logo.svg alt=cta-button class=simple-cta__buttonImg_Q9VV></div></div><div class="ant-row ant-row-stretch cardsSection_wRaP css-5uvb3z" style=margin-left:-8px;margin-right:-8px;row-gap:16px><div style=padding-left:8px;padding-right:8px;display:flex class="ant-col ant-col-xs-24 css-5uvb3z"><div class="ant-card ant-card-bordered card_gKx9 fadeInUp_n33J hoverTransform_Mozy css-5uvb3z" style=flex:1;display:flex;flex-direction:column><div class=ant-card-body><div style=text-align:center;margin-top:1rem><img src=/img/icons/all_in.svg alt="AI / 全端 / 客製 一次搞定 icon" style=width:48px;height:48px></div><span class="ant-tag ant-tag-orange card__tag_PLj3 css-5uvb3z">ALL</span><h4 class=card__title_SQBY>AI / 全端 / 客製 一次搞定</h4><p class=card__concept_Ak8F>從構想到上線，涵蓋顧問、開發與部署，全方位支援你的技術實作。<div class=card__bulletHeader_b6cf><h5 class=card__bulletTitle_R_wg>包含內容</h5></div><ul class=card__bulletList_SrNN><li class=card__bulletItem_wCRd>顧問服務 + 系統建置 + 客製開發<li class=card__bulletItem_wCRd>長期維運與擴充規劃</ul></div></div></div></div><div class="
        simpleCta_ji_Y
        simple-cta__outro_AXbn
        fadeInUp_n33J
        hoverTransform_Mozy
      " style=cursor:pointer><h3 class=simple-cta__title_i7hn>🚀 你的專案準備好了嗎？</h3><p class=simple-cta__subtitle_ol86>如果你需要客製服務或長期顧問，歡迎與我聯繫！</div></section><div style=margin-top:3rem> </div></div></div><button aria-label=回到頂部 class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button></article></article><nav class="pagination-nav docusaurus-mt-lg" aria-label=部落格文章分頁導覽><a class="pagination-nav__link pagination-nav__link--prev" href=/blog/colorful-cli-with-ansi-escape-codes><div class=pagination-nav__sublabel>較新一篇</div><div class=pagination-nav__label>終端機不該只有黑與白</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/blog/should-you-choose-docusaurus><div class=pagination-nav__sublabel>較舊一篇</div><div class=pagination-nav__label>你該選 Docusaurus 嗎？</div></a></nav></main><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label=最近部落格文章導覽><div class="sidebarItemTitle_pO2u margin-bottom--md">All our Posts</div><div role=group><h3 class=yearGroupHeading_rMGB>2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/read-papers-lightly>讀論文，不必太用力</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/cgi-injection-log-analysis>CGI 攻擊的技術側寫</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/closure-in-python>Closure 是什麼？</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/react-hook-vs-python>React 到底在 Hook 什麼？</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/colorful-cli-with-ansi-escape-codes>終端機不該只有黑與白</a><li class=sidebarItem__DBe><a aria-current=page class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href=/blog/fas-paper-roadmap>Face Anti-Spoofing 技術地圖</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/should-you-choose-docusaurus>你該選 Docusaurus 嗎？</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/looking-up-the-ten-steps-of-a-master>仰望大師的十級階梯</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/build-a-resume>用 JS 來寫一份履歷吧！</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/pydantic-intro>Pydantic 入門：Python 資料驗證與管理</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/builds-dashboard-system>我一個做 AI 的，居然寫了後台系統？</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/amazon-ses-setting-dns-on-namecheap>Amazon SES 在 Namecheap 設定 DNS</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/download-from-google-drive-using-python>使用 Python 從 Google Drive 下載檔案</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/mount-disk-on-ubuntu>在 Ubuntu 上掛載隨身硬碟</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/github-markdown-advanced-syntax>好用的 github markdown 語法</a></ul></div><div role=group><h3 class=yearGroupHeading_rMGB>2024</h3><ul class="sidebarItemList_Yudw clean-list"><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/extract-font-info-by-python>取得字型檔案的資訊</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/flexible-video-conversion-by-python>批次影片轉檔</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/system-status-checking-by-chatgpt>Ubuntu 系統基礎狀態檢查自動化</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/customized-docusaurus-author-to-plugin-content-docs>幫 Docusaurus 的 Docs 加上作者資訊</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/graph-convolutional-networks>淺談圖卷積網路</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/fourier-transform>淺談傅立葉轉換</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/fixed-pyenv-install-error>修復 pyenv 建置錯誤</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/update-docusaurus-to-3-6-0>更新 Docusaurus 到 3.6.0</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/file-crawler-python-implementation>下載網頁檔案的 Python 實作</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/customized-docusaurus-sidebars-auto-count>讓 Docusaurus 的 Sidebar 自動計算文章數量</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/customized-docusaurus-404-page>自訂 Docusaurus 的 404 頁面</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/torch-layernorm-mismatch>手算的 LayerNorm 數值不對？</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/get-taiwan-all-stocks-info>取得 TWSE 所有股票代號資料</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/windows-python-settings>簡單配置 Win11 系統的 Python 環境</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/latex-usage>LaTeX 語法快速查詢表</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/impl-normalized-levenshtein-similarity>實作 ANLS</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/python-js-basic-command-equivalents>Python 與 JS 的基本指令對應</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/vscode-settings>常用的 VScode 參數設定</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/setting-up-nextcloud>搭建 Nextcloud 記錄</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/pytorch-training-out-of-memory>PyTorch 的 List 陷阱</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/convert-pdf-to-images>使用 Python 把 PDF 轉圖片</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/opencv-imread>用 Python 讀取 HEIC 圖檔與加速載入</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/error-record>日常錯誤排除紀錄</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/gosu-usage>容器下的使用者切換工具：gosu</a></ul></div><div role=group><h3 class=yearGroupHeading_rMGB>2023</h3><ul class="sidebarItemList_Yudw clean-list"><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/buy-a-new-computer>買電腦紀錄</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/pyenv-installation>使用 pyenv 管理 Python 版本</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/python-env-info-collector>記錄與排查模型訓練環境問題</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/setting-up-pypiserver-on-ubuntu-with-docker>搭建 PyPiServer 記錄</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/ubuntu-install-ssh>在 Ubuntu 上設定 SSH 伺服器</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/ubuntu-github-runner-systemd>自動運行 GitHub Runner</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/login-rtf8207w>登入 RTF8207W 路由器</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/fail2ban-settings>Fail2ban：保護 SSH 服務</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/unicode-table>Unicode 編碼區段表</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/blog/mac-selective-vpn-routing>為 VPN 設定選擇性流量路由</a></ul></div></nav></aside><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#第一章起源的低解析光 class="table-of-contents__link toc-highlight">第一章：起源的低解析光</a><li><a href=#第二章真實世界的舞台 class="table-of-contents__link toc-highlight">第二章：真實世界的舞台</a><li><a href=#第三章跨域的修羅場 class="table-of-contents__link toc-highlight">第三章：跨域的修羅場</a><li><a href=#第四章新世界的崛起 class="table-of-contents__link toc-highlight">第四章：新世界的崛起</a><li><a href=#第五章風格之戰 class="table-of-contents__link toc-highlight">第五章：風格之戰</a><li><a href=#第六章多模態的召喚術 class="table-of-contents__link toc-highlight">第六章：多模態的召喚術</a><li><a href=#第七章拆解假象的軌跡 class="table-of-contents__link toc-highlight">第七章：拆解假象的軌跡</a><li><a href=#第八章未來的混沌之境 class="table-of-contents__link toc-highlight">第八章：未來的混沌之境</a><li><a href=#結語 class="table-of-contents__link toc-highlight">結語</a></ul></div></div></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class=footer__links><a class=footer__link-item href=/docs>開源專案</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/papers/intro>論文筆記</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/blog>部落格</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/terms-of-service>使用條款</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/privacy-policy>隱私政策</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/become-an-author>成為作者</a><span class=footer__link-separator>·</span><a class=footer__link-item href=/worklog>工作日誌</a></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2025 DOCSAID.</div></div></div></footer></div>