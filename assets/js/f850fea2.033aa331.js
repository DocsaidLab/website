"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([["58928"],{86533:function(e,n,t){t.r(n),t.d(n,{assets:function(){return a},contentTitle:function(){return l},default:function(){return u},frontMatter:function(){return o},metadata:function(){return s},toc:function(){return c}});var s=t(46794),i=t(85893),r=t(50065);let o={slug:"impl-normalized-levenshtein-similarity",title:"\u5BE6\u4F5C ANLS",authors:"Zephyr",image:"/img/2024/0516.webp",tags:["pytorch","anls"],description:"Average Normalized Levenshtein Similarity"},l=void 0,a={authorsImageUrls:[void 0]},c=[{value:"\u53C3\u8003\u8CC7\u6599",id:"\u53C3\u8003\u8CC7\u6599",level:2},{value:"\u5C0E\u5165\u5FC5\u8981\u7684\u5EAB",id:"\u5C0E\u5165\u5FC5\u8981\u7684\u5EAB",level:2},{value:"\u5BE6\u4F5C\u6A19\u6E96\u5316\u529F\u80FD",id:"\u5BE6\u4F5C\u6A19\u6E96\u5316\u529F\u80FD",level:2},{value:"\u5BE6\u4F5C <code>reduction</code> \u53C3\u6578",id:"\u5BE6\u4F5C-reduction-\u53C3\u6578",level:2},{value:"\u5B8C\u6574\u7684\u5BE6\u4F5C",id:"\u5B8C\u6574\u7684\u5BE6\u4F5C",level:2},{value:"\u6700\u5F8C",id:"\u6700\u5F8C",level:2}];function d(e){let n={a:"a",admonition:"admonition",code:"code",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"Average Normalized Levenshtein Similarity\uFF0C\u7C21\u7A31 ANLS\uFF0C\u662F\u4E00\u7A2E\u7528\u65BC\u8A08\u7B97\u5169\u500B\u5B57\u4E32\u4E4B\u9593\u76F8\u4F3C\u6027\u7684\u6307\u6A19\u3002"}),"\n",(0,i.jsx)(n.p,{children:"Levenshtein Similarity\uFF0C\u4EE5\u4E0B\u6211\u5011\u7C21\u7A31\u70BA LS\u3002"}),"\n",(0,i.jsxs)(n.p,{children:["\u5728\u81EA\u7136\u8A9E\u8A00\u8655\u7406\uFF08NLP\uFF09\u4E2D\uFF0C\u6211\u5011\u7D93\u5E38\u9700\u8981\u6BD4\u8F03\u5169\u500B\u5B57\u4E32\u7684\u76F8\u4F3C\u6027\u3002LS \u662F\u4E00\u7A2E\u5E38\u898B\u7684\u5EA6\u91CF\u65B9\u6CD5\uFF0C\u5B83\u8861\u91CF\u4E86\u5169\u500B\u5B57\u4E32\u4E4B\u9593\u7684\u300C",(0,i.jsx)(n.strong,{children:"\u7DE8\u8F2F\u8DDD\u96E2"}),"\u300D\uFF0C\u5373\u901A\u904E\u591A\u5C11\u6B21\u63D2\u5165\u3001\u522A\u9664\u6216\u66FF\u63DB\u64CD\u4F5C\u53EF\u4EE5\u5C07\u4E00\u500B\u5B57\u4E32\u8F49\u63DB\u70BA\u53E6\u4E00\u500B\u5B57\u4E32\u3002"]}),"\n",(0,i.jsx)(n.p,{children:"\u53EA\u662F LS \u672C\u8EAB\u4E26\u4E0D\u76F4\u89C0\uFF0C\u56E0\u70BA\u5B83\u53D6\u6C7A\u65BC\u5B57\u4E32\u7684\u9577\u5EA6\u3002\u70BA\u4E86\u89E3\u6C7A\u9019\u500B\u554F\u984C\uFF0C\u6211\u5011\u53EF\u4EE5\u5C07 LS \u6A19\u6E96\u5316\u70BA [0, 1] \u5340\u9593\uFF0C\u9019\u6A23\u6211\u5011\u5C31\u53EF\u4EE5\u66F4\u5BB9\u6613\u5730\u7406\u89E3\u548C\u6BD4\u8F03\u4E0D\u540C\u5B57\u4E32\u4E4B\u9593\u7684\u76F8\u4F3C\u6027\uFF0C\u7A31\u70BA Normalized Levenshtein Similarity\uFF08NLS\uFF09\u3002"}),"\n",(0,i.jsx)(n.p,{children:"\u7531\u65BC NLS \u6307\u7684\u662F\u4E00\u7D44\u5B57\u4E32\u4E4B\u9593\u7684\u76F8\u4F3C\u6027\uFF0C\u6211\u5011\u53EF\u4EE5\u5C07\u5176\u9032\u4E00\u6B65\u64F4\u5C55\u70BA ANLS\uFF0C\u5B83\u8A08\u7B97\u4E86\u591A\u7D44\u5B57\u4E32\u4E4B\u9593\u7684\u5E73\u5747\u76F8\u4F3C\u6027\uFF0C\u85C9\u6B64\u4F86\u6A6B\u91CF\u6A21\u578B\u7684\u6027\u80FD\u3002"}),"\n",(0,i.jsx)(n.p,{children:"\u7136\u5F8C......"}),"\n",(0,i.jsx)(n.p,{children:"\u6211\u5011\u7E3D\u662F\u627E\u4E0D\u5230\u559C\u6B61\u7684\u5BE6\u4F5C\uFF0C\u6700\u5F8C\u6C7A\u5B9A\u81EA\u5DF1\u5BEB\u4E00\u500B\u3002"}),"\n",(0,i.jsx)(n.h2,{id:"\u53C3\u8003\u8CC7\u6599",children:"\u53C3\u8003\u8CC7\u6599"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://lightning.ai/docs/torchmetrics/stable/text/edit.html",children:(0,i.jsx)(n.strong,{children:"torchmetrics.text.EditDistance"})})}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"\u5C0E\u5165\u5FC5\u8981\u7684\u5EAB",children:"\u5C0E\u5165\u5FC5\u8981\u7684\u5EAB"}),"\n",(0,i.jsxs)(n.p,{children:["\u9996\u5148\uFF0C\u6211\u5011\u9700\u8981\u5C0E\u5165\u4E00\u4E9B\u5FC5\u8981\u7684\u5EAB\uFF0C\u7279\u5225\u662F\u7531 ",(0,i.jsx)(n.code,{children:"torchmetrics"})," \u5BE6\u4F5C\u7684 ",(0,i.jsx)(n.code,{children:"EditDistance"}),"\uFF1A"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from typing import Any, Literal, Optional, Sequence, Union\n\nimport torch\nfrom torch import Tensor\nfrom torchmetrics.metric import Metric\nfrom torchmetrics.text import EditDistance\nfrom torchmetrics.utilities.data import dim_zero_cat\n"})}),"\n",(0,i.jsxs)(n.p,{children:["\u7531\u65BC ",(0,i.jsx)(n.code,{children:"EditDistance"})," \u5DF2\u7D93\u53EF\u4EE5\u8A08\u7B97 Levenshtein \u8DDD\u96E2\uFF0C\u6211\u5011\u53EF\u4EE5\u76F4\u63A5\u4F7F\u7528\u5B83\u4F86\u8A08\u7B97\u5169\u500B\u5B57\u4E32\u4E4B\u9593\u7684\u7DE8\u8F2F\u8DDD\u96E2\u3002\u7136\u800C\uFF0C",(0,i.jsx)(n.code,{children:"EditDistance"})," \u4E26\u6C92\u6709\u63D0\u4F9B\u6A19\u6E96\u5316\u7684\u529F\u80FD\uFF0C\u6240\u4EE5\u6211\u5011\u9700\u8981\u81EA\u5DF1\u5BE6\u73FE\u9019\u4E00\u90E8\u5206\u3002"]}),"\n",(0,i.jsx)(n.h2,{id:"\u5BE6\u4F5C\u6A19\u6E96\u5316\u529F\u80FD",children:"\u5BE6\u4F5C\u6A19\u6E96\u5316\u529F\u80FD"}),"\n",(0,i.jsxs)(n.p,{children:["\u5728\u9019\u88E1\uFF0C\u6211\u5011\u7E7C\u627F ",(0,i.jsx)(n.code,{children:"torchmetrics.metric.Metric"})," \u7684\u4ECB\u9762\uFF0C\u6240\u4EE5\u6211\u5011\u9700\u8981\u5BE6\u4F5C ",(0,i.jsx)(n.code,{children:"update"})," \u548C ",(0,i.jsx)(n.code,{children:"compute"})," \u65B9\u6CD5\uFF1A"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class NormalizedLevenshteinSimilarity(Metric):\n\n    def __init__(\n        self,\n        substitution_cost: int = 1,\n        reduction: Optional[Literal["mean", "sum", "none"]] = "mean",\n        **kwargs: Any\n    ) -> None:\n        super().__init__(**kwargs)\n        self.edit_distance = EditDistance(\n            substitution_cost=substitution_cost,\n            reduction=None  # Set to None to get distances for all string pairs\n        )\n\n        # ...\n'})}),"\n",(0,i.jsx)(n.p,{children:"\u9019\u88E1\u6709\u5E7E\u500B\u8981\u9EDE\uFF1A"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\u78BA\u4FDD\u8F38\u5165\u7684 ",(0,i.jsx)(n.code,{children:"preds"})," \u548C ",(0,i.jsx)(n.code,{children:"target"})," \u662F\u5B57\u4E32\u5217\u8868\uFF0C\u5426\u5247\u51FD\u6578\u5C31\u6703\u8A08\u7B97\u5230\u300C\u5B57\u5143\u300D\u7684\u90E8\u5206\u3002"]}),"\n",(0,i.jsx)(n.li,{children:"\u8A08\u7B97\u6BCF\u500B\u5B57\u4E32\u7684\u6700\u5927\u9577\u5EA6\uFF0C\u9019\u6A23\u624D\u80FD\u9032\u884C\u6A19\u6E96\u5316\u3002"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def update(self, preds: Union[str, Sequence[str]], target: Union[str, Sequence[str]]) -> None:\n    """Update state with predictions and targets."""\n\n    if isinstance(preds, str):\n        preds = [preds]\n    if isinstance(target, str):\n        target = [target]\n\n    distances = self.edit_distance(preds, target)\n    max_lengths = torch.tensor([\n        max(len(p), len(t))\n        for p, t in zip(preds, target)\n    ], dtype=torch.float)\n\n    ratio = torch.where(\n        max_lengths == 0,\n        torch.zeros_like(distances).float(),\n        distances.float() / max_lengths\n    )\n\n    nls_values = 1 - ratio\n\n    # ...\n'})}),"\n",(0,i.jsxs)(n.h2,{id:"\u5BE6\u4F5C-reduction-\u53C3\u6578",children:["\u5BE6\u4F5C ",(0,i.jsx)(n.code,{children:"reduction"})," \u53C3\u6578"]}),"\n",(0,i.jsxs)(n.p,{children:["\u6211\u5011\u9084\u9700\u8981\u4FDD\u7559 ",(0,i.jsx)(n.code,{children:"reduction"})," \u53C3\u6578\u7684\u767C\u63EE\u7A7A\u9593\uFF0C\u5982\u679C\u6211\u5011\u6307\u5B9A ",(0,i.jsx)(n.code,{children:"mean"}),"\uFF0C\u90A3\u5C31\u662F\u5E38\u898B\u7684 ANLS \u5206\u6578\u3002"]}),"\n",(0,i.jsxs)(n.p,{children:["\u9664\u4E86\u4E00\u822C\u7684 ",(0,i.jsx)(n.code,{children:"mean"}),"\uFF0C\u6211\u5011\u4E5F\u53EF\u4EE5\u4F7F\u7528 ",(0,i.jsx)(n.code,{children:"sum"})," \u6216 ",(0,i.jsx)(n.code,{children:"none"}),"\uFF0C\u4F86\u5B8C\u6210\u4E0D\u540C\u7684\u9700\u6C42\u3002"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def _compute(\n    self,\n    nls_score: Tensor,\n    num_elements: Union[Tensor, int],\n) -> Tensor:\n    """Compute the ANLS over state."""\n    if nls_score.numel() == 0:\n        return torch.tensor(0, dtype=torch.int32)\n    if self.reduction == "mean":\n        return nls_score.sum() / num_elements\n    if self.reduction == "sum":\n        return nls_score.sum()\n    if self.reduction is None or self.reduction == "none":\n        return nls_score\n\ndef compute(self) -> torch.Tensor:\n    """Compute the NLS over state."""\n    if self.reduction == "none" or self.reduction is None:\n        return self._compute(dim_zero_cat(self.nls_values_list), 1)\n    return self._compute(self.nls_score, self.num_elements)\n'})}),"\n",(0,i.jsxs)(n.p,{children:["\u9019\u88E1\u9700\u8981\u6CE8\u610F\u7684\u90E8\u5206\u662F\u7576\u6211\u5011\u6307\u5B9A ",(0,i.jsx)(n.code,{children:"reduction"})," \u70BA ",(0,i.jsx)(n.code,{children:"none"})," \u6642\uFF0C\u6211\u5011\u9700\u8981\u5C07\u6240\u6709\u7684 NLS \u503C\u8FD4\u56DE\uFF0C\u800C\u4E0D\u662F\u8A08\u7B97\u5E73\u5747\u503C\u3002\u9019\u908A\u6211\u53C3\u8003\u4E86 ",(0,i.jsx)(n.code,{children:"torchmetrics.text.EditDistance"})," \u7684\u5BE6\u73FE\u65B9\u5F0F\uFF0C\u4F7F\u7528\u4E86 ",(0,i.jsx)(n.code,{children:"dim_zero_cat"})," \u4F86\u5C07\u5217\u8868\u4E2D\u7684\u503C\u62FC\u63A5\u5728\u4E00\u8D77\uFF0C\u78BA\u4FDD\u56DE\u50B3\u7684\u662F\u4E00\u500B ",(0,i.jsx)(n.code,{children:"Tensor"}),"\u3002"]}),"\n",(0,i.jsx)(n.h2,{id:"\u5B8C\u6574\u7684\u5BE6\u4F5C",children:"\u5B8C\u6574\u7684\u5BE6\u4F5C"}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["\u6211\u5011\u5C07\u7A0B\u5F0F\u540C\u6B65\u66F4\u65B0\u5230 ",(0,i.jsx)(n.a,{href:"https://github.com/DocsaidLab/DocsaidKit/blob/main/docsaidkit/torch/metrics/normalized_levenshtein_similarity.py",children:(0,i.jsx)(n.strong,{children:"DocsaidKit/.../normalized_levenshtein_similarity.py"})})]})}),"\n",(0,i.jsx)(n.p,{children:"\u5B8C\u6574\u7684\u5BE6\u4F5C\u5982\u4E0B\uFF1A"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from typing import Any, Literal, Optional, Sequence, Union\n\nimport torch\nfrom torch import Tensor\nfrom torchmetrics.metric import Metric\nfrom torchmetrics.text import EditDistance\nfrom torchmetrics.utilities.data import dim_zero_cat\n\n\nclass NormalizedLevenshteinSimilarity(Metric):\n    """\n    Normalized Levenshtein Similarity (NLS) is a metric that computes the\n    normalized Levenshtein similarity between two sequences.\n    This metric is calculated as 1 - (levenshtein_distance / max_length),\n    where `levenshtein_distance` is the Levenshtein distance between the two\n    sequences and `max_length` is the maximum length of the two sequences.\n\n    NLS aims to provide a similarity measure for character sequences\n    (such as text), making it useful in areas like text similarity analysis,\n    Optical Character Recognition (OCR), and Natural Language Processing (NLP).\n\n    This class inherits from `Metric` and uses the `EditDistance` class to\n    compute the Levenshtein distance.\n\n    Inputs to the ``update`` and ``compute`` methods are as follows:\n\n    - ``preds`` (:class:`~Union[str, Sequence[str]]`):\n        Predicted text sequences or a collection of sequences.\n    - ``target`` (:class:`~Union[str, Sequence[str]]`):\n        Target text sequences or a collection of sequences.\n\n    Output from the ``compute`` method is as follows:\n\n    - ``nls`` (:class:`~torch.Tensor`): A tensor containing the NLS value.\n        Returns 0.0 when there are no samples; otherwise, it returns the NLS.\n\n    Args:\n        substitution_cost:\n            The cost of substituting one character for another. Default is 1.\n        reduction:\n            Method to aggregate metric scores.\n            Default is \'mean\', options are \'sum\' or None.\n\n            - ``\'mean\'``: takes the mean over samples, which is ANLS.\n            - ``\'sum\'``: takes the sum over samples\n            - ``None`` or ``\'none\'``: returns the score per sample\n\n        kwargs: Additional keyword arguments.\n\n    Example::\n        Multiple strings example:\n\n        >>> metric = NormalizedLevenshteinSimilarity(reduction=None)\n        >>> preds = ["rain", "lnaguaeg"]\n        >>> target = ["shine", "language"]\n        >>> metric(preds, target)\n        tensor([0.4000, 0.5000])\n        >>> metric = NormalizedLevenshteinSimilarity(reduction="mean")\n        >>> metric(preds, target)\n        tensor(0.4500)\n    """\n\n    def __init__(\n        self,\n        substitution_cost: int = 1,\n        reduction: Optional[Literal["mean", "sum", "none"]] = "mean",\n        **kwargs: Any\n    ) -> None:\n        super().__init__(**kwargs)\n        self.edit_distance = EditDistance(\n            substitution_cost=substitution_cost,\n            reduction=None  # Set to None to get distances for all string pairs\n        )\n\n        allowed_reduction = (None, "mean", "sum", "none")\n        if reduction not in allowed_reduction:\n            raise ValueError(\n                f"Expected argument `reduction` to be one of {allowed_reduction}, but got {reduction}")\n        self.reduction = reduction\n\n        if self.reduction == "none" or self.reduction is None:\n            self.add_state(\n                "nls_values_list",\n                default=[],\n                dist_reduce_fx="cat"\n            )\n        else:\n            self.add_state(\n                "nls_score",\n                default=torch.tensor(0.0),\n                dist_reduce_fx="sum"\n            )\n            self.add_state(\n                "num_elements",\n                default=torch.tensor(0),\n                dist_reduce_fx="sum"\n            )\n\n    def update(self, preds: Union[str, Sequence[str]], target: Union[str, Sequence[str]]) -> None:\n        """Update state with predictions and targets."""\n        if isinstance(preds, str):\n            preds = [preds]\n        if isinstance(target, str):\n            target = [target]\n\n        distances = self.edit_distance(preds, target)\n        max_lengths = torch.tensor([\n            max(len(p), len(t))\n            for p, t in zip(preds, target)\n        ], dtype=torch.float)\n\n        ratio = torch.where(\n            max_lengths == 0,\n            torch.zeros_like(distances).float(),\n            distances.float() / max_lengths\n        )\n\n        nls_values = 1 - ratio\n\n        if self.reduction == "none" or self.reduction is None:\n            self.nls_values_list.append(nls_values)\n        else:\n            self.nls_score += nls_values.sum()\n            self.num_elements += nls_values.shape[0]\n\n    def _compute(\n        self,\n        nls_score: Tensor,\n        num_elements: Union[Tensor, int],\n    ) -> Tensor:\n        """Compute the ANLS over state."""\n        if nls_score.numel() == 0:\n            return torch.tensor(0, dtype=torch.int32)\n        if self.reduction == "mean":\n            return nls_score.sum() / num_elements\n        if self.reduction == "sum":\n            return nls_score.sum()\n        if self.reduction is None or self.reduction == "none":\n            return nls_score\n\n    def compute(self) -> torch.Tensor:\n        """Compute the NLS over state."""\n        if self.reduction == "none" or self.reduction is None:\n            return self._compute(dim_zero_cat(self.nls_values_list), 1)\n        return self._compute(self.nls_score, self.num_elements)\n\n\nif __name__ == "__main__":\n    anls = NormalizedLevenshteinSimilarity(reduction=\'mean\')\n    preds = ["rain", "lnaguaeg"]\n    target = ["shine", "language"]\n    print(anls(preds, target))\n'})}),"\n",(0,i.jsx)(n.h2,{id:"\u6700\u5F8C",children:"\u6700\u5F8C"}),"\n",(0,i.jsx)(n.p,{children:"\u6211\u5011\u53EF\u4EE5\u4FDD\u8B49\u9019\u500B\u5BE6\u4F5C\u662F\u6B63\u78BA\u7684\u55CE\uFF1F"}),"\n",(0,i.jsx)(n.p,{children:"\u7B54\u6848\u662F\u4E0D\u884C\uFF0C\u5982\u679C\u4F60\u767C\u73FE\u4E86\u4EFB\u4F55\u554F\u984C\uFF0C\u8ACB\u544A\u8A34\u6211\u5011\uFF0C\u975E\u5E38\u611F\u8B1D\uFF01"})]})}function u(e={}){let{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},50065:function(e,n,t){t.d(n,{Z:function(){return l},a:function(){return o}});var s=t(67294);let i={},r=s.createContext(i);function o(e){let n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(r.Provider,{value:n},e.children)}},46794:function(e){e.exports=JSON.parse('{"permalink":"/blog/impl-normalized-levenshtein-similarity","source":"@site/blog/2024/05-16-impl-normalized-levenshtein-similarity/index.md","title":"\u5BE6\u4F5C ANLS","description":"Average Normalized Levenshtein Similarity","date":"2024-05-16T00:00:00.000Z","tags":[{"inline":true,"label":"pytorch","permalink":"/blog/tags/pytorch"},{"inline":true,"label":"anls","permalink":"/blog/tags/anls"}],"readingTime":6.965,"hasTruncateMarker":true,"authors":[{"name":"Zephyr","title":"Dosaid maintainer, Full-Stack AI Engineer","url":"https://github.com/zephyr-sh","socials":{"github":"https://github.com/zephyr-sh"},"imageURL":"https://github.com/zephyr-sh.png","key":"Zephyr","page":null}],"frontMatter":{"slug":"impl-normalized-levenshtein-similarity","title":"\u5BE6\u4F5C ANLS","authors":"Zephyr","image":"/img/2024/0516.webp","tags":["pytorch","anls"],"description":"Average Normalized Levenshtein Similarity"},"unlisted":false,"prevItem":{"title":"LaTeX \u8A9E\u6CD5\u5FEB\u901F\u67E5\u8A62\u8868","permalink":"/blog/latex-usage"},"nextItem":{"title":"Python \u8207 JS \u7684\u57FA\u672C\u6307\u4EE4\u5C0D\u61C9","permalink":"/blog/python-js-basic-command-equivalents"}}')}}]);