"use strict";(self.webpackChunkdocsaid_website=self.webpackChunkdocsaid_website||[]).push([["82791"],{37856:function(e,n,t){t.r(n),t.d(n,{assets:function(){return o},contentTitle:function(){return a},default:function(){return c},frontMatter:function(){return l},metadata:function(){return r},toc:function(){return u}});var r=t(22380),i=t(85893),s=t(50065);let l={slug:"file-crawler-python-implementation",title:"\u4E0B\u8F09\u7DB2\u9801\u6A94\u6848\u7684 Python \u5BE6\u4F5C",authors:"Z. Yuan",image:"/img/2024/0923.webp",tags:["Python","File Crawler"],description:"\u4E00\u500B\u7C21\u55AE\u7684\u7DB2\u9801\u6A94\u6848\u4E0B\u8F09\u7A0B\u5F0F\u3002"},a=void 0,o={authorsImageUrls:[void 0]},u=[{value:"\u5B89\u88DD\u5957\u4EF6",id:"\u5B89\u88DD\u5957\u4EF6",level:2},{value:"\u7A0B\u5F0F\u78BC",id:"\u7A0B\u5F0F\u78BC",level:2},{value:"\u57F7\u884C\u7A0B\u5F0F",id:"\u57F7\u884C\u7A0B\u5F0F",level:2}];function p(e){let n={code:"code",h2:"h2",p:"p",pre:"pre",...(0,s.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"\u6211\u5011\u770B\u4E0A\u4E86\u4E00\u500B\u7DB2\u9801\uFF0C\u88E1\u9762\u6709\u4E0A\u767E\u4EFD pdf \u6A94\u6848\u9023\u7D50\u3002"}),"\n",(0,i.jsx)(n.p,{children:"\u8EAB\u70BA\u5DE5\u7A0B\u5E2B\u7684\u6211\u5011\uFF0C\u5982\u679C\u662F\u81EA\u5DF1\u9010\u7BC7\u9EDE\u958B\u4E0B\u8F09\uFF0C\u986F\u7136\u4E0D\u592A\u5C0D\uFF1F"}),"\n",(0,i.jsx)(n.p,{children:"\u6240\u4EE5\u9019\u88E1\u5C31\u9700\u8981\u5BEB\u4E00\u500B\u5C0F\u7A0B\u5F0F\uFF0C\u5E6B\u6211\u5011\u4E0B\u8F09\u6240\u6709\u6A94\u6848\u3002"}),"\n",(0,i.jsx)(n.h2,{id:"\u5B89\u88DD\u5957\u4EF6",children:"\u5B89\u88DD\u5957\u4EF6"}),"\n",(0,i.jsx)(n.p,{children:"\u9996\u5148\uFF0C\u4F60\u9700\u8981\u5B89\u88DD\u6240\u9700\u7684\u5957\u4EF6\uFF0C\u5982\u679C\u9084\u6C92\u5B89\u88DD\u7684\u8A71\uFF0C\u53EF\u4EE5\u900F\u904E\u4EE5\u4E0B\u547D\u4EE4\u4F86\u5B89\u88DD\uFF1A"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install requests beautifulsoup4 urllib3\n"})}),"\n",(0,i.jsx)(n.h2,{id:"\u7A0B\u5F0F\u78BC",children:"\u7A0B\u5F0F\u78BC"}),"\n",(0,i.jsx)(n.p,{children:"\u8A71\u4E0D\u591A\u8AAA\uFF0C\u65E2\u7136\u7A0B\u5F0F\u5BEB\u5B8C\u4E86\uFF0C\u6211\u5011\u5C31\u76F4\u63A5\u4E0A\u7A0B\u5F0F\u78BC\u5427\uFF01"}),"\n",(0,i.jsx)(n.p,{children:"\u91CD\u9EDE\u6846\u8D77\u4F86\u7684\u90E8\u5206\uFF0C\u662F\u4F60\u5F97\u81EA\u5DF1\u4FEE\u6539\u7684\u5730\u65B9\uFF0C\u8ACB\u6839\u64DA\u4F60\u7684\u9700\u6C42\u4F86\u8ABF\u6574\u7A0B\u5F0F\u78BC\u3002"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:'{13,16} title="file_crawler.py"',children:'import os\nfrom urllib.parse import urljoin\n\nimport requests\nfrom bs4 import BeautifulSoup\n\n# \u6A21\u64EC\u700F\u89BD\u5668\u7684 headers\nheaders = {\n    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36"\n}\n\n# \u7DB2\u9801 URL\nurl = "put_your_url_here"\n\n# \u76EE\u6A19\u683C\u5F0F\ntarget_format = ".pdf"\n\n# \u767C\u9001 HTTP GET \u8ACB\u6C42\uFF0C\u6DFB\u52A0 headers\nresponse = requests.get(url, headers=headers)\n\n# \u6AA2\u67E5\u8ACB\u6C42\u662F\u5426\u6210\u529F\nif response.status_code == 200:\n    # \u4F7F\u7528 BeautifulSoup \u89E3\u6790 HTML\n    soup = BeautifulSoup(response.text, "html.parser")\n\n    # \u67E5\u627E\u6240\u6709\u7684<a>\u6A19\u7C64\uFF0C\u7BE9\u9078\u51FA href \u5C6C\u6027\u7B26\u5408\u76EE\u6A19\u683C\u5F0F\u7684\u9023\u7D50\n    target_links = []\n    for link in soup.find_all("a"):\n        href = link.get("href")\n        if href and href.endswith(target_format): # \u5728\u9019\u908A\u6307\u5B9A\u8981\u4E0B\u8F09\u7684\u6A94\u6848\u683C\u5F0F\n            target_links.append(urljoin(url, href))\n\n    # \u5275\u5EFA\u8CC7\u6599\u593E\u4F86\u5132\u5B58\u6A94\u6848\n    os.makedirs("downloads", exist_ok=True)\n\n    # \u4E0B\u8F09\u6BCF\u500B\u6A94\u6848\n    for url in target_links:\n        file_name = url.split("/")[-1]  # \u5F9E URL \u4E2D\u63D0\u53D6\u6A94\u540D\n        file_path = os.path.join("downloads", file_name)\n\n        # \u767C\u9001\u8ACB\u6C42\u4E0B\u8F09\n        response = requests.get(url, headers=headers)  # \u540C\u6A23\u6DFB\u52A0 headers\n        if response.status_code == 200:\n            with open(file_path, "wb") as f:\n                f.write(response.content)\n            print(f"\u5DF2\u4E0B\u8F09: {file_name}")\n        else:\n            print(f"\u7121\u6CD5\u4E0B\u8F09: {url}")\nelse:\n    print(f"\u7121\u6CD5\u5B58\u53D6\u7DB2\u9801\uFF0C\u72C0\u614B\u78BC: {response.status_code}")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"\u57F7\u884C\u7A0B\u5F0F",children:"\u57F7\u884C\u7A0B\u5F0F"}),"\n",(0,i.jsx)(n.p,{children:"\u5B8C\u6210\u5F8C\uFF0C\u53EF\u4EE5\u76F4\u63A5\u57F7\u884C\u7A0B\u5F0F\uFF0C\u4E0B\u8F09\u6240\u6709\u7B26\u5408\u76EE\u6A19\u683C\u5F0F\u7684\u6A94\u6848\u3002"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python file_crawler.py\n"})})]})}function c(e={}){let{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},50065:function(e,n,t){t.d(n,{Z:function(){return a},a:function(){return l}});var r=t(67294);let i={},s=r.createContext(i);function l(e){let n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),r.createElement(s.Provider,{value:n},e.children)}},22380:function(e){e.exports=JSON.parse('{"permalink":"/blog/file-crawler-python-implementation","source":"@site/blog/2024/09-23-file-crawler/index.md","title":"\u4E0B\u8F09\u7DB2\u9801\u6A94\u6848\u7684 Python \u5BE6\u4F5C","description":"\u4E00\u500B\u7C21\u55AE\u7684\u7DB2\u9801\u6A94\u6848\u4E0B\u8F09\u7A0B\u5F0F\u3002","date":"2024-09-23T00:00:00.000Z","tags":[{"inline":true,"label":"Python","permalink":"/blog/tags/python"},{"inline":true,"label":"File Crawler","permalink":"/blog/tags/file-crawler"}],"readingTime":2.19,"hasTruncateMarker":true,"authors":[{"name":"Z. Yuan","title":"Dosaid maintainer, Full-Stack AI Engineer","url":"https://github.com/zephyr-sh","socials":{"github":"https://github.com/zephyr-sh","linkedin":"https://www.linkedin.com/in/ze-yuan-sh7/"},"imageURL":"https://github.com/zephyr-sh.png","key":"Z. Yuan","page":null}],"frontMatter":{"slug":"file-crawler-python-implementation","title":"\u4E0B\u8F09\u7DB2\u9801\u6A94\u6848\u7684 Python \u5BE6\u4F5C","authors":"Z. Yuan","image":"/img/2024/0923.webp","tags":["Python","File Crawler"],"description":"\u4E00\u500B\u7C21\u55AE\u7684\u7DB2\u9801\u6A94\u6848\u4E0B\u8F09\u7A0B\u5F0F\u3002"},"unlisted":false,"prevItem":{"title":"\u66F4\u65B0 Docusaurus \u5230 3.6.0","permalink":"/blog/update-docusaurus-to-3-6-0"},"nextItem":{"title":"\u8B93 Docusaurus \u7684 Sidebar \u81EA\u52D5\u8A08\u7B97\u6587\u7AE0\u6578\u91CF","permalink":"/blog/customized-docusaurus-sidebars-auto-count"}}')}}]);